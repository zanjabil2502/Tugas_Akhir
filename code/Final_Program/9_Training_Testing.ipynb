{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772d562f",
   "metadata": {},
   "source": [
    "## Downloading Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8f6614e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-29 01:28:02--  https://zenodo.org/record/3987831/files/ResNet22_mAP%3D0.430.pth\n",
      "SSL_INIT\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
      "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 259135254 (247M) [application/octet-stream]\n",
      "Saving to: ‘ResNet22_mAP=0.430.pth’\n",
      "\n",
      "ResNet22_mAP=0.430. 100%[===================>] 247.13M  2.93MB/s    in 2m 3s   \n",
      "\n",
      "2022-03-29 01:30:07 (2.02 MB/s) - ‘ResNet22_mAP=0.430.pth’ saved [259135254/259135254]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/3987831/files/ResNet22_mAP%3D0.430.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91998164",
   "metadata": {},
   "source": [
    "## Modify JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2e8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25b7ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'result/threshold_detection/90_persen'\n",
    "\n",
    "if os.path.exists(folder)==False:\n",
    "    os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "602478d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'csv_files/threshold_detection/90_persen/data_01'\n",
    "csv_train = os.path.join(folder,'train.csv')\n",
    "csv_devel = os.path.join(folder,'devel.csv')\n",
    "csv_test = os.path.join(folder,'test.csv')\n",
    "\n",
    "dir_input = 'dataset/threshold_detection/90_persen'\n",
    "dir_output = 'result/threshold_detection/90_persen'\n",
    "\n",
    "if os.path.exists(dir_output)==False:\n",
    "    os.mkdir(dir_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3ff3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'script/json/config.json'\n",
    "with open(file_path, 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    data['dataset']['train_csv'] = csv_train\n",
    "    data['dataset']['eval_csv'] = csv_devel\n",
    "    data['dataset']['test_csv'] = csv_test\n",
    "    data['dataset']['train_data_root_path'] = dir_input\n",
    "    data['dataset']['eval_data_root_path'] = dir_input\n",
    "    data['dataset']['test_data_root_path'] = dir_input\n",
    "    data['dataset']['class_balancer_batch'] = True\n",
    "    data['train_config']['logs_path'] = dir_output\n",
    "    \n",
    "    data['model']['spec_aug'] = False\n",
    "    data['data_aumentation']['insert_noise'] = False\n",
    "    data['model']['mixup'] = True\n",
    "    data['model']['mixup_alpha'] = 0.7\n",
    "    \n",
    "    data['model_name'] = 'panns'\n",
    "    data['model']['pretreined_checkpoint'] = 'Cnn14_16k_mAP=0.438.pth'\n",
    "    \n",
    "    data['audio']['feature'] = 'melspectrogram'\n",
    "    data['audio']['num_mels'] = 64\n",
    "    data['audio']['hop_length'] = 320\n",
    "    \n",
    "    data['train_config']['optimizer'] = 'adamw'\n",
    "    data['train_config']['learning_rate'] = 0.001\n",
    "    data['train_config']['weight_decay'] = 0.001\n",
    "    data['train_config']['batch_size'] = 16\n",
    "    \n",
    "    \n",
    "    f.seek(0)        # <--- should reset file position to the beginning.\n",
    "    json.dump(data,f,indent=4)\n",
    "    f.truncate()     # remove remaining part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4877155d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'panns',\n",
       " 'dataset': {'class_balancer_batch': True,\n",
       "  'window_len': 3,\n",
       "  'step': 1,\n",
       "  'padding_with_max_lenght': True,\n",
       "  'temporal_control': 'padding',\n",
       "  'max_seq_len': None,\n",
       "  'train_csv': 'csv_files/threshold_detection/90_persen/data_01/train.csv',\n",
       "  'train_data_root_path': 'dataset/threshold_detection/90_persen',\n",
       "  'eval_csv': 'csv_files/threshold_detection/90_persen/data_01/devel.csv',\n",
       "  'eval_data_root_path': 'dataset/threshold_detection/90_persen',\n",
       "  'test_csv': 'csv_files/threshold_detection/90_persen/data_01/test.csv',\n",
       "  'test_data_root_path': 'dataset/threshold_detection/90_persen',\n",
       "  'control_class': 0,\n",
       "  'patient_class': 1},\n",
       " 'model': {'pretreined_checkpoint': 'Cnn14_16k_mAP=0.438.pth',\n",
       "  'freeze_base': False,\n",
       "  'mixup': True,\n",
       "  'mixup_alpha': 0.7,\n",
       "  'spec_aug': False,\n",
       "  'num_class': 1},\n",
       " 'train_config': {'early_stop_epochs': 0,\n",
       "  'lr_decay': True,\n",
       "  'warmup_steps': 500,\n",
       "  'epochs': 100,\n",
       "  'learning_rate': 0.001,\n",
       "  'weight_decay': 0.001,\n",
       "  'optimizer': 'adamw',\n",
       "  'loss1_weight': 3.0,\n",
       "  'batch_size': 16,\n",
       "  'seed': 42,\n",
       "  'num_workers': 14,\n",
       "  'logs_path': 'result/threshold_detection/90_persen',\n",
       "  'reinit_layers': None,\n",
       "  'summary_interval': 10,\n",
       "  'checkpoint_interval': 500},\n",
       " 'data_aumentation': {'noisetypes': ['noise'],\n",
       "  'musan_path': 'dataset/Musan-Data/',\n",
       "  'insert_noise': False,\n",
       "  'num_noise_control': 4,\n",
       "  'num_noise_patient': 3,\n",
       "  'noise_max_amp': 0.19233719,\n",
       "  'noise_min_amp': 0.033474047},\n",
       " 'test_config': {'batch_size': 10, 'num_workers': 10},\n",
       " 'audio': {'feature': 'melspectrogram',\n",
       "  'sample_rate': 16000,\n",
       "  'normalize': True,\n",
       "  'num_mels': 64,\n",
       "  'mel_fmin': 0.0,\n",
       "  'mel_fmax': None,\n",
       "  'num_mfcc': 40,\n",
       "  'log_mels': False,\n",
       "  'n_fft': 1024,\n",
       "  'num_freq': 513,\n",
       "  'hop_length': 320,\n",
       "  'win_length': 1024}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51816a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This File is CSV for Train, Devel, and Test\n",
      "Train Data: \n",
      "--Compare Train\n",
      "--Coughvid Positive Train\n",
      "--Coswara Positive Train\n",
      "\n",
      "Devel Data: \n",
      "--Compare Devel\n",
      "--Coughvid Positive Devel\n",
      "--Coswara Positive Devel\n",
      "\n",
      "Devel Partision: 20.0%\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(folder,'readme.txt')) as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8396638",
   "metadata": {},
   "source": [
    "## Training 5 Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f85d2071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 108 (+- 2.16 seconds)\n",
      "Using Class Batch Balancer\n",
      "Enable Mixup with alpha: 0.7\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.988673210144043\n",
      "Write summary at step 20  Loss:  0.7619819045066833\n",
      "Write summary at step 30  Loss:  0.7722558975219727\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2722222222222222 Acurracy Control:  0.967741935483871 Acurracy Patient:  0.12751677852348994 Acurracy Balanced 0.5476293570036804\n",
      "Loss normal: 0.741675697432624 Loss Control: 0.6177162085810015 Loss Patient: 0.7674659278568805 Loss balanced:  0.692591068218941 Loss1+loss2: 0.692591068218941\n",
      "\n",
      " > BEST MODEL (0.69259) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 40  Loss:  0.6738421320915222\n",
      "Write summary at step 50  Loss:  0.6856983304023743\n",
      "Write summary at step 60  Loss:  0.8010435104370117\n",
      "Write summary at step 70  Loss:  0.6214013695716858\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7888888888888889 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.7919463087248322 Acurracy Balanced 0.7830699285559645\n",
      "Loss normal: 0.5812410990397135 Loss Control: 0.6722815690502044 Loss Patient: 0.5622997943986983 Loss balanced:  0.6172906817244513 Loss1+loss2: 0.6172906817244513\n",
      "\n",
      " > BEST MODEL (0.61729) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 80  Loss:  0.6273477077484131\n",
      "Write summary at step 90  Loss:  0.542621374130249\n",
      "Write summary at step 100  Loss:  0.6073307394981384\n",
      "Write summary at step 110  Loss:  0.5222196578979492\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7666666666666667 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.7449664429530202 Acurracy Balanced 0.807967092444252\n",
      "Loss normal: 0.4673643496301439 Loss Control: 0.5527742505073547 Loss Patient: 0.44959450088091346 Loss balanced:  0.5011843756941341 Loss1+loss2: 0.5011843756941341\n",
      "\n",
      " > BEST MODEL (0.50118) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 120  Loss:  0.6087040305137634\n",
      "Write summary at step 130  Loss:  0.5412680506706238\n",
      "Write summary at step 140  Loss:  0.5037041306495667\n",
      "Write summary at step 150  Loss:  0.402240514755249\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8944444444444445 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9060402684563759 Acurracy Balanced 0.8723749729378654\n",
      "Loss normal: 0.4532055185900794 Loss Control: 0.5969769570135302 Loss Patient: 0.42329333772595296 Loss balanced:  0.5101351473697415 Loss1+loss2: 0.5101351473697415\n",
      "Write summary at step 160  Loss:  0.4921373128890991\n",
      "Write summary at step 170  Loss:  0.6248142719268799\n",
      "Write summary at step 180  Loss:  0.5849024653434753\n",
      "Write summary at step 190  Loss:  0.7943253517150879\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8777777777777778 Acurracy Control:  0.4838709677419355 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.7218012556830482\n",
      "Loss normal: 0.24886957613958252 Loss Control: 0.9740316944737588 Loss Patient: 0.09799692264739299 Loss balanced:  0.5360143085605759 Loss1+loss2: 0.5360143085605759\n",
      "Write summary at step 200  Loss:  0.2682076692581177\n",
      "Write summary at step 210  Loss:  0.4406256079673767\n",
      "Write summary at step 220  Loss:  0.43924254179000854\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9261744966442953 Acurracy Balanced 0.8985711192898895\n",
      "Loss normal: 0.25929693919089103 Loss Control: 0.39253817162206095 Loss Patient: 0.23157560835348678 Loss balanced:  0.31205688998777387 Loss1+loss2: 0.31205688998777387\n",
      "\n",
      " > BEST MODEL (0.31206) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 230  Loss:  0.41902977228164673\n",
      "Write summary at step 240  Loss:  0.3001236319541931\n",
      "Write summary at step 250  Loss:  0.33224114775657654\n",
      "Write summary at step 260  Loss:  0.39457330107688904\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.967741935483871 Acurracy Patient:  0.9261744966442953 Acurracy Balanced 0.9469582160640831\n",
      "Loss normal: 0.3166931584477425 Loss Control: 0.14123786889737652 Loss Patient: 0.3531972651913662 Loss balanced:  0.24721756704437137 Loss1+loss2: 0.24721756704437137\n",
      "\n",
      " > BEST MODEL (0.24722) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 270  Loss:  0.4213050901889801\n",
      "Write summary at step 280  Loss:  0.30251842737197876\n",
      "Write summary at step 290  Loss:  0.5120807886123657\n",
      "Write summary at step 300  Loss:  0.4676591753959656\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  1.0 Acurracy Patient:  0.8791946308724832 Acurracy Balanced 0.9395973154362416\n",
      "Loss normal: 0.39279532101419234 Loss Control: 0.14099376360254903 Loss Patient: 0.44518356115225977 Loss balanced:  0.2930886623774044 Loss1+loss2: 0.2930886623774044\n",
      "Write summary at step 310  Loss:  0.32001399993896484\n",
      "Write summary at step 320  Loss:  0.2590557932853699\n",
      "Write summary at step 330  Loss:  0.36121994256973267\n",
      "Write summary at step 340  Loss:  0.40281596779823303\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8888888888888888 Acurracy Control:  0.6774193548387096 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.805152630439489\n",
      "Loss normal: 0.24029615976744229 Loss Control: 0.5109196795571235 Loss Patient: 0.1839919281285881 Loss balanced:  0.3474558038428558 Loss1+loss2: 0.3474558038428558\n",
      "Write summary at step 350  Loss:  0.48533907532691956\n",
      "Write summary at step 360  Loss:  0.2957953214645386\n",
      "Write summary at step 370  Loss:  0.5958789587020874\n",
      "Write summary at step 380  Loss:  0.3200961947441101\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8777777777777778 Acurracy Control:  1.0 Acurracy Patient:  0.8523489932885906 Acurracy Balanced 0.9261744966442953\n",
      "Loss normal: 0.8252117104000516 Loss Control: 0.03417349017918754 Loss Patient: 0.9897901099800264 Loss balanced:  0.5119818000796069 Loss1+loss2: 0.5119818000796069\n",
      "Write summary at step 390  Loss:  0.1905590295791626\n",
      "Write summary at step 400  Loss:  0.42173656821250916\n",
      "Write summary at step 410  Loss:  0.45253390073776245\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8722222222222222 Acurracy Control:  0.5161290322580645 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.7312188785451397\n",
      "Loss normal: 0.25514223360353044 Loss Control: 0.881130983752589 Loss Patient: 0.12490296263822773 Loss balanced:  0.5030169731954084 Loss1+loss2: 0.5030169731954084\n",
      "Write summary at step 420  Loss:  0.18551862239837646\n",
      "Write summary at step 430  Loss:  0.4209769070148468\n",
      "Write summary at step 440  Loss:  0.27540454268455505\n",
      "Write summary at step 450  Loss:  0.7426965236663818\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9194630872483222 Acurracy Balanced 0.9113444468499675\n",
      "Loss normal: 0.3160061127506196 Loss Control: 0.2643433514374098 Loss Patient: 0.3267547436083523 Loss balanced:  0.295549047522881 Loss1+loss2: 0.295549047522881\n",
      "Write summary at step 460  Loss:  0.3067321181297302\n",
      "Write summary at step 470  Loss:  0.2993176579475403\n",
      "Write summary at step 480  Loss:  0.35116684436798096\n",
      "Write summary at step 490  Loss:  0.5359079837799072\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.7096774193548387 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8246373673955402\n",
      "Loss normal: 0.3124019059869978 Loss Control: 0.4576820500435368 Loss Patient: 0.2821758361470779 Loss balanced:  0.3699289430953073 Loss1+loss2: 0.3699289430953073\n",
      "Write summary at step 500  Loss:  0.6723043322563171\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.7096774193548387 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8246373673955402\n",
      "Loss normal: 0.3186786777443356 Loss Control: 0.5793148894463817 Loss Patient: 0.26445235742018525 Loss balanced:  0.42188362343328345 Loss1+loss2: 0.42188362343328345\n",
      "Write summary at step 510  Loss:  0.33095136284828186\n",
      "Write summary at step 520  Loss:  0.3970873951911926\n",
      "Write summary at step 530  Loss:  0.41937172412872314\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9388888888888889 Acurracy Control:  0.967741935483871 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.9503139207620697\n",
      "Loss normal: 0.25531998583012155 Loss Control: 0.20946547292893933 Loss Patient: 0.2648601865008373 Loss balanced:  0.23716282971488833 Loss1+loss2: 0.23716282971488833\n",
      "\n",
      " > BEST MODEL (0.23716) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 540  Loss:  0.569812536239624\n",
      "Write summary at step 550  Loss:  0.24061430990695953\n",
      "Write summary at step 560  Loss:  0.6272627115249634\n",
      "Write summary at step 570  Loss:  0.4527474045753479\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.9354838709677419 Acurracy Patient:  0.9261744966442953 Acurracy Balanced 0.9308291838060185\n",
      "Loss normal: 0.37542795373333826 Loss Control: 0.2367705140383013 Loss Patient: 0.4042761457846469 Loss balanced:  0.3205233299114741 Loss1+loss2: 0.3205233299114741\n",
      "Write summary at step 580  Loss:  0.4762214422225952\n",
      "Write summary at step 590  Loss:  0.4921345114707947\n",
      "Write summary at step 600  Loss:  0.44290125370025635\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8333333333333334 Acurracy Control:  0.967741935483871 Acurracy Patient:  0.8053691275167785 Acurracy Balanced 0.8865555315003247\n",
      "Loss normal: 0.4881411996152666 Loss Control: 0.06374210816237234 Loss Patient: 0.5764389942156388 Loss balanced:  0.3200905511890056 Loss1+loss2: 0.3200905511890056\n",
      "Write summary at step 610  Loss:  0.8355733156204224\n",
      "Write summary at step 620  Loss:  0.47197115421295166\n",
      "Write summary at step 630  Loss:  0.5341472625732422\n",
      "Write summary at step 640  Loss:  0.3580591678619385\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8763801688677202\n",
      "Loss normal: 0.25929765328764914 Loss Control: 0.4601561100252213 Loss Patient: 0.21750831313981306 Loss balanced:  0.3388322115825172 Loss1+loss2: 0.3388322115825172\n",
      "Write summary at step 650  Loss:  0.22288253903388977\n",
      "Write summary at step 660  Loss:  0.1380954384803772\n",
      "Write summary at step 670  Loss:  0.5266942977905273\n",
      "Write summary at step 680  Loss:  0.20170241594314575\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9194630872483222 Acurracy Balanced 0.9113444468499675\n",
      "Loss normal: 0.34344354768594104 Loss Control: 0.24778999532422713 Loss Patient: 0.3633446281388302 Loss balanced:  0.3055673117315286 Loss1+loss2: 0.3055673117315286\n",
      "Write summary at step 690  Loss:  0.1461072862148285\n",
      "Write summary at step 700  Loss:  0.2256198674440384\n",
      "Write summary at step 710  Loss:  0.18681415915489197\n",
      "Write summary at step 720  Loss:  0.3699687123298645\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8944444444444445 Acurracy Control:  0.6129032258064516 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.7829616800173198\n",
      "Loss normal: 0.3432955256766743 Loss Control: 0.8937197577568793 Loss Patient: 0.22877773242508806 Loss balanced:  0.5612487450909837 Loss1+loss2: 0.5612487450909837\n",
      "Write summary at step 730  Loss:  0.2839893698692322\n",
      "Write summary at step 740  Loss:  0.668550968170166\n",
      "Write summary at step 750  Loss:  0.6092326641082764\n",
      "Write summary at step 760  Loss:  0.24411898851394653\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9261744966442953 Acurracy Balanced 0.914700151547954\n",
      "Loss normal: 0.3466266651948293 Loss Control: 0.17153628603104623 Loss Patient: 0.3830548700870284 Loss balanced:  0.2772955780590373 Loss1+loss2: 0.2772955780590373\n",
      "Write summary at step 770  Loss:  0.3476063013076782\n",
      "Write summary at step 780  Loss:  0.37621450424194336\n",
      "Write summary at step 790  Loss:  0.3436911106109619\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.9354838709677419 Acurracy Patient:  0.9194630872483222 Acurracy Balanced 0.927473479108032\n",
      "Loss normal: 0.41962373819616106 Loss Control: 0.18076349818898785 Loss Patient: 0.46931947197690105 Loss balanced:  0.32504148508294445 Loss1+loss2: 0.32504148508294445\n",
      "Write summary at step 800  Loss:  0.27870047092437744\n",
      "Write summary at step 810  Loss:  0.4225972890853882\n",
      "Write summary at step 820  Loss:  0.29303568601608276\n",
      "Write summary at step 830  Loss:  0.38775166869163513\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8944444444444445 Acurracy Control:  0.6774193548387096 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8085083351374756\n",
      "Loss normal: 0.22765345084998342 Loss Control: 0.603239563203627 Loss Patient: 0.14951136978280624 Loss balanced:  0.3763754664932166 Loss1+loss2: 0.3763754664932166\n",
      "Write summary at step 840  Loss:  0.3033904433250427\n",
      "Write summary at step 850  Loss:  0.20076006650924683\n",
      "Write summary at step 860  Loss:  0.39960750937461853\n",
      "Write summary at step 870  Loss:  0.3258103132247925\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.8857977917298117\n",
      "Loss normal: 0.2697278575764762 Loss Control: 0.3098148703575134 Loss Patient: 0.2613876021948437 Loss balanced:  0.28560123627617856 Loss1+loss2: 0.28560123627617856\n",
      "Write summary at step 880  Loss:  0.3520714044570923\n",
      "Write summary at step 890  Loss:  0.4869251847267151\n",
      "Write summary at step 900  Loss:  0.445934534072876\n",
      "Write summary at step 910  Loss:  0.37542885541915894\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.9180558562459407\n",
      "Loss normal: 0.31169570022159154 Loss Control: 0.2501742205312175 Loss Patient: 0.32449547236397763 Loss balanced:  0.28733484644759755 Loss1+loss2: 0.28733484644759755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 920  Loss:  0.19212502241134644\n",
      "Write summary at step 930  Loss:  0.251920223236084\n",
      "Write summary at step 940  Loss:  0.21968132257461548\n",
      "Write summary at step 950  Loss:  0.30332106351852417\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.8857977917298117\n",
      "Loss normal: 0.3146513349480099 Loss Control: 0.3141085966940849 Loss Patient: 0.31476424604454295 Loss balanced:  0.31443642136931393 Loss1+loss2: 0.31443642136931393\n",
      "Write summary at step 960  Loss:  0.22066906094551086\n",
      "Write summary at step 970  Loss:  0.41841670870780945\n",
      "Write summary at step 980  Loss:  0.40577688813209534\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8730244641697337\n",
      "Loss normal: 0.284209292795923 Loss Control: 0.374382080570344 Loss Patient: 0.2654485066465083 Loss balanced:  0.3199152936084262 Loss1+loss2: 0.3199152936084262\n",
      "Write summary at step 990  Loss:  0.42186805605888367\n",
      "Write summary at step 1000  Loss:  0.2706604599952698\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.9354838709677419 Acurracy Patient:  0.9261744966442953 Acurracy Balanced 0.9308291838060185\n",
      "Loss normal: 0.2951995872788959 Loss Control: 0.23606800648473925 Loss Patient: 0.30750213493436773 Loss balanced:  0.2717850707095535 Loss1+loss2: 0.2717850707095535\n",
      "Write summary at step 1010  Loss:  0.2726238965988159\n",
      "Write summary at step 1020  Loss:  0.41534754633903503\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.8857977917298117\n",
      "Loss normal: 0.35115779373380873 Loss Control: 0.28909208024701766 Loss Patient: 0.36407080112687695 Loss balanced:  0.3265814406869473 Loss1+loss2: 0.3265814406869473\n",
      "Write summary at step 1030  Loss:  0.6911354064941406\n",
      "Write summary at step 1040  Loss:  0.2724638879299164\n",
      "Write summary at step 1050  Loss:  0.23846827447414398\n",
      "Write summary at step 1060  Loss:  0.3656567335128784\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9194630872483222 Acurracy Balanced 0.9113444468499675\n",
      "Loss normal: 0.36521844764550526 Loss Control: 0.23029339505780128 Loss Patient: 0.39329009928159264 Loss balanced:  0.31179174716969693 Loss1+loss2: 0.31179174716969693\n",
      "Write summary at step 1070  Loss:  0.31713420152664185\n",
      "Write summary at step 1080  Loss:  0.30472779273986816\n",
      "Write summary at step 1090  Loss:  0.24608825147151947\n",
      "Write summary at step 1100  Loss:  0.32775598764419556\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9055555555555556 Acurracy Control:  0.6129032258064516 Acurracy Patient:  0.9664429530201343 Acurracy Balanced 0.789673089413293\n",
      "Loss normal: 0.2748583323425717 Loss Control: 0.7563318821691698 Loss Patient: 0.1746859926505377 Loss balanced:  0.4655089374098538 Loss1+loss2: 0.4655089374098538\n",
      "Write summary at step 1110  Loss:  0.25096946954727173\n",
      "Write summary at step 1120  Loss:  0.2789851129055023\n",
      "Write summary at step 1130  Loss:  0.27138903737068176\n",
      "Write summary at step 1140  Loss:  0.2487795054912567\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.9214115609439273\n",
      "Loss normal: 0.29071089377005893 Loss Control: 0.27761187861042635 Loss Patient: 0.2934361922260899 Loss balanced:  0.2855240354182581 Loss1+loss2: 0.2855240354182581\n",
      "Write summary at step 1150  Loss:  0.6174899935722351\n",
      "Write summary at step 1160  Loss:  0.20048101246356964\n",
      "Write summary at step 1170  Loss:  0.4114343225955963\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8669625460056289\n",
      "Loss normal: 0.25794844362470837 Loss Control: 0.46991096388909126 Loss Patient: 0.21384885167115486 Loss balanced:  0.34187990778012306 Loss1+loss2: 0.34187990778012306\n",
      "Write summary at step 1180  Loss:  0.6850055456161499\n",
      "Write summary at step 1190  Loss:  0.16854120790958405\n",
      "Write summary at step 1200  Loss:  0.3337235450744629\n",
      "Write summary at step 1210  Loss:  0.28432998061180115\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.2378493673271603 Loss Control: 0.40534787601040256 Loss Patient: 0.20300067751199607 Loss balanced:  0.30417427676119935 Loss1+loss2: 0.30417427676119935\n",
      "Write summary at step 1220  Loss:  0.3283081352710724\n",
      "Write summary at step 1230  Loss:  0.30167192220687866\n",
      "Write summary at step 1240  Loss:  0.3290430009365082\n",
      "Write summary at step 1250  Loss:  0.2668339014053345\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.6129032258064516 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.7863173847153063\n",
      "Loss normal: 0.2521107630597221 Loss Control: 0.6953832987816103 Loss Patient: 0.15988627096150546 Loss balanced:  0.42763478487155787 Loss1+loss2: 0.42763478487155787\n",
      "Write summary at step 1260  Loss:  0.3821043074131012\n",
      "Write summary at step 1270  Loss:  0.3676968812942505\n",
      "Write summary at step 1280  Loss:  0.5402491688728333\n",
      "Write summary at step 1290  Loss:  0.3420388698577881\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8602511366096557\n",
      "Loss normal: 0.2739375235305892 Loss Control: 0.41276090183565695 Loss Patient: 0.24505479083765272 Loss balanced:  0.3289078463366548 Loss1+loss2: 0.3289078463366548\n",
      "Write summary at step 1300  Loss:  0.1555761843919754\n",
      "Write summary at step 1310  Loss:  0.33624061942100525\n",
      "Write summary at step 1320  Loss:  0.8694726824760437\n",
      "Write summary at step 1330  Loss:  0.27488231658935547\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8763801688677202\n",
      "Loss normal: 0.2856055663691627 Loss Control: 0.3650957038325648 Loss Patient: 0.2690673506499937 Loss balanced:  0.31708152724127925 Loss1+loss2: 0.31708152724127925\n",
      "Write summary at step 1340  Loss:  0.2403191477060318\n",
      "Write summary at step 1350  Loss:  0.3719015121459961\n",
      "Write summary at step 1360  Loss:  0.41982436180114746\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8797358735657068\n",
      "Loss normal: 0.25181787841849856 Loss Control: 0.3839576590445734 Loss Patient: 0.22432570849489045 Loss balanced:  0.30414168376973194 Loss1+loss2: 0.30414168376973194\n",
      "Write summary at step 1370  Loss:  0.20429155230522156\n",
      "Write summary at step 1380  Loss:  0.21568062901496887\n",
      "Write summary at step 1390  Loss:  0.4113887548446655\n",
      "Write summary at step 1400  Loss:  0.24534642696380615\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9111111111111111 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8441221043515912\n",
      "Loss normal: 0.2740199064215024 Loss Control: 0.4861879271845664 Loss Patient: 0.2298775553303277 Loss balanced:  0.35803274125744705 Loss1+loss2: 0.35803274125744705\n",
      "Write summary at step 1410  Loss:  0.3191447854042053\n",
      "Write summary at step 1420  Loss:  0.07831175625324249\n",
      "Write summary at step 1430  Loss:  0.44955974817276\n",
      "Write summary at step 1440  Loss:  0.500402569770813\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8602511366096557\n",
      "Loss normal: 0.2338977629939715 Loss Control: 0.3394639261307255 Loss Patient: 0.21193434428048613 Loss balanced:  0.27569913520560585 Loss1+loss2: 0.27569913520560585\n",
      "Write summary at step 1450  Loss:  0.29160943627357483\n",
      "Write summary at step 1460  Loss:  0.31885671615600586\n",
      "Write summary at step 1470  Loss:  0.3291260004043579\n",
      "Write summary at step 1480  Loss:  0.3430434465408325\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9111111111111111 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8441221043515912\n",
      "Loss normal: 0.24046488089693918 Loss Control: 0.4299295006259795 Loss Patient: 0.2010460605957364 Loss balanced:  0.31548778061085797 Loss1+loss2: 0.31548778061085797\n",
      "Write summary at step 1490  Loss:  0.5700642466545105\n",
      "Write summary at step 1500  Loss:  0.34648019075393677\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8474778090495778\n",
      "Loss normal: 0.22016457642118137 Loss Control: 0.5741634522714922 Loss Patient: 0.1465138083936384 Loss balanced:  0.3603386303325653 Loss1+loss2: 0.3603386303325653\n",
      "Write summary at step 1510  Loss:  0.12149962782859802\n",
      "Write summary at step 1520  Loss:  0.2798563539981842\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.9086382333838493\n",
      "Loss normal: 0.24509472648302713 Loss Control: 0.30571565416551405 Loss Patient: 0.23248231570992695 Loss balanced:  0.2690989849377205 Loss1+loss2: 0.2690989849377205\n",
      "Write summary at step 1530  Loss:  0.2887631952762604\n",
      "Write summary at step 1540  Loss:  0.07963027060031891\n",
      "Write summary at step 1550  Loss:  0.5979374647140503\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8602511366096557\n",
      "Loss normal: 0.24329911313123173 Loss Control: 0.46230712436860605 Loss Patient: 0.19773368677436906 Loss balanced:  0.33002040557148754 Loss1+loss2: 0.33002040557148754\n",
      "Write summary at step 1560  Loss:  0.21999266743659973\n",
      "Write summary at step 1570  Loss:  0.41580528020858765\n",
      "Write summary at step 1580  Loss:  0.25088346004486084\n",
      "Write summary at step 1590  Loss:  0.34299010038375854\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.9354838709677419 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.9341848885040052\n",
      "Loss normal: 0.22474932339456347 Loss Control: 0.2406008676175148 Loss Patient: 0.2214513569070189 Loss balanced:  0.23102611226226685 Loss1+loss2: 0.23102611226226685\n",
      "\n",
      " > BEST MODEL (0.23103) : result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1600  Loss:  0.29508137702941895\n",
      "Write summary at step 1610  Loss:  0.24747993052005768\n",
      "Write summary at step 1620  Loss:  0.26999151706695557\n",
      "Write summary at step 1630  Loss:  0.4873155951499939\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.9180558562459407\n",
      "Loss normal: 0.27077647546927136 Loss Control: 0.28627227102556535 Loss Patient: 0.2675525082037753 Loss balanced:  0.27691238961467035 Loss1+loss2: 0.27691238961467035\n",
      "Write summary at step 1640  Loss:  0.20256724953651428\n",
      "Write summary at step 1650  Loss:  0.32741230726242065\n",
      "Write summary at step 1660  Loss:  0.21456900238990784\n",
      "Write summary at step 1670  Loss:  0.3963041305541992\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8958649058237713\n",
      "Loss normal: 0.2566420666873455 Loss Control: 0.38551212414618463 Loss Patient: 0.22983017293798844 Loss balanced:  0.30767114854208655 Loss1+loss2: 0.30767114854208655\n",
      "Write summary at step 1680  Loss:  0.1724861115217209\n",
      "Write summary at step 1690  Loss:  0.2204640507698059\n",
      "Write summary at step 1700  Loss:  0.3178858757019043\n",
      "Write summary at step 1710  Loss:  0.44460391998291016\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.6774193548387096 Acurracy Patient:  0.9664429530201343 Acurracy Balanced 0.821931153929422\n",
      "Loss normal: 0.27839672532346516 Loss Control: 0.8764004630427207 Loss Patient: 0.1539798302938474 Loss balanced:  0.515190146668284 Loss1+loss2: 0.515190146668284\n",
      "Write summary at step 1720  Loss:  0.1204795390367508\n",
      "Write summary at step 1730  Loss:  0.38251787424087524\n",
      "Write summary at step 1740  Loss:  0.3408910632133484\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9055555555555556 Acurracy Control:  0.6451612903225806 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8024464169733708\n",
      "Loss normal: 0.26170189049508835 Loss Control: 0.6977524988112911 Loss Patient: 0.17097995825261877 Loss balanced:  0.43436622853195495 Loss1+loss2: 0.43436622853195495\n",
      "Write summary at step 1750  Loss:  0.4364955425262451\n",
      "Write summary at step 1760  Loss:  0.2847822904586792\n",
      "Write summary at step 1770  Loss:  0.5540038347244263\n",
      "Write summary at step 1780  Loss:  0.318574458360672\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8958649058237713\n",
      "Loss normal: 0.2376925143930647 Loss Control: 0.39935962038655437 Loss Patient: 0.2040570894343741 Loss balanced:  0.3017083549104642 Loss1+loss2: 0.3017083549104642\n",
      "Write summary at step 1790  Loss:  0.39090538024902344\n",
      "Write summary at step 1800  Loss:  0.11778474599123001\n",
      "Write summary at step 1810  Loss:  0.3070636987686157\n",
      "Write summary at step 1820  Loss:  0.21512708067893982\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.9086382333838493\n",
      "Loss normal: 0.25903304583496517 Loss Control: 0.3620415570274476 Loss Patient: 0.2376017382480954 Loss balanced:  0.2998216476377715 Loss1+loss2: 0.2998216476377715\n",
      "Write summary at step 1830  Loss:  0.3224339485168457\n",
      "Write summary at step 1840  Loss:  0.35865285992622375\n",
      "Write summary at step 1850  Loss:  0.26425454020500183\n",
      "Write summary at step 1860  Loss:  0.2361525595188141\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8797358735657068\n",
      "Loss normal: 0.2343848421341843 Loss Control: 0.47998526980800016 Loss Patient: 0.18328676537779354 Loss balanced:  0.33163601759289685 Loss1+loss2: 0.33163601759289685\n",
      "Write summary at step 1870  Loss:  0.28511154651641846\n",
      "Write summary at step 1880  Loss:  0.3930319547653198\n",
      "Write summary at step 1890  Loss:  0.34581029415130615\n",
      "Write summary at step 1900  Loss:  0.21423976123332977\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8891534964277983\n",
      "Loss normal: 0.27943643058339757 Loss Control: 0.38246802264644253 Loss Patient: 0.25800033373720693 Loss balanced:  0.32023417819182476 Loss1+loss2: 0.32023417819182476\n",
      "Write summary at step 1910  Loss:  0.14383360743522644\n",
      "Write summary at step 1920  Loss:  0.31965166330337524\n",
      "Write summary at step 1930  Loss:  0.2982233464717865\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.967741935483871 Acurracy Patient:  0.9194630872483222 Acurracy Balanced 0.9436025113660966\n",
      "Loss normal: 0.35903646416134305 Loss Control: 0.16352844767032132 Loss Patient: 0.399712636166771 Loss balanced:  0.28162054191854613 Loss1+loss2: 0.28162054191854613\n",
      "Write summary at step 1940  Loss:  0.2810634672641754\n",
      "Write summary at step 1950  Loss:  0.2767776846885681\n",
      "Write summary at step 1960  Loss:  0.33842170238494873\n",
      "Write summary at step 1970  Loss:  0.178350567817688\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9055555555555556 Acurracy Control:  0.6451612903225806 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8024464169733708\n",
      "Loss normal: 0.2759240680270725 Loss Control: 0.6014260745817616 Loss Patient: 0.20820217004558383 Loss balanced:  0.4048141223136727 Loss1+loss2: 0.4048141223136727\n",
      "Write summary at step 1980  Loss:  0.09424033761024475\n",
      "Write summary at step 1990  Loss:  0.08515770733356476\n",
      "Write summary at step 2000  Loss:  0.19900721311569214\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.9052825286858628\n",
      "Loss normal: 0.28443904485967425 Loss Control: 0.32250004862585374 Loss Patient: 0.27652030383180454 Loss balanced:  0.29951017622882914 Loss1+loss2: 0.29951017622882914\n",
      "Write summary at step 2010  Loss:  0.3613225817680359\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8958649058237713\n",
      "Loss normal: 0.27390616569254134 Loss Control: 0.4287713727643413 Loss Patient: 0.24168588931128482 Loss balanced:  0.3352286310378131 Loss1+loss2: 0.3352286310378131\n",
      "Write summary at step 2020  Loss:  0.40602296590805054\n",
      "Write summary at step 2030  Loss:  0.3757628798484802\n",
      "Write summary at step 2040  Loss:  0.4676167368888855\n",
      "Write summary at step 2050  Loss:  0.504770040512085\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.9052825286858628\n",
      "Loss normal: 0.26358362634976706 Loss Control: 0.2771205200302985 Loss Patient: 0.2607672190506186 Loss balanced:  0.26894386954045857 Loss1+loss2: 0.26894386954045857\n",
      "Write summary at step 2060  Loss:  0.40282779932022095\n",
      "Write summary at step 2070  Loss:  0.26616817712783813\n",
      "Write summary at step 2080  Loss:  0.36822590231895447\n",
      "Write summary at step 2090  Loss:  0.49992918968200684\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.9052825286858628\n",
      "Loss normal: 0.2749610071380933 Loss Control: 0.29775681226484235 Loss Patient: 0.27021825773603964 Loss balanced:  0.283987535000441 Loss1+loss2: 0.283987535000441\n",
      "Write summary at step 2100  Loss:  0.3747468590736389\n",
      "Write summary at step 2110  Loss:  0.23858202993869781\n",
      "Write summary at step 2120  Loss:  0.27186277508735657\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.6451612903225806 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.7990907122753843\n",
      "Loss normal: 0.235740874045425 Loss Control: 0.5415835361326894 Loss Patient: 0.1721091884494628 Loss balanced:  0.3568463622910761 Loss1+loss2: 0.3568463622910761\n",
      "Write summary at step 2130  Loss:  0.16284847259521484\n",
      "Write summary at step 2140  Loss:  0.3548150360584259\n",
      "Write summary at step 2150  Loss:  0.1949322521686554\n",
      "Write summary at step 2160  Loss:  0.4186733663082123\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8925092011257848\n",
      "Loss normal: 0.2183515810718139 Loss Control: 0.4455618973701231 Loss Patient: 0.17107962566934176 Loss balanced:  0.3083207615197324 Loss1+loss2: 0.3083207615197324\n",
      "Write summary at step 2170  Loss:  0.13536706566810608\n",
      "Write summary at step 2180  Loss:  0.20145775377750397\n",
      "Write summary at step 2190  Loss:  0.2612665295600891\n",
      "Write summary at step 2200  Loss:  0.217633455991745\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.22336117029190064 Loss Control: 0.5547979108748897 Loss Patient: 0.1544045233886514 Loss balanced:  0.35460121713177056 Loss1+loss2: 0.35460121713177056\n",
      "Write summary at step 2210  Loss:  0.29075849056243896\n",
      "Write summary at step 2220  Loss:  0.6231900453567505\n",
      "Write summary at step 2230  Loss:  0.2566581964492798\n",
      "Write summary at step 2240  Loss:  0.2620581090450287\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8669625460056289\n",
      "Loss normal: 0.26319567494922214 Loss Control: 0.5986153502618113 Loss Patient: 0.1934103821748055 Loss balanced:  0.39601286621830845 Loss1+loss2: 0.39601286621830845\n",
      "Write summary at step 2250  Loss:  0.2393784523010254\n",
      "Write summary at step 2260  Loss:  0.2321304827928543\n",
      "Write summary at step 2270  Loss:  0.45641428232192993\n",
      "Write summary at step 2280  Loss:  0.31694328784942627\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.8857977917298117\n",
      "Loss normal: 0.24956929120752547 Loss Control: 0.39276719862414944 Loss Patient: 0.21977644438711588 Loss balanced:  0.30627182150563265 Loss1+loss2: 0.30627182150563265\n",
      "Write summary at step 2290  Loss:  0.3834027647972107\n",
      "Write summary at step 2300  Loss:  0.35166770219802856\n",
      "Write summary at step 2310  Loss:  0.5694050788879395\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9388888888888889 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.9247672656419138\n",
      "Loss normal: 0.2916102409362793 Loss Control: 0.31492125315050923 Loss Patient: 0.28676030459820023 Loss balanced:  0.30084077887435473 Loss1+loss2: 0.30084077887435473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 2320  Loss:  0.343784362077713\n",
      "Write summary at step 2330  Loss:  0.3437480926513672\n",
      "Write summary at step 2340  Loss:  0.1864379644393921\n",
      "Write summary at step 2350  Loss:  0.26289188861846924\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8508335137475644\n",
      "Loss normal: 0.24578294240766102 Loss Control: 0.6421990240773847 Loss Patient: 0.163307116535686 Loss balanced:  0.40275307030653534 Loss1+loss2: 0.40275307030653534\n",
      "Write summary at step 2360  Loss:  0.29943859577178955\n",
      "Write summary at step 2370  Loss:  0.27692654728889465\n",
      "Write summary at step 2380  Loss:  0.3230093717575073\n",
      "Write summary at step 2390  Loss:  0.3934566080570221\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8958649058237713\n",
      "Loss normal: 0.27310999168290034 Loss Control: 0.47879308462142944 Loss Patient: 0.23031687656504995 Loss balanced:  0.3545549805932397 Loss1+loss2: 0.3545549805932397\n",
      "Write summary at step 2400  Loss:  0.4327608644962311\n",
      "Write summary at step 2410  Loss:  0.3807923495769501\n",
      "Write summary at step 2420  Loss:  0.2882083058357239\n",
      "Write summary at step 2430  Loss:  0.29193225502967834\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8777777777777778 Acurracy Control:  0.3870967741935484 Acurracy Patient:  0.9798657718120806 Acurracy Balanced 0.6834812730028145\n",
      "Loss normal: 0.3262479015522533 Loss Control: 1.3368303929605792 Loss Patient: 0.11599246947557335 Loss balanced:  0.7264114312180763 Loss1+loss2: 0.7264114312180763\n",
      "Write summary at step 2440  Loss:  0.23852811753749847\n",
      "Write summary at step 2450  Loss:  0.11305943131446838\n",
      "Write summary at step 2460  Loss:  0.1750078797340393\n",
      "Write summary at step 2470  Loss:  0.20001348853111267\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8958649058237713\n",
      "Loss normal: 0.26500196804602943 Loss Control: 0.4166757272135827 Loss Patient: 0.2334456917823561 Loss balanced:  0.3250607094979694 Loss1+loss2: 0.3250607094979694\n",
      "Write summary at step 2480  Loss:  0.24055978655815125\n",
      "Write summary at step 2490  Loss:  0.34105557203292847\n",
      "Write summary at step 2500  Loss:  0.31588447093963623\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8925092011257848\n",
      "Loss normal: 0.22463602961765394 Loss Control: 0.36384210663457073 Loss Patient: 0.19567370024703493 Loss balanced:  0.2797579034408028 Loss1+loss2: 0.2797579034408028\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.9354838709677419 Acurracy Patient:  0.9328859060402684 Acurracy Balanced 0.9341848885040052\n",
      "Loss normal: 0.29970973134040835 Loss Control: 0.20957050015849452 Loss Patient: 0.3184635311165112 Loss balanced:  0.26401701563750285 Loss1+loss2: 0.26401701563750285\n",
      "Write summary at step 2510  Loss:  0.20978915691375732\n",
      "Write summary at step 2520  Loss:  0.3927961587905884\n",
      "Write summary at step 2530  Loss:  0.266853392124176\n",
      "Write summary at step 2540  Loss:  0.1204104870557785\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.23218154907226562 Loss Control: 0.46107211036066853 Loss Patient: 0.18456002849860478 Loss balanced:  0.32281606942963664 Loss1+loss2: 0.32281606942963664\n",
      "Write summary at step 2550  Loss:  0.435674786567688\n",
      "Write summary at step 2560  Loss:  0.2046317607164383\n",
      "Write summary at step 2570  Loss:  0.266926109790802\n",
      "Write summary at step 2580  Loss:  0.16896729171276093\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8797358735657068\n",
      "Loss normal: 0.23631315065754785 Loss Control: 0.48024781673185285 Loss Patient: 0.18556164695112498 Loss balanced:  0.33290473184148894 Loss1+loss2: 0.33290473184148894\n",
      "Write summary at step 2590  Loss:  0.3994409143924713\n",
      "Write summary at step 2600  Loss:  0.18103626370429993\n",
      "Write summary at step 2610  Loss:  0.33446699380874634\n",
      "Write summary at step 2620  Loss:  0.29966941475868225\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8891534964277983\n",
      "Loss normal: 0.23457149039540026 Loss Control: 0.3070199518434463 Loss Patient: 0.21949832276409906 Loss balanced:  0.2632591373037727 Loss1+loss2: 0.2632591373037727\n",
      "Write summary at step 2630  Loss:  0.36158207058906555\n",
      "Write summary at step 2640  Loss:  0.03485408052802086\n",
      "Write summary at step 2650  Loss:  0.41769713163375854\n",
      "Write summary at step 2660  Loss:  0.16040579974651337\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8944444444444445 Acurracy Control:  0.5161290322580645 Acurracy Patient:  0.9731543624161074 Acurracy Balanced 0.744641697337086\n",
      "Loss normal: 0.2598665952682495 Loss Control: 0.9527838153223838 Loss Patient: 0.11570259948704867 Loss balanced:  0.5342432074047162 Loss1+loss2: 0.5342432074047162\n",
      "Write summary at step 2670  Loss:  0.20283639430999756\n",
      "Write summary at step 2680  Loss:  0.25041311979293823\n",
      "Write summary at step 2690  Loss:  0.07721992582082748\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9111111111111111 Acurracy Control:  0.6774193548387096 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8185754492314353\n",
      "Loss normal: 0.2416702869037787 Loss Control: 0.6123771936662735 Loss Patient: 0.16454334897082923 Loss balanced:  0.3884602713185514 Loss1+loss2: 0.3884602713185514\n",
      "Write summary at step 2700  Loss:  0.06868787109851837\n",
      "Write summary at step 2710  Loss:  0.1642598956823349\n",
      "Write summary at step 2720  Loss:  0.33429408073425293\n",
      "Write summary at step 2730  Loss:  0.27548450231552124\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.9086382333838493\n",
      "Loss normal: 0.24955634425083797 Loss Control: 0.3046778373179897 Loss Patient: 0.2380881135495717 Loss balanced:  0.2713829754337807 Loss1+loss2: 0.2713829754337807\n",
      "Write summary at step 2740  Loss:  0.20578539371490479\n",
      "Write summary at step 2750  Loss:  0.28694432973861694\n",
      "Write summary at step 2760  Loss:  0.21935218572616577\n",
      "Write summary at step 2770  Loss:  0.26932990550994873\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.9052825286858628\n",
      "Loss normal: 0.2133112933900621 Loss Control: 0.3571928989502691 Loss Patient: 0.18337619544675687 Loss balanced:  0.270284547198513 Loss1+loss2: 0.270284547198513\n",
      "Write summary at step 2780  Loss:  0.21073280274868011\n",
      "Write summary at step 2790  Loss:  0.33637112379074097\n",
      "Write summary at step 2800  Loss:  0.11642657220363617\n",
      "Write summary at step 2810  Loss:  0.2510567009449005\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9111111111111111 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.8568954319116692\n",
      "Loss normal: 0.2318909347885185 Loss Control: 0.4410672514669357 Loss Patient: 0.18837101917538868 Loss balanced:  0.3147191353211622 Loss1+loss2: 0.3147191353211622\n",
      "Write summary at step 2820  Loss:  0.43977999687194824\n",
      "Write summary at step 2830  Loss:  0.1264352947473526\n",
      "Write summary at step 2840  Loss:  0.42663097381591797\n",
      "Write summary at step 2850  Loss:  0.39924806356430054\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.5806451612903226 Acurracy Patient:  0.9664429530201343 Acurracy Balanced 0.7735440571552284\n",
      "Loss normal: 0.23021544449859196 Loss Control: 0.7064169222308744 Loss Patient: 0.13113997446610623 Loss balanced:  0.4187784483484903 Loss1+loss2: 0.4187784483484903\n",
      "Write summary at step 2860  Loss:  0.22178654372692108\n",
      "Write summary at step 2870  Loss:  0.4520326852798462\n",
      "Write summary at step 2880  Loss:  0.23982946574687958\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8763801688677202\n",
      "Loss normal: 0.25463856872585083 Loss Control: 0.4259897182064672 Loss Patient: 0.21898832597188503 Loss balanced:  0.3224890220891761 Loss1+loss2: 0.3224890220891761\n",
      "Write summary at step 2890  Loss:  0.0739513412117958\n",
      "Write summary at step 2900  Loss:  0.33416569232940674\n",
      "Write summary at step 2910  Loss:  0.15010671317577362\n",
      "Write summary at step 2920  Loss:  0.43387049436569214\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8474778090495778\n",
      "Loss normal: 0.25324035949177215 Loss Control: 0.5407705345461445 Loss Patient: 0.19341863801815365 Loss balanced:  0.3670945862821491 Loss1+loss2: 0.3670945862821491\n",
      "Write summary at step 2930  Loss:  0.23884829878807068\n",
      "Write summary at step 2940  Loss:  0.17076422274112701\n",
      "Write summary at step 2950  Loss:  0.10118527710437775\n",
      "Write summary at step 2960  Loss:  0.30680638551712036\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.9086382333838493\n",
      "Loss normal: 0.23153942690955268 Loss Control: 0.33743737589928413 Loss Patient: 0.20950697892464248 Loss balanced:  0.2734721774119633 Loss1+loss2: 0.2734721774119633\n",
      "Write summary at step 2970  Loss:  0.2107996940612793\n",
      "Write summary at step 2980  Loss:  0.24718409776687622\n",
      "Write summary at step 2990  Loss:  0.13232070207595825\n",
      "Write summary at step 3000  Loss:  0.2568035423755646\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8387096774193549 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8925092011257848\n",
      "Loss normal: 0.24203474819660187 Loss Control: 0.38791459991085914 Loss Patient: 0.2116839041645895 Loss balanced:  0.2997992520377243 Loss1+loss2: 0.2997992520377243\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9333333333333333 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.9086382333838493\n",
      "Loss normal: 0.24473898510138195 Loss Control: 0.3552070644594008 Loss Patient: 0.2217556914227121 Loss balanced:  0.28848137794105644 Loss1+loss2: 0.28848137794105644\n",
      "Write summary at step 3010  Loss:  0.27804213762283325\n",
      "Write summary at step 3020  Loss:  0.33473116159439087\n",
      "Write summary at step 3030  Loss:  0.2601131796836853\n",
      "Write summary at step 3040  Loss:  0.3542710840702057\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.6451612903225806 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.7990907122753843\n",
      "Loss normal: 0.25062702898350026 Loss Control: 0.5169495767162692 Loss Patient: 0.1952176342574542 Loss balanced:  0.3560836054868617 Loss1+loss2: 0.3560836054868617\n",
      "Write summary at step 3050  Loss:  0.1730593740940094\n",
      "Write summary at step 3060  Loss:  0.16150444746017456\n",
      "Write summary at step 3070  Loss:  0.30403006076812744\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8763801688677202\n",
      "Loss normal: 0.2244998186826706 Loss Control: 0.4681737807489211 Loss Patient: 0.1738025466067679 Loss balanced:  0.3209881636778445 Loss1+loss2: 0.3209881636778445\n",
      "Write summary at step 3080  Loss:  0.31921273469924927\n",
      "Write summary at step 3090  Loss:  0.24227368831634521\n",
      "Write summary at step 3100  Loss:  0.3494586944580078\n",
      "Write summary at step 3110  Loss:  0.29952532052993774\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9277777777777778 Acurracy Control:  0.8709677419354839 Acurracy Patient:  0.9395973154362416 Acurracy Balanced 0.9052825286858628\n",
      "Loss normal: 0.2376644532713625 Loss Control: 0.28761927158601824 Loss Patient: 0.22727117932482854 Loss balanced:  0.25744522545542337 Loss1+loss2: 0.25744522545542337\n",
      "Write summary at step 3120  Loss:  0.2638797461986542\n",
      "Write summary at step 3130  Loss:  0.3406730890274048\n",
      "Write summary at step 3140  Loss:  0.24077261984348297\n",
      "Write summary at step 3150  Loss:  0.5587376952171326\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.6774193548387096 Acurracy Patient:  0.9664429530201343 Acurracy Balanced 0.821931153929422\n",
      "Loss normal: 0.24885724691881073 Loss Control: 0.8331943096653107 Loss Patient: 0.1272837608652627 Loss balanced:  0.4802390352652867 Loss1+loss2: 0.4802390352652867\n",
      "Write summary at step 3160  Loss:  0.3656112849712372\n",
      "Write summary at step 3170  Loss:  0.33451345562934875\n",
      "Write summary at step 3180  Loss:  0.11022178083658218\n",
      "Write summary at step 3190  Loss:  0.295431524515152\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.9032258064516129 Acurracy Patient:  0.9261744966442953 Acurracy Balanced 0.914700151547954\n",
      "Loss normal: 0.277315274046527 Loss Control: 0.22605582975572155 Loss Patient: 0.2879799858435688 Loss balanced:  0.2570179077996452 Loss1+loss2: 0.2570179077996452\n",
      "Write summary at step 3200  Loss:  0.318419873714447\n",
      "Write summary at step 3210  Loss:  0.40164995193481445\n",
      "Write summary at step 3220  Loss:  0.14420589804649353\n",
      "Write summary at step 3230  Loss:  0.2563233971595764\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9111111111111111 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8441221043515912\n",
      "Loss normal: 0.23576841263307466 Loss Control: 0.47712469485498243 Loss Patient: 0.18555334640429325 Loss balanced:  0.3313390206296378 Loss1+loss2: 0.3313390206296378\n",
      "Write summary at step 3240  Loss:  0.19716650247573853\n",
      "Write summary at step 3250  Loss:  0.18015553057193756\n",
      "Write summary at step 3260  Loss:  0.15097297728061676\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.2307306904759672 Loss Control: 0.5039505631692948 Loss Patient: 0.1738862854322331 Loss balanced:  0.3389184243007639 Loss1+loss2: 0.3389184243007639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 3270  Loss:  0.1910688281059265\n",
      "Write summary at step 3280  Loss:  0.3020232021808624\n",
      "Write summary at step 3290  Loss:  0.22406670451164246\n",
      "Write summary at step 3300  Loss:  0.17382991313934326\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.8064516129032258 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8763801688677202\n",
      "Loss normal: 0.22338392130202717 Loss Control: 0.364692009264423 Loss Patient: 0.19398426599550567 Loss balanced:  0.27933813762996434 Loss1+loss2: 0.27933813762996434\n",
      "Write summary at step 3310  Loss:  0.36584579944610596\n",
      "Write summary at step 3320  Loss:  0.3986508250236511\n",
      "Write summary at step 3330  Loss:  0.11777383089065552\n",
      "Write summary at step 3340  Loss:  0.2725604176521301\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7096774193548387 Acurracy Patient:  0.959731543624161 Acurracy Balanced 0.8347044814894999\n",
      "Loss normal: 0.22963433116674423 Loss Control: 0.6115073042531167 Loss Patient: 0.15018425671846275 Loss balanced:  0.38084578048578976 Loss1+loss2: 0.38084578048578976\n",
      "Write summary at step 3350  Loss:  0.0866311714053154\n",
      "Write summary at step 3360  Loss:  0.3381783366203308\n",
      "Write summary at step 3370  Loss:  0.4124128222465515\n",
      "Write summary at step 3380  Loss:  0.3057786226272583\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8722222222222222 Acurracy Control:  0.3548387096774194 Acurracy Patient:  0.9798657718120806 Acurracy Balanced 0.66735224074475\n",
      "Loss normal: 0.3236179913083712 Loss Control: 1.4905485491598807 Loss Patient: 0.080833780785535 Loss balanced:  0.7856911649727079 Loss1+loss2: 0.7856911649727079\n",
      "Write summary at step 3390  Loss:  0.12103819102048874\n",
      "Write summary at step 3400  Loss:  0.22682158648967743\n",
      "Write summary at step 3410  Loss:  0.2635972201824188\n",
      "Write summary at step 3420  Loss:  0.24541904032230377\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8474778090495778\n",
      "Loss normal: 0.22837715264823702 Loss Control: 0.5331708654280631 Loss Patient: 0.16496369482686857 Loss balanced:  0.34906728012746585 Loss1+loss2: 0.34906728012746585\n",
      "Write summary at step 3430  Loss:  0.4318447709083557\n",
      "Write summary at step 3440  Loss:  0.2202819287776947\n",
      "Write summary at step 3450  Loss:  0.29602664709091187\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.23707967119084464 Loss Control: 0.3994304345500085 Loss Patient: 0.20330200319322164 Loss balanced:  0.3013662188716151 Loss1+loss2: 0.3013662188716151\n",
      "Write summary at step 3460  Loss:  0.30249089002609253\n",
      "Write summary at step 3470  Loss:  0.1694771945476532\n",
      "Write summary at step 3480  Loss:  0.2868919372558594\n",
      "Write summary at step 3490  Loss:  0.37355464696884155\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.22277231800059477 Loss Control: 0.5091886904931837 Loss Patient: 0.16318232646124475 Loss balanced:  0.33618550847721423 Loss1+loss2: 0.33618550847721423\n",
      "Write summary at step 3500  Loss:  0.1460414081811905\n",
      "Saved checkpoint to: result/threshold_detection/90_persen/42/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8474778090495778\n",
      "Loss normal: 0.21974138584401873 Loss Control: 0.5554014021350492 Loss Patient: 0.1499060836414363 Loss balanced:  0.35265374288824275 Loss1+loss2: 0.35265374288824275\n",
      "Write summary at step 3510  Loss:  0.19067233800888062\n",
      "Write summary at step 3520  Loss:  0.24154561758041382\n",
      "Write summary at step 3530  Loss:  0.27925410866737366\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9 Acurracy Control:  0.5483870967741935 Acurracy Patient:  0.9731543624161074 Acurracy Balanced 0.7607707295951505\n",
      "Loss normal: 0.28675313111808565 Loss Control: 0.9284714383463706 Loss Patient: 0.15324127814113694 Loss balanced:  0.5408563582437538 Loss1+loss2: 0.5408563582437538\n",
      "Write summary at step 3540  Loss:  0.05623536929488182\n",
      "Write summary at step 3550  Loss:  0.21599644422531128\n",
      "Write summary at step 3560  Loss:  0.37502720952033997\n",
      "Write summary at step 3570  Loss:  0.3143830895423889\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9111111111111111 Acurracy Control:  0.7096774193548387 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8313487767915133\n",
      "Loss normal: 0.22826033723023204 Loss Control: 0.5557413831833871 Loss Patient: 0.16012669839714996 Loss balanced:  0.3579340407902685 Loss1+loss2: 0.3579340407902685\n",
      "Write summary at step 3580  Loss:  0.24194838106632233\n",
      "Write summary at step 3590  Loss:  0.1689213514328003\n",
      "Write summary at step 3600  Loss:  0.4249385595321655\n",
      "Write summary at step 3610  Loss:  0.4745079278945923\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9222222222222223 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8636068413076423\n",
      "Loss normal: 0.2156728604601489 Loss Control: 0.4762864247445137 Loss Patient: 0.1614512444142527 Loss balanced:  0.3188688345793832 Loss1+loss2: 0.3188688345793832\n",
      "Write summary at step 3620  Loss:  0.09675650298595428\n",
      "Write summary at step 3630  Loss:  0.3118340075016022\n",
      "Write summary at step 3640  Loss:  0.26130297780036926\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8777777777777778 Acurracy Control:  0.45161290322580644 Acurracy Patient:  0.9664429530201343 Acurracy Balanced 0.7090279281229703\n",
      "Loss normal: 0.272359366570082 Loss Control: 1.1213896505294307 Loss Patient: 0.09571548318802911 Loss balanced:  0.6085525668587299 Loss1+loss2: 0.6085525668587299\n",
      "Write summary at step 3650  Loss:  0.2696036994457245\n",
      "Write summary at step 3660  Loss:  0.3836309313774109\n",
      "Write summary at step 3670  Loss:  0.4612621068954468\n",
      "Write summary at step 3680  Loss:  0.3614019453525543\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7419354838709677 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8474778090495778\n",
      "Loss normal: 0.2220027649568187 Loss Control: 0.6187586861272012 Loss Patient: 0.13945622782179173 Loss balanced:  0.37910745697449644 Loss1+loss2: 0.37910745697449644\n",
      "Write summary at step 3690  Loss:  0.21453621983528137\n",
      "Write summary at step 3700  Loss:  0.25431931018829346\n",
      "Write summary at step 3710  Loss:  0.22211840748786926\n",
      "Write summary at step 3720  Loss:  0.7876775860786438\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9166666666666666 Acurracy Control:  0.7741935483870968 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8602511366096557\n",
      "Loss normal: 0.23613240246971448 Loss Control: 0.4283584087125717 Loss Patient: 0.1961390723118046 Loss balanced:  0.31224874051218815 Loss1+loss2: 0.31224874051218815\n",
      "Write summary at step 3730  Loss:  0.12220089137554169\n",
      "Write summary at step 3740  Loss:  0.1722930371761322\n",
      "Write summary at step 3750  Loss:  0.21048015356063843\n",
      "Write summary at step 3760  Loss:  0.3509511649608612\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9055555555555556 Acurracy Control:  0.7096774193548387 Acurracy Patient:  0.9463087248322147 Acurracy Balanced 0.8279930720935267\n",
      "Loss normal: 0.22138202827837733 Loss Control: 0.5781025886535645 Loss Patient: 0.14716500133876032 Loss balanced:  0.3626337949961624 Loss1+loss2: 0.3626337949961624\n",
      "Write summary at step 3770  Loss:  0.4885949194431305\n",
      "Write summary at step 3780  Loss:  0.22532959282398224\n",
      "Write summary at step 3790  Loss:  0.31883642077445984\n",
      "Write summary at step 3800  Loss:  0.39314132928848267\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9055555555555556 Acurracy Control:  0.6774193548387096 Acurracy Patient:  0.9530201342281879 Acurracy Balanced 0.8152197445334488\n",
      "Loss normal: 0.24790112351377805 Loss Control: 0.644174583496586 Loss Patient: 0.16545497221034644 Loss balanced:  0.4048147778534662 Loss1+loss2: 0.4048147778534662\n",
      "------------------------------\n",
      "SEED: 42 Best Loss: 0.23102611226226685\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "config = file_path\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    command = f\"python script/train.py -c {config} -s {seed}\"\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "471b403c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: 1\n",
      "Not K-Fold Experiment\n",
      "Return Potential: False\n",
      "Loading checkpoint: result/threshold_detection/90_persen/42/panns/best_checkpoint.pt\n",
      "Model Sucessful Load !\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Control Files Classified incorrectly:\n",
      "Num. Files: 1\n",
      "['test_033.wav']\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "----------------------------------------\n",
      "Patient Files Classified incorrectly:\n",
      "Num. Files: 3\n",
      "['test_046.wav' 'test_043.wav' 'test_067.wav']\n",
      "----------------------------------------\n",
      "======== Confusion Matrix ==========\n",
      "Predicted  0.0  1.0  All\n",
      "Target                  \n",
      "0           39    1   40\n",
      "1            3    8   11\n",
      "All         42    9   51\n",
      "Test\n",
      "  Acurracy:  0.9215686274509803 Acurracy Control:  0.975 Acurracy Patient:  0.7272727272727273\n",
      "F1: 0.7999999999999999 UAR: 0.8511363636363636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data = csv_test\n",
    "folder = dir_input\n",
    "experiment_dir = dir_output\n",
    "musan = 'dataset/Musan-Data'\n",
    "command = f\"python script/test_all_seeds.py -t {data} -r {folder} --experiment_dir {experiment_dir}\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3918086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(os.path.join(dir_output,'*/*/*.pt'))\n",
    "\n",
    "for file in files:\n",
    "    filename = file.split('/')[-1]\n",
    "    if filename.split('_')[0] == 'checkpoint':\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128b778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95457d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772d562f",
   "metadata": {},
   "source": [
    "## Downloading Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6614e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-17 02:27:07--  https://zenodo.org/record/3987831/files/Cnn14_16k_mAP%3D0.438.pth\n",
      "SSL_INIT\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
      "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358668570 (342M) [application/octet-stream]\n",
      "Saving to: ‘Cnn14_16k_mAP=0.438.pth’\n",
      "\n",
      "Cnn14_16k_mAP=0.438 100%[===================>] 342.05M  1.22MB/s    in 5m 20s  \n",
      "\n",
      "2021-12-17 02:32:30 (1.07 MB/s) - ‘Cnn14_16k_mAP=0.438.pth’ saved [358668570/358668570]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/3987831/files/Cnn14_16k_mAP%3D0.438.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8396638",
   "metadata": {},
   "source": [
    "## Training 5 Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4f41261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Time dim Lenght is: 1498 (+- 29.96 seconds)\n",
      "The Min Time dim Lenght is: 19 (+- 0.38 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.5929449200630188\n",
      "Write summary at step 20  Loss:  0.6246069669723511\n",
      "Write summary at step 30  Loss:  0.7659214735031128\n",
      "Write summary at step 40  Loss:  0.7620083689689636\n",
      "Write summary at step 50  Loss:  0.7076361775398254\n",
      "Write summary at step 60  Loss:  0.6577913165092468\n",
      "Write summary at step 70  Loss:  0.7049864530563354\n",
      "Write summary at step 80  Loss:  0.6981961131095886\n",
      "Write summary at step 90  Loss:  0.7558374404907227\n",
      "Write summary at step 100  Loss:  0.7307949662208557\n",
      "Write summary at step 110  Loss:  0.6638988256454468\n",
      "Write summary at step 120  Loss:  0.8047611117362976\n",
      "Write summary at step 130  Loss:  0.7490450739860535\n",
      "Write summary at step 140  Loss:  0.6549336910247803\n",
      "Write summary at step 150  Loss:  0.7075457572937012\n",
      "Write summary at step 160  Loss:  0.7346354722976685\n",
      "Write summary at step 170  Loss:  0.6011365056037903\n",
      "Write summary at step 180  Loss:  0.6989613771438599\n",
      "Write summary at step 190  Loss:  0.7152332663536072\n",
      "Write summary at step 200  Loss:  0.7207351922988892\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0 Acurracy Balanced 0.49453551912568305\n",
      "Loss normal: 0.6096299556426672 Loss Control: 0.5355284155392256 Loss Patient: 0.8921420760452747 Loss balanced:  0.7138352457922501 Loss1+loss2: 0.7138352457922501\n",
      "\n",
      " > BEST MODEL (0.71384) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 210  Loss:  0.7082568407058716\n",
      "Write summary at step 220  Loss:  0.6292784214019775\n",
      "Write summary at step 230  Loss:  0.8029174208641052\n",
      "Write summary at step 240  Loss:  0.7376914024353027\n",
      "Write summary at step 250  Loss:  0.7777577042579651\n",
      "Write summary at step 260  Loss:  0.7627014517784119\n",
      "Write summary at step 270  Loss:  0.7180777192115784\n",
      "Write summary at step 280  Loss:  0.5559689998626709\n",
      "Write summary at step 290  Loss:  0.7602242231369019\n",
      "Write summary at step 300  Loss:  0.7564306259155273\n",
      "Write summary at step 310  Loss:  0.7417601943016052\n",
      "Write summary at step 320  Loss:  0.660419225692749\n",
      "Write summary at step 330  Loss:  0.6891682147979736\n",
      "Write summary at step 340  Loss:  0.7200886011123657\n",
      "Write summary at step 350  Loss:  0.8386403322219849\n",
      "Write summary at step 360  Loss:  0.7704527974128723\n",
      "Write summary at step 370  Loss:  1.328430414199829\n",
      "Write summary at step 380  Loss:  0.8343667984008789\n",
      "Write summary at step 390  Loss:  0.6449717283248901\n",
      "Write summary at step 400  Loss:  0.7960653901100159\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7630823992547535 Loss Control: 0.8036893785325556 Loss Patient: 0.6082682746152083 Loss balanced:  0.705978826573882 Loss1+loss2: 0.705978826573882\n",
      "\n",
      " > BEST MODEL (0.70598) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 410  Loss:  0.6814337968826294\n",
      "Write summary at step 420  Loss:  0.7268205285072327\n",
      "Write summary at step 430  Loss:  0.7585379481315613\n",
      "Write summary at step 440  Loss:  0.6956290006637573\n",
      "Write summary at step 450  Loss:  0.7291441559791565\n",
      "Write summary at step 460  Loss:  0.7741777896881104\n",
      "Write summary at step 470  Loss:  0.6615660786628723\n",
      "Write summary at step 480  Loss:  0.7503551840782166\n",
      "Write summary at step 490  Loss:  0.6636223196983337\n",
      "Write summary at step 500  Loss:  0.6760107278823853\n",
      "Saved checkpoint to: result/9/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.19480519480519481 Acurracy Control:  0.01092896174863388 Acurracy Patient:  0.8958333333333334 Acurracy Balanced 0.45338114754098363\n",
      "Loss normal: 1.0202408531011442 Loss Control: 1.178603408440866 Loss Patient: 0.41648363570372265 Loss balanced:  0.7975435220722944 Loss1+loss2: 0.7975435220722944\n",
      "Write summary at step 510  Loss:  0.8194077014923096\n",
      "Write summary at step 520  Loss:  0.8215941190719604\n",
      "Write summary at step 530  Loss:  0.7785888910293579\n",
      "Write summary at step 540  Loss:  0.7485674619674683\n",
      "Write summary at step 550  Loss:  0.658710241317749\n",
      "Write summary at step 560  Loss:  0.7132347822189331\n",
      "Write summary at step 570  Loss:  0.7213745713233948\n",
      "Write summary at step 580  Loss:  0.6155226230621338\n",
      "Write summary at step 590  Loss:  0.7962005138397217\n",
      "Write summary at step 600  Loss:  0.7362821698188782\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6365810723015757 Loss Control: 0.5921189631920695 Loss Patient: 0.8060928471386433 Loss balanced:  0.6991059051653563 Loss1+loss2: 0.6991059051653563\n",
      "\n",
      " > BEST MODEL (0.69911) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 610  Loss:  0.7611990571022034\n",
      "Write summary at step 620  Loss:  0.6785407662391663\n",
      "Write summary at step 630  Loss:  0.7346757650375366\n",
      "Write summary at step 640  Loss:  0.6579900979995728\n",
      "Write summary at step 650  Loss:  0.7832187414169312\n",
      "Write summary at step 660  Loss:  0.7361751198768616\n",
      "Write summary at step 670  Loss:  0.6527031660079956\n",
      "Write summary at step 680  Loss:  0.7271828651428223\n",
      "Write summary at step 690  Loss:  0.735252857208252\n",
      "Write summary at step 700  Loss:  0.6931309103965759\n",
      "Write summary at step 710  Loss:  0.7097433805465698\n",
      "Write summary at step 720  Loss:  0.6479237079620361\n",
      "Write summary at step 730  Loss:  0.7051964998245239\n",
      "Write summary at step 740  Loss:  0.7188763618469238\n",
      "Write summary at step 750  Loss:  0.6704286336898804\n",
      "Write summary at step 760  Loss:  0.7754241228103638\n",
      "Write summary at step 770  Loss:  0.7130542397499084\n",
      "Write summary at step 780  Loss:  0.725176215171814\n",
      "Write summary at step 790  Loss:  0.75008225440979\n",
      "Write summary at step 800  Loss:  0.6702398657798767\n",
      "Write summary at step 810  Loss:  0.7599848508834839\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7400943835576376 Loss Control: 0.7714827080241969 Loss Patient: 0.620426437507073 Loss balanced:  0.695954572765635 Loss1+loss2: 0.695954572765635\n",
      "\n",
      " > BEST MODEL (0.69595) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 820  Loss:  0.7104963064193726\n",
      "Write summary at step 830  Loss:  0.7520749568939209\n",
      "Write summary at step 840  Loss:  0.7034815549850464\n",
      "Write summary at step 850  Loss:  0.7222154140472412\n",
      "Write summary at step 860  Loss:  0.7048741579055786\n",
      "Write summary at step 870  Loss:  0.6484153270721436\n",
      "Write summary at step 880  Loss:  0.6669886708259583\n",
      "Write summary at step 890  Loss:  0.7115028500556946\n",
      "Write summary at step 900  Loss:  0.7432092428207397\n",
      "Write summary at step 910  Loss:  0.7624297142028809\n",
      "Write summary at step 920  Loss:  0.7759212255477905\n",
      "Write summary at step 930  Loss:  0.7056605815887451\n",
      "Write summary at step 940  Loss:  0.7025943994522095\n",
      "Write summary at step 950  Loss:  0.7038237452507019\n",
      "Write summary at step 960  Loss:  0.664068341255188\n",
      "Write summary at step 970  Loss:  0.6886210441589355\n",
      "Write summary at step 980  Loss:  0.6807771921157837\n",
      "Write summary at step 990  Loss:  0.6918268203735352\n",
      "Write summary at step 1000  Loss:  0.6688781976699829\n",
      "Saved checkpoint to: result/9/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6289386994394905 Loss Control: 0.5779550424039038 Loss Patient: 0.8233139080305895 Loss balanced:  0.7006344752172466 Loss1+loss2: 0.7006344752172466\n",
      "Write summary at step 1010  Loss:  0.6650210618972778\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6259517329079765 Loss Control: 0.5723417925704373 Loss Patient: 0.8303396254777908 Loss balanced:  0.701340709024114 Loss1+loss2: 0.701340709024114\n",
      "Write summary at step 1020  Loss:  0.7155251502990723\n",
      "Write summary at step 1030  Loss:  0.7158472537994385\n",
      "Write summary at step 1040  Loss:  0.6869693398475647\n",
      "Write summary at step 1050  Loss:  0.6642435789108276\n",
      "Write summary at step 1060  Loss:  0.6589082479476929\n",
      "Write summary at step 1070  Loss:  0.7421070337295532\n",
      "Write summary at step 1080  Loss:  0.7053841948509216\n",
      "Write summary at step 1090  Loss:  0.5606130957603455\n",
      "Write summary at step 1100  Loss:  0.8086212277412415\n",
      "Write summary at step 1110  Loss:  0.5500494837760925\n",
      "Write summary at step 1120  Loss:  0.750952959060669\n",
      "Write summary at step 1130  Loss:  0.7187749147415161\n",
      "Write summary at step 1140  Loss:  0.6720569729804993\n",
      "Write summary at step 1150  Loss:  0.6884431838989258\n",
      "Write summary at step 1160  Loss:  0.7104222774505615\n",
      "Write summary at step 1170  Loss:  0.6882808208465576\n",
      "Write summary at step 1180  Loss:  0.706273078918457\n",
      "Write summary at step 1190  Loss:  0.819198727607727\n",
      "Write summary at step 1200  Loss:  0.7021538615226746\n",
      "Write summary at step 1210  Loss:  0.6735643148422241\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6512472608904818 Loss Control: 0.619322707744244 Loss Patient: 0.7729596284528574 Loss balanced:  0.6961411680985508 Loss1+loss2: 0.6961411680985508\n",
      "Write summary at step 1220  Loss:  0.7244938611984253\n",
      "Write summary at step 1230  Loss:  0.8214925527572632\n",
      "Write summary at step 1240  Loss:  0.6295514106750488\n",
      "Write summary at step 1250  Loss:  0.6941861510276794\n",
      "Write summary at step 1260  Loss:  0.7594020366668701\n",
      "Write summary at step 1270  Loss:  0.5930140018463135\n",
      "Write summary at step 1280  Loss:  0.7201311588287354\n",
      "Write summary at step 1290  Loss:  0.7376716136932373\n",
      "Write summary at step 1300  Loss:  0.682356595993042\n",
      "Write summary at step 1310  Loss:  0.7435865998268127\n",
      "Write summary at step 1320  Loss:  0.7376298904418945\n",
      "Write summary at step 1330  Loss:  0.6978062987327576\n",
      "Write summary at step 1340  Loss:  0.7116647958755493\n",
      "Write summary at step 1350  Loss:  0.6747326850891113\n",
      "Write summary at step 1360  Loss:  0.6747390031814575\n",
      "Write summary at step 1370  Loss:  0.7072570323944092\n",
      "Write summary at step 1380  Loss:  0.7005647420883179\n",
      "Write summary at step 1390  Loss:  0.6518586277961731\n",
      "Write summary at step 1400  Loss:  0.7395902872085571\n",
      "Write summary at step 1410  Loss:  0.6430859565734863\n",
      "Write summary at step 1420  Loss:  0.7282865047454834\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.5934041524346256 Loss Control: 0.5073498881579749 Loss Patient: 0.9214860064287981 Loss balanced:  0.7144179472933865 Loss1+loss2: 0.7144179472933865\n",
      "Write summary at step 1430  Loss:  0.6604366898536682\n",
      "Write summary at step 1440  Loss:  0.6970300674438477\n",
      "Write summary at step 1450  Loss:  0.6533827781677246\n",
      "Write summary at step 1460  Loss:  0.7036937475204468\n",
      "Write summary at step 1470  Loss:  0.6572144627571106\n",
      "Write summary at step 1480  Loss:  0.7360585927963257\n",
      "Write summary at step 1490  Loss:  0.7052515745162964\n",
      "Write summary at step 1500  Loss:  0.7463467717170715\n",
      "Saved checkpoint to: result/9/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7502076496809592 Loss Control: 0.7878677630033649 Loss Patient: 0.6066284738481045 Loss balanced:  0.6972481184257346 Loss1+loss2: 0.6972481184257346\n",
      "Write summary at step 1510  Loss:  0.6749393939971924\n",
      "Write summary at step 1520  Loss:  0.7045120596885681\n",
      "Write summary at step 1530  Loss:  0.7405112385749817\n",
      "Write summary at step 1540  Loss:  0.7211464047431946\n",
      "Write summary at step 1550  Loss:  0.6813787221908569\n",
      "Write summary at step 1560  Loss:  0.6470159292221069\n",
      "Write summary at step 1570  Loss:  0.7018471956253052\n",
      "Write summary at step 1580  Loss:  0.7393648624420166\n",
      "Write summary at step 1590  Loss:  0.6765162944793701\n",
      "Write summary at step 1600  Loss:  0.7062539458274841\n",
      "Write summary at step 1610  Loss:  0.6884495615959167\n",
      "Write summary at step 1620  Loss:  0.6977049708366394\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6425629627136957 Loss Control: 0.6034290666788653 Loss Patient: 0.7917608991265297 Loss balanced:  0.6975949829026975 Loss1+loss2: 0.6975949829026975\n",
      "Write summary at step 1630  Loss:  0.6894217729568481\n",
      "Write summary at step 1640  Loss:  0.6606553792953491\n",
      "Write summary at step 1650  Loss:  0.7290314435958862\n",
      "Write summary at step 1660  Loss:  0.6819597482681274\n",
      "Write summary at step 1670  Loss:  0.6578361988067627\n",
      "Write summary at step 1680  Loss:  0.6731240153312683\n",
      "Write summary at step 1690  Loss:  0.7512073516845703\n",
      "Write summary at step 1700  Loss:  0.7083538174629211\n",
      "Write summary at step 1710  Loss:  0.7413133382797241\n",
      "Write summary at step 1720  Loss:  0.7081296443939209\n",
      "Write summary at step 1730  Loss:  0.7074960470199585\n",
      "Write summary at step 1740  Loss:  0.6991944313049316\n",
      "Write summary at step 1750  Loss:  0.6928556561470032\n",
      "Write summary at step 1760  Loss:  0.7637114524841309\n",
      "Write summary at step 1770  Loss:  0.8222958445549011\n",
      "Write summary at step 1780  Loss:  0.7552458047866821\n",
      "Write summary at step 1790  Loss:  0.6726342439651489\n",
      "Write summary at step 1800  Loss:  0.7076436281204224\n",
      "Write summary at step 1810  Loss:  0.7266889810562134\n",
      "Write summary at step 1820  Loss:  0.712975263595581\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6651827669762945 Loss Control: 0.6444075003347761 Loss Patient: 0.7443883741895357 Loss balanced:  0.6943979372621559 Loss1+loss2: 0.6943979372621559\n",
      "\n",
      " > BEST MODEL (0.69440) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 1830  Loss:  0.6958494782447815\n",
      "Write summary at step 1840  Loss:  0.7151064872741699\n",
      "Write summary at step 1850  Loss:  0.6795030832290649\n",
      "Write summary at step 1860  Loss:  0.68695068359375\n",
      "Write summary at step 1870  Loss:  0.6705703139305115\n",
      "Write summary at step 1880  Loss:  0.6827088594436646\n",
      "Write summary at step 1890  Loss:  0.7364324331283569\n",
      "Write summary at step 1900  Loss:  0.7167104482650757\n",
      "Write summary at step 1910  Loss:  0.772037923336029\n",
      "Write summary at step 1920  Loss:  0.6964304447174072\n",
      "Write summary at step 1930  Loss:  0.7408981323242188\n",
      "Write summary at step 1940  Loss:  0.6845211982727051\n",
      "Write summary at step 1950  Loss:  0.723429799079895\n",
      "Write summary at step 1960  Loss:  0.7356478571891785\n",
      "Write summary at step 1970  Loss:  0.6813105344772339\n",
      "Write summary at step 1980  Loss:  0.7080860733985901\n",
      "Write summary at step 1990  Loss:  0.6697647571563721\n",
      "Write summary at step 2000  Loss:  0.6904604434967041\n",
      "Saved checkpoint to: result/9/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7239261205062205 Loss Control: 0.7448061821890659 Loss Patient: 0.6443208567798138 Loss balanced:  0.6945635194844398 Loss1+loss2: 0.6945635194844398\n",
      "Write summary at step 2010  Loss:  0.7289886474609375\n",
      "Write summary at step 2020  Loss:  0.7612278461456299\n",
      "Write summary at step 2030  Loss:  0.6785074472427368\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7009364252998715 Loss Control: 0.7063491155541008 Loss Patient: 0.68030059710145 Loss balanced:  0.6933248563277754 Loss1+loss2: 0.6933248563277754\n",
      "\n",
      " > BEST MODEL (0.69332) : result/9/panns/best_checkpoint.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 2040  Loss:  0.6875209212303162\n",
      "Write summary at step 2050  Loss:  0.7437820434570312\n",
      "Write summary at step 2060  Loss:  0.6941022276878357\n",
      "Write summary at step 2070  Loss:  0.7402759790420532\n",
      "Write summary at step 2080  Loss:  0.7329797744750977\n",
      "Write summary at step 2090  Loss:  0.7470666170120239\n",
      "Write summary at step 2100  Loss:  0.6791190505027771\n",
      "Write summary at step 2110  Loss:  0.6842974424362183\n",
      "Write summary at step 2120  Loss:  0.6370128393173218\n",
      "Write summary at step 2130  Loss:  0.5807508230209351\n",
      "Write summary at step 2140  Loss:  0.7498286962509155\n",
      "Write summary at step 2150  Loss:  0.6460657119750977\n",
      "Write summary at step 2160  Loss:  0.6433042287826538\n",
      "Write summary at step 2170  Loss:  0.730085015296936\n",
      "Write summary at step 2180  Loss:  0.6860998868942261\n",
      "Write summary at step 2190  Loss:  0.7204620838165283\n",
      "Write summary at step 2200  Loss:  0.6600162982940674\n",
      "Write summary at step 2210  Loss:  0.6779112815856934\n",
      "Write summary at step 2220  Loss:  0.7003191113471985\n",
      "Write summary at step 2230  Loss:  0.7063360214233398\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0 Acurracy Balanced 0.49453551912568305\n",
      "Loss normal: 0.6897892242386228 Loss Control: 0.6873076512513916 Loss Patient: 0.699250182757775 Loss balanced:  0.6932789170045832 Loss1+loss2: 0.6932789170045832\n",
      "\n",
      " > BEST MODEL (0.69328) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 2240  Loss:  0.5857250094413757\n",
      "Write summary at step 2250  Loss:  0.7679111361503601\n",
      "Write summary at step 2260  Loss:  0.7134801149368286\n",
      "Write summary at step 2270  Loss:  0.6885976791381836\n",
      "Write summary at step 2280  Loss:  0.7336714267730713\n",
      "Write summary at step 2290  Loss:  0.680514931678772\n",
      "Write summary at step 2300  Loss:  0.6714495420455933\n",
      "Write summary at step 2310  Loss:  0.650138258934021\n",
      "Write summary at step 2320  Loss:  0.6321563720703125\n",
      "Write summary at step 2330  Loss:  0.6703648567199707\n",
      "Write summary at step 2340  Loss:  0.8068651556968689\n",
      "Write summary at step 2350  Loss:  0.6865301132202148\n",
      "Write summary at step 2360  Loss:  0.7177203297615051\n",
      "Write summary at step 2370  Loss:  0.7399869561195374\n",
      "Write summary at step 2380  Loss:  0.7025341987609863\n",
      "Write summary at step 2390  Loss:  0.7189688682556152\n",
      "Write summary at step 2400  Loss:  0.6291419267654419\n",
      "Write summary at step 2410  Loss:  0.7443848848342896\n",
      "Write summary at step 2420  Loss:  0.6849300861358643\n",
      "Write summary at step 2430  Loss:  0.7084264755249023\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.00546448087431694 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.4923155737704918\n",
      "Loss normal: 0.7153422280307457 Loss Control: 0.7303784890253036 Loss Patient: 0.6580164805054665 Loss balanced:  0.694197484765385 Loss1+loss2: 0.694197484765385\n",
      "Write summary at step 2440  Loss:  0.7039937973022461\n",
      "Write summary at step 2450  Loss:  0.6736072301864624\n",
      "Write summary at step 2460  Loss:  0.71845543384552\n",
      "Write summary at step 2470  Loss:  0.6592516899108887\n",
      "Write summary at step 2480  Loss:  0.7234767079353333\n",
      "Write summary at step 2490  Loss:  0.6728426814079285\n",
      "Write summary at step 2500  Loss:  0.6472206711769104\n",
      "Saved checkpoint to: result/9/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.00546448087431694 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.4923155737704918\n",
      "Loss normal: 0.6963934761621219 Loss Control: 0.6987248154285827 Loss Patient: 0.687505287428697 Loss balanced:  0.6931150514286398 Loss1+loss2: 0.6931150514286398\n",
      "\n",
      " > BEST MODEL (0.69312) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 2510  Loss:  0.6739475727081299\n",
      "Write summary at step 2520  Loss:  0.653597354888916\n",
      "Write summary at step 2530  Loss:  0.7151558995246887\n",
      "Write summary at step 2540  Loss:  0.696161150932312\n",
      "Write summary at step 2550  Loss:  0.6636068224906921\n",
      "Write summary at step 2560  Loss:  0.7373441457748413\n",
      "Write summary at step 2570  Loss:  0.7499514818191528\n",
      "Write summary at step 2580  Loss:  0.682774007320404\n",
      "Write summary at step 2590  Loss:  0.7314906716346741\n",
      "Write summary at step 2600  Loss:  0.6787772178649902\n",
      "Write summary at step 2610  Loss:  0.6829628348350525\n",
      "Write summary at step 2620  Loss:  0.6830825805664062\n",
      "Write summary at step 2630  Loss:  0.688071608543396\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6665938672049221 Loss Control: 0.6468003665814634 Loss Patient: 0.7420565870900949 Loss balanced:  0.6944284768357791 Loss1+loss2: 0.6944284768357791\n",
      "Write summary at step 2640  Loss:  0.7081410884857178\n",
      "Write summary at step 2650  Loss:  0.7182068824768066\n",
      "Write summary at step 2660  Loss:  0.7014954090118408\n",
      "Write summary at step 2670  Loss:  0.7042419910430908\n",
      "Write summary at step 2680  Loss:  0.696568489074707\n",
      "Write summary at step 2690  Loss:  0.7059354782104492\n",
      "Write summary at step 2700  Loss:  0.7083097696304321\n",
      "Write summary at step 2710  Loss:  0.7799450755119324\n",
      "Write summary at step 2720  Loss:  0.6736271381378174\n",
      "Write summary at step 2730  Loss:  0.7466808557510376\n",
      "Write summary at step 2740  Loss:  0.7456574440002441\n",
      "Write summary at step 2750  Loss:  0.7212870121002197\n",
      "Write summary at step 2760  Loss:  0.6904432773590088\n",
      "Write summary at step 2770  Loss:  0.6865172386169434\n",
      "Write summary at step 2780  Loss:  0.7071987390518188\n",
      "Write summary at step 2790  Loss:  0.7137049436569214\n",
      "Write summary at step 2800  Loss:  0.6619876027107239\n",
      "Write summary at step 2810  Loss:  0.7111519575119019\n",
      "Write summary at step 2820  Loss:  0.7204626798629761\n",
      "Write summary at step 2830  Loss:  0.7089385986328125\n",
      "Write summary at step 2840  Loss:  0.691643238067627\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6190476190476191 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.4521857923497268\n",
      "Loss normal: 0.68844245161329 Loss Control: 0.683808178849559 Loss Patient: 0.7061106078326702 Loss balanced:  0.6949593933411147 Loss1+loss2: 0.6949593933411147\n",
      "Write summary at step 2850  Loss:  0.6770051717758179\n",
      "Write summary at step 2860  Loss:  0.6982706785202026\n",
      "Write summary at step 2870  Loss:  0.6996854543685913\n",
      "Write summary at step 2880  Loss:  0.7203226685523987\n",
      "Write summary at step 2890  Loss:  0.6942092180252075\n",
      "Write summary at step 2900  Loss:  0.7107478976249695\n",
      "Write summary at step 2910  Loss:  0.7420772314071655\n",
      "Write summary at step 2920  Loss:  0.6808409690856934\n",
      "Write summary at step 2930  Loss:  0.7012444734573364\n",
      "Write summary at step 2940  Loss:  0.6858552694320679\n",
      "Write summary at step 2950  Loss:  0.6829922199249268\n",
      "Write summary at step 2960  Loss:  0.7170262932777405\n",
      "Write summary at step 2970  Loss:  0.7317475080490112\n",
      "Write summary at step 2980  Loss:  0.728591799736023\n",
      "Write summary at step 2990  Loss:  0.6906377077102661\n",
      "Write summary at step 3000  Loss:  0.699176549911499\n",
      "Saved checkpoint to: result/9/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6828821051172363 Loss Control: 0.6750868480713641 Loss Patient: 0.7126015623410543 Loss balanced:  0.6938442052062093 Loss1+loss2: 0.6938442052062093\n",
      "Write summary at step 3010  Loss:  0.6976900100708008\n",
      "Write summary at step 3020  Loss:  0.6930292844772339\n",
      "Write summary at step 3030  Loss:  0.700652539730072\n",
      "Write summary at step 3040  Loss:  0.7188407182693481\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.713503788301955 Loss Control: 0.7274762193361918 Loss Patient: 0.6602338949839274 Loss balanced:  0.6938550571600596 Loss1+loss2: 0.6938550571600596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 3050  Loss:  0.6914613246917725\n",
      "Write summary at step 3060  Loss:  0.7794171571731567\n",
      "Write summary at step 3070  Loss:  0.6761952638626099\n",
      "Write summary at step 3080  Loss:  0.7573599219322205\n",
      "Write summary at step 3090  Loss:  0.6440916061401367\n",
      "Write summary at step 3100  Loss:  0.6845000386238098\n",
      "Write summary at step 3110  Loss:  0.7156065702438354\n",
      "Write summary at step 3120  Loss:  0.7221271991729736\n",
      "Write summary at step 3130  Loss:  0.6741180419921875\n",
      "Write summary at step 3140  Loss:  0.6485985517501831\n",
      "Write summary at step 3150  Loss:  0.7340489625930786\n",
      "Write summary at step 3160  Loss:  0.7350951433181763\n",
      "Write summary at step 3170  Loss:  0.6984162926673889\n",
      "Write summary at step 3180  Loss:  0.7187389135360718\n",
      "Write summary at step 3190  Loss:  0.650012731552124\n",
      "Write summary at step 3200  Loss:  0.7033430337905884\n",
      "Write summary at step 3210  Loss:  0.7057037353515625\n",
      "Write summary at step 3220  Loss:  0.6975204944610596\n",
      "Write summary at step 3230  Loss:  0.6953150033950806\n",
      "Write summary at step 3240  Loss:  0.6798840165138245\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21212121212121213 Acurracy Control:  0.00546448087431694 Acurracy Patient:  1.0 Acurracy Balanced 0.5027322404371585\n",
      "Loss normal: 0.6956374712320633 Loss Control: 0.6973185715128164 Loss Patient: 0.6892282788952192 Loss balanced:  0.6932734252040178 Loss1+loss2: 0.6932734252040178\n",
      "Write summary at step 3250  Loss:  0.721877932548523\n",
      "Write summary at step 3260  Loss:  0.6783396005630493\n",
      "Write summary at step 3270  Loss:  0.6691421270370483\n",
      "Write summary at step 3280  Loss:  0.6771636009216309\n",
      "Write summary at step 3290  Loss:  0.6806062459945679\n",
      "Write summary at step 3300  Loss:  0.6989610195159912\n",
      "Write summary at step 3310  Loss:  0.7420780658721924\n",
      "Write summary at step 3320  Loss:  0.7216475009918213\n",
      "Write summary at step 3330  Loss:  0.6895872950553894\n",
      "Write summary at step 3340  Loss:  0.6782206296920776\n",
      "Write summary at step 3350  Loss:  0.7013825178146362\n",
      "Write summary at step 3360  Loss:  0.7166336178779602\n",
      "Write summary at step 3370  Loss:  0.6952552795410156\n",
      "Write summary at step 3380  Loss:  0.682300865650177\n",
      "Write summary at step 3390  Loss:  0.6737302541732788\n",
      "Write summary at step 3400  Loss:  0.7212319374084473\n",
      "Write summary at step 3410  Loss:  0.6864256858825684\n",
      "Write summary at step 3420  Loss:  0.6966440677642822\n",
      "Write summary at step 3430  Loss:  0.693043053150177\n",
      "Write summary at step 3440  Loss:  0.6839039325714111\n",
      "Write summary at step 3450  Loss:  0.649955153465271\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7170635464387539 Loss Control: 0.7333570748079018 Loss Patient: 0.6549444372455279 Loss balanced:  0.6941507560267148 Loss1+loss2: 0.6941507560267148\n",
      "Write summary at step 3460  Loss:  0.6976193785667419\n",
      "Write summary at step 3470  Loss:  0.6686785221099854\n",
      "Write summary at step 3480  Loss:  0.6885051727294922\n",
      "Write summary at step 3490  Loss:  0.6896648406982422\n",
      "Write summary at step 3500  Loss:  0.7006291151046753\n",
      "Saved checkpoint to: result/9/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7272727272727273 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.0625 Acurracy Balanced 0.48206967213114754\n",
      "Loss normal: 0.6774859010399162 Loss Control: 0.6658955656114172 Loss Patient: 0.7216740436851978 Loss balanced:  0.6937848046483075 Loss1+loss2: 0.6937848046483075\n",
      "Write summary at step 3510  Loss:  0.7045422792434692\n",
      "Write summary at step 3520  Loss:  0.6712744832038879\n",
      "Write summary at step 3530  Loss:  0.7015964984893799\n",
      "Write summary at step 3540  Loss:  0.686393141746521\n",
      "Write summary at step 3550  Loss:  0.7050294280052185\n",
      "Write summary at step 3560  Loss:  0.6830241680145264\n",
      "Write summary at step 3570  Loss:  0.6864970922470093\n",
      "Write summary at step 3580  Loss:  0.7122044563293457\n",
      "Write summary at step 3590  Loss:  0.7228082418441772\n",
      "Write summary at step 3600  Loss:  0.6804927587509155\n",
      "Write summary at step 3610  Loss:  0.7045028209686279\n",
      "Write summary at step 3620  Loss:  0.7436949014663696\n",
      "Write summary at step 3630  Loss:  0.7286009788513184\n",
      "Write summary at step 3640  Loss:  0.6702553033828735\n",
      "Write summary at step 3650  Loss:  0.71257483959198\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6692532602842752 Loss Control: 0.6512553167473423 Loss Patient: 0.7378704299529394 Loss balanced:  0.6945628733501408 Loss1+loss2: 0.6945628733501408\n",
      "Write summary at step 3660  Loss:  0.6752141714096069\n",
      "Write summary at step 3670  Loss:  0.6708330512046814\n",
      "Write summary at step 3680  Loss:  0.7086567878723145\n",
      "Write summary at step 3690  Loss:  0.7016853094100952\n",
      "Write summary at step 3700  Loss:  0.6832491755485535\n",
      "Write summary at step 3710  Loss:  0.6923838257789612\n",
      "Write summary at step 3720  Loss:  0.702203631401062\n",
      "Write summary at step 3730  Loss:  0.7151516675949097\n",
      "Write summary at step 3740  Loss:  0.7192186713218689\n",
      "Write summary at step 3750  Loss:  0.663644552230835\n",
      "Write summary at step 3760  Loss:  0.6866745948791504\n",
      "Write summary at step 3770  Loss:  0.7157727479934692\n",
      "Write summary at step 3780  Loss:  0.7095197439193726\n",
      "Write summary at step 3790  Loss:  0.7050056457519531\n",
      "Write summary at step 3800  Loss:  0.7269770503044128\n",
      "Write summary at step 3810  Loss:  0.698271632194519\n",
      "Write summary at step 3820  Loss:  0.6876742839813232\n",
      "Write summary at step 3830  Loss:  0.685226559638977\n",
      "Write summary at step 3840  Loss:  0.6963118314743042\n",
      "Write summary at step 3850  Loss:  0.7186753749847412\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0625 Acurracy Balanced 0.525785519125683\n",
      "Loss normal: 0.675123358443702 Loss Control: 0.6613614822997421 Loss Patient: 0.7275905075172583 Loss balanced:  0.6944759949085002 Loss1+loss2: 0.6944759949085002\n",
      "Write summary at step 3860  Loss:  0.6970714926719666\n",
      "Write summary at step 3870  Loss:  0.6413989663124084\n",
      "Write summary at step 3880  Loss:  0.6726143956184387\n",
      "Write summary at step 3890  Loss:  0.702844500541687\n",
      "Write summary at step 3900  Loss:  0.6736445426940918\n",
      "Write summary at step 3910  Loss:  0.7071649432182312\n",
      "Write summary at step 3920  Loss:  0.6779875159263611\n",
      "Write summary at step 3930  Loss:  0.6491984128952026\n",
      "Write summary at step 3940  Loss:  0.7212538719177246\n",
      "Write summary at step 3950  Loss:  0.6887295842170715\n",
      "Write summary at step 3960  Loss:  0.699042558670044\n",
      "Write summary at step 3970  Loss:  0.6531920433044434\n",
      "Write summary at step 3980  Loss:  0.7472052574157715\n",
      "Write summary at step 3990  Loss:  0.6559315919876099\n",
      "Write summary at step 4000  Loss:  0.7229809761047363\n",
      "Saved checkpoint to: result/9/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6720155534290132 Loss Control: 0.6566477199721206 Loss Patient: 0.7306054246922334 Loss balanced:  0.6936265723321771 Loss1+loss2: 0.6936265723321771\n",
      "Write summary at step 4010  Loss:  0.678568959236145\n",
      "Write summary at step 4020  Loss:  0.6721009612083435\n",
      "Write summary at step 4030  Loss:  0.7179872393608093\n",
      "Write summary at step 4040  Loss:  0.7357397079467773\n",
      "Write summary at step 4050  Loss:  0.6897393465042114\n",
      "Write summary at step 4060  Loss:  0.680814802646637\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6602568231619798 Loss Control: 0.6359039092324471 Loss Patient: 0.7531023273865382 Loss balanced:  0.6945031183094926 Loss1+loss2: 0.6945031183094926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 4070  Loss:  0.704886794090271\n",
      "Write summary at step 4080  Loss:  0.668613851070404\n",
      "Write summary at step 4090  Loss:  0.708976149559021\n",
      "Write summary at step 4100  Loss:  0.6864738464355469\n",
      "Write summary at step 4110  Loss:  0.7003008127212524\n",
      "Write summary at step 4120  Loss:  0.7595632672309875\n",
      "Write summary at step 4130  Loss:  0.7033038139343262\n",
      "Write summary at step 4140  Loss:  0.6661156415939331\n",
      "Write summary at step 4150  Loss:  0.6809544563293457\n",
      "Write summary at step 4160  Loss:  0.8229748010635376\n",
      "Write summary at step 4170  Loss:  0.6893369555473328\n",
      "Write summary at step 4180  Loss:  0.6758913993835449\n",
      "Write summary at step 4190  Loss:  0.6696034669876099\n",
      "Write summary at step 4200  Loss:  0.6766042709350586\n",
      "Write summary at step 4210  Loss:  0.7179999351501465\n",
      "Write summary at step 4220  Loss:  0.6826421022415161\n",
      "Write summary at step 4230  Loss:  0.6825448870658875\n",
      "Write summary at step 4240  Loss:  0.6808449029922485\n",
      "Write summary at step 4250  Loss:  0.6898963451385498\n",
      "Write summary at step 4260  Loss:  0.7055944800376892\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.24242424242424243 Acurracy Control:  0.07650273224043716 Acurracy Patient:  0.875 Acurracy Balanced 0.47575136612021857\n",
      "Loss normal: 0.7080482892143778 Loss Control: 0.7184632713677453 Loss Patient: 0.6683411275347074 Loss balanced:  0.6934021994512264 Loss1+loss2: 0.6934021994512264\n",
      "Write summary at step 4270  Loss:  0.6514214277267456\n",
      "Write summary at step 4280  Loss:  0.6872760057449341\n",
      "Write summary at step 4290  Loss:  0.6914297342300415\n",
      "Write summary at step 4300  Loss:  0.672266960144043\n",
      "Write summary at step 4310  Loss:  0.7065095901489258\n",
      "Write summary at step 4320  Loss:  0.712746262550354\n",
      "Write summary at step 4330  Loss:  0.690773606300354\n",
      "Write summary at step 4340  Loss:  0.6553752422332764\n",
      "Write summary at step 4350  Loss:  0.6991838216781616\n",
      "Write summary at step 4360  Loss:  0.6857364773750305\n",
      "Write summary at step 4370  Loss:  0.7359986305236816\n",
      "Write summary at step 4380  Loss:  0.6915117502212524\n",
      "Write summary at step 4390  Loss:  0.6818282604217529\n",
      "Write summary at step 4400  Loss:  0.6869937777519226\n",
      "Write summary at step 4410  Loss:  0.6937640309333801\n",
      "Write summary at step 4420  Loss:  0.733957827091217\n",
      "Write summary at step 4430  Loss:  0.6797213554382324\n",
      "Write summary at step 4440  Loss:  0.7150523662567139\n",
      "Write summary at step 4450  Loss:  0.641728401184082\n",
      "Write summary at step 4460  Loss:  0.6926717758178711\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7748917748917749 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.5044398907103825\n",
      "Loss normal: 0.6766987040445402 Loss Control: 0.6641791723465007 Loss Patient: 0.7244293751815954 Loss balanced:  0.6943042737640481 Loss1+loss2: 0.6943042737640481\n",
      "Write summary at step 4470  Loss:  0.7200859189033508\n",
      "Write summary at step 4480  Loss:  0.6995795369148254\n",
      "Write summary at step 4490  Loss:  0.7121915817260742\n",
      "Write summary at step 4500  Loss:  0.6826738119125366\n",
      "Saved checkpoint to: result/9/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6600306382426968 Loss Control: 0.6343952225205677 Loss Patient: 0.7577656383315722 Loss balanced:  0.6960804304260699 Loss1+loss2: 0.6960804304260699\n",
      "Write summary at step 4510  Loss:  0.7179110646247864\n",
      "Write summary at step 4520  Loss:  0.7122375965118408\n",
      "Write summary at step 4530  Loss:  0.691740870475769\n",
      "Write summary at step 4540  Loss:  0.683596134185791\n",
      "Write summary at step 4550  Loss:  0.7089046239852905\n",
      "Write summary at step 4560  Loss:  0.6809437274932861\n",
      "Write summary at step 4570  Loss:  0.6738630533218384\n",
      "Write summary at step 4580  Loss:  0.6898263692855835\n",
      "Write summary at step 4590  Loss:  0.6938396692276001\n",
      "Write summary at step 4600  Loss:  0.703837513923645\n",
      "Write summary at step 4610  Loss:  0.6744615435600281\n",
      "Write summary at step 4620  Loss:  0.6968465447425842\n",
      "Write summary at step 4630  Loss:  0.689602255821228\n",
      "Write summary at step 4640  Loss:  0.6916627883911133\n",
      "Write summary at step 4650  Loss:  0.7028056979179382\n",
      "Write summary at step 4660  Loss:  0.6647729873657227\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7170500094756419 Loss Control: 0.733676863498375 Loss Patient: 0.6536602179209391 Loss balanced:  0.693668540709657 Loss1+loss2: 0.693668540709657\n",
      "Write summary at step 4670  Loss:  0.6990658044815063\n",
      "Write summary at step 4680  Loss:  0.6914225816726685\n",
      "Write summary at step 4690  Loss:  0.6730893850326538\n",
      "Write summary at step 4700  Loss:  0.6594062447547913\n",
      "Write summary at step 4710  Loss:  0.7153365015983582\n",
      "Write summary at step 4720  Loss:  0.6824926733970642\n",
      "Write summary at step 4730  Loss:  0.6873095631599426\n",
      "Write summary at step 4740  Loss:  0.7292907238006592\n",
      "Write summary at step 4750  Loss:  0.6965320110321045\n",
      "Write summary at step 4760  Loss:  0.6866714954376221\n",
      "Write summary at step 4770  Loss:  0.715894341468811\n",
      "Write summary at step 4780  Loss:  0.6579857468605042\n",
      "Write summary at step 4790  Loss:  0.763440728187561\n",
      "Write summary at step 4800  Loss:  0.7154912948608398\n",
      "Write summary at step 4810  Loss:  0.6804539561271667\n",
      "Write summary at step 4820  Loss:  0.6892168521881104\n",
      "Write summary at step 4830  Loss:  0.6852135062217712\n",
      "Write summary at step 4840  Loss:  0.6438916921615601\n",
      "Write summary at step 4850  Loss:  0.6843363046646118\n",
      "Write summary at step 4860  Loss:  0.7657053470611572\n",
      "Write summary at step 4870  Loss:  0.6741344928741455\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6685662917244486 Loss Control: 0.6504556934038798 Loss Patient: 0.7376129118104776 Loss balanced:  0.6940343026071787 Loss1+loss2: 0.6940343026071787\n",
      "Write summary at step 4880  Loss:  0.6904585361480713\n",
      "Write summary at step 4890  Loss:  0.6735043525695801\n",
      "Write summary at step 4900  Loss:  0.688872218132019\n",
      "Write summary at step 4910  Loss:  0.6867790818214417\n",
      "Write summary at step 4920  Loss:  0.6696596741676331\n",
      "Write summary at step 4930  Loss:  0.6832164525985718\n",
      "Write summary at step 4940  Loss:  0.6957007646560669\n",
      "Write summary at step 4950  Loss:  0.6918216943740845\n",
      "Write summary at step 4960  Loss:  0.7128820419311523\n",
      "Write summary at step 4970  Loss:  0.7052766680717468\n",
      "Write summary at step 4980  Loss:  0.6891340017318726\n",
      "Write summary at step 4990  Loss:  0.6662179231643677\n",
      "Write summary at step 5000  Loss:  0.6579047441482544\n",
      "Saved checkpoint to: result/9/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6466206544405454 Loss Control: 0.6119007751589916 Loss Patient: 0.7789902103443941 Loss balanced:  0.6954454927516929 Loss1+loss2: 0.6954454927516929\n",
      "Write summary at step 5010  Loss:  0.6885725855827332\n",
      "Write summary at step 5020  Loss:  0.6891580820083618\n",
      "Write summary at step 5030  Loss:  0.691038966178894\n",
      "Write summary at step 5040  Loss:  0.7003974914550781\n",
      "Write summary at step 5050  Loss:  0.7031874656677246\n",
      "Write summary at step 5060  Loss:  0.6683725118637085\n",
      "Write summary at step 5070  Loss:  0.748487114906311\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7174103902531909 Loss Control: 0.7351819898912816 Loss Patient: 0.6496561529735724 Loss balanced:  0.692419071432427 Loss1+loss2: 0.692419071432427\n",
      "\n",
      " > BEST MODEL (0.69242) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 5080  Loss:  0.6744645237922668\n",
      "Write summary at step 5090  Loss:  0.6927315592765808\n",
      "Write summary at step 5100  Loss:  0.7107912302017212\n",
      "Write summary at step 5110  Loss:  0.7787182331085205\n",
      "Write summary at step 5120  Loss:  0.6856095790863037\n",
      "Write summary at step 5130  Loss:  0.6894558668136597\n",
      "Write summary at step 5140  Loss:  0.7279502153396606\n",
      "Write summary at step 5150  Loss:  0.6869338154792786\n",
      "Write summary at step 5160  Loss:  0.707040548324585\n",
      "Write summary at step 5170  Loss:  0.692064642906189\n",
      "Write summary at step 5180  Loss:  0.6950345039367676\n",
      "Write summary at step 5190  Loss:  0.6939716339111328\n",
      "Write summary at step 5200  Loss:  0.6658847332000732\n",
      "Write summary at step 5210  Loss:  0.6574345827102661\n",
      "Write summary at step 5220  Loss:  0.6762022376060486\n",
      "Write summary at step 5230  Loss:  0.696216344833374\n",
      "Write summary at step 5240  Loss:  0.6925915479660034\n",
      "Write summary at step 5250  Loss:  0.6608695983886719\n",
      "Write summary at step 5260  Loss:  0.6875211000442505\n",
      "Write summary at step 5270  Loss:  0.6553253531455994\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6600958052135649 Loss Control: 0.635845361511564 Loss Patient: 0.7525505870580673 Loss balanced:  0.6941979742848157 Loss1+loss2: 0.6941979742848157\n",
      "Write summary at step 5280  Loss:  0.6754832863807678\n",
      "Write summary at step 5290  Loss:  0.7045873403549194\n",
      "Write summary at step 5300  Loss:  0.6856409311294556\n",
      "Write summary at step 5310  Loss:  0.6740273833274841\n",
      "Write summary at step 5320  Loss:  0.7056820392608643\n",
      "Write summary at step 5330  Loss:  0.6950401067733765\n",
      "Write summary at step 5340  Loss:  0.6886449456214905\n",
      "Write summary at step 5350  Loss:  0.6889963150024414\n",
      "Write summary at step 5360  Loss:  0.6930278539657593\n",
      "Write summary at step 5370  Loss:  0.6846967935562134\n",
      "Write summary at step 5380  Loss:  0.7106749415397644\n",
      "Write summary at step 5390  Loss:  0.7287511825561523\n",
      "Write summary at step 5400  Loss:  0.6772704124450684\n",
      "Write summary at step 5410  Loss:  0.6948462724685669\n",
      "Write summary at step 5420  Loss:  0.6912453174591064\n",
      "Write summary at step 5430  Loss:  0.6989753842353821\n",
      "Write summary at step 5440  Loss:  0.6866917014122009\n",
      "Write summary at step 5450  Loss:  0.6784248948097229\n",
      "Write summary at step 5460  Loss:  0.7259732484817505\n",
      "Write summary at step 5470  Loss:  0.6700373888015747\n",
      "Write summary at step 5480  Loss:  0.7246468663215637\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6993783258256459 Loss Control: 0.7049572122553007 Loss Patient: 0.6781088039278984 Loss balanced:  0.6915330080915996 Loss1+loss2: 0.6915330080915996\n",
      "\n",
      " > BEST MODEL (0.69153) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 5490  Loss:  0.7018834352493286\n",
      "Write summary at step 5500  Loss:  0.6925203800201416\n",
      "Saved checkpoint to: result/9/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.5844155844155844 Acurracy Control:  0.6284153005464481 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.5225409836065574\n",
      "Loss normal: 0.6923492414094669 Loss Control: 0.6930188318419326 Loss Patient: 0.6897964837650458 Loss balanced:  0.6914076578034891 Loss1+loss2: 0.6914076578034891\n",
      "\n",
      " > BEST MODEL (0.69141) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 5510  Loss:  0.6888012290000916\n",
      "Write summary at step 5520  Loss:  0.6852688193321228\n",
      "Write summary at step 5530  Loss:  0.6848475933074951\n",
      "Write summary at step 5540  Loss:  0.7195165753364563\n",
      "Write summary at step 5550  Loss:  0.6947559118270874\n",
      "Write summary at step 5560  Loss:  0.7025176882743835\n",
      "Write summary at step 5570  Loss:  0.7616648077964783\n",
      "Write summary at step 5580  Loss:  0.6555284261703491\n",
      "Write summary at step 5590  Loss:  0.7005152702331543\n",
      "Write summary at step 5600  Loss:  0.6871466636657715\n",
      "Write summary at step 5610  Loss:  0.6949034333229065\n",
      "Write summary at step 5620  Loss:  0.6990249156951904\n",
      "Write summary at step 5630  Loss:  0.6827386617660522\n",
      "Write summary at step 5640  Loss:  0.712016224861145\n",
      "Write summary at step 5650  Loss:  0.6901409029960632\n",
      "Write summary at step 5660  Loss:  0.6912422180175781\n",
      "Write summary at step 5670  Loss:  0.6637548804283142\n",
      "Write summary at step 5680  Loss:  0.670188844203949\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6536796536796536 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.25 Acurracy Balanced 0.5047814207650273\n",
      "Loss normal: 0.685976200805598 Loss Control: 0.6817470730328169 Loss Patient: 0.7020997280875841 Loss balanced:  0.6919234005602005 Loss1+loss2: 0.6919234005602005\n",
      "Write summary at step 5690  Loss:  0.6779109835624695\n",
      "Write summary at step 5700  Loss:  0.7327288389205933\n",
      "Write summary at step 5710  Loss:  0.7125155925750732\n",
      "Write summary at step 5720  Loss:  0.6845310926437378\n",
      "Write summary at step 5730  Loss:  0.7284795641899109\n",
      "Write summary at step 5740  Loss:  0.6898430585861206\n",
      "Write summary at step 5750  Loss:  0.7178390026092529\n",
      "Write summary at step 5760  Loss:  0.687188446521759\n",
      "Write summary at step 5770  Loss:  0.698437511920929\n",
      "Write summary at step 5780  Loss:  0.6740766763687134\n",
      "Write summary at step 5790  Loss:  0.6801481246948242\n",
      "Write summary at step 5800  Loss:  0.6825829148292542\n",
      "Write summary at step 5810  Loss:  0.7193219661712646\n",
      "Write summary at step 5820  Loss:  0.6742312908172607\n",
      "Write summary at step 5830  Loss:  0.6849526166915894\n",
      "Write summary at step 5840  Loss:  0.6749496459960938\n",
      "Write summary at step 5850  Loss:  0.688438892364502\n",
      "Write summary at step 5860  Loss:  0.6812776923179626\n",
      "Write summary at step 5870  Loss:  0.6650174856185913\n",
      "Write summary at step 5880  Loss:  0.7127238512039185\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5757575757575758 Acurracy Control:  0.5792349726775956 Acurracy Patient:  0.5625 Acurracy Balanced 0.5708674863387978\n",
      "Loss normal: 0.692866472712843 Loss Control: 0.6948669500689689 Loss Patient: 0.6852396925290426 Loss balanced:  0.6900533212990058 Loss1+loss2: 0.6900533212990058\n",
      "\n",
      " > BEST MODEL (0.69005) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 5890  Loss:  0.7359026670455933\n",
      "Write summary at step 5900  Loss:  0.6549540758132935\n",
      "Write summary at step 5910  Loss:  0.6838721036911011\n",
      "Write summary at step 5920  Loss:  0.7096773982048035\n",
      "Write summary at step 5930  Loss:  0.7140493988990784\n",
      "Write summary at step 5940  Loss:  0.6889815926551819\n",
      "Write summary at step 5950  Loss:  0.7081858515739441\n",
      "Write summary at step 5960  Loss:  0.6814675331115723\n",
      "Write summary at step 5970  Loss:  0.7055150270462036\n",
      "Write summary at step 5980  Loss:  0.7124874591827393\n",
      "Write summary at step 5990  Loss:  0.6567572355270386\n",
      "Write summary at step 6000  Loss:  0.6806812286376953\n",
      "Saved checkpoint to: result/9/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6564215630679936 Loss Control: 0.6306510880345204 Loss Patient: 0.7546715065836906 Loss balanced:  0.6926612973091055 Loss1+loss2: 0.6926612973091055\n",
      "Write summary at step 6010  Loss:  0.6800391674041748\n",
      "Write summary at step 6020  Loss:  0.6743274331092834\n",
      "Write summary at step 6030  Loss:  0.7349830865859985\n",
      "Write summary at step 6040  Loss:  0.6919423341751099\n",
      "Write summary at step 6050  Loss:  0.6694388389587402\n",
      "Write summary at step 6060  Loss:  0.6987379193305969\n",
      "Write summary at step 6070  Loss:  0.6381410956382751\n",
      "Write summary at step 6080  Loss:  0.704277515411377\n",
      "Write summary at step 6090  Loss:  0.6771625280380249\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.5302254098360656\n",
      "Loss normal: 0.6671719143400977 Loss Control: 0.6493463653032897 Loss Patient: 0.7351318821310997 Loss balanced:  0.6922391237171948 Loss1+loss2: 0.6922391237171948\n",
      "Write summary at step 6100  Loss:  0.6877456903457642\n",
      "Write summary at step 6110  Loss:  0.7023237347602844\n",
      "Write summary at step 6120  Loss:  0.6944403648376465\n",
      "Write summary at step 6130  Loss:  0.6944416761398315\n",
      "Write summary at step 6140  Loss:  0.6782037019729614\n",
      "Write summary at step 6150  Loss:  0.7182815074920654\n",
      "Write summary at step 6160  Loss:  0.6781529188156128\n",
      "Write summary at step 6170  Loss:  0.6748065948486328\n",
      "Write summary at step 6180  Loss:  0.688556432723999\n",
      "Write summary at step 6190  Loss:  0.6946247816085815\n",
      "Write summary at step 6200  Loss:  0.7013143301010132\n",
      "Write summary at step 6210  Loss:  0.7046031951904297\n",
      "Write summary at step 6220  Loss:  0.680274248123169\n",
      "Write summary at step 6230  Loss:  0.6655194759368896\n",
      "Write summary at step 6240  Loss:  0.6847549676895142\n",
      "Write summary at step 6250  Loss:  0.6878154873847961\n",
      "Write summary at step 6260  Loss:  0.6592724919319153\n",
      "Write summary at step 6270  Loss:  0.6936402916908264\n",
      "Write summary at step 6280  Loss:  0.6456993818283081\n",
      "Write summary at step 6290  Loss:  0.672147274017334\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.5238095238095238 Acurracy Control:  0.4808743169398907 Acurracy Patient:  0.6875 Acurracy Balanced 0.5841871584699454\n",
      "Loss normal: 0.6952893424343753 Loss Control: 0.6979320596476071 Loss Patient: 0.6852140227953593 Loss balanced:  0.6915730412214831 Loss1+loss2: 0.6915730412214831\n",
      "Write summary at step 6300  Loss:  0.7057272791862488\n",
      "Write summary at step 6310  Loss:  0.6933632493019104\n",
      "Write summary at step 6320  Loss:  0.6706399917602539\n",
      "Write summary at step 6330  Loss:  0.6646817922592163\n",
      "Write summary at step 6340  Loss:  0.6738443374633789\n",
      "Write summary at step 6350  Loss:  0.7167490124702454\n",
      "Write summary at step 6360  Loss:  0.7023831605911255\n",
      "Write summary at step 6370  Loss:  0.7512993812561035\n",
      "Write summary at step 6380  Loss:  0.7297669053077698\n",
      "Write summary at step 6390  Loss:  0.6761560440063477\n",
      "Write summary at step 6400  Loss:  0.711205244064331\n",
      "Write summary at step 6410  Loss:  0.6631324291229248\n",
      "Write summary at step 6420  Loss:  0.7123575806617737\n",
      "Write summary at step 6430  Loss:  0.7681130170822144\n",
      "Write summary at step 6440  Loss:  0.676447331905365\n",
      "Write summary at step 6450  Loss:  0.6559704542160034\n",
      "Write summary at step 6460  Loss:  0.6842365860939026\n",
      "Write summary at step 6470  Loss:  0.697066605091095\n",
      "Write summary at step 6480  Loss:  0.667589545249939\n",
      "Write summary at step 6490  Loss:  0.7337775230407715\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7082582916016187 Loss Control: 0.7187877369057285 Loss Patient: 0.6681147764126459 Loss balanced:  0.6934512566591873 Loss1+loss2: 0.6934512566591873\n",
      "Write summary at step 6500  Loss:  0.6929951906204224\n",
      "Saved checkpoint to: result/9/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.5099043715846995\n",
      "Loss normal: 0.6827115189461481 Loss Control: 0.6752744870759099 Loss Patient: 0.7110652153690656 Loss balanced:  0.6931698512224878 Loss1+loss2: 0.6931698512224878\n",
      "Write summary at step 6510  Loss:  0.7098498344421387\n",
      "Write summary at step 6520  Loss:  0.695060133934021\n",
      "Write summary at step 6530  Loss:  0.7387041449546814\n",
      "Write summary at step 6540  Loss:  0.7041897773742676\n",
      "Write summary at step 6550  Loss:  0.7188754081726074\n",
      "Write summary at step 6560  Loss:  0.667044997215271\n",
      "Write summary at step 6570  Loss:  0.6980310678482056\n",
      "Write summary at step 6580  Loss:  0.7097028493881226\n",
      "Write summary at step 6590  Loss:  0.6979315280914307\n",
      "Write summary at step 6600  Loss:  0.6961984634399414\n",
      "Write summary at step 6610  Loss:  0.7484309673309326\n",
      "Write summary at step 6620  Loss:  0.6836742162704468\n",
      "Write summary at step 6630  Loss:  0.6820640563964844\n",
      "Write summary at step 6640  Loss:  0.6638475656509399\n",
      "Write summary at step 6650  Loss:  0.7321047186851501\n",
      "Write summary at step 6660  Loss:  0.6794004440307617\n",
      "Write summary at step 6670  Loss:  0.6646484136581421\n",
      "Write summary at step 6680  Loss:  0.6975744366645813\n",
      "Write summary at step 6690  Loss:  0.6659823656082153\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.666020393371582 Loss Control: 0.6458969689457794 Loss Patient: 0.7427409763137499 Loss balanced:  0.6943189726297647 Loss1+loss2: 0.6943189726297647\n",
      "Write summary at step 6700  Loss:  0.700727105140686\n",
      "Write summary at step 6710  Loss:  0.6956533193588257\n",
      "Write summary at step 6720  Loss:  0.6873525977134705\n",
      "Write summary at step 6730  Loss:  0.7003418207168579\n",
      "Write summary at step 6740  Loss:  0.6405263543128967\n",
      "Write summary at step 6750  Loss:  0.6805191040039062\n",
      "Write summary at step 6760  Loss:  0.7593975067138672\n",
      "Write summary at step 6770  Loss:  0.7321707010269165\n",
      "Write summary at step 6780  Loss:  0.7183377742767334\n",
      "Write summary at step 6790  Loss:  0.6952848434448242\n",
      "Write summary at step 6800  Loss:  0.6205917596817017\n",
      "Write summary at step 6810  Loss:  0.7332457304000854\n",
      "Write summary at step 6820  Loss:  0.7224672436714172\n",
      "Write summary at step 6830  Loss:  0.6900912523269653\n",
      "Write summary at step 6840  Loss:  0.6871213912963867\n",
      "Write summary at step 6850  Loss:  0.6710793972015381\n",
      "Write summary at step 6860  Loss:  0.6985651254653931\n",
      "Write summary at step 6870  Loss:  0.6869802474975586\n",
      "Write summary at step 6880  Loss:  0.6983968019485474\n",
      "Write summary at step 6890  Loss:  0.6877466440200806\n",
      "Write summary at step 6900  Loss:  0.7312856912612915\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6958434106983664 Loss Control: 0.6977531909942627 Loss Patient: 0.6885623273750147 Loss balanced:  0.6931577591846387 Loss1+loss2: 0.6931577591846387\n",
      "Write summary at step 6910  Loss:  0.6754364967346191\n",
      "Write summary at step 6920  Loss:  0.693499743938446\n",
      "Write summary at step 6930  Loss:  0.7211419343948364\n",
      "Write summary at step 6940  Loss:  0.6757477521896362\n",
      "Write summary at step 6950  Loss:  0.671916663646698\n",
      "Write summary at step 6960  Loss:  0.6928131580352783\n",
      "Write summary at step 6970  Loss:  0.705102801322937\n",
      "Write summary at step 6980  Loss:  0.700393557548523\n",
      "Write summary at step 6990  Loss:  0.7052962779998779\n",
      "Write summary at step 7000  Loss:  0.7155302166938782\n",
      "Saved checkpoint to: result/9/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.748910231249673 Loss Control: 0.785770489544165 Loss Patient: 0.6083803835014502 Loss balanced:  0.6970754365228076 Loss1+loss2: 0.6970754365228076\n",
      "Write summary at step 7010  Loss:  0.7156433463096619\n",
      "Write summary at step 7020  Loss:  0.6904569864273071\n",
      "Write summary at step 7030  Loss:  0.6880034804344177\n",
      "Write summary at step 7040  Loss:  0.7272449731826782\n",
      "Write summary at step 7050  Loss:  0.7252573370933533\n",
      "Write summary at step 7060  Loss:  0.6665125489234924\n",
      "Write summary at step 7070  Loss:  0.6444748640060425\n",
      "Write summary at step 7080  Loss:  0.6763079166412354\n",
      "Write summary at step 7090  Loss:  0.6792711019515991\n",
      "Write summary at step 7100  Loss:  0.6876348257064819\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7147552716783631 Loss Control: 0.7296635502023123 Loss Patient: 0.6579174337287744 Loss balanced:  0.6937904919655433 Loss1+loss2: 0.6937904919655433\n",
      "Write summary at step 7110  Loss:  0.7006689310073853\n",
      "Write summary at step 7120  Loss:  0.7128698229789734\n",
      "Write summary at step 7130  Loss:  0.7134829759597778\n",
      "Write summary at step 7140  Loss:  0.7197688221931458\n",
      "Write summary at step 7150  Loss:  0.693237841129303\n",
      "Write summary at step 7160  Loss:  0.6734052300453186\n",
      "Write summary at step 7170  Loss:  0.7117969989776611\n",
      "Write summary at step 7180  Loss:  0.7202455997467041\n",
      "Write summary at step 7190  Loss:  0.6971820592880249\n",
      "Write summary at step 7200  Loss:  0.7084149122238159\n",
      "Write summary at step 7210  Loss:  0.6759463548660278\n",
      "Write summary at step 7220  Loss:  0.6701749563217163\n",
      "Write summary at step 7230  Loss:  0.6888584494590759\n",
      "Write summary at step 7240  Loss:  0.7054315805435181\n",
      "Write summary at step 7250  Loss:  0.6772180795669556\n",
      "Write summary at step 7260  Loss:  0.7239460945129395\n",
      "Write summary at step 7270  Loss:  0.6994050145149231\n",
      "Write summary at step 7280  Loss:  0.7246965765953064\n",
      "Write summary at step 7290  Loss:  0.702050507068634\n",
      "Write summary at step 7300  Loss:  0.6744797825813293\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7236432670514821 Loss Control: 0.744439423735676 Loss Patient: 0.6443579855064551 Loss balanced:  0.6943987046210656 Loss1+loss2: 0.6943987046210656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 7310  Loss:  0.674425482749939\n",
      "Write summary at step 7320  Loss:  0.7561224699020386\n",
      "Write summary at step 7330  Loss:  0.6239455938339233\n",
      "Write summary at step 7340  Loss:  0.6983199715614319\n",
      "Write summary at step 7350  Loss:  0.7212019562721252\n",
      "Write summary at step 7360  Loss:  0.7251808643341064\n",
      "Write summary at step 7370  Loss:  0.6964471340179443\n",
      "Write summary at step 7380  Loss:  0.7188153266906738\n",
      "Write summary at step 7390  Loss:  0.6995093822479248\n",
      "Write summary at step 7400  Loss:  0.7103774547576904\n",
      "Write summary at step 7410  Loss:  0.7191421985626221\n",
      "Write summary at step 7420  Loss:  0.6866610050201416\n",
      "Write summary at step 7430  Loss:  0.7028415203094482\n",
      "Write summary at step 7440  Loss:  0.7037451267242432\n",
      "Write summary at step 7450  Loss:  0.6766696572303772\n",
      "Write summary at step 7460  Loss:  0.7011796236038208\n",
      "Write summary at step 7470  Loss:  0.7166316509246826\n",
      "Write summary at step 7480  Loss:  0.8078152537345886\n",
      "Write summary at step 7490  Loss:  0.6959314942359924\n",
      "Write summary at step 7500  Loss:  0.674070417881012\n",
      "Saved checkpoint to: result/9/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6681637518849723 Loss Control: 0.649537663967883 Loss Patient: 0.7391757443547249 Loss balanced:  0.6943567041613039 Loss1+loss2: 0.6943567041613039\n",
      "Write summary at step 7510  Loss:  0.7034696340560913\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6766378128683412 Loss Control: 0.6643757810358142 Loss Patient: 0.7233868092298508 Loss balanced:  0.6938812951328325 Loss1+loss2: 0.6938812951328325\n",
      "Write summary at step 7520  Loss:  0.6592096090316772\n",
      "Write summary at step 7530  Loss:  0.6886934041976929\n",
      "Write summary at step 7540  Loss:  0.7390841245651245\n",
      "Write summary at step 7550  Loss:  0.7006844282150269\n",
      "Write summary at step 7560  Loss:  0.6709022521972656\n",
      "Write summary at step 7570  Loss:  0.7123851180076599\n",
      "Write summary at step 7580  Loss:  0.6895731687545776\n",
      "Write summary at step 7590  Loss:  0.7210364937782288\n",
      "Write summary at step 7600  Loss:  0.7190189361572266\n",
      "Write summary at step 7610  Loss:  0.7154067754745483\n",
      "Write summary at step 7620  Loss:  0.7019647359848022\n",
      "Write summary at step 7630  Loss:  0.6687502861022949\n",
      "Write summary at step 7640  Loss:  0.7131167054176331\n",
      "Write summary at step 7650  Loss:  0.7028279304504395\n",
      "Write summary at step 7660  Loss:  0.6846423745155334\n",
      "Write summary at step 7670  Loss:  0.7231492400169373\n",
      "Write summary at step 7680  Loss:  0.6951939463615417\n",
      "Write summary at step 7690  Loss:  0.682675838470459\n",
      "Write summary at step 7700  Loss:  0.7037851810455322\n",
      "Write summary at step 7710  Loss:  0.7375752329826355\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.707257549226026 Loss Control: 0.7168312590630328 Loss Patient: 0.6707577494283518 Loss balanced:  0.6937945042456923 Loss1+loss2: 0.6937945042456923\n",
      "Write summary at step 7720  Loss:  0.7197998762130737\n",
      "Write summary at step 7730  Loss:  0.6955267190933228\n",
      "Write summary at step 7740  Loss:  0.67180335521698\n",
      "Write summary at step 7750  Loss:  0.7117149829864502\n",
      "Write summary at step 7760  Loss:  0.708859920501709\n",
      "Write summary at step 7770  Loss:  0.6958373785018921\n",
      "Write summary at step 7780  Loss:  0.6909894943237305\n",
      "Write summary at step 7790  Loss:  0.7010936737060547\n",
      "Write summary at step 7800  Loss:  0.7037217020988464\n",
      "Write summary at step 7810  Loss:  0.6953577995300293\n",
      "Write summary at step 7820  Loss:  0.6906436681747437\n",
      "Write summary at step 7830  Loss:  0.706752359867096\n",
      "Write summary at step 7840  Loss:  0.707228422164917\n",
      "Write summary at step 7850  Loss:  0.7012951970100403\n",
      "Write summary at step 7860  Loss:  0.6832305192947388\n",
      "Write summary at step 7870  Loss:  0.6835409998893738\n",
      "Write summary at step 7880  Loss:  0.7047679424285889\n",
      "Write summary at step 7890  Loss:  0.7017643451690674\n",
      "Write summary at step 7900  Loss:  0.6855249404907227\n",
      "Write summary at step 7910  Loss:  0.6740889549255371\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6363636363636364 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5322745901639344\n",
      "Loss normal: 0.6926414515032913 Loss Control: 0.6924782284621984 Loss Patient: 0.693263745556275 Loss balanced:  0.6928709870092367 Loss1+loss2: 0.6928709870092367\n",
      "Write summary at step 7920  Loss:  0.69024258852005\n",
      "Write summary at step 7930  Loss:  0.6907632946968079\n",
      "Write summary at step 7940  Loss:  0.6657959818840027\n",
      "Write summary at step 7950  Loss:  0.6949645280838013\n",
      "Write summary at step 7960  Loss:  0.6923904418945312\n",
      "Write summary at step 7970  Loss:  0.6596018075942993\n",
      "Write summary at step 7980  Loss:  0.6807132959365845\n",
      "Write summary at step 7990  Loss:  0.7009131908416748\n",
      "Write summary at step 8000  Loss:  0.6970890760421753\n",
      "Saved checkpoint to: result/9/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  1.0 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5104166666666666\n",
      "Loss normal: 0.6861479452678135 Loss Control: 0.68131198974255 Loss Patient: 0.7045850629607836 Loss balanced:  0.6929485263516668 Loss1+loss2: 0.6929485263516668\n",
      "Write summary at step 8010  Loss:  0.6915711164474487\n",
      "Write summary at step 8020  Loss:  0.7021921873092651\n",
      "Write summary at step 8030  Loss:  0.6664071083068848\n",
      "Write summary at step 8040  Loss:  0.7005534172058105\n",
      "Write summary at step 8050  Loss:  0.7216406464576721\n",
      "Write summary at step 8060  Loss:  0.7037054300308228\n",
      "Write summary at step 8070  Loss:  0.6727567911148071\n",
      "Write summary at step 8080  Loss:  0.7069397568702698\n",
      "Write summary at step 8090  Loss:  0.6898354291915894\n",
      "Write summary at step 8100  Loss:  0.6793684363365173\n",
      "Write summary at step 8110  Loss:  0.6850174069404602\n",
      "Write summary at step 8120  Loss:  0.6957639455795288\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7099540759990741 Loss Control: 0.7219184396045456 Loss Patient: 0.6643399571379026 Loss balanced:  0.6931291983712241 Loss1+loss2: 0.6931291983712241\n",
      "Write summary at step 8130  Loss:  0.6886390447616577\n",
      "Write summary at step 8140  Loss:  0.7029744982719421\n",
      "Write summary at step 8150  Loss:  0.7018802762031555\n",
      "Write summary at step 8160  Loss:  0.7017320394515991\n",
      "Write summary at step 8170  Loss:  0.6868626475334167\n",
      "Write summary at step 8180  Loss:  0.6844826340675354\n",
      "Write summary at step 8190  Loss:  0.6619877815246582\n",
      "Write summary at step 8200  Loss:  0.6995118856430054\n",
      "Write summary at step 8210  Loss:  0.6902848482131958\n",
      "Write summary at step 8220  Loss:  0.7141457200050354\n",
      "Write summary at step 8230  Loss:  0.6947909593582153\n",
      "Write summary at step 8240  Loss:  0.68483966588974\n",
      "Write summary at step 8250  Loss:  0.6811323165893555\n",
      "Write summary at step 8260  Loss:  0.6772968769073486\n",
      "Write summary at step 8270  Loss:  0.7065722942352295\n",
      "Write summary at step 8280  Loss:  0.6929292678833008\n",
      "Write summary at step 8290  Loss:  0.7297409772872925\n",
      "Write summary at step 8300  Loss:  0.6949923038482666\n",
      "Write summary at step 8310  Loss:  0.6832270622253418\n",
      "Write summary at step 8320  Loss:  0.7035993933677673\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7001821427118211 Loss Control: 0.7055809093954785 Loss Patient: 0.679599329829216 Loss balanced:  0.6925901196123472 Loss1+loss2: 0.6925901196123472\n",
      "Write summary at step 8330  Loss:  0.7074354887008667\n",
      "Write summary at step 8340  Loss:  0.7020443081855774\n",
      "Write summary at step 8350  Loss:  0.7132514715194702\n",
      "Write summary at step 8360  Loss:  0.6944645643234253\n",
      "Write summary at step 8370  Loss:  0.6944116353988647\n",
      "Write summary at step 8380  Loss:  0.6956647634506226\n",
      "Write summary at step 8390  Loss:  0.6915313005447388\n",
      "Write summary at step 8400  Loss:  0.6900187730789185\n",
      "Write summary at step 8410  Loss:  0.6911720037460327\n",
      "Write summary at step 8420  Loss:  0.7035572528839111\n",
      "Write summary at step 8430  Loss:  0.6909459829330444\n",
      "Write summary at step 8440  Loss:  0.6909637451171875\n",
      "Write summary at step 8450  Loss:  0.685079038143158\n",
      "Write summary at step 8460  Loss:  0.6889779567718506\n",
      "Write summary at step 8470  Loss:  0.7498164176940918\n",
      "Write summary at step 8480  Loss:  0.6796311140060425\n",
      "Write summary at step 8490  Loss:  0.6791083216667175\n",
      "Write summary at step 8500  Loss:  0.7162522077560425\n",
      "Saved checkpoint to: result/9/panns/checkpoint_8500.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.38961038961038963 Acurracy Control:  0.33879781420765026 Acurracy Patient:  0.5833333333333334 Acurracy Balanced 0.46106557377049184\n",
      "Loss normal: 0.696106594620329 Loss Control: 0.6985204073249317 Loss Patient: 0.6869039113322893 Loss balanced:  0.6927121593286105 Loss1+loss2: 0.6927121593286105\n",
      "Write summary at step 8510  Loss:  0.72889643907547\n",
      "Write summary at step 8520  Loss:  0.6683945655822754\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5281385281385281 Acurracy Control:  0.5300546448087432 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.5254439890710383\n",
      "Loss normal: 0.6924685113357775 Loss Control: 0.6924228905980053 Loss Patient: 0.6926424702008566 Loss balanced:  0.6925326803994309 Loss1+loss2: 0.6925326803994309\n",
      "Write summary at step 8530  Loss:  0.6879233121871948\n",
      "Write summary at step 8540  Loss:  0.6876084208488464\n",
      "Write summary at step 8550  Loss:  0.6917423009872437\n",
      "Write summary at step 8560  Loss:  0.70957350730896\n",
      "Write summary at step 8570  Loss:  0.7081156969070435\n",
      "Write summary at step 8580  Loss:  0.6954269409179688\n",
      "Write summary at step 8590  Loss:  0.706179141998291\n",
      "Write summary at step 8600  Loss:  0.6964160203933716\n",
      "Write summary at step 8610  Loss:  0.6829688549041748\n",
      "Write summary at step 8620  Loss:  0.663232147693634\n",
      "Write summary at step 8630  Loss:  0.6591319441795349\n",
      "Write summary at step 8640  Loss:  0.7013183236122131\n",
      "Write summary at step 8650  Loss:  0.6705053448677063\n",
      "Write summary at step 8660  Loss:  0.6906185150146484\n",
      "Write summary at step 8670  Loss:  0.6966346502304077\n",
      "Write summary at step 8680  Loss:  0.6585255861282349\n",
      "Write summary at step 8690  Loss:  0.7251297235488892\n",
      "Write summary at step 8700  Loss:  0.7390017509460449\n",
      "Write summary at step 8710  Loss:  0.7252739667892456\n",
      "Write summary at step 8720  Loss:  0.6874035596847534\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7049420318562231 Loss Control: 0.7136158259188543 Loss Patient: 0.6718731882671515 Loss balanced:  0.692744507093003 Loss1+loss2: 0.692744507093003\n",
      "Write summary at step 8730  Loss:  0.7113478183746338\n",
      "Write summary at step 8740  Loss:  0.7366607189178467\n",
      "Write summary at step 8750  Loss:  0.7027224898338318\n",
      "Write summary at step 8760  Loss:  0.7018183469772339\n",
      "Write summary at step 8770  Loss:  0.6962181925773621\n",
      "Write summary at step 8780  Loss:  0.6862306594848633\n",
      "Write summary at step 8790  Loss:  0.6775628328323364\n",
      "Write summary at step 8800  Loss:  0.7164403200149536\n",
      "Write summary at step 8810  Loss:  0.7056488394737244\n",
      "Write summary at step 8820  Loss:  0.7273070812225342\n",
      "Write summary at step 8830  Loss:  0.6835172176361084\n",
      "Write summary at step 8840  Loss:  0.697466254234314\n",
      "Write summary at step 8850  Loss:  0.6951137781143188\n",
      "Write summary at step 8860  Loss:  0.6952393054962158\n",
      "Write summary at step 8870  Loss:  0.6999276876449585\n",
      "Write summary at step 8880  Loss:  0.6707487106323242\n",
      "Write summary at step 8890  Loss:  0.6892741918563843\n",
      "Write summary at step 8900  Loss:  0.691948652267456\n",
      "Write summary at step 8910  Loss:  0.6738380193710327\n",
      "Write summary at step 8920  Loss:  0.7301005125045776\n",
      "Write summary at step 8930  Loss:  0.696094274520874\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.341991341991342 Acurracy Control:  0.22404371584699453 Acurracy Patient:  0.7916666666666666 Acurracy Balanced 0.5078551912568305\n",
      "Loss normal: 0.693985195903035 Loss Control: 0.694643703314776 Loss Patient: 0.691474632670482 Loss balanced:  0.693059167992629 Loss1+loss2: 0.693059167992629\n",
      "Write summary at step 8940  Loss:  0.6625908017158508\n",
      "Write summary at step 8950  Loss:  0.7119014263153076\n",
      "Write summary at step 8960  Loss:  0.6909422278404236\n",
      "Write summary at step 8970  Loss:  0.6984139680862427\n",
      "Write summary at step 8980  Loss:  0.7256484031677246\n",
      "Write summary at step 8990  Loss:  0.6817670464515686\n",
      "Write summary at step 9000  Loss:  0.7007961869239807\n",
      "Saved checkpoint to: result/9/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7071383303894109 Loss Control: 0.7170501100561006 Loss Patient: 0.6693497175971667 Loss balanced:  0.6931999138266336 Loss1+loss2: 0.6931999138266336\n",
      "Write summary at step 9010  Loss:  0.6939560174942017\n",
      "Write summary at step 9020  Loss:  0.6943917274475098\n",
      "Write summary at step 9030  Loss:  0.6775782108306885\n",
      "Write summary at step 9040  Loss:  0.7001504302024841\n",
      "Write summary at step 9050  Loss:  0.7047675251960754\n",
      "Write summary at step 9060  Loss:  0.7021125555038452\n",
      "Write summary at step 9070  Loss:  0.6966580152511597\n",
      "Write summary at step 9080  Loss:  0.6928344964981079\n",
      "Write summary at step 9090  Loss:  0.6880881786346436\n",
      "Write summary at step 9100  Loss:  0.692873477935791\n",
      "Write summary at step 9110  Loss:  0.6903958320617676\n",
      "Write summary at step 9120  Loss:  0.6808586120605469\n",
      "Write summary at step 9130  Loss:  0.6839798092842102\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6856395682215175 Loss Control: 0.6803804994280872 Loss Patient: 0.7056897319853306 Loss balanced:  0.693035115706709 Loss1+loss2: 0.693035115706709\n",
      "Write summary at step 9140  Loss:  0.6814574003219604\n",
      "Write summary at step 9150  Loss:  0.6880989670753479\n",
      "Write summary at step 9160  Loss:  0.6964685916900635\n",
      "Write summary at step 9170  Loss:  0.698205828666687\n",
      "Write summary at step 9180  Loss:  0.7019064426422119\n",
      "Write summary at step 9190  Loss:  0.6984628438949585\n",
      "Write summary at step 9200  Loss:  0.7071619629859924\n",
      "Write summary at step 9210  Loss:  0.7017850279808044\n",
      "Write summary at step 9220  Loss:  0.697856068611145\n",
      "Write summary at step 9230  Loss:  0.6856285929679871\n",
      "Write summary at step 9240  Loss:  0.6989508867263794\n",
      "Write summary at step 9250  Loss:  0.686011791229248\n",
      "Write summary at step 9260  Loss:  0.6808757781982422\n",
      "Write summary at step 9270  Loss:  0.715843677520752\n",
      "Write summary at step 9280  Loss:  0.7090047597885132\n",
      "Write summary at step 9290  Loss:  0.7026199102401733\n",
      "Write summary at step 9300  Loss:  0.6868225932121277\n",
      "Write summary at step 9310  Loss:  0.6845240592956543\n",
      "Write summary at step 9320  Loss:  0.6942453384399414\n",
      "Write summary at step 9330  Loss:  0.6775354146957397\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5670995670995671 Acurracy Control:  0.6338797814207651 Acurracy Patient:  0.3125 Acurracy Balanced 0.47318989071038253\n",
      "Loss normal: 0.6918616359368032 Loss Control: 0.6911745934538502 Loss Patient: 0.6944808984796206 Loss balanced:  0.6928277459667354 Loss1+loss2: 0.6928277459667354\n",
      "Write summary at step 9340  Loss:  0.6737577319145203\n",
      "Write summary at step 9350  Loss:  0.7018095254898071\n",
      "Write summary at step 9360  Loss:  0.6943830251693726\n",
      "Write summary at step 9370  Loss:  0.6764211654663086\n",
      "Write summary at step 9380  Loss:  0.6924582719802856\n",
      "Write summary at step 9390  Loss:  0.6833651065826416\n",
      "Write summary at step 9400  Loss:  0.6903782486915588\n",
      "Write summary at step 9410  Loss:  0.6808226108551025\n",
      "Write summary at step 9420  Loss:  0.6986950635910034\n",
      "Write summary at step 9430  Loss:  0.6910663843154907\n",
      "Write summary at step 9440  Loss:  0.6735239624977112\n",
      "Write summary at step 9450  Loss:  0.6852256059646606\n",
      "Write summary at step 9460  Loss:  0.6889235377311707\n",
      "Write summary at step 9470  Loss:  0.7051981687545776\n",
      "Write summary at step 9480  Loss:  0.6887801289558411\n",
      "Write summary at step 9490  Loss:  0.6977677345275879\n",
      "Write summary at step 9500  Loss:  0.6783879995346069\n",
      "Saved checkpoint to: result/9/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.37662337662337664 Acurracy Control:  0.2677595628415301 Acurracy Patient:  0.7916666666666666 Acurracy Balanced 0.5297131147540983\n",
      "Loss normal: 0.6970373763666524 Loss Control: 0.699966716636074 Loss Patient: 0.6858692976335684 Loss balanced:  0.6929180071348212 Loss1+loss2: 0.6929180071348212\n",
      "Write summary at step 9510  Loss:  0.719510555267334\n",
      "Write summary at step 9520  Loss:  0.7048096060752869\n",
      "Write summary at step 9530  Loss:  0.7049431204795837\n",
      "Write summary at step 9540  Loss:  0.6899696588516235\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4199134199134199 Acurracy Control:  0.34972677595628415 Acurracy Patient:  0.6875 Acurracy Balanced 0.518613387978142\n",
      "Loss normal: 0.6950225479159005 Loss Control: 0.6964308681383811 Loss Patient: 0.6896532836059729 Loss balanced:  0.6930420758721769 Loss1+loss2: 0.6930420758721769\n",
      "Write summary at step 9550  Loss:  0.6785545349121094\n",
      "Write summary at step 9560  Loss:  0.7043200731277466\n",
      "Write summary at step 9570  Loss:  0.6840822696685791\n",
      "Write summary at step 9580  Loss:  0.7140437364578247\n",
      "Write summary at step 9590  Loss:  0.6977912187576294\n",
      "Write summary at step 9600  Loss:  0.6856751441955566\n",
      "Write summary at step 9610  Loss:  0.7021327018737793\n",
      "Write summary at step 9620  Loss:  0.6848239302635193\n",
      "Write summary at step 9630  Loss:  0.6975790858268738\n",
      "Write summary at step 9640  Loss:  0.694277822971344\n",
      "Write summary at step 9650  Loss:  0.6957801580429077\n",
      "Write summary at step 9660  Loss:  0.6913987398147583\n",
      "Write summary at step 9670  Loss:  0.6981608867645264\n",
      "Write summary at step 9680  Loss:  0.6917961835861206\n",
      "Write summary at step 9690  Loss:  0.716870129108429\n",
      "Write summary at step 9700  Loss:  0.698897659778595\n",
      "Write summary at step 9710  Loss:  0.6992313861846924\n",
      "Write summary at step 9720  Loss:  0.707770586013794\n",
      "Write summary at step 9730  Loss:  0.6936845779418945\n",
      "Write summary at step 9740  Loss:  0.6773138046264648\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.125 Acurracy Balanced 0.5488387978142076\n",
      "Loss normal: 0.6821575345415057 Loss Control: 0.6753325038920335 Loss Patient: 0.7081779912114143 Loss balanced:  0.6917552475517239 Loss1+loss2: 0.6917552475517239\n",
      "Write summary at step 9750  Loss:  0.6815733909606934\n",
      "Write summary at step 9760  Loss:  0.7001261711120605\n",
      "Write summary at step 9770  Loss:  0.6906808614730835\n",
      "Write summary at step 9780  Loss:  0.714400589466095\n",
      "Write summary at step 9790  Loss:  0.6819729804992676\n",
      "Write summary at step 9800  Loss:  0.6823082566261292\n",
      "Write summary at step 9810  Loss:  0.731687068939209\n",
      "Write summary at step 9820  Loss:  0.6872589588165283\n",
      "Write summary at step 9830  Loss:  0.6997995376586914\n",
      "Write summary at step 9840  Loss:  0.6968989968299866\n",
      "Write summary at step 9850  Loss:  0.6820552945137024\n",
      "Write summary at step 9860  Loss:  0.7127966284751892\n",
      "Write summary at step 9870  Loss:  0.6806159019470215\n",
      "Write summary at step 9880  Loss:  0.698323130607605\n",
      "Write summary at step 9890  Loss:  0.6948535442352295\n",
      "Write summary at step 9900  Loss:  0.6860929727554321\n",
      "Write summary at step 9910  Loss:  0.6599332094192505\n",
      "Write summary at step 9920  Loss:  0.7033368349075317\n",
      "Write summary at step 9930  Loss:  0.6923008561134338\n",
      "Write summary at step 9940  Loss:  0.6606374979019165\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.716292506688601 Loss Control: 0.7335960871534921 Loss Patient: 0.650322649627924 Loss balanced:  0.691959368390708 Loss1+loss2: 0.691959368390708\n",
      "Write summary at step 9950  Loss:  0.7016681432723999\n",
      "Write summary at step 9960  Loss:  0.6517269611358643\n",
      "Write summary at step 9970  Loss:  0.7220656871795654\n",
      "Write summary at step 9980  Loss:  0.6893928050994873\n",
      "Write summary at step 9990  Loss:  0.7005388736724854\n",
      "Write summary at step 10000  Loss:  0.6654960513114929\n",
      "Saved checkpoint to: result/9/panns/checkpoint_10000.pt\n",
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.601775956284153\n",
      "Loss normal: 0.6909358039562836 Loss Control: 0.6906226739857366 Loss Patient: 0.6921296082437038 Loss balanced:  0.6913761411147202 Loss1+loss2: 0.6913761411147202\n",
      "Write summary at step 10010  Loss:  0.672527551651001\n",
      "Write summary at step 10020  Loss:  0.6910877227783203\n",
      "Write summary at step 10030  Loss:  0.683681070804596\n",
      "Write summary at step 10040  Loss:  0.6681747436523438\n",
      "Write summary at step 10050  Loss:  0.6807024478912354\n",
      "Write summary at step 10060  Loss:  0.6254535913467407\n",
      "Write summary at step 10070  Loss:  0.7024061679840088\n",
      "Write summary at step 10080  Loss:  0.680066704750061\n",
      "Write summary at step 10090  Loss:  0.6305276155471802\n",
      "Write summary at step 10100  Loss:  0.6879831552505493\n",
      "Write summary at step 10110  Loss:  0.7049494981765747\n",
      "Write summary at step 10120  Loss:  0.6882754564285278\n",
      "Write summary at step 10130  Loss:  0.7145752906799316\n",
      "Write summary at step 10140  Loss:  0.6568219661712646\n",
      "Write summary at step 10150  Loss:  0.6698733568191528\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.46320346320346323 Acurracy Control:  0.3879781420765027 Acurracy Patient:  0.75 Acurracy Balanced 0.5689890710382514\n",
      "Loss normal: 0.6967745420736667 Loss Control: 0.6999338252948282 Loss Patient: 0.6847298058370749 Loss balanced:  0.6923318155659515 Loss1+loss2: 0.6923318155659515\n",
      "Write summary at step 10160  Loss:  0.7159551978111267\n",
      "Write summary at step 10170  Loss:  0.6815532445907593\n",
      "Write summary at step 10180  Loss:  0.7354060411453247\n",
      "Write summary at step 10190  Loss:  0.676506519317627\n",
      "Write summary at step 10200  Loss:  0.6838436126708984\n",
      "Write summary at step 10210  Loss:  0.6846299171447754\n",
      "Write summary at step 10220  Loss:  0.6785512566566467\n",
      "Write summary at step 10230  Loss:  0.696704626083374\n",
      "Write summary at step 10240  Loss:  0.7070251107215881\n",
      "Write summary at step 10250  Loss:  0.6876647472381592\n",
      "Write summary at step 10260  Loss:  0.6738569736480713\n",
      "Write summary at step 10270  Loss:  0.682306170463562\n",
      "Write summary at step 10280  Loss:  0.6869336366653442\n",
      "Write summary at step 10290  Loss:  0.7097859978675842\n",
      "Write summary at step 10300  Loss:  0.688693642616272\n",
      "Write summary at step 10310  Loss:  0.7129560112953186\n",
      "Write summary at step 10320  Loss:  0.6974408626556396\n",
      "Write summary at step 10330  Loss:  0.7100321650505066\n",
      "Write summary at step 10340  Loss:  0.6868460774421692\n",
      "Write summary at step 10350  Loss:  0.6979570388793945\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.0625 Acurracy Balanced 0.5285177595628415\n",
      "Loss normal: 0.675982679381515 Loss Control: 0.6646084769176004 Loss Patient: 0.7193468237916628 Loss balanced:  0.6919776503546315 Loss1+loss2: 0.6919776503546315\n",
      "Write summary at step 10360  Loss:  0.6840678453445435\n",
      "Write summary at step 10370  Loss:  0.6805244088172913\n",
      "Write summary at step 10380  Loss:  0.7068256735801697\n",
      "Write summary at step 10390  Loss:  0.6785405874252319\n",
      "Write summary at step 10400  Loss:  0.6997525095939636\n",
      "Write summary at step 10410  Loss:  0.7087195515632629\n",
      "Write summary at step 10420  Loss:  0.7158383131027222\n",
      "Write summary at step 10430  Loss:  0.6939595937728882\n",
      "Write summary at step 10440  Loss:  0.6408096551895142\n",
      "Write summary at step 10450  Loss:  0.6713158488273621\n",
      "Write summary at step 10460  Loss:  0.6915329098701477\n",
      "Write summary at step 10470  Loss:  0.721183180809021\n",
      "Write summary at step 10480  Loss:  0.7603764533996582\n",
      "Write summary at step 10490  Loss:  0.6921589970588684\n",
      "Write summary at step 10500  Loss:  0.855320155620575\n",
      "Saved checkpoint to: result/9/panns/checkpoint_10500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  1.0 Acurracy Patient:  0.0625 Acurracy Balanced 0.53125\n",
      "Loss normal: 0.6582734726724171 Loss Control: 0.6323894825789447 Loss Patient: 0.7569561935961246 Loss balanced:  0.6946728380875347 Loss1+loss2: 0.6946728380875347\n",
      "Write summary at step 10510  Loss:  0.7129940986633301\n",
      "Write summary at step 10520  Loss:  0.6863595843315125\n",
      "Write summary at step 10530  Loss:  0.7086982727050781\n",
      "Write summary at step 10540  Loss:  0.6951465606689453\n",
      "Write summary at step 10550  Loss:  0.694450855255127\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0625 Acurracy Balanced 0.525785519125683\n",
      "Loss normal: 0.6685119348687011 Loss Control: 0.6518559641525393 Loss Patient: 0.7320128319164118 Loss balanced:  0.6919343980344755 Loss1+loss2: 0.6919343980344755\n",
      "Write summary at step 10560  Loss:  0.6991264820098877\n",
      "Write summary at step 10570  Loss:  0.6982744932174683\n",
      "Write summary at step 10580  Loss:  0.6959434747695923\n",
      "Write summary at step 10590  Loss:  0.68776535987854\n",
      "Write summary at step 10600  Loss:  0.6811202764511108\n",
      "Write summary at step 10610  Loss:  0.6960819363594055\n",
      "Write summary at step 10620  Loss:  0.6705377101898193\n",
      "Write summary at step 10630  Loss:  0.7007912397384644\n",
      "Write summary at step 10640  Loss:  0.7378720641136169\n",
      "Write summary at step 10650  Loss:  0.7230591773986816\n",
      "Write summary at step 10660  Loss:  0.7112947702407837\n",
      "Write summary at step 10670  Loss:  0.6846181750297546\n",
      "Write summary at step 10680  Loss:  0.7177310585975647\n",
      "Write summary at step 10690  Loss:  0.6769359707832336\n",
      "Write summary at step 10700  Loss:  0.681926429271698\n",
      "Write summary at step 10710  Loss:  0.6866155862808228\n",
      "Write summary at step 10720  Loss:  0.7148562669754028\n",
      "Write summary at step 10730  Loss:  0.7025173902511597\n",
      "Write summary at step 10740  Loss:  0.6749282479286194\n",
      "Write summary at step 10750  Loss:  0.6901658773422241\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.08333333333333333 Acurracy Balanced 0.5389344262295082\n",
      "Loss normal: 0.66791650639984 Loss Control: 0.6518617041124021 Loss Patient: 0.7291254177689552 Loss balanced:  0.6904935609406786 Loss1+loss2: 0.6904935609406786\n",
      "Write summary at step 10760  Loss:  0.6735620498657227\n",
      "Write summary at step 10770  Loss:  0.694033145904541\n",
      "Write summary at step 10780  Loss:  0.674121618270874\n",
      "Write summary at step 10790  Loss:  0.7043407559394836\n",
      "Write summary at step 10800  Loss:  0.6542453765869141\n",
      "Write summary at step 10810  Loss:  0.6644497513771057\n",
      "Write summary at step 10820  Loss:  0.695685625076294\n",
      "Write summary at step 10830  Loss:  0.7275153398513794\n",
      "Write summary at step 10840  Loss:  0.7119901180267334\n",
      "Write summary at step 10850  Loss:  0.7235065698623657\n",
      "Write summary at step 10860  Loss:  0.6813757419586182\n",
      "Write summary at step 10870  Loss:  0.6839343309402466\n",
      "Write summary at step 10880  Loss:  0.6813678741455078\n",
      "Write summary at step 10890  Loss:  0.6734248995780945\n",
      "Write summary at step 10900  Loss:  0.6869494915008545\n",
      "Write summary at step 10910  Loss:  0.6854041814804077\n",
      "Write summary at step 10920  Loss:  0.7113869190216064\n",
      "Write summary at step 10930  Loss:  0.6806732416152954\n",
      "Write summary at step 10940  Loss:  0.6579506397247314\n",
      "Write summary at step 10950  Loss:  0.7403486371040344\n",
      "Write summary at step 10960  Loss:  0.7108224630355835\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2727272727272727 Acurracy Control:  0.12568306010928962 Acurracy Patient:  0.8333333333333334 Acurracy Balanced 0.4795081967213115\n",
      "Loss normal: 0.6978657145004767 Loss Control: 0.7017417439346105 Loss Patient: 0.6830883733928204 Loss balanced:  0.6924150586637154 Loss1+loss2: 0.6924150586637154\n",
      "Write summary at step 10970  Loss:  0.6550732851028442\n",
      "Write summary at step 10980  Loss:  0.6969140768051147\n",
      "Write summary at step 10990  Loss:  0.6860229969024658\n",
      "Write summary at step 11000  Loss:  0.6774798631668091\n",
      "Saved checkpoint to: result/9/panns/checkpoint_11000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5064935064935064 Acurracy Control:  0.5136612021857924 Acurracy Patient:  0.4791666666666667 Acurracy Balanced 0.4964139344262295\n",
      "Loss normal: 0.6924092973465528 Loss Control: 0.6926180765928467 Loss Patient: 0.6916133562723795 Loss balanced:  0.692115716432613 Loss1+loss2: 0.692115716432613\n",
      "Write summary at step 11010  Loss:  0.6935893893241882\n",
      "Write summary at step 11020  Loss:  0.7022179365158081\n",
      "Write summary at step 11030  Loss:  0.7068918943405151\n",
      "Write summary at step 11040  Loss:  0.6990617513656616\n",
      "Write summary at step 11050  Loss:  0.7128193378448486\n",
      "Write summary at step 11060  Loss:  0.7367923259735107\n",
      "Write summary at step 11070  Loss:  0.7144379615783691\n",
      "Write summary at step 11080  Loss:  0.666982114315033\n",
      "Write summary at step 11090  Loss:  0.6820415258407593\n",
      "Write summary at step 11100  Loss:  0.6910622715950012\n",
      "Write summary at step 11110  Loss:  0.6880505084991455\n",
      "Write summary at step 11120  Loss:  0.6957651972770691\n",
      "Write summary at step 11130  Loss:  0.6969733238220215\n",
      "Write summary at step 11140  Loss:  0.6884703040122986\n",
      "Write summary at step 11150  Loss:  0.7031336426734924\n",
      "Write summary at step 11160  Loss:  0.709324836730957\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.125 Acurracy Balanced 0.5488387978142076\n",
      "Loss normal: 0.6851179419141827 Loss Control: 0.6799443999274832 Loss Patient: 0.7048420334855715 Loss balanced:  0.6923932167065274 Loss1+loss2: 0.6923932167065274\n",
      "Write summary at step 11170  Loss:  0.715417742729187\n",
      "Write summary at step 11180  Loss:  0.7051894664764404\n",
      "Write summary at step 11190  Loss:  0.6956828832626343\n",
      "Write summary at step 11200  Loss:  0.7135249376296997\n",
      "Write summary at step 11210  Loss:  0.7238523364067078\n",
      "Write summary at step 11220  Loss:  0.6961697340011597\n",
      "Write summary at step 11230  Loss:  0.691897988319397\n",
      "Write summary at step 11240  Loss:  0.7150729894638062\n",
      "Write summary at step 11250  Loss:  0.6691765785217285\n",
      "Write summary at step 11260  Loss:  0.6910878419876099\n",
      "Write summary at step 11270  Loss:  0.7676749229431152\n",
      "Write summary at step 11280  Loss:  0.6971902847290039\n",
      "Write summary at step 11290  Loss:  0.679746150970459\n",
      "Write summary at step 11300  Loss:  0.6703606247901917\n",
      "Write summary at step 11310  Loss:  0.6718387603759766\n",
      "Write summary at step 11320  Loss:  0.6874858140945435\n",
      "Write summary at step 11330  Loss:  0.6878729462623596\n",
      "Write summary at step 11340  Loss:  0.683603823184967\n",
      "Write summary at step 11350  Loss:  0.6819482445716858\n",
      "Write summary at step 11360  Loss:  0.6853929758071899\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6968142338645407 Loss Control: 0.6994423895585732 Loss Patient: 0.6867944449186325 Loss balanced:  0.6931184172386029 Loss1+loss2: 0.6931184172386029\n",
      "Write summary at step 11370  Loss:  0.7045270204544067\n",
      "Write summary at step 11380  Loss:  0.6747905015945435\n",
      "Write summary at step 11390  Loss:  0.7044861912727356\n",
      "Write summary at step 11400  Loss:  0.63818359375\n",
      "Write summary at step 11410  Loss:  0.685684084892273\n",
      "Write summary at step 11420  Loss:  0.6967744827270508\n",
      "Write summary at step 11430  Loss:  0.7028072476387024\n",
      "Write summary at step 11440  Loss:  0.6950217485427856\n",
      "Write summary at step 11450  Loss:  0.6867997646331787\n",
      "Write summary at step 11460  Loss:  0.7088184356689453\n",
      "Write summary at step 11470  Loss:  0.7240636944770813\n",
      "Write summary at step 11480  Loss:  0.7291890978813171\n",
      "Write summary at step 11490  Loss:  0.6718080043792725\n",
      "Write summary at step 11500  Loss:  0.6774610280990601\n",
      "Saved checkpoint to: result/9/panns/checkpoint_11500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5599385245901639\n",
      "Loss normal: 0.6890405499057852 Loss Control: 0.6864558757980013 Loss Patient: 0.698894581447045 Loss balanced:  0.6926752286225231 Loss1+loss2: 0.6926752286225231\n",
      "Write summary at step 11510  Loss:  0.6811481714248657\n",
      "Write summary at step 11520  Loss:  0.685894250869751\n",
      "Write summary at step 11530  Loss:  0.7014793157577515\n",
      "Write summary at step 11540  Loss:  0.6923925280570984\n",
      "Write summary at step 11550  Loss:  0.6860442161560059\n",
      "Write summary at step 11560  Loss:  0.6874173283576965\n",
      "Write summary at step 11570  Loss:  0.6925058364868164\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6717662274579466 Loss Control: 0.6572876497696006 Loss Patient: 0.7269657775759697 Loss balanced:  0.6921267136727851 Loss1+loss2: 0.6921267136727851\n",
      "Write summary at step 11580  Loss:  0.6935885548591614\n",
      "Write summary at step 11590  Loss:  0.6907428503036499\n",
      "Write summary at step 11600  Loss:  0.6988396048545837\n",
      "Write summary at step 11610  Loss:  0.6680260896682739\n",
      "Write summary at step 11620  Loss:  0.7027708888053894\n",
      "Write summary at step 11630  Loss:  0.7017508149147034\n",
      "Write summary at step 11640  Loss:  0.7044119238853455\n",
      "Write summary at step 11650  Loss:  0.6893166303634644\n",
      "Write summary at step 11660  Loss:  0.7069089412689209\n",
      "Write summary at step 11670  Loss:  0.690531313419342\n",
      "Write summary at step 11680  Loss:  0.705309271812439\n",
      "Write summary at step 11690  Loss:  0.7049188613891602\n",
      "Write summary at step 11700  Loss:  0.6882692575454712\n",
      "Write summary at step 11710  Loss:  0.7162163257598877\n",
      "Write summary at step 11720  Loss:  0.6962249279022217\n",
      "Write summary at step 11730  Loss:  0.6958817839622498\n",
      "Write summary at step 11740  Loss:  0.671359658241272\n",
      "Write summary at step 11750  Loss:  0.7012084722518921\n",
      "Write summary at step 11760  Loss:  0.7063503265380859\n",
      "Write summary at step 11770  Loss:  0.6970701217651367\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  1.0 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5104166666666666\n",
      "Loss normal: 0.6746416917610994 Loss Control: 0.6621558522917533 Loss Patient: 0.7222439261774222 Loss balanced:  0.6921998892345878 Loss1+loss2: 0.6921998892345878\n",
      "Write summary at step 11780  Loss:  0.6599158048629761\n",
      "Write summary at step 11790  Loss:  0.716909646987915\n",
      "Write summary at step 11800  Loss:  0.6825538873672485\n",
      "Write summary at step 11810  Loss:  0.6871938705444336\n",
      "Write summary at step 11820  Loss:  0.7112789750099182\n",
      "Write summary at step 11830  Loss:  0.6803877353668213\n",
      "Write summary at step 11840  Loss:  0.6916829347610474\n",
      "Write summary at step 11850  Loss:  0.6863797903060913\n",
      "Write summary at step 11860  Loss:  0.6873226761817932\n",
      "Write summary at step 11870  Loss:  0.683059811592102\n",
      "Write summary at step 11880  Loss:  0.6909860372543335\n",
      "Write summary at step 11890  Loss:  0.670974850654602\n",
      "Write summary at step 11900  Loss:  0.7148535251617432\n",
      "Write summary at step 11910  Loss:  0.6742393970489502\n",
      "Write summary at step 11920  Loss:  0.6846582889556885\n",
      "Write summary at step 11930  Loss:  0.704846203327179\n",
      "Write summary at step 11940  Loss:  0.6861530542373657\n",
      "Write summary at step 11950  Loss:  0.6884815096855164\n",
      "Write summary at step 11960  Loss:  0.6502055525779724\n",
      "Write summary at step 11970  Loss:  0.7053623199462891\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.0 Acurracy Balanced 0.4972677595628415\n",
      "Loss normal: 0.6584198051716859 Loss Control: 0.6337595871888875 Loss Patient: 0.7524368800222874 Loss balanced:  0.6930982336055874 Loss1+loss2: 0.6930982336055874\n",
      "Write summary at step 11980  Loss:  0.699487566947937\n",
      "Write summary at step 11990  Loss:  0.6994267106056213\n",
      "Write summary at step 12000  Loss:  0.6813130378723145\n",
      "Saved checkpoint to: result/9/panns/checkpoint_12000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  1.0 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.5208333333333334\n",
      "Loss normal: 0.6544899377988015 Loss Control: 0.6275981417119177 Loss Patient: 0.7570149302482605 Loss balanced:  0.6923065359800891 Loss1+loss2: 0.6923065359800891\n",
      "Write summary at step 12010  Loss:  0.7178047299385071\n",
      "Write summary at step 12020  Loss:  0.6922969818115234\n",
      "Write summary at step 12030  Loss:  0.6825670599937439\n",
      "Write summary at step 12040  Loss:  0.6860771179199219\n",
      "Write summary at step 12050  Loss:  0.6927006244659424\n",
      "Write summary at step 12060  Loss:  0.6933462023735046\n",
      "Write summary at step 12070  Loss:  0.7019237279891968\n",
      "Write summary at step 12080  Loss:  0.693507194519043\n",
      "Write summary at step 12090  Loss:  0.6981655359268188\n",
      "Write summary at step 12100  Loss:  0.6917048692703247\n",
      "Write summary at step 12110  Loss:  0.7094838619232178\n",
      "Write summary at step 12120  Loss:  0.6934733986854553\n",
      "Write summary at step 12130  Loss:  0.6854871511459351\n",
      "Write summary at step 12140  Loss:  0.689712405204773\n",
      "Write summary at step 12150  Loss:  0.7025245428085327\n",
      "Write summary at step 12160  Loss:  0.6925027966499329\n",
      "Write summary at step 12170  Loss:  0.6788137555122375\n",
      "Write summary at step 12180  Loss:  0.7033337354660034\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6670265618340794 Loss Control: 0.6494207496200103 Loss Patient: 0.7341487022737662 Loss balanced:  0.6917847259468882 Loss1+loss2: 0.6917847259468882\n",
      "Write summary at step 12190  Loss:  0.7044637203216553\n",
      "Write summary at step 12200  Loss:  0.6982250213623047\n",
      "Write summary at step 12210  Loss:  0.7034740447998047\n",
      "Write summary at step 12220  Loss:  0.7128105163574219\n",
      "Write summary at step 12230  Loss:  0.6883140206336975\n",
      "Write summary at step 12240  Loss:  0.7052675485610962\n",
      "Write summary at step 12250  Loss:  0.70567387342453\n",
      "Write summary at step 12260  Loss:  0.696679413318634\n",
      "Write summary at step 12270  Loss:  0.7040936946868896\n",
      "Write summary at step 12280  Loss:  0.6835628747940063\n",
      "Write summary at step 12290  Loss:  0.6977554559707642\n",
      "Write summary at step 12300  Loss:  0.701498806476593\n",
      "Write summary at step 12310  Loss:  0.6737642288208008\n",
      "Write summary at step 12320  Loss:  0.7216417193412781\n",
      "Write summary at step 12330  Loss:  0.6835677027702332\n",
      "Write summary at step 12340  Loss:  0.69489985704422\n",
      "Write summary at step 12350  Loss:  0.6892187595367432\n",
      "Write summary at step 12360  Loss:  0.6876922845840454\n",
      "Write summary at step 12370  Loss:  0.6887099146842957\n",
      "Write summary at step 12380  Loss:  0.6869632601737976\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.01092896174863388 Acurracy Patient:  0.9583333333333334 Acurracy Balanced 0.48463114754098363\n",
      "Loss normal: 0.6975572676885695 Loss Control: 0.7015632228121731 Loss Patient: 0.6822845749557018 Loss balanced:  0.6919238988839375 Loss1+loss2: 0.6919238988839375\n",
      "Write summary at step 12390  Loss:  0.6821335554122925\n",
      "Write summary at step 12400  Loss:  0.6592252254486084\n",
      "Write summary at step 12410  Loss:  0.6906242370605469\n",
      "Write summary at step 12420  Loss:  0.692129373550415\n",
      "Write summary at step 12430  Loss:  0.7280255556106567\n",
      "Write summary at step 12440  Loss:  0.6812022924423218\n",
      "Write summary at step 12450  Loss:  0.7149801254272461\n",
      "Write summary at step 12460  Loss:  0.7009370923042297\n",
      "Write summary at step 12470  Loss:  0.686113715171814\n",
      "Write summary at step 12480  Loss:  0.6997659206390381\n",
      "Write summary at step 12490  Loss:  0.6885106563568115\n",
      "Write summary at step 12500  Loss:  0.695020318031311\n",
      "Saved checkpoint to: result/9/panns/checkpoint_12500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.543886612021858\n",
      "Loss normal: 0.6815870104930102 Loss Control: 0.6743410998354844 Loss Patient: 0.7092120796442032 Loss balanced:  0.6917765897398438 Loss1+loss2: 0.6917765897398438\n",
      "Write summary at step 12510  Loss:  0.6873710751533508\n",
      "Write summary at step 12520  Loss:  0.6881828308105469\n",
      "Write summary at step 12530  Loss:  0.703002393245697\n",
      "Write summary at step 12540  Loss:  0.6879333853721619\n",
      "Write summary at step 12550  Loss:  0.6932791471481323\n",
      "Write summary at step 12560  Loss:  0.6766883730888367\n",
      "Write summary at step 12570  Loss:  0.6891428232192993\n",
      "Write summary at step 12580  Loss:  0.7164833545684814\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.4912909836065574\n",
      "Loss normal: 0.6843925933817249 Loss Control: 0.6785788207106251 Loss Patient: 0.7065576103826364 Loss balanced:  0.6925682155466308 Loss1+loss2: 0.6925682155466308\n",
      "Write summary at step 12590  Loss:  0.7023892402648926\n",
      "Write summary at step 12600  Loss:  0.6796743869781494\n",
      "Write summary at step 12610  Loss:  0.7037627696990967\n",
      "Write summary at step 12620  Loss:  0.6956011652946472\n",
      "Write summary at step 12630  Loss:  0.6937683820724487\n",
      "Write summary at step 12640  Loss:  0.6765550971031189\n",
      "Write summary at step 12650  Loss:  0.7013733386993408\n",
      "Write summary at step 12660  Loss:  0.669143795967102\n",
      "Write summary at step 12670  Loss:  0.6801153421401978\n",
      "Write summary at step 12680  Loss:  0.7425522804260254\n",
      "Write summary at step 12690  Loss:  0.7202003002166748\n",
      "Write summary at step 12700  Loss:  0.705033540725708\n",
      "Write summary at step 12710  Loss:  0.7030670642852783\n",
      "Write summary at step 12720  Loss:  0.6903474926948547\n",
      "Write summary at step 12730  Loss:  0.7128753662109375\n",
      "Write summary at step 12740  Loss:  0.7348282337188721\n",
      "Write summary at step 12750  Loss:  0.6892731785774231\n",
      "Write summary at step 12760  Loss:  0.6777382493019104\n",
      "Write summary at step 12770  Loss:  0.6813561916351318\n",
      "Write summary at step 12780  Loss:  0.6857070326805115\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7093334182516321 Loss Control: 0.7196677323898982 Loss Patient: 0.6699338356653849 Loss balanced:  0.6948007840276416 Loss1+loss2: 0.6948007840276416\n",
      "Write summary at step 12790  Loss:  0.702186644077301\n",
      "Write summary at step 12800  Loss:  0.6846985816955566\n",
      "Write summary at step 12810  Loss:  0.6598448753356934\n",
      "Write summary at step 12820  Loss:  0.6712321639060974\n",
      "Write summary at step 12830  Loss:  0.7013391256332397\n",
      "Write summary at step 12840  Loss:  0.6563704013824463\n",
      "Write summary at step 12850  Loss:  0.6857661008834839\n",
      "Write summary at step 12860  Loss:  0.7053136825561523\n",
      "Write summary at step 12870  Loss:  0.6765753626823425\n",
      "Write summary at step 12880  Loss:  0.6978034973144531\n",
      "Write summary at step 12890  Loss:  0.6677969694137573\n",
      "Write summary at step 12900  Loss:  0.6849526166915894\n",
      "Write summary at step 12910  Loss:  0.6851893663406372\n",
      "Write summary at step 12920  Loss:  0.656595766544342\n",
      "Write summary at step 12930  Loss:  0.6849126815795898\n",
      "Write summary at step 12940  Loss:  0.6982365846633911\n",
      "Write summary at step 12950  Loss:  0.6927030086517334\n",
      "Write summary at step 12960  Loss:  0.690638542175293\n",
      "Write summary at step 12970  Loss:  0.7027190923690796\n",
      "Write summary at step 12980  Loss:  0.6941956877708435\n",
      "Write summary at step 12990  Loss:  0.7000292539596558\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7025139631130994 Loss Control: 0.7100589105991718 Loss Patient: 0.6737488607565562 Loss balanced:  0.691903885677864 Loss1+loss2: 0.691903885677864\n",
      "Write summary at step 13000  Loss:  0.6870019435882568\n",
      "Saved checkpoint to: result/9/panns/checkpoint_13000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.708944938399575 Loss Control: 0.7206688637290496 Loss Patient: 0.6642474470039209 Loss balanced:  0.6924581553664853 Loss1+loss2: 0.6924581553664853\n",
      "Write summary at step 13010  Loss:  0.6755215525627136\n",
      "Write summary at step 13020  Loss:  0.7382124066352844\n",
      "Write summary at step 13030  Loss:  0.7205798029899597\n",
      "Write summary at step 13040  Loss:  0.6945234537124634\n",
      "Write summary at step 13050  Loss:  0.6336774826049805\n",
      "Write summary at step 13060  Loss:  0.6899417638778687\n",
      "Write summary at step 13070  Loss:  0.6974314451217651\n",
      "Write summary at step 13080  Loss:  0.6745113730430603\n",
      "Write summary at step 13090  Loss:  0.7121849060058594\n",
      "Write summary at step 13100  Loss:  0.6927890181541443\n",
      "Write summary at step 13110  Loss:  0.6961631774902344\n",
      "Write summary at step 13120  Loss:  0.6785218715667725\n",
      "Write summary at step 13130  Loss:  0.7258050441741943\n",
      "Write summary at step 13140  Loss:  0.6972939372062683\n",
      "Write summary at step 13150  Loss:  0.7019503116607666\n",
      "Write summary at step 13160  Loss:  0.6979616284370422\n",
      "Write summary at step 13170  Loss:  0.6933314800262451\n",
      "Write summary at step 13180  Loss:  0.6804496645927429\n",
      "Write summary at step 13190  Loss:  0.6944630146026611\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.543886612021858\n",
      "Loss normal: 0.6742095805349804 Loss Control: 0.6614484034600805 Loss Patient: 0.7228615581989288 Loss balanced:  0.6921549808295047 Loss1+loss2: 0.6921549808295047\n",
      "Write summary at step 13200  Loss:  0.689134418964386\n",
      "Write summary at step 13210  Loss:  0.6716018319129944\n",
      "Write summary at step 13220  Loss:  0.7137220501899719\n",
      "Write summary at step 13230  Loss:  0.6985421180725098\n",
      "Write summary at step 13240  Loss:  0.6723281741142273\n",
      "Write summary at step 13250  Loss:  0.7014009952545166\n",
      "Write summary at step 13260  Loss:  0.6748962998390198\n",
      "Write summary at step 13270  Loss:  0.6933865547180176\n",
      "Write summary at step 13280  Loss:  0.734330415725708\n",
      "Write summary at step 13290  Loss:  0.7166756391525269\n",
      "Write summary at step 13300  Loss:  0.7297208905220032\n",
      "Write summary at step 13310  Loss:  0.6942855715751648\n",
      "Write summary at step 13320  Loss:  0.682836651802063\n",
      "Write summary at step 13330  Loss:  0.6826837062835693\n",
      "Write summary at step 13340  Loss:  0.6879028677940369\n",
      "Write summary at step 13350  Loss:  0.7003368735313416\n",
      "Write summary at step 13360  Loss:  0.6558508276939392\n",
      "Write summary at step 13370  Loss:  0.6686910390853882\n",
      "Write summary at step 13380  Loss:  0.7014241814613342\n",
      "Write summary at step 13390  Loss:  0.6872360706329346\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6623376623376623 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5256147540983607\n",
      "Loss normal: 0.6852557708174636 Loss Control: 0.6806739037805568 Loss Patient: 0.7027241364121437 Loss balanced:  0.6916990200963502 Loss1+loss2: 0.6916990200963502\n",
      "Write summary at step 13400  Loss:  0.6960232853889465\n",
      "Write summary at step 13410  Loss:  0.7036412954330444\n",
      "Write summary at step 13420  Loss:  0.6839089393615723\n",
      "Write summary at step 13430  Loss:  0.685301661491394\n",
      "Write summary at step 13440  Loss:  0.6957442760467529\n",
      "Write summary at step 13450  Loss:  0.6791900396347046\n",
      "Write summary at step 13460  Loss:  0.703335165977478\n",
      "Write summary at step 13470  Loss:  0.701637327671051\n",
      "Write summary at step 13480  Loss:  0.68885737657547\n",
      "Write summary at step 13490  Loss:  0.6898835897445679\n",
      "Write summary at step 13500  Loss:  0.6848915219306946\n",
      "Saved checkpoint to: result/9/panns/checkpoint_13500.pt\n",
      "Validation:\n",
      "Acurracy:  0.683982683982684 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5315915300546448\n",
      "Loss normal: 0.6817092498143514 Loss Control: 0.6741954426947838 Loss Patient: 0.7103555935124556 Loss balanced:  0.6922755181036198 Loss1+loss2: 0.6922755181036198\n",
      "Write summary at step 13510  Loss:  0.6948122382164001\n",
      "Write summary at step 13520  Loss:  0.6978970170021057\n",
      "Write summary at step 13530  Loss:  0.7155081033706665\n",
      "Write summary at step 13540  Loss:  0.7172544598579407\n",
      "Write summary at step 13550  Loss:  0.6980893611907959\n",
      "Write summary at step 13560  Loss:  0.7006211280822754\n",
      "Write summary at step 13570  Loss:  0.7034916877746582\n",
      "Write summary at step 13580  Loss:  0.6869276762008667\n",
      "Write summary at step 13590  Loss:  0.714441180229187\n",
      "Write summary at step 13600  Loss:  0.6868526935577393\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2510822510822511 Acurracy Control:  0.07650273224043716 Acurracy Patient:  0.9166666666666666 Acurracy Balanced 0.4965846994535519\n",
      "Loss normal: 0.6984449937230065 Loss Control: 0.7030454694899053 Loss Patient: 0.6809056885540485 Loss balanced:  0.6919755790219769 Loss1+loss2: 0.6919755790219769\n",
      "Write summary at step 13610  Loss:  0.6836555004119873\n",
      "Write summary at step 13620  Loss:  0.7098871469497681\n",
      "Write summary at step 13630  Loss:  0.6816498041152954\n",
      "Write summary at step 13640  Loss:  0.7010440826416016\n",
      "Write summary at step 13650  Loss:  0.6703698039054871\n",
      "Write summary at step 13660  Loss:  0.7054741382598877\n",
      "Write summary at step 13670  Loss:  0.6947807669639587\n",
      "Write summary at step 13680  Loss:  0.6786127090454102\n",
      "Write summary at step 13690  Loss:  0.6985052824020386\n",
      "Write summary at step 13700  Loss:  0.6879978179931641\n",
      "Write summary at step 13710  Loss:  0.7062278985977173\n",
      "Write summary at step 13720  Loss:  0.701378345489502\n",
      "Write summary at step 13730  Loss:  0.6902894973754883\n",
      "Write summary at step 13740  Loss:  0.6861785650253296\n",
      "Write summary at step 13750  Loss:  0.6764121055603027\n",
      "Write summary at step 13760  Loss:  0.6938619613647461\n",
      "Write summary at step 13770  Loss:  0.712040364742279\n",
      "Write summary at step 13780  Loss:  0.6915751695632935\n",
      "Write summary at step 13790  Loss:  0.67670738697052\n",
      "Write summary at step 13800  Loss:  0.6945306062698364\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7045164758508856 Loss Control: 0.7132513627328508 Loss Patient: 0.6712147456904253 Loss balanced:  0.692233054211638 Loss1+loss2: 0.692233054211638\n",
      "Write summary at step 13810  Loss:  0.7210589051246643\n",
      "Write summary at step 13820  Loss:  0.7180447578430176\n",
      "Write summary at step 13830  Loss:  0.687139093875885\n",
      "Write summary at step 13840  Loss:  0.6931153535842896\n",
      "Write summary at step 13850  Loss:  0.698094367980957\n",
      "Write summary at step 13860  Loss:  0.6999222636222839\n",
      "Write summary at step 13870  Loss:  0.687990665435791\n",
      "Write summary at step 13880  Loss:  0.6892872452735901\n",
      "Write summary at step 13890  Loss:  0.6953976154327393\n",
      "Write summary at step 13900  Loss:  0.6922526359558105\n",
      "Write summary at step 13910  Loss:  0.6801482439041138\n",
      "Write summary at step 13920  Loss:  0.6854729056358337\n",
      "Write summary at step 13930  Loss:  0.6743754148483276\n",
      "Write summary at step 13940  Loss:  0.6924400329589844\n",
      "Write summary at step 13950  Loss:  0.6923552751541138\n",
      "Write summary at step 13960  Loss:  0.6819168329238892\n",
      "Write summary at step 13970  Loss:  0.6674064993858337\n",
      "Write summary at step 13980  Loss:  0.695928692817688\n",
      "Write summary at step 13990  Loss:  0.6898144483566284\n",
      "Write summary at step 14000  Loss:  0.6769285798072815\n",
      "Saved checkpoint to: result/9/panns/checkpoint_14000.pt\n",
      "Validation:\n",
      "Acurracy:  0.20346320346320346 Acurracy Control:  0.00546448087431694 Acurracy Patient:  0.9583333333333334 Acurracy Balanced 0.48189890710382516\n",
      "Loss normal: 0.6963953048119813 Loss Control: 0.6991861172712566 Loss Patient: 0.6857553049921989 Loss balanced:  0.6924707111317278 Loss1+loss2: 0.6924707111317278\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7018094264067612 Loss Control: 0.7081643864105308 Loss Patient: 0.6775811451176802 Loss balanced:  0.6928727657641055 Loss1+loss2: 0.6928727657641055\n",
      "Write summary at step 14010  Loss:  0.682239294052124\n",
      "Write summary at step 14020  Loss:  0.6899700164794922\n",
      "Write summary at step 14030  Loss:  0.6907830834388733\n",
      "Write summary at step 14040  Loss:  0.6892613768577576\n",
      "Write summary at step 14050  Loss:  0.6969778537750244\n",
      "Write summary at step 14060  Loss:  0.6966094970703125\n",
      "Write summary at step 14070  Loss:  0.699108362197876\n",
      "Write summary at step 14080  Loss:  0.7189737558364868\n",
      "Write summary at step 14090  Loss:  0.6867613792419434\n",
      "Write summary at step 14100  Loss:  0.690567135810852\n",
      "Write summary at step 14110  Loss:  0.6940716505050659\n",
      "Write summary at step 14120  Loss:  0.6964951753616333\n",
      "Write summary at step 14130  Loss:  0.682299017906189\n",
      "Write summary at step 14140  Loss:  0.6958408355712891\n",
      "Write summary at step 14150  Loss:  0.6885014772415161\n",
      "Write summary at step 14160  Loss:  0.709449291229248\n",
      "Write summary at step 14170  Loss:  0.6864923238754272\n",
      "Write summary at step 14180  Loss:  0.6947849988937378\n",
      "Write summary at step 14190  Loss:  0.7012721300125122\n",
      "Write summary at step 14200  Loss:  0.7048647403717041\n",
      "Write summary at step 14210  Loss:  0.6972125768661499\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.1875 Acurracy Balanced 0.5773565573770492\n",
      "Loss normal: 0.6888073086738586 Loss Control: 0.6861142991670494 Loss Patient: 0.6990743825833002 Loss balanced:  0.6925943408751748 Loss1+loss2: 0.6925943408751748\n",
      "Write summary at step 14220  Loss:  0.7003118395805359\n",
      "Write summary at step 14230  Loss:  0.691919207572937\n",
      "Write summary at step 14240  Loss:  0.6920169591903687\n",
      "Write summary at step 14250  Loss:  0.669908881187439\n",
      "Write summary at step 14260  Loss:  0.7380927801132202\n",
      "Write summary at step 14270  Loss:  0.6820666193962097\n",
      "Write summary at step 14280  Loss:  0.6826478838920593\n",
      "Write summary at step 14290  Loss:  0.6891058087348938\n",
      "Write summary at step 14300  Loss:  0.6935903429985046\n",
      "Write summary at step 14310  Loss:  0.6817610263824463\n",
      "Write summary at step 14320  Loss:  0.6956685781478882\n",
      "Write summary at step 14330  Loss:  0.7067102789878845\n",
      "Write summary at step 14340  Loss:  0.7031131386756897\n",
      "Write summary at step 14350  Loss:  0.6882642507553101\n",
      "Write summary at step 14360  Loss:  0.7122606039047241\n",
      "Write summary at step 14370  Loss:  0.7007520794868469\n",
      "Write summary at step 14380  Loss:  0.7036541700363159\n",
      "Write summary at step 14390  Loss:  0.6889423131942749\n",
      "Write summary at step 14400  Loss:  0.6993518471717834\n",
      "Write summary at step 14410  Loss:  0.697307288646698\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6803214410682777 Loss Control: 0.6713268242247118 Loss Patient: 0.714613351970911 Loss balanced:  0.6929700880978114 Loss1+loss2: 0.6929700880978114\n",
      "Write summary at step 14420  Loss:  0.6934674978256226\n",
      "Write summary at step 14430  Loss:  0.7035732865333557\n",
      "Write summary at step 14440  Loss:  0.7039668560028076\n",
      "Write summary at step 14450  Loss:  0.6831073760986328\n",
      "Write summary at step 14460  Loss:  0.6993119716644287\n",
      "Write summary at step 14470  Loss:  0.6955215930938721\n",
      "Write summary at step 14480  Loss:  0.6925618052482605\n",
      "Write summary at step 14490  Loss:  0.6873564124107361\n",
      "Write summary at step 14500  Loss:  0.6957029700279236\n",
      "Saved checkpoint to: result/9/panns/checkpoint_14500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6772744859451856 Loss Control: 0.6661515167502107 Loss Patient: 0.719680787374576 Loss balanced:  0.6929161520623933 Loss1+loss2: 0.6929161520623933\n",
      "Write summary at step 14510  Loss:  0.6882308125495911\n",
      "Write summary at step 14520  Loss:  0.6956415176391602\n",
      "Write summary at step 14530  Loss:  0.7053650617599487\n",
      "Write summary at step 14540  Loss:  0.6671271324157715\n",
      "Write summary at step 14550  Loss:  0.6568785905838013\n",
      "Write summary at step 14560  Loss:  0.7362146377563477\n",
      "Write summary at step 14570  Loss:  0.6905784010887146\n",
      "Write summary at step 14580  Loss:  0.7052162289619446\n",
      "Write summary at step 14590  Loss:  0.686095118522644\n",
      "Write summary at step 14600  Loss:  0.6926225423812866\n",
      "Write summary at step 14610  Loss:  0.6805583238601685\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  1.0 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.5208333333333334\n",
      "Loss normal: 0.6728507411944402 Loss Control: 0.6583804553323757 Loss Patient: 0.7280186998347441 Loss balanced:  0.6931995775835599 Loss1+loss2: 0.6931995775835599\n",
      "Write summary at step 14620  Loss:  0.7118866443634033\n",
      "Write summary at step 14630  Loss:  0.6940526962280273\n",
      "Write summary at step 14640  Loss:  0.6915923953056335\n",
      "Write summary at step 14650  Loss:  0.6834224462509155\n",
      "Write summary at step 14660  Loss:  0.6895718574523926\n",
      "Write summary at step 14670  Loss:  0.7202572226524353\n",
      "Write summary at step 14680  Loss:  0.7081729769706726\n",
      "Write summary at step 14690  Loss:  0.7053135633468628\n",
      "Write summary at step 14700  Loss:  0.7102451324462891\n",
      "Write summary at step 14710  Loss:  0.6800152659416199\n",
      "Write summary at step 14720  Loss:  0.6859461069107056\n",
      "Write summary at step 14730  Loss:  0.6825565695762634\n",
      "Write summary at step 14740  Loss:  0.6969867944717407\n",
      "Write summary at step 14750  Loss:  0.6793992519378662\n",
      "Write summary at step 14760  Loss:  0.6982724070549011\n",
      "Write summary at step 14770  Loss:  0.7113450765609741\n",
      "Write summary at step 14780  Loss:  0.6886121034622192\n",
      "Write summary at step 14790  Loss:  0.6870611906051636\n",
      "Write summary at step 14800  Loss:  0.7084484100341797\n",
      "Write summary at step 14810  Loss:  0.7009747624397278\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6989468516725482 Loss Control: 0.7036307418281263 Loss Patient: 0.6810895415643851 Loss balanced:  0.6923601416962557 Loss1+loss2: 0.6923601416962557\n",
      "Write summary at step 14820  Loss:  0.6743579506874084\n",
      "Write summary at step 14830  Loss:  0.6932717561721802\n",
      "Write summary at step 14840  Loss:  0.6803079843521118\n",
      "Write summary at step 14850  Loss:  0.683044970035553\n",
      "Write summary at step 14860  Loss:  0.701276421546936\n",
      "Write summary at step 14870  Loss:  0.6974115371704102\n",
      "Write summary at step 14880  Loss:  0.7060593366622925\n",
      "Write summary at step 14890  Loss:  0.6877484321594238\n",
      "Write summary at step 14900  Loss:  0.6934241056442261\n",
      "Write summary at step 14910  Loss:  0.7031530141830444\n",
      "Write summary at step 14920  Loss:  0.6890304088592529\n",
      "Write summary at step 14930  Loss:  0.6781212091445923\n",
      "Write summary at step 14940  Loss:  0.6956280469894409\n",
      "Write summary at step 14950  Loss:  0.6927657723426819\n",
      "Write summary at step 14960  Loss:  0.7218114137649536\n",
      "Write summary at step 14970  Loss:  0.7070826292037964\n",
      "Write summary at step 14980  Loss:  0.7081031203269958\n",
      "Write summary at step 14990  Loss:  0.6836507320404053\n",
      "Write summary at step 15000  Loss:  0.6867416501045227\n",
      "Saved checkpoint to: result/9/panns/checkpoint_15000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5800865800865801 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.4660177595628415\n",
      "Loss normal: 0.6894263093605703 Loss Control: 0.687352655689573 Loss Patient: 0.6973321003218492 Loss balanced:  0.6923423780057112 Loss1+loss2: 0.6923423780057112\n",
      "Write summary at step 15010  Loss:  0.6614004969596863\n",
      "Write summary at step 15020  Loss:  0.7018616795539856\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0625 Acurracy Balanced 0.525785519125683\n",
      "Loss normal: 0.6860464037238777 Loss Control: 0.681495806558536 Loss Patient: 0.7033955877025923 Loss balanced:  0.6924456971305641 Loss1+loss2: 0.6924456971305641\n",
      "Write summary at step 15030  Loss:  0.6971283555030823\n",
      "Write summary at step 15040  Loss:  0.6809577345848083\n",
      "Write summary at step 15050  Loss:  0.6901625394821167\n",
      "Write summary at step 15060  Loss:  0.69435715675354\n",
      "Write summary at step 15070  Loss:  0.6926677823066711\n",
      "Write summary at step 15080  Loss:  0.6897388696670532\n",
      "Write summary at step 15090  Loss:  0.6943796873092651\n",
      "Write summary at step 15100  Loss:  0.6802071332931519\n",
      "Write summary at step 15110  Loss:  0.6883187294006348\n",
      "Write summary at step 15120  Loss:  0.6975717544555664\n",
      "Write summary at step 15130  Loss:  0.6918773651123047\n",
      "Write summary at step 15140  Loss:  0.6914310455322266\n",
      "Write summary at step 15150  Loss:  0.6982676982879639\n",
      "Write summary at step 15160  Loss:  0.6955264806747437\n",
      "Write summary at step 15170  Loss:  0.6845446825027466\n",
      "Write summary at step 15180  Loss:  0.6849240064620972\n",
      "Write summary at step 15190  Loss:  0.6957765817642212\n",
      "Write summary at step 15200  Loss:  0.7088236212730408\n",
      "Write summary at step 15210  Loss:  0.7000000476837158\n",
      "Write summary at step 15220  Loss:  0.7010120153427124\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.0625 Acurracy Balanced 0.5285177595628415\n",
      "Loss normal: 0.6695466263469679 Loss Control: 0.6528887742204093 Loss Patient: 0.7330546900629997 Loss balanced:  0.6929717321417045 Loss1+loss2: 0.6929717321417045\n",
      "Write summary at step 15230  Loss:  0.7087738513946533\n",
      "Write summary at step 15240  Loss:  0.6872634291648865\n",
      "Write summary at step 15250  Loss:  0.6926339864730835\n",
      "Write summary at step 15260  Loss:  0.7073595523834229\n",
      "Write summary at step 15270  Loss:  0.7135803699493408\n",
      "Write summary at step 15280  Loss:  0.6983368396759033\n",
      "Write summary at step 15290  Loss:  0.7041292786598206\n",
      "Write summary at step 15300  Loss:  0.6621838212013245\n",
      "Write summary at step 15310  Loss:  0.7302842140197754\n",
      "Write summary at step 15320  Loss:  0.6835349798202515\n",
      "Write summary at step 15330  Loss:  0.6893220543861389\n",
      "Write summary at step 15340  Loss:  0.6926627159118652\n",
      "Write summary at step 15350  Loss:  0.7097538709640503\n",
      "Write summary at step 15360  Loss:  0.6525083780288696\n",
      "Write summary at step 15370  Loss:  0.6843048334121704\n",
      "Write summary at step 15380  Loss:  0.6872974634170532\n",
      "Write summary at step 15390  Loss:  0.7104751467704773\n",
      "Write summary at step 15400  Loss:  0.6904511451721191\n",
      "Write summary at step 15410  Loss:  0.7052440643310547\n",
      "Write summary at step 15420  Loss:  0.7141180634498596\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.01639344262295082 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.49778005464480873\n",
      "Loss normal: 0.7017358796937125 Loss Control: 0.7081242379595022 Loss Patient: 0.6773802625636259 Loss balanced:  0.6927522502615641 Loss1+loss2: 0.6927522502615641\n",
      "Write summary at step 15430  Loss:  0.692344069480896\n",
      "Write summary at step 15440  Loss:  0.6923244595527649\n",
      "Write summary at step 15450  Loss:  0.6926764845848083\n",
      "Write summary at step 15460  Loss:  0.7042174339294434\n",
      "Write summary at step 15470  Loss:  0.681050181388855\n",
      "Write summary at step 15480  Loss:  0.6741009950637817\n",
      "Write summary at step 15490  Loss:  0.7066558003425598\n",
      "Write summary at step 15500  Loss:  0.6803981065750122\n",
      "Saved checkpoint to: result/9/panns/checkpoint_15500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7101222694694221 Loss Control: 0.7222460580002414 Loss Patient: 0.6639003703991572 Loss balanced:  0.6930732141996994 Loss1+loss2: 0.6930732141996994\n",
      "Write summary at step 15510  Loss:  0.6970027685165405\n",
      "Write summary at step 15520  Loss:  0.6811027526855469\n",
      "Write summary at step 15530  Loss:  0.6877450346946716\n",
      "Write summary at step 15540  Loss:  0.692240834236145\n",
      "Write summary at step 15550  Loss:  0.6947861909866333\n",
      "Write summary at step 15560  Loss:  0.6906702518463135\n",
      "Write summary at step 15570  Loss:  0.684395432472229\n",
      "Write summary at step 15580  Loss:  0.6943647861480713\n",
      "Write summary at step 15590  Loss:  0.6813614368438721\n",
      "Write summary at step 15600  Loss:  0.6905851364135742\n",
      "Write summary at step 15610  Loss:  0.6958743929862976\n",
      "Write summary at step 15620  Loss:  0.6736164093017578\n",
      "Write summary at step 15630  Loss:  0.7031446695327759\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5049521857923497\n",
      "Loss normal: 0.678032652124182 Loss Control: 0.6676026094155233 Loss Patient: 0.7177971675992012 Loss balanced:  0.6926998885073623 Loss1+loss2: 0.6926998885073623\n",
      "Write summary at step 15640  Loss:  0.7075255513191223\n",
      "Write summary at step 15650  Loss:  0.7032104730606079\n",
      "Write summary at step 15660  Loss:  0.7069134712219238\n",
      "Write summary at step 15670  Loss:  0.6963859796524048\n",
      "Write summary at step 15680  Loss:  0.6965612173080444\n",
      "Write summary at step 15690  Loss:  0.6865291595458984\n",
      "Write summary at step 15700  Loss:  0.6842105984687805\n",
      "Write summary at step 15710  Loss:  0.6917322874069214\n",
      "Write summary at step 15720  Loss:  0.6813704967498779\n",
      "Write summary at step 15730  Loss:  0.6910535097122192\n",
      "Write summary at step 15740  Loss:  0.7183793187141418\n",
      "Write summary at step 15750  Loss:  0.6933889389038086\n",
      "Write summary at step 15760  Loss:  0.6857039928436279\n",
      "Write summary at step 15770  Loss:  0.7078878879547119\n",
      "Write summary at step 15780  Loss:  0.7097659111022949\n",
      "Write summary at step 15790  Loss:  0.7165635824203491\n",
      "Write summary at step 15800  Loss:  0.695065975189209\n",
      "Write summary at step 15810  Loss:  0.6967301368713379\n",
      "Write summary at step 15820  Loss:  0.6850086450576782\n",
      "Write summary at step 15830  Loss:  0.7047630548477173\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.01639344262295082 Acurracy Patient:  0.9375 Acurracy Balanced 0.4769467213114754\n",
      "Loss normal: 0.7013109419252965 Loss Control: 0.7077407260410121 Loss Patient: 0.6767974309623241 Loss balanced:  0.6922690785016681 Loss1+loss2: 0.6922690785016681\n",
      "Write summary at step 15840  Loss:  0.6878626346588135\n",
      "Write summary at step 15850  Loss:  0.6900820732116699\n",
      "Write summary at step 15860  Loss:  0.6938313841819763\n",
      "Write summary at step 15870  Loss:  0.7004691362380981\n",
      "Write summary at step 15880  Loss:  0.6746851801872253\n",
      "Write summary at step 15890  Loss:  0.6804395318031311\n",
      "Write summary at step 15900  Loss:  0.6615899205207825\n",
      "Write summary at step 15910  Loss:  0.678572416305542\n",
      "Write summary at step 15920  Loss:  0.6929096579551697\n",
      "Write summary at step 15930  Loss:  0.6902085542678833\n",
      "Write summary at step 15940  Loss:  0.717761754989624\n",
      "Write summary at step 15950  Loss:  0.6808828115463257\n",
      "Write summary at step 15960  Loss:  0.6789877414703369\n",
      "Write summary at step 15970  Loss:  0.7008689641952515\n",
      "Write summary at step 15980  Loss:  0.7015455961227417\n",
      "Write summary at step 15990  Loss:  0.6958683729171753\n",
      "Write summary at step 16000  Loss:  0.6974892616271973\n",
      "Saved checkpoint to: result/9/panns/checkpoint_16000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.5181010928961749\n",
      "Loss normal: 0.6689963505897687 Loss Control: 0.6523440691942726 Loss Patient: 0.7324832168718179 Loss balanced:  0.6924136430330452 Loss1+loss2: 0.6924136430330452\n",
      "Write summary at step 16010  Loss:  0.6690373420715332\n",
      "Write summary at step 16020  Loss:  0.6770333051681519\n",
      "Write summary at step 16030  Loss:  0.6907448768615723\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.5181010928961749\n",
      "Loss normal: 0.6766513193840589 Loss Control: 0.6652539707923848 Loss Patient: 0.7201037121315798 Loss balanced:  0.6926788414619822 Loss1+loss2: 0.6926788414619822\n",
      "Write summary at step 16040  Loss:  0.7092294692993164\n",
      "Write summary at step 16050  Loss:  0.6796560287475586\n",
      "Write summary at step 16060  Loss:  0.6995002031326294\n",
      "Write summary at step 16070  Loss:  0.682260274887085\n",
      "Write summary at step 16080  Loss:  0.693029522895813\n",
      "Write summary at step 16090  Loss:  0.6967941522598267\n",
      "Write summary at step 16100  Loss:  0.6822344660758972\n",
      "Write summary at step 16110  Loss:  0.716570258140564\n",
      "Write summary at step 16120  Loss:  0.7161656618118286\n",
      "Write summary at step 16130  Loss:  0.6829788088798523\n",
      "Write summary at step 16140  Loss:  0.7098616361618042\n",
      "Write summary at step 16150  Loss:  0.6907110214233398\n",
      "Write summary at step 16160  Loss:  0.6926190853118896\n",
      "Write summary at step 16170  Loss:  0.6774114966392517\n",
      "Write summary at step 16180  Loss:  0.7407853603363037\n",
      "Write summary at step 16190  Loss:  0.6842043995857239\n",
      "Write summary at step 16200  Loss:  0.7100504040718079\n",
      "Write summary at step 16210  Loss:  0.6867374181747437\n",
      "Write summary at step 16220  Loss:  0.6948367953300476\n",
      "Write summary at step 16230  Loss:  0.7081043124198914\n",
      "Write summary at step 16240  Loss:  0.6973642110824585\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.48484848484848486 Acurracy Control:  0.4371584699453552 Acurracy Patient:  0.6666666666666666 Acurracy Balanced 0.5519125683060109\n",
      "Loss normal: 0.6952715789600884 Loss Control: 0.6975754756745094 Loss Patient: 0.6864879379669825 Loss balanced:  0.692031706820746 Loss1+loss2: 0.692031706820746\n",
      "Write summary at step 16250  Loss:  0.6962705850601196\n",
      "Write summary at step 16260  Loss:  0.6936855912208557\n",
      "Write summary at step 16270  Loss:  0.6993253827095032\n",
      "Write summary at step 16280  Loss:  0.7019760012626648\n",
      "Write summary at step 16290  Loss:  0.6837801933288574\n",
      "Write summary at step 16300  Loss:  0.7000936269760132\n",
      "Write summary at step 16310  Loss:  0.6894124746322632\n",
      "Write summary at step 16320  Loss:  0.6921950578689575\n",
      "Write summary at step 16330  Loss:  0.68011474609375\n",
      "Write summary at step 16340  Loss:  0.6748255491256714\n",
      "Write summary at step 16350  Loss:  0.6887224912643433\n",
      "Write summary at step 16360  Loss:  0.6879309415817261\n",
      "Write summary at step 16370  Loss:  0.7093466520309448\n",
      "Write summary at step 16380  Loss:  0.6896097660064697\n",
      "Write summary at step 16390  Loss:  0.6849958896636963\n",
      "Write summary at step 16400  Loss:  0.6967505216598511\n",
      "Write summary at step 16410  Loss:  0.7151683568954468\n",
      "Write summary at step 16420  Loss:  0.6996828317642212\n",
      "Write summary at step 16430  Loss:  0.7046421766281128\n",
      "Write summary at step 16440  Loss:  0.6759241819381714\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.125 Acurracy Balanced 0.5515710382513661\n",
      "Loss normal: 0.6817455766520975 Loss Control: 0.6757130466523718 Loss Patient: 0.7047446270783743 Loss balanced:  0.6902288368653731 Loss1+loss2: 0.6902288368653731\n",
      "Write summary at step 16450  Loss:  0.662726879119873\n",
      "Write summary at step 16460  Loss:  0.7009839415550232\n",
      "Write summary at step 16470  Loss:  0.6973422169685364\n",
      "Write summary at step 16480  Loss:  0.6754933595657349\n",
      "Write summary at step 16490  Loss:  0.752549409866333\n",
      "Write summary at step 16500  Loss:  0.7050118446350098\n",
      "Saved checkpoint to: result/9/panns/checkpoint_16500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  1.0 Acurracy Patient:  0.08333333333333333 Acurracy Balanced 0.5416666666666666\n",
      "Loss normal: 0.6475457990324343 Loss Control: 0.6161282036473842 Loss Patient: 0.7673254311084747 Loss balanced:  0.6917268173779294 Loss1+loss2: 0.6917268173779294\n",
      "Write summary at step 16510  Loss:  0.6686697602272034\n",
      "Write summary at step 16520  Loss:  0.693087637424469\n",
      "Write summary at step 16530  Loss:  0.662833034992218\n",
      "Write summary at step 16540  Loss:  0.6604748964309692\n",
      "Write summary at step 16550  Loss:  0.676864504814148\n",
      "Write summary at step 16560  Loss:  0.7009631991386414\n",
      "Write summary at step 16570  Loss:  0.7065439224243164\n",
      "Write summary at step 16580  Loss:  0.6995100975036621\n",
      "Write summary at step 16590  Loss:  0.692007303237915\n",
      "Write summary at step 16600  Loss:  0.6613941192626953\n",
      "Write summary at step 16610  Loss:  0.6937615871429443\n",
      "Write summary at step 16620  Loss:  0.6574649810791016\n",
      "Write summary at step 16630  Loss:  0.7300199270248413\n",
      "Write summary at step 16640  Loss:  0.6507825255393982\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7705627705627706 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.125 Acurracy Balanced 0.5324453551912569\n",
      "Loss normal: 0.6670701679213222 Loss Control: 0.6515906078567921 Loss Patient: 0.7260859658320745 Loss balanced:  0.6888382868444334 Loss1+loss2: 0.6888382868444334\n",
      "\n",
      " > BEST MODEL (0.68884) : result/9/panns/best_checkpoint.pt\n",
      "Write summary at step 16650  Loss:  0.694340705871582\n",
      "Write summary at step 16660  Loss:  0.6745495796203613\n",
      "Write summary at step 16670  Loss:  0.6951978206634521\n",
      "Write summary at step 16680  Loss:  0.690742552280426\n",
      "Write summary at step 16690  Loss:  0.7304675579071045\n",
      "Write summary at step 16700  Loss:  0.6947115659713745\n",
      "Write summary at step 16710  Loss:  0.6557400822639465\n",
      "Write summary at step 16720  Loss:  0.6917178630828857\n",
      "Write summary at step 16730  Loss:  0.6992626190185547\n",
      "Write summary at step 16740  Loss:  0.6657352447509766\n",
      "Write summary at step 16750  Loss:  0.7130851149559021\n",
      "Write summary at step 16760  Loss:  0.7005679607391357\n",
      "Write summary at step 16770  Loss:  0.6816166639328003\n",
      "Write summary at step 16780  Loss:  0.6881985068321228\n",
      "Write summary at step 16790  Loss:  0.7034158706665039\n",
      "Write summary at step 16800  Loss:  0.6854650974273682\n",
      "Write summary at step 16810  Loss:  0.7084008455276489\n",
      "Write summary at step 16820  Loss:  0.6858997344970703\n",
      "Write summary at step 16830  Loss:  0.7205132246017456\n",
      "Write summary at step 16840  Loss:  0.6949188709259033\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5022199453551912\n",
      "Loss normal: 0.6660743686027857 Loss Control: 0.647238147389042 Loss Patient: 0.7378874321778616 Loss balanced:  0.6925627897834518 Loss1+loss2: 0.6925627897834518\n",
      "Write summary at step 16850  Loss:  0.6782957911491394\n",
      "Write summary at step 16860  Loss:  0.731515645980835\n",
      "Write summary at step 16870  Loss:  0.6798801422119141\n",
      "Write summary at step 16880  Loss:  0.6824264526367188\n",
      "Write summary at step 16890  Loss:  0.692133903503418\n",
      "Write summary at step 16900  Loss:  0.7000380754470825\n",
      "Write summary at step 16910  Loss:  0.7121354341506958\n",
      "Write summary at step 16920  Loss:  0.7049716711044312\n",
      "Write summary at step 16930  Loss:  0.6923331022262573\n",
      "Write summary at step 16940  Loss:  0.665999174118042\n",
      "Write summary at step 16950  Loss:  0.6669648885726929\n",
      "Write summary at step 16960  Loss:  0.6568382978439331\n",
      "Write summary at step 16970  Loss:  0.6976474523544312\n",
      "Write summary at step 16980  Loss:  0.6706215143203735\n",
      "Write summary at step 16990  Loss:  0.6693695783615112\n",
      "Write summary at step 17000  Loss:  0.6735169887542725\n",
      "Saved checkpoint to: result/9/panns/checkpoint_17000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.543886612021858\n",
      "Loss normal: 0.665061182015902 Loss Control: 0.6456019360511029 Loss Patient: 0.7392495932678381 Loss balanced:  0.6924257646594705 Loss1+loss2: 0.6924257646594705\n",
      "Write summary at step 17010  Loss:  0.6921359300613403\n",
      "Write summary at step 17020  Loss:  0.6910400390625\n",
      "Write summary at step 17030  Loss:  0.6713089942932129\n",
      "Write summary at step 17040  Loss:  0.7328388690948486\n",
      "Write summary at step 17050  Loss:  0.7365241646766663\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  1.0 Acurracy Patient:  0.0625 Acurracy Balanced 0.53125\n",
      "Loss normal: 0.6686174905661381 Loss Control: 0.651279325042266 Loss Patient: 0.7347192404170831 Loss balanced:  0.6929992827296746 Loss1+loss2: 0.6929992827296746\n",
      "Write summary at step 17060  Loss:  0.6698028445243835\n",
      "Write summary at step 17070  Loss:  0.7177044749259949\n",
      "Write summary at step 17080  Loss:  0.6710464954376221\n",
      "Write summary at step 17090  Loss:  0.679515540599823\n",
      "Write summary at step 17100  Loss:  0.688080906867981\n",
      "Write summary at step 17110  Loss:  0.7147535085678101\n",
      "Write summary at step 17120  Loss:  0.6876749396324158\n",
      "Write summary at step 17130  Loss:  0.6995664238929749\n",
      "Write summary at step 17140  Loss:  0.6882224082946777\n",
      "Write summary at step 17150  Loss:  0.7062118053436279\n",
      "Write summary at step 17160  Loss:  0.6694817543029785\n",
      "Write summary at step 17170  Loss:  0.6992506384849548\n",
      "Write summary at step 17180  Loss:  0.7019754648208618\n",
      "Write summary at step 17190  Loss:  0.713263750076294\n",
      "Write summary at step 17200  Loss:  0.7224521040916443\n",
      "Write summary at step 17210  Loss:  0.6831715703010559\n",
      "Write summary at step 17220  Loss:  0.6662700772285461\n",
      "Write summary at step 17230  Loss:  0.6576291918754578\n",
      "Write summary at step 17240  Loss:  0.6780838966369629\n",
      "Write summary at step 17250  Loss:  0.7109386324882507\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.1875 Acurracy Balanced 0.5418374316939891\n",
      "Loss normal: 0.6793451208572883 Loss Control: 0.6712716449805296 Loss Patient: 0.7101253171761831 Loss balanced:  0.6906984810783563 Loss1+loss2: 0.6906984810783563\n",
      "Write summary at step 17260  Loss:  0.7025941610336304\n",
      "Write summary at step 17270  Loss:  0.6844033002853394\n",
      "Write summary at step 17280  Loss:  0.6864656805992126\n",
      "Write summary at step 17290  Loss:  0.6706821918487549\n",
      "Write summary at step 17300  Loss:  0.6931440830230713\n",
      "Write summary at step 17310  Loss:  0.6605384349822998\n",
      "Write summary at step 17320  Loss:  0.7170183658599854\n",
      "Write summary at step 17330  Loss:  0.6894608736038208\n",
      "Write summary at step 17340  Loss:  0.7115873098373413\n",
      "Write summary at step 17350  Loss:  0.6743906736373901\n",
      "Write summary at step 17360  Loss:  0.6344224810600281\n",
      "Write summary at step 17370  Loss:  0.6780343055725098\n",
      "Write summary at step 17380  Loss:  0.7252020835876465\n",
      "Write summary at step 17390  Loss:  0.6916494369506836\n",
      "Write summary at step 17400  Loss:  0.6739741563796997\n",
      "Write summary at step 17410  Loss:  0.6749610304832458\n",
      "Write summary at step 17420  Loss:  0.7009425759315491\n",
      "Write summary at step 17430  Loss:  0.6911896467208862\n",
      "Write summary at step 17440  Loss:  0.6744529604911804\n",
      "Write summary at step 17450  Loss:  0.6820001006126404\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.125 Acurracy Balanced 0.5297131147540983\n",
      "Loss normal: 0.6797339887846083 Loss Control: 0.6714038904247388 Loss Patient: 0.711492427935203 Loss balanced:  0.6914481591799708 Loss1+loss2: 0.6914481591799708\n",
      "Write summary at step 17460  Loss:  0.6867181062698364\n",
      "Write summary at step 17470  Loss:  0.6967043876647949\n",
      "Write summary at step 17480  Loss:  0.6760427951812744\n",
      "Write summary at step 17490  Loss:  0.6983249187469482\n",
      "Write summary at step 17500  Loss:  0.6733658313751221\n",
      "Saved checkpoint to: result/9/panns/checkpoint_17500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.543886612021858\n",
      "Loss normal: 0.6722941950802163 Loss Control: 0.6584347447410959 Loss Patient: 0.725133358190457 Loss balanced:  0.6917840514657765 Loss1+loss2: 0.6917840514657765\n",
      "Write summary at step 17510  Loss:  0.7134166359901428\n",
      "Write summary at step 17520  Loss:  0.6623514890670776\n",
      "Write summary at step 17530  Loss:  0.6870962381362915\n",
      "Write summary at step 17540  Loss:  0.6859838366508484\n",
      "Write summary at step 17550  Loss:  0.690980851650238\n",
      "Write summary at step 17560  Loss:  0.705674409866333\n",
      "Write summary at step 17570  Loss:  0.6822632551193237\n",
      "Write summary at step 17580  Loss:  0.6538301706314087\n",
      "Write summary at step 17590  Loss:  0.7158703804016113\n",
      "Write summary at step 17600  Loss:  0.6780004501342773\n",
      "Write summary at step 17610  Loss:  0.6514830589294434\n",
      "Write summary at step 17620  Loss:  0.7112752199172974\n",
      "Write summary at step 17630  Loss:  0.698112428188324\n",
      "Write summary at step 17640  Loss:  0.7337712049484253\n",
      "Write summary at step 17650  Loss:  0.6907263994216919\n",
      "Write summary at step 17660  Loss:  0.6776552200317383\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4675324675324675 Acurracy Control:  0.4207650273224044 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5332991803278688\n",
      "Loss normal: 0.6902985608938969 Loss Control: 0.6888151474989177 Loss Patient: 0.6959540657699108 Loss balanced:  0.6923846066344143 Loss1+loss2: 0.6923846066344143\n",
      "Write summary at step 17670  Loss:  0.6556285619735718\n",
      "Write summary at step 17680  Loss:  0.6692174673080444\n",
      "Write summary at step 17690  Loss:  0.6669012308120728\n",
      "Write summary at step 17700  Loss:  0.703082263469696\n",
      "Write summary at step 17710  Loss:  0.6093496084213257\n",
      "Write summary at step 17720  Loss:  0.6936551332473755\n",
      "Write summary at step 17730  Loss:  0.6974970102310181\n",
      "Write summary at step 17740  Loss:  0.7306065559387207\n",
      "Write summary at step 17750  Loss:  0.7153000235557556\n",
      "Write summary at step 17760  Loss:  0.7371424436569214\n",
      "Write summary at step 17770  Loss:  0.7116608023643494\n",
      "Write summary at step 17780  Loss:  0.6849199533462524\n",
      "Write summary at step 17790  Loss:  0.6981608867645264\n",
      "Write summary at step 17800  Loss:  0.6826729774475098\n",
      "Write summary at step 17810  Loss:  0.6777453422546387\n",
      "Write summary at step 17820  Loss:  0.6945521831512451\n",
      "Write summary at step 17830  Loss:  0.6895477175712585\n",
      "Write summary at step 17840  Loss:  0.7139742374420166\n",
      "Write summary at step 17850  Loss:  0.6877986192703247\n",
      "Write summary at step 17860  Loss:  0.7300510406494141\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7445887445887446 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.0625 Acurracy Balanced 0.49299863387978143\n",
      "Loss normal: 0.6397464148926012 Loss Control: 0.5986875168612746 Loss Patient: 0.7962834872305393 Loss balanced:  0.697485502045907 Loss1+loss2: 0.697485502045907\n",
      "Write summary at step 17870  Loss:  0.6815423369407654\n",
      "Write summary at step 17880  Loss:  0.7081421613693237\n",
      "Write summary at step 17890  Loss:  0.6983673572540283\n",
      "Write summary at step 17900  Loss:  0.6941208839416504\n",
      "Write summary at step 17910  Loss:  0.6577527523040771\n",
      "Write summary at step 17920  Loss:  0.7051721811294556\n",
      "Write summary at step 17930  Loss:  0.7358949184417725\n",
      "Write summary at step 17940  Loss:  0.7347927093505859\n",
      "Write summary at step 17950  Loss:  0.7243893146514893\n",
      "Write summary at step 17960  Loss:  0.696932315826416\n",
      "Write summary at step 17970  Loss:  0.6853548288345337\n",
      "Write summary at step 17980  Loss:  0.7021613121032715\n",
      "Write summary at step 17990  Loss:  0.6955845355987549\n",
      "Write summary at step 18000  Loss:  0.6857432126998901\n",
      "Saved checkpoint to: result/9/panns/checkpoint_18000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2727272727272727 Acurracy Control:  0.1092896174863388 Acurracy Patient:  0.8958333333333334 Acurracy Balanced 0.5025614754098361\n",
      "Loss normal: 0.7109055005626761 Loss Control: 0.7219084888859525 Loss Patient: 0.6689566398660342 Loss balanced:  0.6954325643759933 Loss1+loss2: 0.6954325643759933\n",
      "Write summary at step 18010  Loss:  0.6946728825569153\n",
      "Write summary at step 18020  Loss:  0.6892490386962891\n",
      "Write summary at step 18030  Loss:  0.6691884994506836\n",
      "Write summary at step 18040  Loss:  0.6932728886604309\n",
      "Write summary at step 18050  Loss:  0.697050929069519\n",
      "Write summary at step 18060  Loss:  0.727597713470459\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2813852813852814 Acurracy Control:  0.1366120218579235 Acurracy Patient:  0.8333333333333334 Acurracy Balanced 0.48497267759562845\n",
      "Loss normal: 0.7114003927676709 Loss Control: 0.7194422522529227 Loss Patient: 0.6807407389084498 Loss balanced:  0.7000914955806863 Loss1+loss2: 0.7000914955806863\n",
      "Write summary at step 18070  Loss:  0.6867055296897888\n",
      "Write summary at step 18080  Loss:  0.6648014783859253\n",
      "Write summary at step 18090  Loss:  0.6902186870574951\n",
      "Write summary at step 18100  Loss:  0.7430552244186401\n",
      "Write summary at step 18110  Loss:  0.6628873944282532\n",
      "Write summary at step 18120  Loss:  0.6621441841125488\n",
      "Write summary at step 18130  Loss:  0.7025780081748962\n",
      "Write summary at step 18140  Loss:  0.6616277694702148\n",
      "Write summary at step 18150  Loss:  0.6935173869132996\n",
      "Write summary at step 18160  Loss:  0.6955852508544922\n",
      "Write summary at step 18170  Loss:  0.6778956651687622\n",
      "Write summary at step 18180  Loss:  0.6872687339782715\n",
      "Write summary at step 18190  Loss:  0.6786829233169556\n",
      "Write summary at step 18200  Loss:  0.6979602575302124\n",
      "Write summary at step 18210  Loss:  0.6689387559890747\n",
      "Write summary at step 18220  Loss:  0.6587861776351929\n",
      "Write summary at step 18230  Loss:  0.6848528981208801\n",
      "Write summary at step 18240  Loss:  0.6825370788574219\n",
      "Write summary at step 18250  Loss:  0.7666469812393188\n",
      "Write summary at step 18260  Loss:  0.708465039730072\n",
      "Write summary at step 18270  Loss:  0.6547695398330688\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.45021645021645024 Acurracy Control:  0.3989071038251366 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5223702185792349\n",
      "Loss normal: 0.6943247145388549 Loss Control: 0.6952984297210402 Loss Patient: 0.6906124179561933 Loss balanced:  0.6929554238386167 Loss1+loss2: 0.6929554238386167\n",
      "Write summary at step 18280  Loss:  0.6562836170196533\n",
      "Write summary at step 18290  Loss:  0.6800278425216675\n",
      "Write summary at step 18300  Loss:  0.6934001445770264\n",
      "Write summary at step 18310  Loss:  0.7027006149291992\n",
      "Write summary at step 18320  Loss:  0.6927486062049866\n",
      "Write summary at step 18330  Loss:  0.7396821975708008\n",
      "Write summary at step 18340  Loss:  0.7311078310012817\n",
      "Write summary at step 18350  Loss:  0.7157747745513916\n",
      "Write summary at step 18360  Loss:  0.6940112709999084\n",
      "Write summary at step 18370  Loss:  0.6716458797454834\n",
      "Write summary at step 18380  Loss:  0.6995235681533813\n",
      "Write summary at step 18390  Loss:  0.6888946890830994\n",
      "Write summary at step 18400  Loss:  0.6916660070419312\n",
      "Write summary at step 18410  Loss:  0.7011222839355469\n",
      "Write summary at step 18420  Loss:  0.6844221949577332\n",
      "Write summary at step 18430  Loss:  0.6840531229972839\n",
      "Write summary at step 18440  Loss:  0.6977120637893677\n",
      "Write summary at step 18450  Loss:  0.6426515579223633\n",
      "Write summary at step 18460  Loss:  0.7053250670433044\n",
      "Write summary at step 18470  Loss:  0.7362731099128723\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.35064935064935066 Acurracy Control:  0.22950819672131148 Acurracy Patient:  0.8125 Acurracy Balanced 0.5210040983606558\n",
      "Loss normal: 0.7074580724105174 Loss Control: 0.7185971587082076 Loss Patient: 0.6649903456370035 Loss balanced:  0.6917937521726056 Loss1+loss2: 0.6917937521726056\n",
      "Write summary at step 18480  Loss:  0.6837000846862793\n",
      "Write summary at step 18490  Loss:  0.6636953353881836\n",
      "Write summary at step 18500  Loss:  0.6732597351074219\n",
      "Saved checkpoint to: result/9/panns/checkpoint_18500.pt\n",
      "Validation:\n",
      "Acurracy:  0.4155844155844156 Acurracy Control:  0.3551912568306011 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5005122950819673\n",
      "Loss normal: 0.698049026392239 Loss Control: 0.7015046646686199 Loss Patient: 0.6848744017382463 Loss balanced:  0.6931895332034331 Loss1+loss2: 0.6931895332034331\n",
      "Write summary at step 18510  Loss:  0.7464064359664917\n",
      "Write summary at step 18520  Loss:  0.6942888498306274\n",
      "Write summary at step 18530  Loss:  0.7170454263687134\n",
      "Write summary at step 18540  Loss:  0.6687130928039551\n",
      "Write summary at step 18550  Loss:  0.6905790567398071\n",
      "Write summary at step 18560  Loss:  0.6709907054901123\n",
      "Write summary at step 18570  Loss:  0.7178561687469482\n",
      "Write summary at step 18580  Loss:  0.6993339657783508\n",
      "Write summary at step 18590  Loss:  0.7089882493019104\n",
      "Write summary at step 18600  Loss:  0.7005574703216553\n",
      "Write summary at step 18610  Loss:  0.685799241065979\n",
      "Write summary at step 18620  Loss:  0.6873489618301392\n",
      "Write summary at step 18630  Loss:  0.6733201146125793\n",
      "Write summary at step 18640  Loss:  0.7084671258926392\n",
      "Write summary at step 18650  Loss:  0.6947321891784668\n",
      "Write summary at step 18660  Loss:  0.6860649585723877\n",
      "Write summary at step 18670  Loss:  0.7102473378181458\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4675324675324675 Acurracy Control:  0.453551912568306 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.48719262295081966\n",
      "Loss normal: 0.6927298544805287 Loss Control: 0.6923402248184538 Loss Patient: 0.6942153684794903 Loss balanced:  0.693277796648972 Loss1+loss2: 0.693277796648972\n",
      "Write summary at step 18680  Loss:  0.6915693283081055\n",
      "Write summary at step 18690  Loss:  0.703056812286377\n",
      "Write summary at step 18700  Loss:  0.6799508333206177\n",
      "Write summary at step 18710  Loss:  0.7073663473129272\n",
      "Write summary at step 18720  Loss:  0.6892586946487427\n",
      "Write summary at step 18730  Loss:  0.6777188777923584\n",
      "Write summary at step 18740  Loss:  0.6485660076141357\n",
      "Write summary at step 18750  Loss:  0.7054789066314697\n",
      "Write summary at step 18760  Loss:  0.6997044086456299\n",
      "Write summary at step 18770  Loss:  0.7000608444213867\n",
      "Write summary at step 18780  Loss:  0.6775659322738647\n",
      "Write summary at step 18790  Loss:  0.6917858123779297\n",
      "Write summary at step 18800  Loss:  0.6706728935241699\n",
      "Write summary at step 18810  Loss:  0.6709604263305664\n",
      "Write summary at step 18820  Loss:  0.6274648904800415\n",
      "Write summary at step 18830  Loss:  0.6720116138458252\n",
      "Write summary at step 18840  Loss:  0.6132082939147949\n",
      "Write summary at step 18850  Loss:  0.6380282640457153\n",
      "Write summary at step 18860  Loss:  0.6729945540428162\n",
      "Write summary at step 18870  Loss:  0.6982161998748779\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.354978354978355 Acurracy Control:  0.26229508196721313 Acurracy Patient:  0.7083333333333334 Acurracy Balanced 0.4853142076502732\n",
      "Loss normal: 0.7096427519084055 Loss Control: 0.7166400177231251 Loss Patient: 0.6829656759897867 Loss balanced:  0.6998028468564559 Loss1+loss2: 0.6998028468564559\n",
      "Write summary at step 18880  Loss:  0.7369730472564697\n",
      "Write summary at step 18890  Loss:  0.6131207346916199\n",
      "Write summary at step 18900  Loss:  0.6491529941558838\n",
      "Write summary at step 18910  Loss:  0.7015531063079834\n",
      "Write summary at step 18920  Loss:  0.7133959531784058\n",
      "Write summary at step 18930  Loss:  0.6786974668502808\n",
      "Write summary at step 18940  Loss:  0.6842427849769592\n",
      "Write summary at step 18950  Loss:  0.6768144369125366\n",
      "Write summary at step 18960  Loss:  0.732741117477417\n",
      "Write summary at step 18970  Loss:  0.6835856437683105\n",
      "Write summary at step 18980  Loss:  0.6886416077613831\n",
      "Write summary at step 18990  Loss:  0.7306832075119019\n",
      "Write summary at step 19000  Loss:  0.6791059374809265\n",
      "Saved checkpoint to: result/9/panns/checkpoint_19000.pt\n",
      "Validation:\n",
      "Acurracy:  0.29004329004329005 Acurracy Control:  0.12021857923497267 Acurracy Patient:  0.9375 Acurracy Balanced 0.5288592896174863\n",
      "Loss normal: 0.7221601153865005 Loss Control: 0.7419158161663618 Loss Patient: 0.6468415260314941 Loss balanced:  0.6943786710989279 Loss1+loss2: 0.6943786710989279\n",
      "Write summary at step 19010  Loss:  0.6860182881355286\n",
      "Write summary at step 19020  Loss:  0.6647921800613403\n",
      "Write summary at step 19030  Loss:  0.70716392993927\n",
      "Write summary at step 19040  Loss:  0.707139253616333\n",
      "Write summary at step 19050  Loss:  0.6614459156990051\n",
      "Write summary at step 19060  Loss:  0.6873705387115479\n",
      "Write summary at step 19070  Loss:  0.6729998588562012\n",
      "Write summary at step 19080  Loss:  0.691999614238739\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.47619047619047616 Acurracy Control:  0.48633879781420764 Acurracy Patient:  0.4375 Acurracy Balanced 0.4619193989071038\n",
      "Loss normal: 0.6923750651863231 Loss Control: 0.6903189436985495 Loss Patient: 0.700214018424352 Loss balanced:  0.6952664810614508 Loss1+loss2: 0.6952664810614508\n",
      "Write summary at step 19090  Loss:  0.6745584011077881\n",
      "Write summary at step 19100  Loss:  0.6924210786819458\n",
      "Write summary at step 19110  Loss:  0.7047790288925171\n",
      "Write summary at step 19120  Loss:  0.6718844175338745\n",
      "Write summary at step 19130  Loss:  0.7080168724060059\n",
      "Write summary at step 19140  Loss:  0.6413440704345703\n",
      "Write summary at step 19150  Loss:  0.6373871564865112\n",
      "Write summary at step 19160  Loss:  0.7178940773010254\n",
      "Write summary at step 19170  Loss:  0.7366113662719727\n",
      "Write summary at step 19180  Loss:  0.6983142495155334\n",
      "Write summary at step 19190  Loss:  0.7082107067108154\n",
      "Write summary at step 19200  Loss:  0.6572705507278442\n",
      "Write summary at step 19210  Loss:  0.6746646165847778\n",
      "Write summary at step 19220  Loss:  0.6625393629074097\n",
      "Write summary at step 19230  Loss:  0.7210728526115417\n",
      "Write summary at step 19240  Loss:  0.6816186904907227\n",
      "Write summary at step 19250  Loss:  0.6918408870697021\n",
      "Write summary at step 19260  Loss:  0.7122105360031128\n",
      "Write summary at step 19270  Loss:  0.6802850961685181\n",
      "Write summary at step 19280  Loss:  0.7238147854804993\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3463203463203463 Acurracy Control:  0.24043715846994534 Acurracy Patient:  0.75 Acurracy Balanced 0.4952185792349727\n",
      "Loss normal: 0.7245022267490239 Loss Control: 0.7419568251390927 Loss Patient: 0.6579565815627575 Loss balanced:  0.6999567033509251 Loss1+loss2: 0.6999567033509251\n",
      "Write summary at step 19290  Loss:  0.6838884949684143\n",
      "Write summary at step 19300  Loss:  0.6191279888153076\n",
      "Write summary at step 19310  Loss:  0.7211800813674927\n",
      "Write summary at step 19320  Loss:  0.6872189044952393\n",
      "Write summary at step 19330  Loss:  0.6541671752929688\n",
      "Write summary at step 19340  Loss:  0.6815029382705688\n",
      "Write summary at step 19350  Loss:  0.7158282995223999\n",
      "Write summary at step 19360  Loss:  0.7157556414604187\n",
      "Write summary at step 19370  Loss:  0.6533174514770508\n",
      "Write summary at step 19380  Loss:  0.6805226802825928\n",
      "Write summary at step 19390  Loss:  0.6714348793029785\n",
      "Write summary at step 19400  Loss:  0.7447853684425354\n",
      "Write summary at step 19410  Loss:  0.687475323677063\n",
      "Write summary at step 19420  Loss:  0.6839267015457153\n",
      "Write summary at step 19430  Loss:  0.6356773972511292\n",
      "Write summary at step 19440  Loss:  0.7427945733070374\n",
      "Write summary at step 19450  Loss:  0.6654627919197083\n",
      "Write summary at step 19460  Loss:  0.6432451009750366\n",
      "Write summary at step 19470  Loss:  0.7643471956253052\n",
      "Write summary at step 19480  Loss:  0.6728273630142212\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2554112554112554 Acurracy Control:  0.07103825136612021 Acurracy Patient:  0.9583333333333334 Acurracy Balanced 0.5146857923497268\n",
      "Loss normal: 0.7431338122396758 Loss Control: 0.7745711152019397 Loss Patient: 0.623279103388389 Loss balanced:  0.6989251092951643 Loss1+loss2: 0.6989251092951643\n",
      "Write summary at step 19490  Loss:  0.6954160332679749\n",
      "Write summary at step 19500  Loss:  0.7071090936660767\n",
      "Saved checkpoint to: result/9/panns/checkpoint_19500.pt\n",
      "Validation:\n",
      "Acurracy:  0.26406926406926406 Acurracy Control:  0.09289617486338798 Acurracy Patient:  0.9166666666666666 Acurracy Balanced 0.5047814207650273\n",
      "Loss normal: 0.7406046380212297 Loss Control: 0.7699956867864223 Loss Patient: 0.6285512745380402 Loss balanced:  0.6992734806622312 Loss1+loss2: 0.6992734806622312\n",
      "Write summary at step 19510  Loss:  0.6754878163337708\n",
      "Write summary at step 19520  Loss:  0.6488689184188843\n",
      "Write summary at step 19530  Loss:  0.6664125919342041\n",
      "Write summary at step 19540  Loss:  0.6902331113815308\n",
      "Write summary at step 19550  Loss:  0.6317929029464722\n",
      "Write summary at step 19560  Loss:  0.7545314431190491\n",
      "Write summary at step 19570  Loss:  0.635860800743103\n",
      "Write summary at step 19580  Loss:  0.6811445355415344\n",
      "Write summary at step 19590  Loss:  0.6930246353149414\n",
      "Write summary at step 19600  Loss:  0.6359984874725342\n",
      "Write summary at step 19610  Loss:  0.7565686106681824\n",
      "Write summary at step 19620  Loss:  0.729158878326416\n",
      "Write summary at step 19630  Loss:  0.6933314204216003\n",
      "Write summary at step 19640  Loss:  0.7072924375534058\n",
      "Write summary at step 19650  Loss:  0.6290897727012634\n",
      "Write summary at step 19660  Loss:  0.6362155675888062\n",
      "Write summary at step 19670  Loss:  0.8069407939910889\n",
      "Write summary at step 19680  Loss:  0.6734305024147034\n",
      "Write summary at step 19690  Loss:  0.692649245262146\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4199134199134199 Acurracy Control:  0.32786885245901637 Acurracy Patient:  0.7708333333333334 Acurracy Balanced 0.5493510928961749\n",
      "Loss normal: 0.7053187690772019 Loss Control: 0.7145499534945671 Loss Patient: 0.6701248586177826 Loss balanced:  0.6923374060561749 Loss1+loss2: 0.6923374060561749\n",
      "Write summary at step 19700  Loss:  0.7072567343711853\n",
      "Write summary at step 19710  Loss:  0.7195022106170654\n",
      "Write summary at step 19720  Loss:  0.6119256019592285\n",
      "Write summary at step 19730  Loss:  0.698326051235199\n",
      "Write summary at step 19740  Loss:  0.6913670897483826\n",
      "Write summary at step 19750  Loss:  0.7240918874740601\n",
      "Write summary at step 19760  Loss:  0.7701641321182251\n",
      "Write summary at step 19770  Loss:  0.6287016272544861\n",
      "Write summary at step 19780  Loss:  0.6288228034973145\n",
      "Write summary at step 19790  Loss:  0.675001859664917\n",
      "Write summary at step 19800  Loss:  0.6408767700195312\n",
      "Write summary at step 19810  Loss:  0.7178934216499329\n",
      "Write summary at step 19820  Loss:  0.748447060585022\n",
      "Write summary at step 19830  Loss:  0.7005321979522705\n",
      "Write summary at step 19840  Loss:  0.7608170509338379\n",
      "Write summary at step 19850  Loss:  0.6586533784866333\n",
      "Write summary at step 19860  Loss:  0.6743015050888062\n",
      "Write summary at step 19870  Loss:  0.7251209020614624\n",
      "Write summary at step 19880  Loss:  0.705125093460083\n",
      "Write summary at step 19890  Loss:  0.7474250793457031\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.43722943722943725 Acurracy Control:  0.40437158469945356 Acurracy Patient:  0.5625 Acurracy Balanced 0.4834357923497268\n",
      "Loss normal: 0.6953396683647519 Loss Control: 0.6945606750217291 Loss Patient: 0.6983095792432626 Loss balanced:  0.6964351271324959 Loss1+loss2: 0.6964351271324959\n",
      "Write summary at step 19900  Loss:  0.6762586832046509\n",
      "Write summary at step 19910  Loss:  0.6331943273544312\n",
      "Write summary at step 19920  Loss:  0.70316481590271\n",
      "Write summary at step 19930  Loss:  0.6694127917289734\n",
      "Write summary at step 19940  Loss:  0.7154396176338196\n",
      "Write summary at step 19950  Loss:  0.7136654257774353\n",
      "Write summary at step 19960  Loss:  0.6506165266036987\n",
      "Write summary at step 19970  Loss:  0.6555147171020508\n",
      "Write summary at step 19980  Loss:  0.6638278961181641\n",
      "Write summary at step 19990  Loss:  0.7143712639808655\n",
      "Write summary at step 20000  Loss:  0.632642388343811\n",
      "Saved checkpoint to: result/9/panns/checkpoint_20000.pt\n",
      "Validation:\n",
      "Acurracy:  0.354978354978355 Acurracy Control:  0.26229508196721313 Acurracy Patient:  0.7083333333333334 Acurracy Balanced 0.4853142076502732\n",
      "Loss normal: 0.7125915552114511 Loss Control: 0.7238513289904985 Loss Patient: 0.6696636714041233 Loss balanced:  0.696757500197311 Loss1+loss2: 0.696757500197311\n",
      "Write summary at step 20010  Loss:  0.6857996582984924\n",
      "Write summary at step 20020  Loss:  0.7078925371170044\n",
      "Write summary at step 20030  Loss:  0.714613676071167\n",
      "Write summary at step 20040  Loss:  0.7065283060073853\n",
      "Write summary at step 20050  Loss:  0.701882004737854\n",
      "Write summary at step 20060  Loss:  0.67494797706604\n",
      "Write summary at step 20070  Loss:  0.7179746031761169\n",
      "Write summary at step 20080  Loss:  0.717318058013916\n",
      "Write summary at step 20090  Loss:  0.6899824142456055\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7186147186147186 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.1875 Acurracy Balanced 0.5227117486338797\n",
      "Loss normal: 0.6358407152679576 Loss Control: 0.593795896227894 Loss Patient: 0.7961365766823292 Loss balanced:  0.6949662364551116 Loss1+loss2: 0.6949662364551116\n",
      "Write summary at step 20100  Loss:  0.7104244828224182\n",
      "Write summary at step 20110  Loss:  0.6616705656051636\n",
      "Write summary at step 20120  Loss:  0.6644837260246277\n",
      "Write summary at step 20130  Loss:  0.6769884824752808\n",
      "Write summary at step 20140  Loss:  0.7501137256622314\n",
      "Write summary at step 20150  Loss:  0.6687710881233215\n",
      "Write summary at step 20160  Loss:  0.6991201639175415\n",
      "Write summary at step 20170  Loss:  0.635562539100647\n",
      "Write summary at step 20180  Loss:  0.6872119903564453\n",
      "Write summary at step 20190  Loss:  0.6869683861732483\n",
      "Write summary at step 20200  Loss:  0.679305911064148\n",
      "Write summary at step 20210  Loss:  0.696924090385437\n",
      "Write summary at step 20220  Loss:  0.6805484890937805\n",
      "Write summary at step 20230  Loss:  0.6743041276931763\n",
      "Write summary at step 20240  Loss:  0.6619623899459839\n",
      "Write summary at step 20250  Loss:  0.6607117652893066\n",
      "Write summary at step 20260  Loss:  0.6558277010917664\n",
      "Write summary at step 20270  Loss:  0.6741819977760315\n",
      "Write summary at step 20280  Loss:  0.691442608833313\n",
      "Write summary at step 20290  Loss:  0.6471058130264282\n",
      "Write summary at step 20300  Loss:  0.7755758762359619\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.37662337662337664 Acurracy Control:  0.30601092896174864 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.475922131147541\n",
      "Loss normal: 0.7122823810164547 Loss Control: 0.7200973854690301 Loss Patient: 0.6824876641233762 Loss balanced:  0.7012925247962032 Loss1+loss2: 0.7012925247962032\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/run/media/viblab/Markov1/Abil/Tugas Akhir/Progress 4/Github_Cough/script/train.py\", line 89, in <module>\n",
      "    print(\"SEED:\",s, \"Best Loss:\", loss)\n",
      "NameError: name 's' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Time dim Lenght is: 1498 (+- 29.96 seconds)\n",
      "The Min Time dim Lenght is: 19 (+- 0.38 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.6404058933258057\n",
      "Write summary at step 20  Loss:  0.9507796764373779\n",
      "Write summary at step 30  Loss:  0.6973340511322021\n",
      "Write summary at step 40  Loss:  0.7304366827011108\n",
      "Write summary at step 50  Loss:  0.8715453147888184\n",
      "Write summary at step 60  Loss:  0.783595085144043\n",
      "Write summary at step 70  Loss:  0.6315101981163025\n",
      "Write summary at step 80  Loss:  0.6849467158317566\n",
      "Write summary at step 90  Loss:  0.670199990272522\n",
      "Write summary at step 100  Loss:  0.620061457157135\n",
      "Write summary at step 110  Loss:  0.722298264503479\n",
      "Write summary at step 120  Loss:  0.7122515439987183\n",
      "Write summary at step 130  Loss:  0.6720514297485352\n",
      "Write summary at step 140  Loss:  0.7037301063537598\n",
      "Write summary at step 150  Loss:  0.7666443586349487\n",
      "Write summary at step 160  Loss:  0.7566205263137817\n",
      "Write summary at step 170  Loss:  0.6686447858810425\n",
      "Write summary at step 180  Loss:  0.7463980913162231\n",
      "Write summary at step 190  Loss:  0.7731888890266418\n",
      "Write summary at step 200  Loss:  0.7341526746749878\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.04918032786885246 Acurracy Patient:  0.8541666666666666 Acurracy Balanced 0.4516734972677595\n",
      "Loss normal: 0.7583283954884583 Loss Control: 0.7889187726818148 Loss Patient: 0.6417026221752167 Loss balanced:  0.7153106974285157 Loss1+loss2: 0.7153106974285157\n",
      "\n",
      " > BEST MODEL (0.71531) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 210  Loss:  0.811230480670929\n",
      "Write summary at step 220  Loss:  0.7348861694335938\n",
      "Write summary at step 230  Loss:  0.7087488174438477\n",
      "Write summary at step 240  Loss:  0.742355227470398\n",
      "Write summary at step 250  Loss:  0.6970438957214355\n",
      "Write summary at step 260  Loss:  0.7494498491287231\n",
      "Write summary at step 270  Loss:  0.7561179995536804\n",
      "Write summary at step 280  Loss:  0.785060703754425\n",
      "Write summary at step 290  Loss:  0.6768896579742432\n",
      "Write summary at step 300  Loss:  0.6412009000778198\n",
      "Write summary at step 310  Loss:  0.6692701578140259\n",
      "Write summary at step 320  Loss:  1.0024555921554565\n",
      "Write summary at step 330  Loss:  0.9815486073493958\n",
      "Write summary at step 340  Loss:  0.7210589647293091\n",
      "Write summary at step 350  Loss:  0.6582874059677124\n",
      "Write summary at step 360  Loss:  0.6627294421195984\n",
      "Write summary at step 370  Loss:  0.6967740058898926\n",
      "Write summary at step 380  Loss:  0.6671945452690125\n",
      "Write summary at step 390  Loss:  0.6688660979270935\n",
      "Write summary at step 400  Loss:  0.7365228533744812\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6147186147186147 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.4375 Acurracy Balanced 0.5493510928961749\n",
      "Loss normal: 0.6335839409848828 Loss Control: 0.5871888692261743 Loss Patient: 0.8104651918013891 Loss balanced:  0.6988270305137817 Loss1+loss2: 0.6988270305137817\n",
      "\n",
      " > BEST MODEL (0.69883) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 410  Loss:  0.5671164989471436\n",
      "Write summary at step 420  Loss:  0.6985175609588623\n",
      "Write summary at step 430  Loss:  0.670901894569397\n",
      "Write summary at step 440  Loss:  0.6513704061508179\n",
      "Write summary at step 450  Loss:  0.7521896362304688\n",
      "Write summary at step 460  Loss:  0.7101684808731079\n",
      "Write summary at step 470  Loss:  0.7490131855010986\n",
      "Write summary at step 480  Loss:  0.9373888969421387\n",
      "Write summary at step 490  Loss:  0.8223237991333008\n",
      "Write summary at step 500  Loss:  0.782188892364502\n",
      "Saved checkpoint to: result/30/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 1.1813077044177365 Loss Control: 1.4138408964448939 Loss Patient: 0.29477486790468294 Loss balanced:  0.8543078821747884 Loss1+loss2: 0.8543078821747884\n",
      "Write summary at step 510  Loss:  0.6844356656074524\n",
      "Write summary at step 520  Loss:  0.7314887046813965\n",
      "Write summary at step 530  Loss:  0.6792724132537842\n",
      "Write summary at step 540  Loss:  0.6307845711708069\n",
      "Write summary at step 550  Loss:  0.7862457633018494\n",
      "Write summary at step 560  Loss:  0.8199594020843506\n",
      "Write summary at step 570  Loss:  0.8181670904159546\n",
      "Write summary at step 580  Loss:  0.6615568399429321\n",
      "Write summary at step 590  Loss:  0.6424715518951416\n",
      "Write summary at step 600  Loss:  0.7924542427062988\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.42424242424242425 Acurracy Control:  0.366120218579235 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5059767759562842\n",
      "Loss normal: 0.7078234757179822 Loss Control: 0.717992473821171 Loss Patient: 0.6690541505813599 Loss balanced:  0.6935233122012654 Loss1+loss2: 0.6935233122012654\n",
      "\n",
      " > BEST MODEL (0.69352) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 610  Loss:  0.7505826950073242\n",
      "Write summary at step 620  Loss:  0.8346623182296753\n",
      "Write summary at step 630  Loss:  0.6991380453109741\n",
      "Write summary at step 640  Loss:  0.6571778059005737\n",
      "Write summary at step 650  Loss:  0.6124266982078552\n",
      "Write summary at step 660  Loss:  0.7317912578582764\n",
      "Write summary at step 670  Loss:  0.7648959159851074\n",
      "Write summary at step 680  Loss:  0.7819157838821411\n",
      "Write summary at step 690  Loss:  0.7216569781303406\n",
      "Write summary at step 700  Loss:  0.8174837827682495\n",
      "Write summary at step 710  Loss:  0.7005536556243896\n",
      "Write summary at step 720  Loss:  0.7578861713409424\n",
      "Write summary at step 730  Loss:  0.7187576293945312\n",
      "Write summary at step 740  Loss:  0.7604882717132568\n",
      "Write summary at step 750  Loss:  0.6539018154144287\n",
      "Write summary at step 760  Loss:  0.7780681848526001\n",
      "Write summary at step 770  Loss:  0.6941863298416138\n",
      "Write summary at step 780  Loss:  0.7943243980407715\n",
      "Write summary at step 790  Loss:  0.6659417748451233\n",
      "Write summary at step 800  Loss:  0.5783044099807739\n",
      "Write summary at step 810  Loss:  0.7696715593338013\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  1.0 Acurracy Patient:  0.0625 Acurracy Balanced 0.53125\n",
      "Loss normal: 0.6616708133127782 Loss Control: 0.6412219173921262 Loss Patient: 0.7396322165926298 Loss balanced:  0.690427066992378 Loss1+loss2: 0.690427066992378\n",
      "\n",
      " > BEST MODEL (0.69043) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 820  Loss:  0.7288508415222168\n",
      "Write summary at step 830  Loss:  0.7767407298088074\n",
      "Write summary at step 840  Loss:  0.678519070148468\n",
      "Write summary at step 850  Loss:  0.6838827133178711\n",
      "Write summary at step 860  Loss:  0.6676607131958008\n",
      "Write summary at step 870  Loss:  0.6723215579986572\n",
      "Write summary at step 880  Loss:  0.6766409873962402\n",
      "Write summary at step 890  Loss:  0.5768629312515259\n",
      "Write summary at step 900  Loss:  0.7035025358200073\n",
      "Write summary at step 910  Loss:  0.7463914155960083\n",
      "Write summary at step 920  Loss:  0.8050168752670288\n",
      "Write summary at step 930  Loss:  0.7391332983970642\n",
      "Write summary at step 940  Loss:  0.6612401008605957\n",
      "Write summary at step 950  Loss:  0.7399095296859741\n",
      "Write summary at step 960  Loss:  0.6559476852416992\n",
      "Write summary at step 970  Loss:  0.7299299240112305\n",
      "Write summary at step 980  Loss:  0.8088083267211914\n",
      "Write summary at step 990  Loss:  0.7022101879119873\n",
      "Write summary at step 1000  Loss:  0.7501047849655151\n",
      "Saved checkpoint to: result/30/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5327868852459017\n",
      "Loss normal: 0.6777842323501388 Loss Control: 0.6636350845378605 Loss Patient: 0.7317278894285361 Loss balanced:  0.6976814869831982 Loss1+loss2: 0.6976814869831982\n",
      "Write summary at step 1010  Loss:  0.7375737428665161\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.125 Acurracy Balanced 0.4832650273224044\n",
      "Loss normal: 0.6277154886619353 Loss Control: 0.5314841636868773 Loss Patient: 0.9945974846680959 Loss balanced:  0.7630408241774866 Loss1+loss2: 0.7630408241774866\n",
      "Write summary at step 1020  Loss:  0.866301417350769\n",
      "Write summary at step 1030  Loss:  0.65230393409729\n",
      "Write summary at step 1040  Loss:  0.7041827440261841\n",
      "Write summary at step 1050  Loss:  0.6968464255332947\n",
      "Write summary at step 1060  Loss:  0.6917303204536438\n",
      "Write summary at step 1070  Loss:  0.7324629426002502\n",
      "Write summary at step 1080  Loss:  0.6430627107620239\n",
      "Write summary at step 1090  Loss:  0.5953806638717651\n",
      "Write summary at step 1100  Loss:  0.7242323756217957\n",
      "Write summary at step 1110  Loss:  0.6933826208114624\n",
      "Write summary at step 1120  Loss:  0.6817130446434021\n",
      "Write summary at step 1130  Loss:  0.6459363698959351\n",
      "Write summary at step 1140  Loss:  0.8135638236999512\n",
      "Write summary at step 1150  Loss:  0.6772541999816895\n",
      "Write summary at step 1160  Loss:  0.6847846508026123\n",
      "Write summary at step 1170  Loss:  0.7603683471679688\n",
      "Write summary at step 1180  Loss:  0.728929877281189\n",
      "Write summary at step 1190  Loss:  0.7592244148254395\n",
      "Write summary at step 1200  Loss:  0.6811963319778442\n",
      "Write summary at step 1210  Loss:  0.6679449081420898\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7619047619047619 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5654030054644809\n",
      "Loss normal: 0.6430656953807518 Loss Control: 0.6038017263177966 Loss Patient: 0.7927595550815264 Loss balanced:  0.6982806406996616 Loss1+loss2: 0.6982806406996616\n",
      "Write summary at step 1220  Loss:  0.7008386254310608\n",
      "Write summary at step 1230  Loss:  0.6433594822883606\n",
      "Write summary at step 1240  Loss:  0.7094534635543823\n",
      "Write summary at step 1250  Loss:  0.6961437463760376\n",
      "Write summary at step 1260  Loss:  0.7119282484054565\n",
      "Write summary at step 1270  Loss:  0.6704822778701782\n",
      "Write summary at step 1280  Loss:  0.6919018030166626\n",
      "Write summary at step 1290  Loss:  0.6879135370254517\n",
      "Write summary at step 1300  Loss:  0.6747198104858398\n",
      "Write summary at step 1310  Loss:  0.619040310382843\n",
      "Write summary at step 1320  Loss:  0.762226939201355\n",
      "Write summary at step 1330  Loss:  0.7007783055305481\n",
      "Write summary at step 1340  Loss:  0.753106951713562\n",
      "Write summary at step 1350  Loss:  0.667477548122406\n",
      "Write summary at step 1360  Loss:  0.65016770362854\n",
      "Write summary at step 1370  Loss:  0.7058033347129822\n",
      "Write summary at step 1380  Loss:  0.6750224828720093\n",
      "Write summary at step 1390  Loss:  0.6803028583526611\n",
      "Write summary at step 1400  Loss:  0.6733448505401611\n",
      "Write summary at step 1410  Loss:  0.6662857532501221\n",
      "Write summary at step 1420  Loss:  0.7570778727531433\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0 Acurracy Balanced 0.49453551912568305\n",
      "Loss normal: 0.6705069807700781 Loss Control: 0.6540185177261061 Loss Patient: 0.7333692076305548 Loss balanced:  0.6936938626783304 Loss1+loss2: 0.6936938626783304\n",
      "Write summary at step 1430  Loss:  0.6800150275230408\n",
      "Write summary at step 1440  Loss:  0.7028361558914185\n",
      "Write summary at step 1450  Loss:  0.7250103950500488\n",
      "Write summary at step 1460  Loss:  0.7379530668258667\n",
      "Write summary at step 1470  Loss:  0.6882141828536987\n",
      "Write summary at step 1480  Loss:  0.6603196859359741\n",
      "Write summary at step 1490  Loss:  0.6785593032836914\n",
      "Write summary at step 1500  Loss:  0.568892240524292\n",
      "Saved checkpoint to: result/30/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7840996340755776 Loss Control: 0.841162391699077 Loss Patient: 0.566547941416502 Loss balanced:  0.7038551665577895 Loss1+loss2: 0.7038551665577895\n",
      "Write summary at step 1510  Loss:  0.7794791460037231\n",
      "Write summary at step 1520  Loss:  0.6571176052093506\n",
      "Write summary at step 1530  Loss:  0.6659002304077148\n",
      "Write summary at step 1540  Loss:  0.7351374626159668\n",
      "Write summary at step 1550  Loss:  0.6337822675704956\n",
      "Write summary at step 1560  Loss:  0.8212665915489197\n",
      "Write summary at step 1570  Loss:  0.7260991334915161\n",
      "Write summary at step 1580  Loss:  0.7433210611343384\n",
      "Write summary at step 1590  Loss:  0.6618080735206604\n",
      "Write summary at step 1600  Loss:  0.8001184463500977\n",
      "Write summary at step 1610  Loss:  0.6220566630363464\n",
      "Write summary at step 1620  Loss:  0.7014641761779785\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.19480519480519481 Acurracy Control:  0.03278688524590164 Acurracy Patient:  0.8125 Acurracy Balanced 0.42264344262295084\n",
      "Loss normal: 0.7009913689130313 Loss Control: 0.700666297980345 Loss Patient: 0.702230674525102 Loss balanced:  0.7014484862527235 Loss1+loss2: 0.7014484862527235\n",
      "Write summary at step 1630  Loss:  0.6782532930374146\n",
      "Write summary at step 1640  Loss:  0.6747305393218994\n",
      "Write summary at step 1650  Loss:  0.6669036746025085\n",
      "Write summary at step 1660  Loss:  0.7047450542449951\n",
      "Write summary at step 1670  Loss:  0.6952605247497559\n",
      "Write summary at step 1680  Loss:  0.6867847442626953\n",
      "Write summary at step 1690  Loss:  0.6902850866317749\n",
      "Write summary at step 1700  Loss:  0.6771646738052368\n",
      "Write summary at step 1710  Loss:  0.6659966707229614\n",
      "Write summary at step 1720  Loss:  0.8303001523017883\n",
      "Write summary at step 1730  Loss:  0.6763123869895935\n",
      "Write summary at step 1740  Loss:  0.690250039100647\n",
      "Write summary at step 1750  Loss:  0.7518792152404785\n",
      "Write summary at step 1760  Loss:  0.6760114431381226\n",
      "Write summary at step 1770  Loss:  0.675948977470398\n",
      "Write summary at step 1780  Loss:  0.672281801700592\n",
      "Write summary at step 1790  Loss:  0.6915611624717712\n",
      "Write summary at step 1800  Loss:  0.662704348564148\n",
      "Write summary at step 1810  Loss:  0.6951028108596802\n",
      "Write summary at step 1820  Loss:  0.8378877639770508\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5076844262295082\n",
      "Loss normal: 0.6171599447211146 Loss Control: 0.5447854736789328 Loss Patient: 0.8930876019100348 Loss balanced:  0.7189365377944839 Loss1+loss2: 0.7189365377944839\n",
      "Write summary at step 1830  Loss:  0.655274510383606\n",
      "Write summary at step 1840  Loss:  0.6918783187866211\n",
      "Write summary at step 1850  Loss:  0.7417202591896057\n",
      "Write summary at step 1860  Loss:  0.7045372128486633\n",
      "Write summary at step 1870  Loss:  0.6852817535400391\n",
      "Write summary at step 1880  Loss:  0.7199615240097046\n",
      "Write summary at step 1890  Loss:  0.7352259159088135\n",
      "Write summary at step 1900  Loss:  0.7060467004776001\n",
      "Write summary at step 1910  Loss:  0.7641218304634094\n",
      "Write summary at step 1920  Loss:  0.6809006333351135\n",
      "Write summary at step 1930  Loss:  0.6927523016929626\n",
      "Write summary at step 1940  Loss:  0.6824573278427124\n",
      "Write summary at step 1950  Loss:  0.696245014667511\n",
      "Write summary at step 1960  Loss:  0.6738760471343994\n",
      "Write summary at step 1970  Loss:  0.6861562728881836\n",
      "Write summary at step 1980  Loss:  0.7544448971748352\n",
      "Write summary at step 1990  Loss:  0.6818172931671143\n",
      "Write summary at step 2000  Loss:  0.6813435554504395\n",
      "Saved checkpoint to: result/30/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6837402540883977 Loss Control: 0.673017433432282 Loss Patient: 0.7246209941804409 Loss balanced:  0.6988192138063615 Loss1+loss2: 0.6988192138063615\n",
      "Write summary at step 2010  Loss:  0.7519314885139465\n",
      "Write summary at step 2020  Loss:  0.6958487629890442\n",
      "Write summary at step 2030  Loss:  0.6534218788146973\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.18614718614718614 Acurracy Control:  0.01092896174863388 Acurracy Patient:  0.8541666666666666 Acurracy Balanced 0.43254781420765026\n",
      "Loss normal: 0.7327788492817899 Loss Control: 0.7501170866476382 Loss Patient: 0.6666768280168375 Loss balanced:  0.7083969573322378 Loss1+loss2: 0.7083969573322378\n",
      "Write summary at step 2040  Loss:  0.7690989971160889\n",
      "Write summary at step 2050  Loss:  0.7593741416931152\n",
      "Write summary at step 2060  Loss:  0.6846272945404053\n",
      "Write summary at step 2070  Loss:  0.7079750895500183\n",
      "Write summary at step 2080  Loss:  0.7023153901100159\n",
      "Write summary at step 2090  Loss:  0.6902850866317749\n",
      "Write summary at step 2100  Loss:  0.6619808077812195\n",
      "Write summary at step 2110  Loss:  0.6882505416870117\n",
      "Write summary at step 2120  Loss:  0.6484714150428772\n",
      "Write summary at step 2130  Loss:  0.7021510004997253\n",
      "Write summary at step 2140  Loss:  0.6484845280647278\n",
      "Write summary at step 2150  Loss:  0.686482310295105\n",
      "Write summary at step 2160  Loss:  0.7822695374488831\n",
      "Write summary at step 2170  Loss:  0.731329083442688\n",
      "Write summary at step 2180  Loss:  0.6417776346206665\n",
      "Write summary at step 2190  Loss:  0.6797139048576355\n",
      "Write summary at step 2200  Loss:  0.6998242139816284\n",
      "Write summary at step 2210  Loss:  0.6852810382843018\n",
      "Write summary at step 2220  Loss:  0.6920523643493652\n",
      "Write summary at step 2230  Loss:  0.7116261720657349\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7705627705627706 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.0625 Acurracy Balanced 0.5093920765027322\n",
      "Loss normal: 0.6305022162276429 Loss Control: 0.5601149888637939 Loss Patient: 0.8988535677393278 Loss balanced:  0.7294842783015608 Loss1+loss2: 0.7294842783015608\n",
      "Write summary at step 2240  Loss:  0.7046794295310974\n",
      "Write summary at step 2250  Loss:  0.7107312679290771\n",
      "Write summary at step 2260  Loss:  0.7209810018539429\n",
      "Write summary at step 2270  Loss:  0.7031058669090271\n",
      "Write summary at step 2280  Loss:  0.8032440543174744\n",
      "Write summary at step 2290  Loss:  0.714457631111145\n",
      "Write summary at step 2300  Loss:  0.6291249394416809\n",
      "Write summary at step 2310  Loss:  0.7175981998443604\n",
      "Write summary at step 2320  Loss:  0.7218111157417297\n",
      "Write summary at step 2330  Loss:  0.6839178204536438\n",
      "Write summary at step 2340  Loss:  0.7321728467941284\n",
      "Write summary at step 2350  Loss:  0.6962610483169556\n",
      "Write summary at step 2360  Loss:  0.697076141834259\n",
      "Write summary at step 2370  Loss:  0.693652868270874\n",
      "Write summary at step 2380  Loss:  0.6918041110038757\n",
      "Write summary at step 2390  Loss:  0.6758286952972412\n",
      "Write summary at step 2400  Loss:  0.7011317610740662\n",
      "Write summary at step 2410  Loss:  0.6875054836273193\n",
      "Write summary at step 2420  Loss:  0.6187706589698792\n",
      "Write summary at step 2430  Loss:  0.6352858543395996\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.641338330197644 Loss Control: 0.5841433824411507 Loss Patient: 0.8593940585851669 Loss balanced:  0.7217687205131589 Loss1+loss2: 0.7217687205131589\n",
      "Write summary at step 2440  Loss:  0.6851500272750854\n",
      "Write summary at step 2450  Loss:  0.7425456047058105\n",
      "Write summary at step 2460  Loss:  0.6642486453056335\n",
      "Write summary at step 2470  Loss:  0.6929113268852234\n",
      "Write summary at step 2480  Loss:  0.709484338760376\n",
      "Write summary at step 2490  Loss:  0.7141063213348389\n",
      "Write summary at step 2500  Loss:  0.7245174646377563\n",
      "Saved checkpoint to: result/30/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.22510822510822512 Acurracy Control:  0.08743169398907104 Acurracy Patient:  0.75 Acurracy Balanced 0.4187158469945355\n",
      "Loss normal: 0.7132492026725372 Loss Control: 0.7221130806891645 Loss Patient: 0.6794556664923826 Loss balanced:  0.7007843735907735 Loss1+loss2: 0.7007843735907735\n",
      "Write summary at step 2510  Loss:  0.7219257354736328\n",
      "Write summary at step 2520  Loss:  0.6644774675369263\n",
      "Write summary at step 2530  Loss:  0.671265721321106\n",
      "Write summary at step 2540  Loss:  0.6942663192749023\n",
      "Write summary at step 2550  Loss:  0.6978343725204468\n",
      "Write summary at step 2560  Loss:  0.6793676614761353\n",
      "Write summary at step 2570  Loss:  0.6516613364219666\n",
      "Write summary at step 2580  Loss:  0.7091218829154968\n",
      "Write summary at step 2590  Loss:  0.686324954032898\n",
      "Write summary at step 2600  Loss:  0.7075288891792297\n",
      "Write summary at step 2610  Loss:  0.7068783044815063\n",
      "Write summary at step 2620  Loss:  0.7235129475593567\n",
      "Write summary at step 2630  Loss:  0.7259626388549805\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5522540983606558\n",
      "Loss normal: 0.6641047893664538 Loss Control: 0.6465658587836177 Loss Patient: 0.7309719957411289 Loss balanced:  0.6887689272623734 Loss1+loss2: 0.6887689272623734\n",
      "\n",
      " > BEST MODEL (0.68877) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 2640  Loss:  0.6843458414077759\n",
      "Write summary at step 2650  Loss:  0.7050608396530151\n",
      "Write summary at step 2660  Loss:  0.6788907051086426\n",
      "Write summary at step 2670  Loss:  0.7337824106216431\n",
      "Write summary at step 2680  Loss:  0.7202068567276001\n",
      "Write summary at step 2690  Loss:  0.6664689779281616\n",
      "Write summary at step 2700  Loss:  0.6387319564819336\n",
      "Write summary at step 2710  Loss:  0.7343460321426392\n",
      "Write summary at step 2720  Loss:  0.7031362652778625\n",
      "Write summary at step 2730  Loss:  0.6890507936477661\n",
      "Write summary at step 2740  Loss:  0.7120236754417419\n",
      "Write summary at step 2750  Loss:  0.6361505389213562\n",
      "Write summary at step 2760  Loss:  0.6875678300857544\n",
      "Write summary at step 2770  Loss:  0.697821319103241\n",
      "Write summary at step 2780  Loss:  0.7023591995239258\n",
      "Write summary at step 2790  Loss:  0.7169744968414307\n",
      "Write summary at step 2800  Loss:  0.6687418818473816\n",
      "Write summary at step 2810  Loss:  0.7254065275192261\n",
      "Write summary at step 2820  Loss:  0.6728537678718567\n",
      "Write summary at step 2830  Loss:  0.7295547723770142\n",
      "Write summary at step 2840  Loss:  0.6750339865684509\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5396174863387978\n",
      "Loss normal: 0.6413305837870676 Loss Control: 0.6016659554236573 Loss Patient: 0.7925519732137521 Loss balanced:  0.6971089643187047 Loss1+loss2: 0.6971089643187047\n",
      "Write summary at step 2850  Loss:  0.680894672870636\n",
      "Write summary at step 2860  Loss:  0.687901496887207\n",
      "Write summary at step 2870  Loss:  0.6670197248458862\n",
      "Write summary at step 2880  Loss:  0.7097097039222717\n",
      "Write summary at step 2890  Loss:  0.6817893981933594\n",
      "Write summary at step 2900  Loss:  0.7081738710403442\n",
      "Write summary at step 2910  Loss:  0.6936423182487488\n",
      "Write summary at step 2920  Loss:  0.7398881912231445\n",
      "Write summary at step 2930  Loss:  0.7310154438018799\n",
      "Write summary at step 2940  Loss:  0.6720636487007141\n",
      "Write summary at step 2950  Loss:  0.6649219989776611\n",
      "Write summary at step 2960  Loss:  0.7017841339111328\n",
      "Write summary at step 2970  Loss:  0.7164382934570312\n",
      "Write summary at step 2980  Loss:  0.637836217880249\n",
      "Write summary at step 2990  Loss:  0.6808465719223022\n",
      "Write summary at step 3000  Loss:  0.6792904138565063\n",
      "Saved checkpoint to: result/30/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6753246753246753 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5261270491803278\n",
      "Loss normal: 0.6482786714256584 Loss Control: 0.6101316461146203 Loss Patient: 0.7937141669293245 Loss balanced:  0.7019229065219724 Loss1+loss2: 0.7019229065219724\n",
      "Write summary at step 3010  Loss:  0.6004383563995361\n",
      "Write summary at step 3020  Loss:  0.6887189149856567\n",
      "Write summary at step 3030  Loss:  0.6831951141357422\n",
      "Write summary at step 3040  Loss:  0.7040001153945923\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6796536796536796 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.51349043715847\n",
      "Loss normal: 0.6517334817807912 Loss Control: 0.614550780403158 Loss Patient: 0.7934925382335981 Loss balanced:  0.7040216593183781 Loss1+loss2: 0.7040216593183781\n",
      "Write summary at step 3050  Loss:  0.7828009128570557\n",
      "Write summary at step 3060  Loss:  0.687336802482605\n",
      "Write summary at step 3070  Loss:  0.7471975684165955\n",
      "Write summary at step 3080  Loss:  0.6587104201316833\n",
      "Write summary at step 3090  Loss:  0.6682246923446655\n",
      "Write summary at step 3100  Loss:  0.7075947523117065\n",
      "Write summary at step 3110  Loss:  0.7068158388137817\n",
      "Write summary at step 3120  Loss:  0.6797037124633789\n",
      "Write summary at step 3130  Loss:  0.696304440498352\n",
      "Write summary at step 3140  Loss:  0.6588044166564941\n",
      "Write summary at step 3150  Loss:  0.7185673713684082\n",
      "Write summary at step 3160  Loss:  0.6917162537574768\n",
      "Write summary at step 3170  Loss:  0.7260195016860962\n",
      "Write summary at step 3180  Loss:  0.6488571763038635\n",
      "Write summary at step 3190  Loss:  0.681427001953125\n",
      "Write summary at step 3200  Loss:  0.7385162115097046\n",
      "Write summary at step 3210  Loss:  0.6714781522750854\n",
      "Write summary at step 3220  Loss:  0.6886593103408813\n",
      "Write summary at step 3230  Loss:  0.6816151142120361\n",
      "Write summary at step 3240  Loss:  0.7010343074798584\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5974025974025974 Acurracy Control:  0.6721311475409836 Acurracy Patient:  0.3125 Acurracy Balanced 0.4923155737704918\n",
      "Loss normal: 0.6713483676765905 Loss Control: 0.6495603814802534 Loss Patient: 0.7544150340060393 Loss balanced:  0.7019877077431463 Loss1+loss2: 0.7019877077431463\n",
      "Write summary at step 3250  Loss:  0.6910146474838257\n",
      "Write summary at step 3260  Loss:  0.7047617435455322\n",
      "Write summary at step 3270  Loss:  0.6932961344718933\n",
      "Write summary at step 3280  Loss:  0.7461826801300049\n",
      "Write summary at step 3290  Loss:  0.7126368284225464\n",
      "Write summary at step 3300  Loss:  0.698046088218689\n",
      "Write summary at step 3310  Loss:  0.7431025505065918\n",
      "Write summary at step 3320  Loss:  0.6744828820228577\n",
      "Write summary at step 3330  Loss:  0.6682127714157104\n",
      "Write summary at step 3340  Loss:  0.6098099946975708\n",
      "Write summary at step 3350  Loss:  0.6937382221221924\n",
      "Write summary at step 3360  Loss:  0.7368733286857605\n",
      "Write summary at step 3370  Loss:  0.7271265983581543\n",
      "Write summary at step 3380  Loss:  0.6874606013298035\n",
      "Write summary at step 3390  Loss:  0.6553156971931458\n",
      "Write summary at step 3400  Loss:  0.6670997142791748\n",
      "Write summary at step 3410  Loss:  0.6305918097496033\n",
      "Write summary at step 3420  Loss:  0.7565874457359314\n",
      "Write summary at step 3430  Loss:  0.7204394936561584\n",
      "Write summary at step 3440  Loss:  0.7396069169044495\n",
      "Write summary at step 3450  Loss:  0.7073758244514465\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.5302254098360656\n",
      "Loss normal: 0.5794611414531609 Loss Control: 0.48462394466165637 Loss Patient: 0.9410279554625353 Loss balanced:  0.7128259500620958 Loss1+loss2: 0.7128259500620958\n",
      "Write summary at step 3460  Loss:  0.7078399062156677\n",
      "Write summary at step 3470  Loss:  0.6548308730125427\n",
      "Write summary at step 3480  Loss:  0.691712498664856\n",
      "Write summary at step 3490  Loss:  0.69769287109375\n",
      "Write summary at step 3500  Loss:  0.7571852207183838\n",
      "Saved checkpoint to: result/30/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.48036202185792354\n",
      "Loss normal: 0.6520487606783449 Loss Control: 0.611961646809604 Loss Patient: 0.804880873610576 Loss balanced:  0.70842126021009 Loss1+loss2: 0.70842126021009\n",
      "Write summary at step 3510  Loss:  0.696398913860321\n",
      "Write summary at step 3520  Loss:  0.6864182949066162\n",
      "Write summary at step 3530  Loss:  0.6494420170783997\n",
      "Write summary at step 3540  Loss:  0.6490813493728638\n",
      "Write summary at step 3550  Loss:  0.6354057788848877\n",
      "Write summary at step 3560  Loss:  0.6671984195709229\n",
      "Write summary at step 3570  Loss:  0.6254110336303711\n",
      "Write summary at step 3580  Loss:  0.7278609275817871\n",
      "Write summary at step 3590  Loss:  0.7667766809463501\n",
      "Write summary at step 3600  Loss:  0.6301467418670654\n",
      "Write summary at step 3610  Loss:  0.655842661857605\n",
      "Write summary at step 3620  Loss:  0.6893196105957031\n",
      "Write summary at step 3630  Loss:  0.6795458793640137\n",
      "Write summary at step 3640  Loss:  0.6846898794174194\n",
      "Write summary at step 3650  Loss:  0.7099764347076416\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6796536796536796 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5058060109289617\n",
      "Loss normal: 0.6348539988199869 Loss Control: 0.5889113235994766 Loss Patient: 0.810010431955258 Loss balanced:  0.6994608777773673 Loss1+loss2: 0.6994608777773673\n",
      "Write summary at step 3660  Loss:  0.666824460029602\n",
      "Write summary at step 3670  Loss:  0.7012155055999756\n",
      "Write summary at step 3680  Loss:  0.7198330163955688\n",
      "Write summary at step 3690  Loss:  0.7623531818389893\n",
      "Write summary at step 3700  Loss:  0.7277222871780396\n",
      "Write summary at step 3710  Loss:  0.6773478388786316\n",
      "Write summary at step 3720  Loss:  0.7231780290603638\n",
      "Write summary at step 3730  Loss:  0.73126220703125\n",
      "Write summary at step 3740  Loss:  0.6946077346801758\n",
      "Write summary at step 3750  Loss:  0.6531470417976379\n",
      "Write summary at step 3760  Loss:  0.7532931566238403\n",
      "Write summary at step 3770  Loss:  0.7632290720939636\n",
      "Write summary at step 3780  Loss:  0.6741392016410828\n",
      "Write summary at step 3790  Loss:  0.6584373712539673\n",
      "Write summary at step 3800  Loss:  0.6441658735275269\n",
      "Write summary at step 3810  Loss:  0.7397828698158264\n",
      "Write summary at step 3820  Loss:  0.6635254621505737\n",
      "Write summary at step 3830  Loss:  0.6856154203414917\n",
      "Write summary at step 3840  Loss:  0.6781787276268005\n",
      "Write summary at step 3850  Loss:  0.6677899360656738\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.5340785310639964 Loss Control: 0.37776199080904976 Loss Patient: 1.1300353333353996 Loss balanced:  0.7538986620722247 Loss1+loss2: 0.7538986620722247\n",
      "Write summary at step 3860  Loss:  0.7118659019470215\n",
      "Write summary at step 3870  Loss:  0.6196171045303345\n",
      "Write summary at step 3880  Loss:  0.6857949495315552\n",
      "Write summary at step 3890  Loss:  0.639218807220459\n",
      "Write summary at step 3900  Loss:  0.6964079141616821\n",
      "Write summary at step 3910  Loss:  0.6941564679145813\n",
      "Write summary at step 3920  Loss:  0.7247146368026733\n",
      "Write summary at step 3930  Loss:  0.6886341571807861\n",
      "Write summary at step 3940  Loss:  0.7187175154685974\n",
      "Write summary at step 3950  Loss:  0.7088518142700195\n",
      "Write summary at step 3960  Loss:  0.6985107660293579\n",
      "Write summary at step 3970  Loss:  0.6984574794769287\n",
      "Write summary at step 3980  Loss:  0.6868171691894531\n",
      "Write summary at step 3990  Loss:  0.7150482535362244\n",
      "Write summary at step 4000  Loss:  0.6863718628883362\n",
      "Saved checkpoint to: result/30/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.4155844155844156 Acurracy Control:  0.3879781420765027 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.45440573770491804\n",
      "Loss normal: 0.7147531573906606 Loss Control: 0.7223539433844103 Loss Patient: 0.6857751657565435 Loss balanced:  0.7040645545704769 Loss1+loss2: 0.7040645545704769\n",
      "Write summary at step 4010  Loss:  0.7253409624099731\n",
      "Write summary at step 4020  Loss:  0.7245541214942932\n",
      "Write summary at step 4030  Loss:  0.6964269280433655\n",
      "Write summary at step 4040  Loss:  0.6916743516921997\n",
      "Write summary at step 4050  Loss:  0.6539881229400635\n",
      "Write summary at step 4060  Loss:  0.7445061206817627\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2510822510822511 Acurracy Control:  0.1092896174863388 Acurracy Patient:  0.7916666666666666 Acurracy Balanced 0.4504781420765027\n",
      "Loss normal: 0.7610389074205837 Loss Control: 0.7967239588987632 Loss Patient: 0.624989602714777 Loss balanced:  0.7108567808067701 Loss1+loss2: 0.7108567808067701\n",
      "Write summary at step 4070  Loss:  0.7415414452552795\n",
      "Write summary at step 4080  Loss:  0.6693117022514343\n",
      "Write summary at step 4090  Loss:  0.73947674036026\n",
      "Write summary at step 4100  Loss:  0.6806553602218628\n",
      "Write summary at step 4110  Loss:  0.7255434989929199\n",
      "Write summary at step 4120  Loss:  0.6554311513900757\n",
      "Write summary at step 4130  Loss:  0.7088660001754761\n",
      "Write summary at step 4140  Loss:  0.6644253730773926\n",
      "Write summary at step 4150  Loss:  0.6444897651672363\n",
      "Write summary at step 4160  Loss:  0.6691740155220032\n",
      "Write summary at step 4170  Loss:  0.7576889991760254\n",
      "Write summary at step 4180  Loss:  0.7704629898071289\n",
      "Write summary at step 4190  Loss:  0.6737245321273804\n",
      "Write summary at step 4200  Loss:  0.6502940654754639\n",
      "Write summary at step 4210  Loss:  0.7095637321472168\n",
      "Write summary at step 4220  Loss:  0.6369748115539551\n",
      "Write summary at step 4230  Loss:  0.6568804979324341\n",
      "Write summary at step 4240  Loss:  0.6611328125\n",
      "Write summary at step 4250  Loss:  0.6653745174407959\n",
      "Write summary at step 4260  Loss:  0.9147594571113586\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.0 Acurracy Balanced 0.4972677595628415\n",
      "Loss normal: 0.6835914148396743 Loss Control: 0.6727582502886246 Loss Patient: 0.7248929006357988 Loss balanced:  0.6988255754622117 Loss1+loss2: 0.6988255754622117\n",
      "Write summary at step 4270  Loss:  0.6949204206466675\n",
      "Write summary at step 4280  Loss:  0.6676574349403381\n",
      "Write summary at step 4290  Loss:  0.6722498536109924\n",
      "Write summary at step 4300  Loss:  0.6881917715072632\n",
      "Write summary at step 4310  Loss:  0.6309527158737183\n",
      "Write summary at step 4320  Loss:  0.7339320182800293\n",
      "Write summary at step 4330  Loss:  0.6825505495071411\n",
      "Write summary at step 4340  Loss:  0.683546781539917\n",
      "Write summary at step 4350  Loss:  0.6965382695198059\n",
      "Write summary at step 4360  Loss:  0.7047459483146667\n",
      "Write summary at step 4370  Loss:  0.6842873096466064\n",
      "Write summary at step 4380  Loss:  0.6092511415481567\n",
      "Write summary at step 4390  Loss:  0.6180621385574341\n",
      "Write summary at step 4400  Loss:  0.6095759272575378\n",
      "Write summary at step 4410  Loss:  0.7318428754806519\n",
      "Write summary at step 4420  Loss:  0.6223665475845337\n",
      "Write summary at step 4430  Loss:  0.6772142648696899\n",
      "Write summary at step 4440  Loss:  0.5640904903411865\n",
      "Write summary at step 4450  Loss:  0.5872362852096558\n",
      "Write summary at step 4460  Loss:  0.6273522973060608\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4458874458874459 Acurracy Control:  0.43169398907103823 Acurracy Patient:  0.5 Acurracy Balanced 0.46584699453551914\n",
      "Loss normal: 0.7021831593988261 Loss Control: 0.7036736096189322 Loss Patient: 0.6965008353193601 Loss balanced:  0.7000872224691461 Loss1+loss2: 0.7000872224691461\n",
      "Write summary at step 4470  Loss:  0.6232916116714478\n",
      "Write summary at step 4480  Loss:  0.6471030712127686\n",
      "Write summary at step 4490  Loss:  0.7697518467903137\n",
      "Write summary at step 4500  Loss:  0.7086154818534851\n",
      "Saved checkpoint to: result/30/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.26406926406926406 Acurracy Control:  0.10382513661202186 Acurracy Patient:  0.875 Acurracy Balanced 0.48941256830601093\n",
      "Loss normal: 0.7561814746299347 Loss Control: 0.7937685221922203 Loss Patient: 0.6128808570404848 Loss balanced:  0.7033246896163525 Loss1+loss2: 0.7033246896163525\n",
      "Write summary at step 4510  Loss:  0.6742984652519226\n",
      "Write summary at step 4520  Loss:  0.6849466562271118\n",
      "Write summary at step 4530  Loss:  0.671445369720459\n",
      "Write summary at step 4540  Loss:  0.6656811237335205\n",
      "Write summary at step 4550  Loss:  0.6602560877799988\n",
      "Write summary at step 4560  Loss:  0.7794139385223389\n",
      "Write summary at step 4570  Loss:  0.7051277160644531\n",
      "Write summary at step 4580  Loss:  0.6467992067337036\n",
      "Write summary at step 4590  Loss:  0.6946350336074829\n",
      "Write summary at step 4600  Loss:  0.6531876921653748\n",
      "Write summary at step 4610  Loss:  0.6848279237747192\n",
      "Write summary at step 4620  Loss:  0.7440711259841919\n",
      "Write summary at step 4630  Loss:  0.721718966960907\n",
      "Write summary at step 4640  Loss:  0.691561222076416\n",
      "Write summary at step 4650  Loss:  0.6731956005096436\n",
      "Write summary at step 4660  Loss:  0.6168910264968872\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5021645021645021 Acurracy Control:  0.5081967213114754 Acurracy Patient:  0.4791666666666667 Acurracy Balanced 0.493681693989071\n",
      "Loss normal: 0.6907975880098549 Loss Control: 0.6708079439694764 Loss Patient: 0.7670080537597338 Loss balanced:  0.7189079988646051 Loss1+loss2: 0.7189079988646051\n",
      "Write summary at step 4670  Loss:  0.6949498653411865\n",
      "Write summary at step 4680  Loss:  0.6290861368179321\n",
      "Write summary at step 4690  Loss:  0.7313473224639893\n",
      "Write summary at step 4700  Loss:  0.611501157283783\n",
      "Write summary at step 4710  Loss:  0.7188990116119385\n",
      "Write summary at step 4720  Loss:  0.5782235860824585\n",
      "Write summary at step 4730  Loss:  0.5881041288375854\n",
      "Write summary at step 4740  Loss:  0.6406801342964172\n",
      "Write summary at step 4750  Loss:  0.7024726867675781\n",
      "Write summary at step 4760  Loss:  0.607499361038208\n",
      "Write summary at step 4770  Loss:  0.7403090000152588\n",
      "Write summary at step 4780  Loss:  0.6956700682640076\n",
      "Write summary at step 4790  Loss:  0.6030117273330688\n",
      "Write summary at step 4800  Loss:  0.6985580921173096\n",
      "Write summary at step 4810  Loss:  0.6416949033737183\n",
      "Write summary at step 4820  Loss:  0.6347533464431763\n",
      "Write summary at step 4830  Loss:  0.6840859651565552\n",
      "Write summary at step 4840  Loss:  0.8941709995269775\n",
      "Write summary at step 4850  Loss:  0.6741995811462402\n",
      "Write summary at step 4860  Loss:  0.6220182776451111\n",
      "Write summary at step 4870  Loss:  0.6494431495666504\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4329004329004329 Acurracy Control:  0.3879781420765027 Acurracy Patient:  0.6041666666666666 Acurracy Balanced 0.4960724043715847\n",
      "Loss normal: 0.7195873306943225 Loss Control: 0.7384743775174918 Loss Patient: 0.6475804050763448 Loss balanced:  0.6930273912969183 Loss1+loss2: 0.6930273912969183\n",
      "Write summary at step 4880  Loss:  0.6438518762588501\n",
      "Write summary at step 4890  Loss:  0.676379382610321\n",
      "Write summary at step 4900  Loss:  0.65096116065979\n",
      "Write summary at step 4910  Loss:  0.7094059586524963\n",
      "Write summary at step 4920  Loss:  0.6724475622177124\n",
      "Write summary at step 4930  Loss:  0.674714982509613\n",
      "Write summary at step 4940  Loss:  0.732455849647522\n",
      "Write summary at step 4950  Loss:  0.7003700733184814\n",
      "Write summary at step 4960  Loss:  0.652029275894165\n",
      "Write summary at step 4970  Loss:  0.7636593580245972\n",
      "Write summary at step 4980  Loss:  0.7284950017929077\n",
      "Write summary at step 4990  Loss:  0.7507312893867493\n",
      "Write summary at step 5000  Loss:  0.7214104533195496\n",
      "Saved checkpoint to: result/30/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6796536796536796 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.3125 Acurracy Balanced 0.5442281420765027\n",
      "Loss normal: 0.6371883979607454 Loss Control: 0.5988028199294877 Loss Patient: 0.7835334253807863 Loss balanced:  0.6911681226551369 Loss1+loss2: 0.6911681226551369\n",
      "Write summary at step 5010  Loss:  0.765073299407959\n",
      "Write summary at step 5020  Loss:  0.6964133977890015\n",
      "Write summary at step 5030  Loss:  0.6439427137374878\n",
      "Write summary at step 5040  Loss:  0.6429135799407959\n",
      "Write summary at step 5050  Loss:  0.6937985420227051\n",
      "Write summary at step 5060  Loss:  0.6823331117630005\n",
      "Write summary at step 5070  Loss:  0.7154340744018555\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6623376623376623 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.25 Acurracy Balanced 0.5102459016393442\n",
      "Loss normal: 0.6470486609450666 Loss Control: 0.6000061813599425 Loss Patient: 0.8263980597257614 Loss balanced:  0.713202120542852 Loss1+loss2: 0.713202120542852\n",
      "Write summary at step 5080  Loss:  0.6543089151382446\n",
      "Write summary at step 5090  Loss:  0.698743462562561\n",
      "Write summary at step 5100  Loss:  0.5989077091217041\n",
      "Write summary at step 5110  Loss:  0.6192969083786011\n",
      "Write summary at step 5120  Loss:  0.58197021484375\n",
      "Write summary at step 5130  Loss:  0.6913203001022339\n",
      "Write summary at step 5140  Loss:  0.738013505935669\n",
      "Write summary at step 5150  Loss:  0.6463350057601929\n",
      "Write summary at step 5160  Loss:  0.7651845216751099\n",
      "Write summary at step 5170  Loss:  0.6672284603118896\n",
      "Write summary at step 5180  Loss:  0.6676488518714905\n",
      "Write summary at step 5190  Loss:  0.7369204759597778\n",
      "Write summary at step 5200  Loss:  0.6816002130508423\n",
      "Write summary at step 5210  Loss:  0.6306568384170532\n",
      "Write summary at step 5220  Loss:  0.7508038878440857\n",
      "Write summary at step 5230  Loss:  0.6369430422782898\n",
      "Write summary at step 5240  Loss:  0.6481318473815918\n",
      "Write summary at step 5250  Loss:  0.612786054611206\n",
      "Write summary at step 5260  Loss:  0.7315213084220886\n",
      "Write summary at step 5270  Loss:  0.6840267777442932\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5541125541125541 Acurracy Control:  0.5628415300546448 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.5418374316939891\n",
      "Loss normal: 0.6869127845867372 Loss Control: 0.6730767967271023 Loss Patient: 0.7396624398728212 Loss balanced:  0.7063696182999617 Loss1+loss2: 0.7063696182999617\n",
      "Write summary at step 5280  Loss:  0.688583493232727\n",
      "Write summary at step 5290  Loss:  0.7000491619110107\n",
      "Write summary at step 5300  Loss:  0.701180100440979\n",
      "Write summary at step 5310  Loss:  0.7314637899398804\n",
      "Write summary at step 5320  Loss:  0.647634744644165\n",
      "Write summary at step 5330  Loss:  0.7258042097091675\n",
      "Write summary at step 5340  Loss:  0.7132845520973206\n",
      "Write summary at step 5350  Loss:  0.7272392511367798\n",
      "Write summary at step 5360  Loss:  0.5969489812850952\n",
      "Write summary at step 5370  Loss:  0.5650489926338196\n",
      "Write summary at step 5380  Loss:  0.6524893045425415\n",
      "Write summary at step 5390  Loss:  0.7541431188583374\n",
      "Write summary at step 5400  Loss:  0.618201494216919\n",
      "Write summary at step 5410  Loss:  0.698034405708313\n",
      "Write summary at step 5420  Loss:  0.6124410629272461\n",
      "Write summary at step 5430  Loss:  0.6498922109603882\n",
      "Write summary at step 5440  Loss:  0.6774036288261414\n",
      "Write summary at step 5450  Loss:  0.6410254836082458\n",
      "Write summary at step 5460  Loss:  0.685907244682312\n",
      "Write summary at step 5470  Loss:  0.6717246174812317\n",
      "Write summary at step 5480  Loss:  0.6735923290252686\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5681352459016393\n",
      "Loss normal: 0.620577546425196 Loss Control: 0.5526056296187021 Loss Patient: 0.879720492909352 Loss balanced:  0.7161630612640271 Loss1+loss2: 0.7161630612640271\n",
      "Write summary at step 5490  Loss:  0.6600581407546997\n",
      "Write summary at step 5500  Loss:  0.5809318423271179\n",
      "Saved checkpoint to: result/30/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.4025974025974026 Acurracy Control:  0.3551912568306011 Acurracy Patient:  0.5833333333333334 Acurracy Balanced 0.46926229508196726\n",
      "Loss normal: 0.7176009460445091 Loss Control: 0.7265968580063575 Loss Patient: 0.6833040167888006 Loss balanced:  0.704950437397579 Loss1+loss2: 0.704950437397579\n",
      "Write summary at step 5510  Loss:  0.6084050536155701\n",
      "Write summary at step 5520  Loss:  0.6862848997116089\n",
      "Write summary at step 5530  Loss:  0.7838871479034424\n",
      "Write summary at step 5540  Loss:  0.6673057675361633\n",
      "Write summary at step 5550  Loss:  0.6650962233543396\n",
      "Write summary at step 5560  Loss:  0.6387851238250732\n",
      "Write summary at step 5570  Loss:  0.6428753137588501\n",
      "Write summary at step 5580  Loss:  0.7361170053482056\n",
      "Write summary at step 5590  Loss:  0.6724365949630737\n",
      "Write summary at step 5600  Loss:  0.6375013589859009\n",
      "Write summary at step 5610  Loss:  0.6666732430458069\n",
      "Write summary at step 5620  Loss:  0.5771929025650024\n",
      "Write summary at step 5630  Loss:  0.6390001177787781\n",
      "Write summary at step 5640  Loss:  0.5707230567932129\n",
      "Write summary at step 5650  Loss:  0.7168881893157959\n",
      "Write summary at step 5660  Loss:  0.7151110172271729\n",
      "Write summary at step 5670  Loss:  0.7264989614486694\n",
      "Write summary at step 5680  Loss:  0.6477414965629578\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  1.0 Acurracy Patient:  0.0625 Acurracy Balanced 0.53125\n",
      "Loss normal: 0.558913208963551 Loss Control: 0.4409942284959262 Loss Patient: 1.0084793120622635 Loss balanced:  0.7247367702790948 Loss1+loss2: 0.7247367702790948\n",
      "Write summary at step 5690  Loss:  0.7391574382781982\n",
      "Write summary at step 5700  Loss:  0.6669600009918213\n",
      "Write summary at step 5710  Loss:  0.6073624491691589\n",
      "Write summary at step 5720  Loss:  0.6444791555404663\n",
      "Write summary at step 5730  Loss:  0.6302809715270996\n",
      "Write summary at step 5740  Loss:  0.7019640207290649\n",
      "Write summary at step 5750  Loss:  0.7360219955444336\n",
      "Write summary at step 5760  Loss:  0.7613784670829773\n",
      "Write summary at step 5770  Loss:  0.6921496987342834\n",
      "Write summary at step 5780  Loss:  0.6765068769454956\n",
      "Write summary at step 5790  Loss:  0.6840710639953613\n",
      "Write summary at step 5800  Loss:  0.6260949373245239\n",
      "Write summary at step 5810  Loss:  0.7106510400772095\n",
      "Write summary at step 5820  Loss:  0.7044683694839478\n",
      "Write summary at step 5830  Loss:  0.6953032612800598\n",
      "Write summary at step 5840  Loss:  0.7103583812713623\n",
      "Write summary at step 5850  Loss:  0.7184289693832397\n",
      "Write summary at step 5860  Loss:  0.6993934512138367\n",
      "Write summary at step 5870  Loss:  0.6861541271209717\n",
      "Write summary at step 5880  Loss:  0.7233608961105347\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.1875 Acurracy Balanced 0.5855532786885246\n",
      "Loss normal: 0.6210573315620422 Loss Control: 0.5648004015286764 Loss Patient: 0.8355368872483572 Loss balanced:  0.7001686443885168 Loss1+loss2: 0.7001686443885168\n",
      "Write summary at step 5890  Loss:  0.6754777431488037\n",
      "Write summary at step 5900  Loss:  0.7247651815414429\n",
      "Write summary at step 5910  Loss:  0.6723688840866089\n",
      "Write summary at step 5920  Loss:  0.7170894145965576\n",
      "Write summary at step 5930  Loss:  0.6622040271759033\n",
      "Write summary at step 5940  Loss:  0.5976604223251343\n",
      "Write summary at step 5950  Loss:  0.665820837020874\n",
      "Write summary at step 5960  Loss:  0.7101271152496338\n",
      "Write summary at step 5970  Loss:  0.7313315868377686\n",
      "Write summary at step 5980  Loss:  0.6575730443000793\n",
      "Write summary at step 5990  Loss:  0.5729078054428101\n",
      "Write summary at step 6000  Loss:  0.6386333703994751\n",
      "Saved checkpoint to: result/30/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7272727272727273 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5435450819672131\n",
      "Loss normal: 0.6290626195602087 Loss Control: 0.5737199496701767 Loss Patient: 0.8400565659006437 Loss balanced:  0.7068882577854102 Loss1+loss2: 0.7068882577854102\n",
      "Write summary at step 6010  Loss:  0.6860387325286865\n",
      "Write summary at step 6020  Loss:  0.6589134931564331\n",
      "Write summary at step 6030  Loss:  0.6954790353775024\n",
      "Write summary at step 6040  Loss:  0.6608835458755493\n",
      "Write summary at step 6050  Loss:  0.6362361907958984\n",
      "Write summary at step 6060  Loss:  0.6543758511543274\n",
      "Write summary at step 6070  Loss:  0.7090263366699219\n",
      "Write summary at step 6080  Loss:  0.7352247834205627\n",
      "Write summary at step 6090  Loss:  0.7113456130027771\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.524931693989071\n",
      "Loss normal: 0.6337728647442608 Loss Control: 0.5900728718830588 Loss Patient: 0.8003790974617004 Loss balanced:  0.6952259846723796 Loss1+loss2: 0.6952259846723796\n",
      "Write summary at step 6100  Loss:  0.7455013990402222\n",
      "Write summary at step 6110  Loss:  0.6507423520088196\n",
      "Write summary at step 6120  Loss:  0.6590214967727661\n",
      "Write summary at step 6130  Loss:  0.7200546264648438\n",
      "Write summary at step 6140  Loss:  0.6865161657333374\n",
      "Write summary at step 6150  Loss:  0.6558908820152283\n",
      "Write summary at step 6160  Loss:  0.6351630091667175\n",
      "Write summary at step 6170  Loss:  0.644397497177124\n",
      "Write summary at step 6180  Loss:  0.6091102361679077\n",
      "Write summary at step 6190  Loss:  0.742048978805542\n",
      "Write summary at step 6200  Loss:  0.6851458549499512\n",
      "Write summary at step 6210  Loss:  0.703955888748169\n",
      "Write summary at step 6220  Loss:  0.7158557176589966\n",
      "Write summary at step 6230  Loss:  0.697188138961792\n",
      "Write summary at step 6240  Loss:  0.6370935440063477\n",
      "Write summary at step 6250  Loss:  0.714011549949646\n",
      "Write summary at step 6260  Loss:  0.5775687098503113\n",
      "Write summary at step 6270  Loss:  0.6603883504867554\n",
      "Write summary at step 6280  Loss:  0.7103558778762817\n",
      "Write summary at step 6290  Loss:  0.6815892457962036\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8268398268398268 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5987021857923497\n",
      "Loss normal: 0.5744569652524345 Loss Control: 0.4564792041570111 Loss Patient: 1.024247204264005 Loss balanced:  0.740363204210508 Loss1+loss2: 0.740363204210508\n",
      "Write summary at step 6300  Loss:  0.6888703107833862\n",
      "Write summary at step 6310  Loss:  0.7030978798866272\n",
      "Write summary at step 6320  Loss:  0.6865123510360718\n",
      "Write summary at step 6330  Loss:  0.7109019160270691\n",
      "Write summary at step 6340  Loss:  0.6210333108901978\n",
      "Write summary at step 6350  Loss:  0.6950775384902954\n",
      "Write summary at step 6360  Loss:  0.7568858861923218\n",
      "Write summary at step 6370  Loss:  0.7438589334487915\n",
      "Write summary at step 6380  Loss:  0.6951990127563477\n",
      "Write summary at step 6390  Loss:  0.6989226341247559\n",
      "Write summary at step 6400  Loss:  0.7420105338096619\n",
      "Write summary at step 6410  Loss:  0.7356273531913757\n",
      "Write summary at step 6420  Loss:  0.7616852521896362\n",
      "Write summary at step 6430  Loss:  0.6784924268722534\n",
      "Write summary at step 6440  Loss:  0.6532719731330872\n",
      "Write summary at step 6450  Loss:  0.5872994065284729\n",
      "Write summary at step 6460  Loss:  0.6961150765419006\n",
      "Write summary at step 6470  Loss:  0.7798944711685181\n",
      "Write summary at step 6480  Loss:  0.6348038911819458\n",
      "Write summary at step 6490  Loss:  0.6444518566131592\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5974025974025974 Acurracy Control:  0.6885245901639344 Acurracy Patient:  0.25 Acurracy Balanced 0.4692622950819672\n",
      "Loss normal: 0.6719934150770113 Loss Control: 0.6415120063583708 Loss Patient: 0.7882037969926993 Loss balanced:  0.714857901675535 Loss1+loss2: 0.714857901675535\n",
      "Write summary at step 6500  Loss:  0.6433584690093994\n",
      "Saved checkpoint to: result/30/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6190476190476191 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.4906079234972678\n",
      "Loss normal: 0.6693368118046682 Loss Control: 0.6385187079997662 Loss Patient: 0.7868308424949646 Loss balanced:  0.7126747752473654 Loss1+loss2: 0.7126747752473654\n",
      "Write summary at step 6510  Loss:  0.9667349457740784\n",
      "Write summary at step 6520  Loss:  0.7335177659988403\n",
      "Write summary at step 6530  Loss:  0.6719694137573242\n",
      "Write summary at step 6540  Loss:  0.7157663106918335\n",
      "Write summary at step 6550  Loss:  0.7402850985527039\n",
      "Write summary at step 6560  Loss:  0.5555487871170044\n",
      "Write summary at step 6570  Loss:  0.5092408061027527\n",
      "Write summary at step 6580  Loss:  0.6536896228790283\n",
      "Write summary at step 6590  Loss:  0.6373051404953003\n",
      "Write summary at step 6600  Loss:  0.7496110796928406\n",
      "Write summary at step 6610  Loss:  0.6527576446533203\n",
      "Write summary at step 6620  Loss:  0.6414388418197632\n",
      "Write summary at step 6630  Loss:  0.6258456707000732\n",
      "Write summary at step 6640  Loss:  0.6769784688949585\n",
      "Write summary at step 6650  Loss:  0.6206430196762085\n",
      "Write summary at step 6660  Loss:  0.6756883859634399\n",
      "Write summary at step 6670  Loss:  0.6263798475265503\n",
      "Write summary at step 6680  Loss:  0.7775455713272095\n",
      "Write summary at step 6690  Loss:  0.6754758358001709\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.4943647540983606\n",
      "Loss normal: 0.6471650112758983 Loss Control: 0.591621553637291 Loss Patient: 0.8589245130618414 Loss balanced:  0.7252730333495662 Loss1+loss2: 0.7252730333495662\n",
      "Write summary at step 6700  Loss:  0.6601567268371582\n",
      "Write summary at step 6710  Loss:  0.7561001777648926\n",
      "Write summary at step 6720  Loss:  0.7168002128601074\n",
      "Write summary at step 6730  Loss:  0.7029176950454712\n",
      "Write summary at step 6740  Loss:  0.6663055419921875\n",
      "Write summary at step 6750  Loss:  0.6762909293174744\n",
      "Write summary at step 6760  Loss:  0.5578799247741699\n",
      "Write summary at step 6770  Loss:  0.749777615070343\n",
      "Write summary at step 6780  Loss:  0.6395838260650635\n",
      "Write summary at step 6790  Loss:  0.6782211065292358\n",
      "Write summary at step 6800  Loss:  0.6899730563163757\n",
      "Write summary at step 6810  Loss:  0.6213345527648926\n",
      "Write summary at step 6820  Loss:  0.6242337822914124\n",
      "Write summary at step 6830  Loss:  0.6555753946304321\n",
      "Write summary at step 6840  Loss:  0.6969602704048157\n",
      "Write summary at step 6850  Loss:  0.6851283311843872\n",
      "Write summary at step 6860  Loss:  0.7918392419815063\n",
      "Write summary at step 6870  Loss:  0.753237783908844\n",
      "Write summary at step 6880  Loss:  0.7407096028327942\n",
      "Write summary at step 6890  Loss:  0.7151373624801636\n",
      "Write summary at step 6900  Loss:  0.650530219078064\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8138528138528138 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.25 Acurracy Balanced 0.6058743169398907\n",
      "Loss normal: 0.6010722538609525 Loss Control: 0.53857832300207 Loss Patient: 0.839330367743969 Loss balanced:  0.6889543453730195 Loss1+loss2: 0.6889543453730195\n",
      "Write summary at step 6910  Loss:  0.6936718821525574\n",
      "Write summary at step 6920  Loss:  0.6507521271705627\n",
      "Write summary at step 6930  Loss:  0.6810662150382996\n",
      "Write summary at step 6940  Loss:  0.68729567527771\n",
      "Write summary at step 6950  Loss:  0.643984317779541\n",
      "Write summary at step 6960  Loss:  0.673889696598053\n",
      "Write summary at step 6970  Loss:  0.7004614472389221\n",
      "Write summary at step 6980  Loss:  0.7310774326324463\n",
      "Write summary at step 6990  Loss:  0.6647428274154663\n",
      "Write summary at step 7000  Loss:  0.6172971725463867\n",
      "Saved checkpoint to: result/30/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5701844262295082\n",
      "Loss normal: 0.5660852206733836 Loss Control: 0.4586105512790993 Loss Patient: 0.975832425057888 Loss balanced:  0.7172214881684936 Loss1+loss2: 0.7172214881684936\n",
      "Write summary at step 7010  Loss:  0.675378680229187\n",
      "Write summary at step 7020  Loss:  0.7898407578468323\n",
      "Write summary at step 7030  Loss:  0.7701901197433472\n",
      "Write summary at step 7040  Loss:  0.6692006587982178\n",
      "Write summary at step 7050  Loss:  0.6782623529434204\n",
      "Write summary at step 7060  Loss:  0.7737933397293091\n",
      "Write summary at step 7070  Loss:  0.5718638300895691\n",
      "Write summary at step 7080  Loss:  0.683085560798645\n",
      "Write summary at step 7090  Loss:  0.5597070455551147\n",
      "Write summary at step 7100  Loss:  0.6512407660484314\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4329004329004329 Acurracy Control:  0.4262295081967213 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.4422814207650273\n",
      "Loss normal: 0.7295153667400409 Loss Control: 0.7347036007323552 Loss Patient: 0.7097352656225363 Loss balanced:  0.7222194331774457 Loss1+loss2: 0.7222194331774457\n",
      "Write summary at step 7110  Loss:  0.6878544092178345\n",
      "Write summary at step 7120  Loss:  0.6992360949516296\n",
      "Write summary at step 7130  Loss:  0.597247302532196\n",
      "Write summary at step 7140  Loss:  0.6459963321685791\n",
      "Write summary at step 7150  Loss:  0.6252464056015015\n",
      "Write summary at step 7160  Loss:  0.6934893131256104\n",
      "Write summary at step 7170  Loss:  0.6200974583625793\n",
      "Write summary at step 7180  Loss:  0.7570501565933228\n",
      "Write summary at step 7190  Loss:  0.7012622356414795\n",
      "Write summary at step 7200  Loss:  0.6006929874420166\n",
      "Write summary at step 7210  Loss:  0.7083361148834229\n",
      "Write summary at step 7220  Loss:  0.7184264659881592\n",
      "Write summary at step 7230  Loss:  0.7170965671539307\n",
      "Write summary at step 7240  Loss:  0.645860493183136\n",
      "Write summary at step 7250  Loss:  0.7214336395263672\n",
      "Write summary at step 7260  Loss:  0.7238647937774658\n",
      "Write summary at step 7270  Loss:  0.6564092636108398\n",
      "Write summary at step 7280  Loss:  0.7368038892745972\n",
      "Write summary at step 7290  Loss:  0.6450729966163635\n",
      "Write summary at step 7300  Loss:  0.6376594305038452\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5817964480874317\n",
      "Loss normal: 0.6105243971337487 Loss Control: 0.5499229297611883 Loss Patient: 0.8415674368540446 Loss balanced:  0.6957451833076165 Loss1+loss2: 0.6957451833076165\n",
      "Write summary at step 7310  Loss:  0.738513708114624\n",
      "Write summary at step 7320  Loss:  0.6063567399978638\n",
      "Write summary at step 7330  Loss:  0.6595731973648071\n",
      "Write summary at step 7340  Loss:  0.700674831867218\n",
      "Write summary at step 7350  Loss:  0.5946325063705444\n",
      "Write summary at step 7360  Loss:  0.6235065460205078\n",
      "Write summary at step 7370  Loss:  0.6041921377182007\n",
      "Write summary at step 7380  Loss:  0.6187227964401245\n",
      "Write summary at step 7390  Loss:  0.6615340709686279\n",
      "Write summary at step 7400  Loss:  0.6476747393608093\n",
      "Write summary at step 7410  Loss:  0.6619418859481812\n",
      "Write summary at step 7420  Loss:  0.6341207027435303\n",
      "Write summary at step 7430  Loss:  0.7688296437263489\n",
      "Write summary at step 7440  Loss:  0.6288546323776245\n",
      "Write summary at step 7450  Loss:  0.7500699758529663\n",
      "Write summary at step 7460  Loss:  0.6165934801101685\n",
      "Write summary at step 7470  Loss:  0.6630200147628784\n",
      "Write summary at step 7480  Loss:  0.7469436526298523\n",
      "Write summary at step 7490  Loss:  0.6983144283294678\n",
      "Write summary at step 7500  Loss:  0.784758448600769\n",
      "Saved checkpoint to: result/30/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.6053620218579235\n",
      "Loss normal: 0.6097035955041001 Loss Control: 0.5555345829718751 Loss Patient: 0.8162229185303053 Loss balanced:  0.6858787507510902 Loss1+loss2: 0.6858787507510902\n",
      "\n",
      " > BEST MODEL (0.68588) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 7510  Loss:  0.6695641279220581\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.6060450819672131\n",
      "Loss normal: 0.633510225004964 Loss Control: 0.5977948581586119 Loss Patient: 0.7696751281619072 Loss balanced:  0.6837349931602595 Loss1+loss2: 0.6837349931602595\n",
      "\n",
      " > BEST MODEL (0.68373) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 7520  Loss:  0.6319599151611328\n",
      "Write summary at step 7530  Loss:  0.6597908139228821\n",
      "Write summary at step 7540  Loss:  0.6511245369911194\n",
      "Write summary at step 7550  Loss:  0.7392626404762268\n",
      "Write summary at step 7560  Loss:  0.6204075813293457\n",
      "Write summary at step 7570  Loss:  0.7010033130645752\n",
      "Write summary at step 7580  Loss:  0.6833921670913696\n",
      "Write summary at step 7590  Loss:  0.6532677412033081\n",
      "Write summary at step 7600  Loss:  0.5524190664291382\n",
      "Write summary at step 7610  Loss:  0.6401676535606384\n",
      "Write summary at step 7620  Loss:  0.8176594376564026\n",
      "Write summary at step 7630  Loss:  0.5854978561401367\n",
      "Write summary at step 7640  Loss:  0.809126615524292\n",
      "Write summary at step 7650  Loss:  0.6781970858573914\n",
      "Write summary at step 7660  Loss:  0.6912978887557983\n",
      "Write summary at step 7670  Loss:  0.7181299924850464\n",
      "Write summary at step 7680  Loss:  0.6740533113479614\n",
      "Write summary at step 7690  Loss:  0.7158460021018982\n",
      "Write summary at step 7700  Loss:  0.6542810797691345\n",
      "Write summary at step 7710  Loss:  0.6983029246330261\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5404713114754098\n",
      "Loss normal: 0.658449548663515 Loss Control: 0.6392230127678543 Loss Patient: 0.731750700622797 Loss balanced:  0.6854868566953256 Loss1+loss2: 0.6854868566953256\n",
      "Write summary at step 7720  Loss:  0.6460579633712769\n",
      "Write summary at step 7730  Loss:  0.6561015248298645\n",
      "Write summary at step 7740  Loss:  0.6107485890388489\n",
      "Write summary at step 7750  Loss:  0.6746031641960144\n",
      "Write summary at step 7760  Loss:  0.6593708992004395\n",
      "Write summary at step 7770  Loss:  0.6297205686569214\n",
      "Write summary at step 7780  Loss:  0.7518433332443237\n",
      "Write summary at step 7790  Loss:  0.6497530937194824\n",
      "Write summary at step 7800  Loss:  0.650611162185669\n",
      "Write summary at step 7810  Loss:  0.6691015958786011\n",
      "Write summary at step 7820  Loss:  0.6765345335006714\n",
      "Write summary at step 7830  Loss:  0.5149624347686768\n",
      "Write summary at step 7840  Loss:  0.8120089173316956\n",
      "Write summary at step 7850  Loss:  0.8138540983200073\n",
      "Write summary at step 7860  Loss:  0.7492023706436157\n",
      "Write summary at step 7870  Loss:  0.6211687922477722\n",
      "Write summary at step 7880  Loss:  0.6750930547714233\n",
      "Write summary at step 7890  Loss:  0.63847416639328\n",
      "Write summary at step 7900  Loss:  0.606266975402832\n",
      "Write summary at step 7910  Loss:  0.6959268450737\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  1.0 Acurracy Patient:  0.125 Acurracy Balanced 0.5625\n",
      "Loss normal: 0.5305076854311542 Loss Control: 0.34916452257359615 Loss Patient: 1.2218784683694441 Loss balanced:  0.7855214954715202 Loss1+loss2: 0.7855214954715202\n",
      "Write summary at step 7920  Loss:  0.6714849472045898\n",
      "Write summary at step 7930  Loss:  0.7893707752227783\n",
      "Write summary at step 7940  Loss:  0.5613002777099609\n",
      "Write summary at step 7950  Loss:  0.6803392171859741\n",
      "Write summary at step 7960  Loss:  0.7077761888504028\n",
      "Write summary at step 7970  Loss:  0.6407899260520935\n",
      "Write summary at step 7980  Loss:  0.6563937664031982\n",
      "Write summary at step 7990  Loss:  0.7201049327850342\n",
      "Write summary at step 8000  Loss:  0.7124305963516235\n",
      "Saved checkpoint to: result/30/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6277056277056277 Acurracy Control:  0.7213114754098361 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.49607240437158473\n",
      "Loss normal: 0.6567128987023325 Loss Control: 0.6223371787800815 Loss Patient: 0.7877703284223875 Loss balanced:  0.7050537536012345 Loss1+loss2: 0.7050537536012345\n",
      "Write summary at step 8010  Loss:  0.7038028240203857\n",
      "Write summary at step 8020  Loss:  0.706396222114563\n",
      "Write summary at step 8030  Loss:  0.6217393279075623\n",
      "Write summary at step 8040  Loss:  0.6223313808441162\n",
      "Write summary at step 8050  Loss:  0.7402693033218384\n",
      "Write summary at step 8060  Loss:  0.6236721277236938\n",
      "Write summary at step 8070  Loss:  0.5840368270874023\n",
      "Write summary at step 8080  Loss:  0.6058972477912903\n",
      "Write summary at step 8090  Loss:  0.8703646659851074\n",
      "Write summary at step 8100  Loss:  0.9243168830871582\n",
      "Write summary at step 8110  Loss:  0.772205114364624\n",
      "Write summary at step 8120  Loss:  0.7201371192932129\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6666666666666666 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5052937158469946\n",
      "Loss normal: 0.6511162385279998 Loss Control: 0.6144717931747437 Loss Patient: 0.7908232199649016 Loss balanced:  0.7026475065698226 Loss1+loss2: 0.7026475065698226\n",
      "Write summary at step 8130  Loss:  0.6273893117904663\n",
      "Write summary at step 8140  Loss:  0.707184374332428\n",
      "Write summary at step 8150  Loss:  0.5817621350288391\n",
      "Write summary at step 8160  Loss:  0.6878958344459534\n",
      "Write summary at step 8170  Loss:  0.700942873954773\n",
      "Write summary at step 8180  Loss:  0.7030137777328491\n",
      "Write summary at step 8190  Loss:  0.7458425760269165\n",
      "Write summary at step 8200  Loss:  0.7144758701324463\n",
      "Write summary at step 8210  Loss:  0.6896613836288452\n",
      "Write summary at step 8220  Loss:  0.6627376079559326\n",
      "Write summary at step 8230  Loss:  0.71315598487854\n",
      "Write summary at step 8240  Loss:  0.6453269720077515\n",
      "Write summary at step 8250  Loss:  0.6049976348876953\n",
      "Write summary at step 8260  Loss:  0.7433885335922241\n",
      "Write summary at step 8270  Loss:  0.6510870456695557\n",
      "Write summary at step 8280  Loss:  0.6854848861694336\n",
      "Write summary at step 8290  Loss:  0.5734927654266357\n",
      "Write summary at step 8300  Loss:  0.616802453994751\n",
      "Write summary at step 8310  Loss:  0.5713995695114136\n",
      "Write summary at step 8320  Loss:  0.654358446598053\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.645021645021645 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.25 Acurracy Balanced 0.4993169398907104\n",
      "Loss normal: 0.6445807621076509 Loss Control: 0.6053892321925346 Loss Patient: 0.7939984910190105 Loss balanced:  0.6996938616057726 Loss1+loss2: 0.6996938616057726\n",
      "Write summary at step 8330  Loss:  0.6671305894851685\n",
      "Write summary at step 8340  Loss:  0.6755623817443848\n",
      "Write summary at step 8350  Loss:  0.6525198221206665\n",
      "Write summary at step 8360  Loss:  0.6990640163421631\n",
      "Write summary at step 8370  Loss:  0.784643292427063\n",
      "Write summary at step 8380  Loss:  0.6290577054023743\n",
      "Write summary at step 8390  Loss:  0.7378227710723877\n",
      "Write summary at step 8400  Loss:  0.7085895538330078\n",
      "Write summary at step 8410  Loss:  0.7994206547737122\n",
      "Write summary at step 8420  Loss:  0.6277976036071777\n",
      "Write summary at step 8430  Loss:  0.7109044790267944\n",
      "Write summary at step 8440  Loss:  0.7285491228103638\n",
      "Write summary at step 8450  Loss:  0.7015017867088318\n",
      "Write summary at step 8460  Loss:  0.6534438133239746\n",
      "Write summary at step 8470  Loss:  0.5976997017860413\n",
      "Write summary at step 8480  Loss:  0.6985825300216675\n",
      "Write summary at step 8490  Loss:  0.6878753900527954\n",
      "Write summary at step 8500  Loss:  0.6551598310470581\n",
      "Saved checkpoint to: result/30/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.1875 Acurracy Balanced 0.5609631147540983\n",
      "Loss normal: 0.600704847476183 Loss Control: 0.530867799383695 Loss Patient: 0.8669586057464281 Loss balanced:  0.6989132025650615 Loss1+loss2: 0.6989132025650615\n",
      "Write summary at step 8510  Loss:  0.6530247926712036\n",
      "Write summary at step 8520  Loss:  0.697002112865448\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.125 Acurracy Balanced 0.5543032786885246\n",
      "Loss normal: 0.569631910040265 Loss Control: 0.46060914566608074 Loss Patient: 0.9852811731398106 Loss balanced:  0.7229451594029457 Loss1+loss2: 0.7229451594029457\n",
      "Write summary at step 8530  Loss:  0.6605193614959717\n",
      "Write summary at step 8540  Loss:  0.6181511282920837\n",
      "Write summary at step 8550  Loss:  0.550213098526001\n",
      "Write summary at step 8560  Loss:  0.9190584421157837\n",
      "Write summary at step 8570  Loss:  0.668946385383606\n",
      "Write summary at step 8580  Loss:  0.627582848072052\n",
      "Write summary at step 8590  Loss:  0.6709978580474854\n",
      "Write summary at step 8600  Loss:  0.7083882093429565\n",
      "Write summary at step 8610  Loss:  0.6676722764968872\n",
      "Write summary at step 8620  Loss:  0.5628608465194702\n",
      "Write summary at step 8630  Loss:  0.5190128087997437\n",
      "Write summary at step 8640  Loss:  0.6207754611968994\n",
      "Write summary at step 8650  Loss:  0.7596933841705322\n",
      "Write summary at step 8660  Loss:  0.6044518947601318\n",
      "Write summary at step 8670  Loss:  0.6368177533149719\n",
      "Write summary at step 8680  Loss:  0.6613264083862305\n",
      "Write summary at step 8690  Loss:  0.6257702112197876\n",
      "Write summary at step 8700  Loss:  0.7829620838165283\n",
      "Write summary at step 8710  Loss:  0.7175131440162659\n",
      "Write summary at step 8720  Loss:  0.696541428565979\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6147186147186147 Acurracy Control:  0.6994535519125683 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.49556010928961747\n",
      "Loss normal: 0.6559496764496807 Loss Control: 0.6220994233433667 Loss Patient: 0.7850037639339765 Loss balanced:  0.7035515936386716 Loss1+loss2: 0.7035515936386716\n",
      "Write summary at step 8730  Loss:  0.7346067428588867\n",
      "Write summary at step 8740  Loss:  0.541431725025177\n",
      "Write summary at step 8750  Loss:  0.695342481136322\n",
      "Write summary at step 8760  Loss:  0.6340017318725586\n",
      "Write summary at step 8770  Loss:  0.6823252439498901\n",
      "Write summary at step 8780  Loss:  0.6917179226875305\n",
      "Write summary at step 8790  Loss:  0.5397536754608154\n",
      "Write summary at step 8800  Loss:  0.6859325170516968\n",
      "Write summary at step 8810  Loss:  0.6163562536239624\n",
      "Write summary at step 8820  Loss:  0.6840276718139648\n",
      "Write summary at step 8830  Loss:  0.7441897988319397\n",
      "Write summary at step 8840  Loss:  0.6260360479354858\n",
      "Write summary at step 8850  Loss:  0.8519310355186462\n",
      "Write summary at step 8860  Loss:  0.6937220096588135\n",
      "Write summary at step 8870  Loss:  0.6941017508506775\n",
      "Write summary at step 8880  Loss:  0.6100339889526367\n",
      "Write summary at step 8890  Loss:  0.6268576383590698\n",
      "Write summary at step 8900  Loss:  0.6685628890991211\n",
      "Write summary at step 8910  Loss:  0.610333263874054\n",
      "Write summary at step 8920  Loss:  0.6900076866149902\n",
      "Write summary at step 8930  Loss:  0.7283704280853271\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5584415584415584 Acurracy Control:  0.6120218579234973 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.483094262295082\n",
      "Loss normal: 0.6831699503964676 Loss Control: 0.6683717988879303 Loss Patient: 0.7395879613856474 Loss balanced:  0.7039798801367889 Loss1+loss2: 0.7039798801367889\n",
      "Write summary at step 8940  Loss:  0.7160029411315918\n",
      "Write summary at step 8950  Loss:  0.7230426073074341\n",
      "Write summary at step 8960  Loss:  0.5707065463066101\n",
      "Write summary at step 8970  Loss:  0.716066837310791\n",
      "Write summary at step 8980  Loss:  0.7432411313056946\n",
      "Write summary at step 8990  Loss:  0.7506697773933411\n",
      "Write summary at step 9000  Loss:  0.6829463243484497\n",
      "Saved checkpoint to: result/30/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5411255411255411 Acurracy Control:  0.5519125683060109 Acurracy Patient:  0.5 Acurracy Balanced 0.5259562841530054\n",
      "Loss normal: 0.6881556036152365 Loss Control: 0.6829477125178269 Loss Patient: 0.7080106735229492 Loss balanced:  0.6954791930203881 Loss1+loss2: 0.6954791930203881\n",
      "Write summary at step 9010  Loss:  0.5999265909194946\n",
      "Write summary at step 9020  Loss:  0.5480095148086548\n",
      "Write summary at step 9030  Loss:  0.6340320110321045\n",
      "Write summary at step 9040  Loss:  0.5536448955535889\n",
      "Write summary at step 9050  Loss:  0.6335456967353821\n",
      "Write summary at step 9060  Loss:  0.5837655067443848\n",
      "Write summary at step 9070  Loss:  0.5766497850418091\n",
      "Write summary at step 9080  Loss:  0.7022544145584106\n",
      "Write summary at step 9090  Loss:  0.6751503944396973\n",
      "Write summary at step 9100  Loss:  0.6258499622344971\n",
      "Write summary at step 9110  Loss:  0.6147833466529846\n",
      "Write summary at step 9120  Loss:  0.704039454460144\n",
      "Write summary at step 9130  Loss:  0.6841437220573425\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.1875 Acurracy Balanced 0.5445696721311475\n",
      "Loss normal: 0.625343233992011 Loss Control: 0.5802210106875727 Loss Patient: 0.7973716910928488 Loss balanced:  0.6887963508902107 Loss1+loss2: 0.6887963508902107\n",
      "Write summary at step 9140  Loss:  0.6295002102851868\n",
      "Write summary at step 9150  Loss:  0.6343779563903809\n",
      "Write summary at step 9160  Loss:  0.6732254028320312\n",
      "Write summary at step 9170  Loss:  0.6800153255462646\n",
      "Write summary at step 9180  Loss:  0.7064661383628845\n",
      "Write summary at step 9190  Loss:  0.7364562153816223\n",
      "Write summary at step 9200  Loss:  0.6013070940971375\n",
      "Write summary at step 9210  Loss:  0.6832928657531738\n",
      "Write summary at step 9220  Loss:  0.6522684693336487\n",
      "Write summary at step 9230  Loss:  0.8436797261238098\n",
      "Write summary at step 9240  Loss:  0.6670379638671875\n",
      "Write summary at step 9250  Loss:  0.5713616013526917\n",
      "Write summary at step 9260  Loss:  0.7652541399002075\n",
      "Write summary at step 9270  Loss:  0.7071520090103149\n",
      "Write summary at step 9280  Loss:  0.6129230260848999\n",
      "Write summary at step 9290  Loss:  0.7067786455154419\n",
      "Write summary at step 9300  Loss:  0.6207393407821655\n",
      "Write summary at step 9310  Loss:  0.6594356298446655\n",
      "Write summary at step 9320  Loss:  0.6090140342712402\n",
      "Write summary at step 9330  Loss:  0.7244739532470703\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.683982683982684 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.539275956284153\n",
      "Loss normal: 0.6459321472551915 Loss Control: 0.6137603817741728 Loss Patient: 0.768586985146006 Loss balanced:  0.6911736834600894 Loss1+loss2: 0.6911736834600894\n",
      "Write summary at step 9340  Loss:  0.7028985023498535\n",
      "Write summary at step 9350  Loss:  0.6714800000190735\n",
      "Write summary at step 9360  Loss:  0.6819308996200562\n",
      "Write summary at step 9370  Loss:  0.6042085886001587\n",
      "Write summary at step 9380  Loss:  0.668704628944397\n",
      "Write summary at step 9390  Loss:  0.5725353956222534\n",
      "Write summary at step 9400  Loss:  0.7581960558891296\n",
      "Write summary at step 9410  Loss:  0.5776706337928772\n",
      "Write summary at step 9420  Loss:  0.6884190440177917\n",
      "Write summary at step 9430  Loss:  0.6019232273101807\n",
      "Write summary at step 9440  Loss:  0.6069910526275635\n",
      "Write summary at step 9450  Loss:  0.6345107555389404\n",
      "Write summary at step 9460  Loss:  0.6395130157470703\n",
      "Write summary at step 9470  Loss:  0.7860325574874878\n",
      "Write summary at step 9480  Loss:  0.6397334337234497\n",
      "Write summary at step 9490  Loss:  0.6144150495529175\n",
      "Write summary at step 9500  Loss:  0.6471387147903442\n",
      "Saved checkpoint to: result/30/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5140027322404371\n",
      "Loss normal: 0.6460611892469001 Loss Control: 0.6062802161023917 Loss Patient: 0.7977261754373709 Loss balanced:  0.7020031957698813 Loss1+loss2: 0.7020031957698813\n",
      "Write summary at step 9510  Loss:  0.7189096212387085\n",
      "Write summary at step 9520  Loss:  0.856389582157135\n",
      "Write summary at step 9530  Loss:  0.7462978363037109\n",
      "Write summary at step 9540  Loss:  0.6823669672012329\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.3125 Acurracy Balanced 0.5141734972677596\n",
      "Loss normal: 0.6843553270612445 Loss Control: 0.6774216375715746 Loss Patient: 0.7107900312791268 Loss balanced:  0.6941058344253507 Loss1+loss2: 0.6941058344253507\n",
      "Write summary at step 9550  Loss:  0.6806511878967285\n",
      "Write summary at step 9560  Loss:  0.6312805414199829\n",
      "Write summary at step 9570  Loss:  0.6827499866485596\n",
      "Write summary at step 9580  Loss:  0.7138735055923462\n",
      "Write summary at step 9590  Loss:  0.5328189730644226\n",
      "Write summary at step 9600  Loss:  0.7369900345802307\n",
      "Write summary at step 9610  Loss:  0.6158391237258911\n",
      "Write summary at step 9620  Loss:  0.6668368577957153\n",
      "Write summary at step 9630  Loss:  0.6864657402038574\n",
      "Write summary at step 9640  Loss:  0.6987612247467041\n",
      "Write summary at step 9650  Loss:  0.628238320350647\n",
      "Write summary at step 9660  Loss:  0.5701169967651367\n",
      "Write summary at step 9670  Loss:  0.6831233501434326\n",
      "Write summary at step 9680  Loss:  0.5894128084182739\n",
      "Write summary at step 9690  Loss:  0.6870678663253784\n",
      "Write summary at step 9700  Loss:  0.7149636149406433\n",
      "Write summary at step 9710  Loss:  0.5772285461425781\n",
      "Write summary at step 9720  Loss:  0.7478459477424622\n",
      "Write summary at step 9730  Loss:  0.5934778451919556\n",
      "Write summary at step 9740  Loss:  0.6774991154670715\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5647199453551912\n",
      "Loss normal: 0.5978328273409889 Loss Control: 0.5280085092033845 Loss Patient: 0.8640380588670572 Loss balanced:  0.6960232840352208 Loss1+loss2: 0.6960232840352208\n",
      "Write summary at step 9750  Loss:  0.6944526433944702\n",
      "Write summary at step 9760  Loss:  0.7184861898422241\n",
      "Write summary at step 9770  Loss:  0.49867403507232666\n",
      "Write summary at step 9780  Loss:  0.649381160736084\n",
      "Write summary at step 9790  Loss:  0.6608755588531494\n",
      "Write summary at step 9800  Loss:  0.618578314781189\n",
      "Write summary at step 9810  Loss:  0.574901819229126\n",
      "Write summary at step 9820  Loss:  0.5783270597457886\n",
      "Write summary at step 9830  Loss:  0.6495286226272583\n",
      "Write summary at step 9840  Loss:  0.6838340759277344\n",
      "Write summary at step 9850  Loss:  0.5398980379104614\n",
      "Write summary at step 9860  Loss:  0.6073421239852905\n",
      "Write summary at step 9870  Loss:  0.5949900150299072\n",
      "Write summary at step 9880  Loss:  0.7146705389022827\n",
      "Write summary at step 9890  Loss:  0.7873888611793518\n",
      "Write summary at step 9900  Loss:  0.8016424179077148\n",
      "Write summary at step 9910  Loss:  0.6433525085449219\n",
      "Write summary at step 9920  Loss:  0.7435876131057739\n",
      "Write summary at step 9930  Loss:  0.6844123601913452\n",
      "Write summary at step 9940  Loss:  0.5607597231864929\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6363636363636364 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.25 Acurracy Balanced 0.49385245901639346\n",
      "Loss normal: 0.6359618917688147 Loss Control: 0.5925870449816595 Loss Patient: 0.8013285112877687 Loss balanced:  0.696957778134714 Loss1+loss2: 0.696957778134714\n",
      "Write summary at step 9950  Loss:  0.6367903351783752\n",
      "Write summary at step 9960  Loss:  0.593528687953949\n",
      "Write summary at step 9970  Loss:  0.7823011875152588\n",
      "Write summary at step 9980  Loss:  0.6581723690032959\n",
      "Write summary at step 9990  Loss:  0.7491636276245117\n",
      "Write summary at step 10000  Loss:  0.7084264159202576\n",
      "Saved checkpoint to: result/30/panns/checkpoint_10000.pt\n",
      "Validation:\n",
      "Acurracy:  0.36796536796536794 Acurracy Control:  0.25136612021857924 Acurracy Patient:  0.8125 Acurracy Balanced 0.5319330601092896\n",
      "Loss normal: 0.7424974493134073 Loss Control: 0.7797421457988968 Loss Patient: 0.6005019973963499 Loss balanced:  0.6901220715976233 Loss1+loss2: 0.6901220715976233\n",
      "Write summary at step 10010  Loss:  0.6736826300621033\n",
      "Write summary at step 10020  Loss:  0.5102339386940002\n",
      "Write summary at step 10030  Loss:  0.672221302986145\n",
      "Write summary at step 10040  Loss:  0.7448518872261047\n",
      "Write summary at step 10050  Loss:  0.7422725558280945\n",
      "Write summary at step 10060  Loss:  0.674163281917572\n",
      "Write summary at step 10070  Loss:  0.5864310264587402\n",
      "Write summary at step 10080  Loss:  0.6397938132286072\n",
      "Write summary at step 10090  Loss:  0.7242452502250671\n",
      "Write summary at step 10100  Loss:  0.6276054382324219\n",
      "Write summary at step 10110  Loss:  0.7281899452209473\n",
      "Write summary at step 10120  Loss:  0.6261360049247742\n",
      "Write summary at step 10130  Loss:  0.6705291867256165\n",
      "Write summary at step 10140  Loss:  0.7326310873031616\n",
      "Write summary at step 10150  Loss:  0.6120833158493042\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5778688524590164\n",
      "Loss normal: 0.555817389514023 Loss Control: 0.447253271693089 Loss Patient: 0.969718100503087 Loss balanced:  0.708485686098088 Loss1+loss2: 0.708485686098088\n",
      "Write summary at step 10160  Loss:  0.7016655206680298\n",
      "Write summary at step 10170  Loss:  0.6306743025779724\n",
      "Write summary at step 10180  Loss:  0.6549215316772461\n",
      "Write summary at step 10190  Loss:  0.626082718372345\n",
      "Write summary at step 10200  Loss:  0.7612296938896179\n",
      "Write summary at step 10210  Loss:  0.6751084923744202\n",
      "Write summary at step 10220  Loss:  0.7013417482376099\n",
      "Write summary at step 10230  Loss:  0.6162365674972534\n",
      "Write summary at step 10240  Loss:  0.6230643391609192\n",
      "Write summary at step 10250  Loss:  0.693678617477417\n",
      "Write summary at step 10260  Loss:  0.6965078711509705\n",
      "Write summary at step 10270  Loss:  0.6498959064483643\n",
      "Write summary at step 10280  Loss:  0.7296063303947449\n",
      "Write summary at step 10290  Loss:  0.5854456424713135\n",
      "Write summary at step 10300  Loss:  0.6527034044265747\n",
      "Write summary at step 10310  Loss:  0.804749608039856\n",
      "Write summary at step 10320  Loss:  0.6940480470657349\n",
      "Write summary at step 10330  Loss:  0.9422247409820557\n",
      "Write summary at step 10340  Loss:  0.6216965913772583\n",
      "Write summary at step 10350  Loss:  0.6365700960159302\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.25 Acurracy Balanced 0.5594262295081966\n",
      "Loss normal: 0.5962703307985744 Loss Control: 0.5134931727836692 Loss Patient: 0.9118582593897978 Loss balanced:  0.7126757160867335 Loss1+loss2: 0.7126757160867335\n",
      "Write summary at step 10360  Loss:  0.6891492605209351\n",
      "Write summary at step 10370  Loss:  0.659308135509491\n",
      "Write summary at step 10380  Loss:  0.6955597400665283\n",
      "Write summary at step 10390  Loss:  0.6811515092849731\n",
      "Write summary at step 10400  Loss:  0.6859581470489502\n",
      "Write summary at step 10410  Loss:  0.6235237121582031\n",
      "Write summary at step 10420  Loss:  0.6999534368515015\n",
      "Write summary at step 10430  Loss:  0.6785770654678345\n",
      "Write summary at step 10440  Loss:  0.6296742558479309\n",
      "Write summary at step 10450  Loss:  0.6930115222930908\n",
      "Write summary at step 10460  Loss:  0.6889863014221191\n",
      "Write summary at step 10470  Loss:  0.7890760898590088\n",
      "Write summary at step 10480  Loss:  0.7024617195129395\n",
      "Write summary at step 10490  Loss:  0.7311975359916687\n",
      "Write summary at step 10500  Loss:  0.6382344961166382\n",
      "Saved checkpoint to: result/30/panns/checkpoint_10500.pt\n",
      "Validation:\n",
      "Acurracy:  0.658008658008658 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.25 Acurracy Balanced 0.5075136612021858\n",
      "Loss normal: 0.6460969654512612 Loss Control: 0.6141476878702966 Loss Patient: 0.7679036296904087 Loss balanced:  0.6910256587803527 Loss1+loss2: 0.6910256587803527\n",
      "Write summary at step 10510  Loss:  0.6772499680519104\n",
      "Write summary at step 10520  Loss:  0.762050211429596\n",
      "Write summary at step 10530  Loss:  0.6997636556625366\n",
      "Write summary at step 10540  Loss:  0.659227192401886\n",
      "Write summary at step 10550  Loss:  0.6479374170303345\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5064935064935064 Acurracy Control:  0.4808743169398907 Acurracy Patient:  0.6041666666666666 Acurracy Balanced 0.5425204918032787\n",
      "Loss normal: 0.692144758257515 Loss Control: 0.699322218451995 Loss Patient: 0.664780717343092 Loss balanced:  0.6820514678975436 Loss1+loss2: 0.6820514678975436\n",
      "\n",
      " > BEST MODEL (0.68205) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 10560  Loss:  0.6503629684448242\n",
      "Write summary at step 10570  Loss:  0.6504177451133728\n",
      "Write summary at step 10580  Loss:  0.6925476789474487\n",
      "Write summary at step 10590  Loss:  0.6562206745147705\n",
      "Write summary at step 10600  Loss:  0.6343306303024292\n",
      "Write summary at step 10610  Loss:  0.689219057559967\n",
      "Write summary at step 10620  Loss:  0.6550326943397522\n",
      "Write summary at step 10630  Loss:  0.5532209873199463\n",
      "Write summary at step 10640  Loss:  0.6464443802833557\n",
      "Write summary at step 10650  Loss:  0.7274059057235718\n",
      "Write summary at step 10660  Loss:  0.5091415047645569\n",
      "Write summary at step 10670  Loss:  0.6441073417663574\n",
      "Write summary at step 10680  Loss:  0.6310405135154724\n",
      "Write summary at step 10690  Loss:  0.614824652671814\n",
      "Write summary at step 10700  Loss:  0.5907949805259705\n",
      "Write summary at step 10710  Loss:  0.755893349647522\n",
      "Write summary at step 10720  Loss:  0.6529027819633484\n",
      "Write summary at step 10730  Loss:  0.606870710849762\n",
      "Write summary at step 10740  Loss:  0.7210633158683777\n",
      "Write summary at step 10750  Loss:  0.579954981803894\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7619047619047619 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5807718579234973\n",
      "Loss normal: 0.5915724540943708 Loss Control: 0.5273299036455936 Loss Patient: 0.836497193823258 Loss balanced:  0.6819135487344259 Loss1+loss2: 0.6819135487344259\n",
      "\n",
      " > BEST MODEL (0.68191) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 10760  Loss:  0.6933843493461609\n",
      "Write summary at step 10770  Loss:  0.6841849088668823\n",
      "Write summary at step 10780  Loss:  0.773396909236908\n",
      "Write summary at step 10790  Loss:  0.5987797379493713\n",
      "Write summary at step 10800  Loss:  0.6025576591491699\n",
      "Write summary at step 10810  Loss:  0.6709209680557251\n",
      "Write summary at step 10820  Loss:  0.7179285287857056\n",
      "Write summary at step 10830  Loss:  0.7218506336212158\n",
      "Write summary at step 10840  Loss:  0.7732869386672974\n",
      "Write summary at step 10850  Loss:  0.7369959354400635\n",
      "Write summary at step 10860  Loss:  0.7442874908447266\n",
      "Write summary at step 10870  Loss:  0.6207283139228821\n",
      "Write summary at step 10880  Loss:  0.864275336265564\n",
      "Write summary at step 10890  Loss:  0.6055892705917358\n",
      "Write summary at step 10900  Loss:  0.5801419615745544\n",
      "Write summary at step 10910  Loss:  0.5801518559455872\n",
      "Write summary at step 10920  Loss:  0.6041693091392517\n",
      "Write summary at step 10930  Loss:  0.6722686886787415\n",
      "Write summary at step 10940  Loss:  0.7279293537139893\n",
      "Write summary at step 10950  Loss:  0.5636774301528931\n",
      "Write summary at step 10960  Loss:  0.6293181777000427\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6277056277056277 Acurracy Control:  0.6885245901639344 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.5421789617486339\n",
      "Loss normal: 0.6318810365416787 Loss Control: 0.5938289670344911 Loss Patient: 0.7769545409828424 Loss balanced:  0.6853917540086667 Loss1+loss2: 0.6853917540086667\n",
      "Write summary at step 10970  Loss:  0.6946195363998413\n",
      "Write summary at step 10980  Loss:  0.6345263719558716\n",
      "Write summary at step 10990  Loss:  0.734807014465332\n",
      "Write summary at step 11000  Loss:  0.7003902196884155\n",
      "Saved checkpoint to: result/30/panns/checkpoint_11000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6190476190476191 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.4906079234972678\n",
      "Loss normal: 0.6532311034408999 Loss Control: 0.6244442720230812 Loss Patient: 0.7629808560013771 Loss balanced:  0.6937125640122291 Loss1+loss2: 0.6937125640122291\n",
      "Write summary at step 11010  Loss:  0.6629605293273926\n",
      "Write summary at step 11020  Loss:  0.7041399478912354\n",
      "Write summary at step 11030  Loss:  0.6789475679397583\n",
      "Write summary at step 11040  Loss:  0.6764633655548096\n",
      "Write summary at step 11050  Loss:  0.5123201608657837\n",
      "Write summary at step 11060  Loss:  0.7409271597862244\n",
      "Write summary at step 11070  Loss:  0.49423542618751526\n",
      "Write summary at step 11080  Loss:  0.6212782859802246\n",
      "Write summary at step 11090  Loss:  0.6604750156402588\n",
      "Write summary at step 11100  Loss:  0.5949179530143738\n",
      "Write summary at step 11110  Loss:  0.5883833169937134\n",
      "Write summary at step 11120  Loss:  0.5826907157897949\n",
      "Write summary at step 11130  Loss:  0.7564396858215332\n",
      "Write summary at step 11140  Loss:  0.6281493306159973\n",
      "Write summary at step 11150  Loss:  0.6618767976760864\n",
      "Write summary at step 11160  Loss:  0.7094606161117554\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5326161202185793\n",
      "Loss normal: 0.6156461600101355 Loss Control: 0.5698340290882549 Loss Patient: 0.7903048681716124 Loss balanced:  0.6800694486299337 Loss1+loss2: 0.6800694486299337\n",
      "\n",
      " > BEST MODEL (0.68007) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 11170  Loss:  0.6479787230491638\n",
      "Write summary at step 11180  Loss:  0.6349831223487854\n",
      "Write summary at step 11190  Loss:  0.7216106653213501\n",
      "Write summary at step 11200  Loss:  0.6075677871704102\n",
      "Write summary at step 11210  Loss:  0.5666797757148743\n",
      "Write summary at step 11220  Loss:  0.6431220769882202\n",
      "Write summary at step 11230  Loss:  0.6523435115814209\n",
      "Write summary at step 11240  Loss:  0.6270751953125\n",
      "Write summary at step 11250  Loss:  0.5892692804336548\n",
      "Write summary at step 11260  Loss:  0.6598770618438721\n",
      "Write summary at step 11270  Loss:  0.6808909177780151\n",
      "Write summary at step 11280  Loss:  0.560503363609314\n",
      "Write summary at step 11290  Loss:  0.7152864336967468\n",
      "Write summary at step 11300  Loss:  0.6582335233688354\n",
      "Write summary at step 11310  Loss:  0.616705060005188\n",
      "Write summary at step 11320  Loss:  0.7969108819961548\n",
      "Write summary at step 11330  Loss:  0.7350027561187744\n",
      "Write summary at step 11340  Loss:  0.5484269857406616\n",
      "Write summary at step 11350  Loss:  0.7169620990753174\n",
      "Write summary at step 11360  Loss:  0.6838233470916748\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5741120218579235\n",
      "Loss normal: 0.5804619700103612 Loss Control: 0.49815337302906265 Loss Patient: 0.8942634761333466 Loss balanced:  0.6962084245812046 Loss1+loss2: 0.6962084245812046\n",
      "Write summary at step 11370  Loss:  0.687970757484436\n",
      "Write summary at step 11380  Loss:  0.8000738620758057\n",
      "Write summary at step 11390  Loss:  0.6547874212265015\n",
      "Write summary at step 11400  Loss:  0.5688103437423706\n",
      "Write summary at step 11410  Loss:  0.804123044013977\n",
      "Write summary at step 11420  Loss:  0.6287119388580322\n",
      "Write summary at step 11430  Loss:  0.6057367324829102\n",
      "Write summary at step 11440  Loss:  0.6656213998794556\n",
      "Write summary at step 11450  Loss:  0.5462003946304321\n",
      "Write summary at step 11460  Loss:  0.7296947240829468\n",
      "Write summary at step 11470  Loss:  0.611871600151062\n",
      "Write summary at step 11480  Loss:  0.557700514793396\n",
      "Write summary at step 11490  Loss:  0.7673075199127197\n",
      "Write summary at step 11500  Loss:  0.7740331292152405\n",
      "Saved checkpoint to: result/30/panns/checkpoint_11500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.1875 Acurracy Balanced 0.5800887978142076\n",
      "Loss normal: 0.5854698133158993 Loss Control: 0.5065438170902065 Loss Patient: 0.8863751565416654 Loss balanced:  0.696459486815936 Loss1+loss2: 0.696459486815936\n",
      "Write summary at step 11510  Loss:  0.6608008742332458\n",
      "Write summary at step 11520  Loss:  0.6816797852516174\n",
      "Write summary at step 11530  Loss:  0.6461860537528992\n",
      "Write summary at step 11540  Loss:  0.6551885604858398\n",
      "Write summary at step 11550  Loss:  0.5872331857681274\n",
      "Write summary at step 11560  Loss:  0.5576843023300171\n",
      "Write summary at step 11570  Loss:  0.7858012914657593\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8225108225108225 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5959699453551912\n",
      "Loss normal: 0.5410164566267104 Loss Control: 0.41624094065421263 Loss Patient: 1.0167231274147828 Loss balanced:  0.7164820340344977 Loss1+loss2: 0.7164820340344977\n",
      "Write summary at step 11580  Loss:  0.48723575472831726\n",
      "Write summary at step 11590  Loss:  0.6888587474822998\n",
      "Write summary at step 11600  Loss:  0.6928129196166992\n",
      "Write summary at step 11610  Loss:  0.7367093563079834\n",
      "Write summary at step 11620  Loss:  0.5966346263885498\n",
      "Write summary at step 11630  Loss:  0.6744068264961243\n",
      "Write summary at step 11640  Loss:  0.6696948409080505\n",
      "Write summary at step 11650  Loss:  0.748407244682312\n",
      "Write summary at step 11660  Loss:  0.7479641437530518\n",
      "Write summary at step 11670  Loss:  0.625568687915802\n",
      "Write summary at step 11680  Loss:  0.593437671661377\n",
      "Write summary at step 11690  Loss:  0.7346899509429932\n",
      "Write summary at step 11700  Loss:  0.6472691893577576\n",
      "Write summary at step 11710  Loss:  0.7000558376312256\n",
      "Write summary at step 11720  Loss:  0.6013646125793457\n",
      "Write summary at step 11730  Loss:  0.6020865440368652\n",
      "Write summary at step 11740  Loss:  0.6403173208236694\n",
      "Write summary at step 11750  Loss:  0.7466668486595154\n",
      "Write summary at step 11760  Loss:  0.8359706401824951\n",
      "Write summary at step 11770  Loss:  0.6483686566352844\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.25 Acurracy Balanced 0.5976775956284153\n",
      "Loss normal: 0.591438832866165 Loss Control: 0.5364037792865044 Loss Patient: 0.8012599920233091 Loss balanced:  0.6688318856549067 Loss1+loss2: 0.6688318856549067\n",
      "\n",
      " > BEST MODEL (0.66883) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 11780  Loss:  0.5989049673080444\n",
      "Write summary at step 11790  Loss:  0.6275186538696289\n",
      "Write summary at step 11800  Loss:  0.6081129312515259\n",
      "Write summary at step 11810  Loss:  0.7182353138923645\n",
      "Write summary at step 11820  Loss:  0.6631340980529785\n",
      "Write summary at step 11830  Loss:  0.7366973161697388\n",
      "Write summary at step 11840  Loss:  0.6588000059127808\n",
      "Write summary at step 11850  Loss:  0.5838153958320618\n",
      "Write summary at step 11860  Loss:  0.6582333445549011\n",
      "Write summary at step 11870  Loss:  0.658988893032074\n",
      "Write summary at step 11880  Loss:  0.7684047222137451\n",
      "Write summary at step 11890  Loss:  0.7770272493362427\n",
      "Write summary at step 11900  Loss:  0.706936776638031\n",
      "Write summary at step 11910  Loss:  0.6801407337188721\n",
      "Write summary at step 11920  Loss:  0.6443122029304504\n",
      "Write summary at step 11930  Loss:  0.7791803479194641\n",
      "Write summary at step 11940  Loss:  0.6641681790351868\n",
      "Write summary at step 11950  Loss:  0.6604806184768677\n",
      "Write summary at step 11960  Loss:  0.6122631430625916\n",
      "Write summary at step 11970  Loss:  0.7254510521888733\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5795765027322404\n",
      "Loss normal: 0.561807365386517 Loss Control: 0.4731061370646367 Loss Patient: 0.8999808033307394 Loss balanced:  0.686543470197688 Loss1+loss2: 0.686543470197688\n",
      "Write summary at step 11980  Loss:  0.6462855339050293\n",
      "Write summary at step 11990  Loss:  0.7626271843910217\n",
      "Write summary at step 12000  Loss:  0.6238616704940796\n",
      "Saved checkpoint to: result/30/panns/checkpoint_12000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5753073770491803\n",
      "Loss normal: 0.5968077580134074 Loss Control: 0.5454826153041236 Loss Patient: 0.7924849018454552 Loss balanced:  0.6689837585747893 Loss1+loss2: 0.6689837585747893\n",
      "Write summary at step 12010  Loss:  0.7991852164268494\n",
      "Write summary at step 12020  Loss:  0.6696493625640869\n",
      "Write summary at step 12030  Loss:  0.6398453712463379\n",
      "Write summary at step 12040  Loss:  0.7562423944473267\n",
      "Write summary at step 12050  Loss:  0.725356936454773\n",
      "Write summary at step 12060  Loss:  0.6604986190795898\n",
      "Write summary at step 12070  Loss:  0.6838614344596863\n",
      "Write summary at step 12080  Loss:  0.6227656602859497\n",
      "Write summary at step 12090  Loss:  0.6341077089309692\n",
      "Write summary at step 12100  Loss:  0.668741762638092\n",
      "Write summary at step 12110  Loss:  0.6735581755638123\n",
      "Write summary at step 12120  Loss:  0.64565110206604\n",
      "Write summary at step 12130  Loss:  0.6704408526420593\n",
      "Write summary at step 12140  Loss:  0.8647279739379883\n",
      "Write summary at step 12150  Loss:  0.6781472563743591\n",
      "Write summary at step 12160  Loss:  0.6707680225372314\n",
      "Write summary at step 12170  Loss:  0.6580161452293396\n",
      "Write summary at step 12180  Loss:  0.552122950553894\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.7049180327868853 Acurracy Patient:  0.4375 Acurracy Balanced 0.5712090163934427\n",
      "Loss normal: 0.649074104183164 Loss Control: 0.6314986647803926 Loss Patient: 0.7160804644227028 Loss balanced:  0.6737895646015477 Loss1+loss2: 0.6737895646015477\n",
      "Write summary at step 12190  Loss:  0.659179151058197\n",
      "Write summary at step 12200  Loss:  0.612411618232727\n",
      "Write summary at step 12210  Loss:  0.5804429650306702\n",
      "Write summary at step 12220  Loss:  0.7190812826156616\n",
      "Write summary at step 12230  Loss:  0.7310528755187988\n",
      "Write summary at step 12240  Loss:  0.6600500345230103\n",
      "Write summary at step 12250  Loss:  0.7444369196891785\n",
      "Write summary at step 12260  Loss:  0.7370433807373047\n",
      "Write summary at step 12270  Loss:  0.6533019542694092\n",
      "Write summary at step 12280  Loss:  0.5450429320335388\n",
      "Write summary at step 12290  Loss:  0.6080859899520874\n",
      "Write summary at step 12300  Loss:  0.6043444871902466\n",
      "Write summary at step 12310  Loss:  0.6615796089172363\n",
      "Write summary at step 12320  Loss:  0.6909477114677429\n",
      "Write summary at step 12330  Loss:  0.7777800559997559\n",
      "Write summary at step 12340  Loss:  0.6157939434051514\n",
      "Write summary at step 12350  Loss:  0.685552179813385\n",
      "Write summary at step 12360  Loss:  0.585227370262146\n",
      "Write summary at step 12370  Loss:  0.6738206148147583\n",
      "Write summary at step 12380  Loss:  0.7447905540466309\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7445887445887446 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5698428961748634\n",
      "Loss normal: 0.6182336283452583 Loss Control: 0.5742816185690666 Loss Patient: 0.785800681139032 Loss balanced:  0.6800411498540493 Loss1+loss2: 0.6800411498540493\n",
      "Write summary at step 12390  Loss:  0.7059204578399658\n",
      "Write summary at step 12400  Loss:  0.6796602010726929\n",
      "Write summary at step 12410  Loss:  0.6613802313804626\n",
      "Write summary at step 12420  Loss:  0.6136106252670288\n",
      "Write summary at step 12430  Loss:  0.5269540548324585\n",
      "Write summary at step 12440  Loss:  0.5823358297348022\n",
      "Write summary at step 12450  Loss:  0.6213496327400208\n",
      "Write summary at step 12460  Loss:  0.6722614765167236\n",
      "Write summary at step 12470  Loss:  0.570591926574707\n",
      "Write summary at step 12480  Loss:  0.5602555274963379\n",
      "Write summary at step 12490  Loss:  0.698456883430481\n",
      "Write summary at step 12500  Loss:  0.5489497184753418\n",
      "Saved checkpoint to: result/30/panns/checkpoint_12500.pt\n",
      "Validation:\n",
      "Acurracy:  0.4588744588744589 Acurracy Control:  0.3879781420765027 Acurracy Patient:  0.7291666666666666 Acurracy Balanced 0.5585724043715847\n",
      "Loss normal: 0.7021397414145532 Loss Control: 0.7216170661436404 Loss Patient: 0.6278824514398972 Loss balanced:  0.6747497587917688 Loss1+loss2: 0.6747497587917688\n",
      "Write summary at step 12510  Loss:  0.6845690011978149\n",
      "Write summary at step 12520  Loss:  0.6550287008285522\n",
      "Write summary at step 12530  Loss:  0.6287179589271545\n",
      "Write summary at step 12540  Loss:  0.6599286794662476\n",
      "Write summary at step 12550  Loss:  0.6456595063209534\n",
      "Write summary at step 12560  Loss:  0.6133368015289307\n",
      "Write summary at step 12570  Loss:  0.6440485715866089\n",
      "Write summary at step 12580  Loss:  0.6913550496101379\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5677937158469946\n",
      "Loss normal: 0.64520261581842 Loss Control: 0.6220523369768278 Loss Patient: 0.7334630247205496 Loss balanced:  0.6777576808486887 Loss1+loss2: 0.6777576808486887\n",
      "Write summary at step 12590  Loss:  0.5780003070831299\n",
      "Write summary at step 12600  Loss:  0.7471768856048584\n",
      "Write summary at step 12610  Loss:  0.7277392745018005\n",
      "Write summary at step 12620  Loss:  0.5580822825431824\n",
      "Write summary at step 12630  Loss:  0.7839972376823425\n",
      "Write summary at step 12640  Loss:  0.6113563776016235\n",
      "Write summary at step 12650  Loss:  0.6678152084350586\n",
      "Write summary at step 12660  Loss:  0.6697976589202881\n",
      "Write summary at step 12670  Loss:  0.7193496227264404\n",
      "Write summary at step 12680  Loss:  0.5926796197891235\n",
      "Write summary at step 12690  Loss:  0.7574959993362427\n",
      "Write summary at step 12700  Loss:  0.7564033269882202\n",
      "Write summary at step 12710  Loss:  0.6768925189971924\n",
      "Write summary at step 12720  Loss:  0.5786623954772949\n",
      "Write summary at step 12730  Loss:  0.6649250984191895\n",
      "Write summary at step 12740  Loss:  0.7158335447311401\n",
      "Write summary at step 12750  Loss:  0.6193529367446899\n",
      "Write summary at step 12760  Loss:  0.5747871398925781\n",
      "Write summary at step 12770  Loss:  0.6713347434997559\n",
      "Write summary at step 12780  Loss:  0.6326926946640015\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7445887445887446 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5698428961748634\n",
      "Loss normal: 0.6152260386066519 Loss Control: 0.5680632513077533 Loss Patient: 0.7950341993321975 Loss balanced:  0.6815487253199755 Loss1+loss2: 0.6815487253199755\n",
      "Write summary at step 12790  Loss:  0.5904743075370789\n",
      "Write summary at step 12800  Loss:  0.4561091661453247\n",
      "Write summary at step 12810  Loss:  0.5346882343292236\n",
      "Write summary at step 12820  Loss:  0.6892306208610535\n",
      "Write summary at step 12830  Loss:  0.664529025554657\n",
      "Write summary at step 12840  Loss:  0.6320010423660278\n",
      "Write summary at step 12850  Loss:  0.7013146281242371\n",
      "Write summary at step 12860  Loss:  0.6682020425796509\n",
      "Write summary at step 12870  Loss:  0.5290514826774597\n",
      "Write summary at step 12880  Loss:  0.6014954447746277\n",
      "Write summary at step 12890  Loss:  0.6181775331497192\n",
      "Write summary at step 12900  Loss:  0.5836849212646484\n",
      "Write summary at step 12910  Loss:  0.5890009999275208\n",
      "Write summary at step 12920  Loss:  0.7290608882904053\n",
      "Write summary at step 12930  Loss:  0.6440002918243408\n",
      "Write summary at step 12940  Loss:  0.5755391120910645\n",
      "Write summary at step 12950  Loss:  0.5943590402603149\n",
      "Write summary at step 12960  Loss:  0.6628904342651367\n",
      "Write summary at step 12970  Loss:  0.8093323111534119\n",
      "Write summary at step 12980  Loss:  0.6912090182304382\n",
      "Write summary at step 12990  Loss:  0.6303585767745972\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5281385281385281 Acurracy Control:  0.5683060109289617 Acurracy Patient:  0.375 Acurracy Balanced 0.47165300546448086\n",
      "Loss normal: 0.6887237558633218 Loss Control: 0.6809738109020588 Loss Patient: 0.7182704328248898 Loss balanced:  0.6996221218634743 Loss1+loss2: 0.6996221218634743\n",
      "Write summary at step 13000  Loss:  0.6103119850158691\n",
      "Saved checkpoint to: result/30/panns/checkpoint_13000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5281385281385281 Acurracy Control:  0.5683060109289617 Acurracy Patient:  0.375 Acurracy Balanced 0.47165300546448086\n",
      "Loss normal: 0.6890853829198069 Loss Control: 0.6765700044527732 Loss Patient: 0.7368002732594808 Loss balanced:  0.706685138856127 Loss1+loss2: 0.706685138856127\n",
      "Write summary at step 13010  Loss:  0.6459278464317322\n",
      "Write summary at step 13020  Loss:  0.5800808072090149\n",
      "Write summary at step 13030  Loss:  0.6397950053215027\n",
      "Write summary at step 13040  Loss:  0.7035840749740601\n",
      "Write summary at step 13050  Loss:  0.7383887767791748\n",
      "Write summary at step 13060  Loss:  0.6882370710372925\n",
      "Write summary at step 13070  Loss:  0.7149849534034729\n",
      "Write summary at step 13080  Loss:  0.6666736602783203\n",
      "Write summary at step 13090  Loss:  0.7479196190834045\n",
      "Write summary at step 13100  Loss:  0.7850975394248962\n",
      "Write summary at step 13110  Loss:  0.6401463150978088\n",
      "Write summary at step 13120  Loss:  0.6302235722541809\n",
      "Write summary at step 13130  Loss:  0.6242606043815613\n",
      "Write summary at step 13140  Loss:  0.5694632530212402\n",
      "Write summary at step 13150  Loss:  0.7491858601570129\n",
      "Write summary at step 13160  Loss:  0.5715392827987671\n",
      "Write summary at step 13170  Loss:  0.5736525058746338\n",
      "Write summary at step 13180  Loss:  0.785389244556427\n",
      "Write summary at step 13190  Loss:  0.6587775945663452\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7056277056277056 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5683060109289617\n",
      "Loss normal: 0.6005003920623234 Loss Control: 0.5395719658155911 Loss Patient: 0.8327899916718403 Loss balanced:  0.6861809787437156 Loss1+loss2: 0.6861809787437156\n",
      "Write summary at step 13200  Loss:  0.5414642691612244\n",
      "Write summary at step 13210  Loss:  0.4965997338294983\n",
      "Write summary at step 13220  Loss:  0.8627216815948486\n",
      "Write summary at step 13230  Loss:  0.6727412939071655\n",
      "Write summary at step 13240  Loss:  0.7076466679573059\n",
      "Write summary at step 13250  Loss:  0.7754935026168823\n",
      "Write summary at step 13260  Loss:  0.6743522882461548\n",
      "Write summary at step 13270  Loss:  0.6276705861091614\n",
      "Write summary at step 13280  Loss:  0.5556036829948425\n",
      "Write summary at step 13290  Loss:  0.5595238208770752\n",
      "Write summary at step 13300  Loss:  0.7584317922592163\n",
      "Write summary at step 13310  Loss:  0.627687931060791\n",
      "Write summary at step 13320  Loss:  0.7583542466163635\n",
      "Write summary at step 13330  Loss:  0.7335655689239502\n",
      "Write summary at step 13340  Loss:  0.6912009119987488\n",
      "Write summary at step 13350  Loss:  0.7165850400924683\n",
      "Write summary at step 13360  Loss:  0.628199577331543\n",
      "Write summary at step 13370  Loss:  0.6038787364959717\n",
      "Write summary at step 13380  Loss:  0.7324684858322144\n",
      "Write summary at step 13390  Loss:  0.7120708227157593\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.25 Acurracy Balanced 0.5648907103825136\n",
      "Loss normal: 0.6165515012813337 Loss Control: 0.5687950333285201 Loss Patient: 0.7986230043073496 Loss balanced:  0.6837090188179349 Loss1+loss2: 0.6837090188179349\n",
      "Write summary at step 13400  Loss:  0.8132857084274292\n",
      "Write summary at step 13410  Loss:  0.5757569670677185\n",
      "Write summary at step 13420  Loss:  0.6815602779388428\n",
      "Write summary at step 13430  Loss:  0.8255715370178223\n",
      "Write summary at step 13440  Loss:  0.6740783452987671\n",
      "Write summary at step 13450  Loss:  0.5983732342720032\n",
      "Write summary at step 13460  Loss:  0.6244506239891052\n",
      "Write summary at step 13470  Loss:  0.5883142352104187\n",
      "Write summary at step 13480  Loss:  0.6699407696723938\n",
      "Write summary at step 13490  Loss:  0.6953110098838806\n",
      "Write summary at step 13500  Loss:  0.5482290983200073\n",
      "Saved checkpoint to: result/30/panns/checkpoint_13500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.600922131147541\n",
      "Loss normal: 0.5772703673158374 Loss Control: 0.5033366274638255 Loss Patient: 0.8591427467763424 Loss balanced:  0.6812396871200839 Loss1+loss2: 0.6812396871200839\n",
      "Write summary at step 13510  Loss:  0.6627950668334961\n",
      "Write summary at step 13520  Loss:  0.6745080947875977\n",
      "Write summary at step 13530  Loss:  0.6654874682426453\n",
      "Write summary at step 13540  Loss:  0.568444013595581\n",
      "Write summary at step 13550  Loss:  0.7076144218444824\n",
      "Write summary at step 13560  Loss:  0.8006260395050049\n",
      "Write summary at step 13570  Loss:  0.5660064220428467\n",
      "Write summary at step 13580  Loss:  0.7113683223724365\n",
      "Write summary at step 13590  Loss:  0.8646596670150757\n",
      "Write summary at step 13600  Loss:  0.6223196983337402\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.49783549783549785 Acurracy Control:  0.5136612021857924 Acurracy Patient:  0.4375 Acurracy Balanced 0.4755806010928962\n",
      "Loss normal: 0.6965004205703735 Loss Control: 0.704078803948366 Loss Patient: 0.6676078739886483 Loss balanced:  0.6858433389685071 Loss1+loss2: 0.6858433389685071\n",
      "Write summary at step 13610  Loss:  0.5676990747451782\n",
      "Write summary at step 13620  Loss:  0.6409816145896912\n",
      "Write summary at step 13630  Loss:  0.6467700004577637\n",
      "Write summary at step 13640  Loss:  0.6749899387359619\n",
      "Write summary at step 13650  Loss:  0.7096867561340332\n",
      "Write summary at step 13660  Loss:  0.630245566368103\n",
      "Write summary at step 13670  Loss:  0.6566250324249268\n",
      "Write summary at step 13680  Loss:  0.660054087638855\n",
      "Write summary at step 13690  Loss:  0.6365622282028198\n",
      "Write summary at step 13700  Loss:  0.6363887786865234\n",
      "Write summary at step 13710  Loss:  0.7655825614929199\n",
      "Write summary at step 13720  Loss:  0.569007158279419\n",
      "Write summary at step 13730  Loss:  0.6224737167358398\n",
      "Write summary at step 13740  Loss:  0.6290504336357117\n",
      "Write summary at step 13750  Loss:  0.8125137090682983\n",
      "Write summary at step 13760  Loss:  0.679122805595398\n",
      "Write summary at step 13770  Loss:  0.5344332456588745\n",
      "Write summary at step 13780  Loss:  0.6674941182136536\n",
      "Write summary at step 13790  Loss:  0.6150442361831665\n",
      "Write summary at step 13800  Loss:  0.6828147172927856\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5670995670995671 Acurracy Control:  0.6174863387978142 Acurracy Patient:  0.375 Acurracy Balanced 0.4962431693989071\n",
      "Loss normal: 0.6550735828680393 Loss Control: 0.6339992161005572 Loss Patient: 0.7354196074108282 Loss balanced:  0.6847094117556927 Loss1+loss2: 0.6847094117556927\n",
      "Write summary at step 13810  Loss:  0.6359379291534424\n",
      "Write summary at step 13820  Loss:  0.5588290691375732\n",
      "Write summary at step 13830  Loss:  0.7286778688430786\n",
      "Write summary at step 13840  Loss:  0.6204862594604492\n",
      "Write summary at step 13850  Loss:  0.6459962129592896\n",
      "Write summary at step 13860  Loss:  0.8010774850845337\n",
      "Write summary at step 13870  Loss:  0.5601706504821777\n",
      "Write summary at step 13880  Loss:  0.5697450041770935\n",
      "Write summary at step 13890  Loss:  0.5931500792503357\n",
      "Write summary at step 13900  Loss:  0.7726839780807495\n",
      "Write summary at step 13910  Loss:  0.6068684458732605\n",
      "Write summary at step 13920  Loss:  0.6142211556434631\n",
      "Write summary at step 13930  Loss:  0.5996721982955933\n",
      "Write summary at step 13940  Loss:  0.506483793258667\n",
      "Write summary at step 13950  Loss:  0.514245867729187\n",
      "Write summary at step 13960  Loss:  0.634484589099884\n",
      "Write summary at step 13970  Loss:  0.644181489944458\n",
      "Write summary at step 13980  Loss:  0.7445834875106812\n",
      "Write summary at step 13990  Loss:  0.634482741355896\n",
      "Write summary at step 14000  Loss:  0.7251316905021667\n",
      "Saved checkpoint to: result/30/panns/checkpoint_14000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5483265027322404\n",
      "Loss normal: 0.5542309383551279 Loss Control: 0.420087036050734 Loss Patient: 1.0656545255333185 Loss balanced:  0.7428707807920263 Loss1+loss2: 0.7428707807920263\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7748917748917749 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.125 Acurracy Balanced 0.5351775956284153\n",
      "Loss normal: 0.5509349182570652 Loss Control: 0.4029157301767276 Loss Patient: 1.1152581019947927 Loss balanced:  0.7590869160857602 Loss1+loss2: 0.7590869160857602\n",
      "Write summary at step 14010  Loss:  0.7016061544418335\n",
      "Write summary at step 14020  Loss:  0.6042162179946899\n",
      "Write summary at step 14030  Loss:  0.6774278283119202\n",
      "Write summary at step 14040  Loss:  0.5647526383399963\n",
      "Write summary at step 14050  Loss:  0.665814995765686\n",
      "Write summary at step 14060  Loss:  0.6513413786888123\n",
      "Write summary at step 14070  Loss:  0.5704967379570007\n",
      "Write summary at step 14080  Loss:  0.5923453569412231\n",
      "Write summary at step 14090  Loss:  0.6441437005996704\n",
      "Write summary at step 14100  Loss:  0.8232544660568237\n",
      "Write summary at step 14110  Loss:  0.6711970567703247\n",
      "Write summary at step 14120  Loss:  0.6389422416687012\n",
      "Write summary at step 14130  Loss:  0.6489620208740234\n",
      "Write summary at step 14140  Loss:  0.5397576093673706\n",
      "Write summary at step 14150  Loss:  0.6066082715988159\n",
      "Write summary at step 14160  Loss:  0.7710303068161011\n",
      "Write summary at step 14170  Loss:  0.6758342981338501\n",
      "Write summary at step 14180  Loss:  0.6517301797866821\n",
      "Write summary at step 14190  Loss:  0.5835723876953125\n",
      "Write summary at step 14200  Loss:  0.7346183061599731\n",
      "Write summary at step 14210  Loss:  0.6944260001182556\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7186147186147186 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5380806010928962\n",
      "Loss normal: 0.6074382541499612 Loss Control: 0.5326060004573051 Loss Patient: 0.8927362502242128 Loss balanced:  0.7126711253407589 Loss1+loss2: 0.7126711253407589\n",
      "Write summary at step 14220  Loss:  0.4723822772502899\n",
      "Write summary at step 14230  Loss:  0.6164964437484741\n",
      "Write summary at step 14240  Loss:  0.5618857145309448\n",
      "Write summary at step 14250  Loss:  0.7768946886062622\n",
      "Write summary at step 14260  Loss:  0.5433991551399231\n",
      "Write summary at step 14270  Loss:  0.6248146891593933\n",
      "Write summary at step 14280  Loss:  0.5985487699508667\n",
      "Write summary at step 14290  Loss:  0.5803359746932983\n",
      "Write summary at step 14300  Loss:  0.7713949084281921\n",
      "Write summary at step 14310  Loss:  0.6452509760856628\n",
      "Write summary at step 14320  Loss:  0.8136321306228638\n",
      "Write summary at step 14330  Loss:  0.7353245615959167\n",
      "Write summary at step 14340  Loss:  0.5817293524742126\n",
      "Write summary at step 14350  Loss:  0.6252713799476624\n",
      "Write summary at step 14360  Loss:  0.7025286555290222\n",
      "Write summary at step 14370  Loss:  0.6264142990112305\n",
      "Write summary at step 14380  Loss:  0.6452443599700928\n",
      "Write summary at step 14390  Loss:  0.6676539182662964\n",
      "Write summary at step 14400  Loss:  0.5561906099319458\n",
      "Write summary at step 14410  Loss:  0.8976919054985046\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5549863387978142\n",
      "Loss normal: 0.605233608644246 Loss Control: 0.5367792046786658 Loss Patient: 0.8662159871309996 Loss balanced:  0.7014975959048326 Loss1+loss2: 0.7014975959048326\n",
      "Write summary at step 14420  Loss:  0.6113704442977905\n",
      "Write summary at step 14430  Loss:  0.612549364566803\n",
      "Write summary at step 14440  Loss:  0.6547783017158508\n",
      "Write summary at step 14450  Loss:  0.7431333661079407\n",
      "Write summary at step 14460  Loss:  0.5672853589057922\n",
      "Write summary at step 14470  Loss:  0.6920911073684692\n",
      "Write summary at step 14480  Loss:  0.6235635876655579\n",
      "Write summary at step 14490  Loss:  0.7198604345321655\n",
      "Write summary at step 14500  Loss:  0.6370887160301208\n",
      "Saved checkpoint to: result/30/panns/checkpoint_14500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5686475409836066\n",
      "Loss normal: 0.5868458497575867 Loss Control: 0.5169315790869499 Loss Patient: 0.8533939719200134 Loss balanced:  0.6851627755034817 Loss1+loss2: 0.6851627755034817\n",
      "Write summary at step 14510  Loss:  0.6802575588226318\n",
      "Write summary at step 14520  Loss:  0.6718746423721313\n",
      "Write summary at step 14530  Loss:  0.5673942565917969\n",
      "Write summary at step 14540  Loss:  0.7838922739028931\n",
      "Write summary at step 14550  Loss:  0.6228632926940918\n",
      "Write summary at step 14560  Loss:  0.7459461092948914\n",
      "Write summary at step 14570  Loss:  0.6907558441162109\n",
      "Write summary at step 14580  Loss:  0.6813226342201233\n",
      "Write summary at step 14590  Loss:  0.644813060760498\n",
      "Write summary at step 14600  Loss:  0.665361225605011\n",
      "Write summary at step 14610  Loss:  0.6499972343444824\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7056277056277056 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5529371584699454\n",
      "Loss normal: 0.6267212813808805 Loss Control: 0.5776254262754826 Loss Patient: 0.8138992348685861 Loss balanced:  0.6957623305720344 Loss1+loss2: 0.6957623305720344\n",
      "Write summary at step 14620  Loss:  0.6090402007102966\n",
      "Write summary at step 14630  Loss:  0.6993768215179443\n",
      "Write summary at step 14640  Loss:  0.8887196779251099\n",
      "Write summary at step 14650  Loss:  0.6974223852157593\n",
      "Write summary at step 14660  Loss:  0.49473837018013\n",
      "Write summary at step 14670  Loss:  0.6940115690231323\n",
      "Write summary at step 14680  Loss:  0.6188536882400513\n",
      "Write summary at step 14690  Loss:  0.5970896482467651\n",
      "Write summary at step 14700  Loss:  0.5850865840911865\n",
      "Write summary at step 14710  Loss:  0.6647257804870605\n",
      "Write summary at step 14720  Loss:  0.5273310542106628\n",
      "Write summary at step 14730  Loss:  0.6368767023086548\n",
      "Write summary at step 14740  Loss:  0.7153631448745728\n",
      "Write summary at step 14750  Loss:  0.5778824687004089\n",
      "Write summary at step 14760  Loss:  0.6979092359542847\n",
      "Write summary at step 14770  Loss:  0.7828443050384521\n",
      "Write summary at step 14780  Loss:  0.6059304475784302\n",
      "Write summary at step 14790  Loss:  0.7143106460571289\n",
      "Write summary at step 14800  Loss:  0.4288337230682373\n",
      "Write summary at step 14810  Loss:  0.5774581432342529\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.1875 Acurracy Balanced 0.5691598360655737\n",
      "Loss normal: 0.5585721906645473 Loss Control: 0.44992515754178575 Loss Patient: 0.9727890267968178 Loss balanced:  0.7113570921693018 Loss1+loss2: 0.7113570921693018\n",
      "Write summary at step 14820  Loss:  0.5998631119728088\n",
      "Write summary at step 14830  Loss:  0.6929221749305725\n",
      "Write summary at step 14840  Loss:  0.7211229205131531\n",
      "Write summary at step 14850  Loss:  0.6902734041213989\n",
      "Write summary at step 14860  Loss:  0.6230173110961914\n",
      "Write summary at step 14870  Loss:  0.6796752214431763\n",
      "Write summary at step 14880  Loss:  0.8582050800323486\n",
      "Write summary at step 14890  Loss:  0.6609647274017334\n",
      "Write summary at step 14900  Loss:  0.6854360103607178\n",
      "Write summary at step 14910  Loss:  0.6370265483856201\n",
      "Write summary at step 14920  Loss:  0.5612602829933167\n",
      "Write summary at step 14930  Loss:  0.608522891998291\n",
      "Write summary at step 14940  Loss:  0.5555477142333984\n",
      "Write summary at step 14950  Loss:  0.5283806920051575\n",
      "Write summary at step 14960  Loss:  0.4863847494125366\n",
      "Write summary at step 14970  Loss:  0.7401468753814697\n",
      "Write summary at step 14980  Loss:  0.6325167417526245\n",
      "Write summary at step 14990  Loss:  0.5693879127502441\n",
      "Write summary at step 15000  Loss:  0.5537890195846558\n",
      "Saved checkpoint to: result/30/panns/checkpoint_15000.pt\n",
      "Validation:\n",
      "Acurracy:  0.4675324675324675 Acurracy Control:  0.5027322404371585 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.4180327868852459\n",
      "Loss normal: 0.692979633808136 Loss Control: 0.6821388009467412 Loss Patient: 0.7343103314439455 Loss balanced:  0.7082245661953434 Loss1+loss2: 0.7082245661953434\n",
      "Write summary at step 15010  Loss:  0.597456693649292\n",
      "Write summary at step 15020  Loss:  0.673657238483429\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.48917748917748916 Acurracy Control:  0.5191256830601093 Acurracy Patient:  0.375 Acurracy Balanced 0.44706284153005466\n",
      "Loss normal: 0.6887338195012246 Loss Control: 0.6722180807525343 Loss Patient: 0.7517000492662191 Loss balanced:  0.7119590650093768 Loss1+loss2: 0.7119590650093768\n",
      "Write summary at step 15030  Loss:  0.37555640935897827\n",
      "Write summary at step 15040  Loss:  0.6911851167678833\n",
      "Write summary at step 15050  Loss:  0.7080000638961792\n",
      "Write summary at step 15060  Loss:  0.5840768814086914\n",
      "Write summary at step 15070  Loss:  0.7095211148262024\n",
      "Write summary at step 15080  Loss:  0.6705496311187744\n",
      "Write summary at step 15090  Loss:  0.6218124628067017\n",
      "Write summary at step 15100  Loss:  0.6349302530288696\n",
      "Write summary at step 15110  Loss:  0.6361246705055237\n",
      "Write summary at step 15120  Loss:  0.7388955950737\n",
      "Write summary at step 15130  Loss:  0.930251955986023\n",
      "Write summary at step 15140  Loss:  0.5688576698303223\n",
      "Write summary at step 15150  Loss:  0.5732743144035339\n",
      "Write summary at step 15160  Loss:  0.6899574398994446\n",
      "Write summary at step 15170  Loss:  0.6537137627601624\n",
      "Write summary at step 15180  Loss:  0.6328677535057068\n",
      "Write summary at step 15190  Loss:  0.6928608417510986\n",
      "Write summary at step 15200  Loss:  0.6430822014808655\n",
      "Write summary at step 15210  Loss:  0.6400155425071716\n",
      "Write summary at step 15220  Loss:  0.624140202999115\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5747950819672131\n",
      "Loss normal: 0.6154851412876344 Loss Control: 0.5720207437140042 Loss Patient: 0.7811930943280458 Loss balanced:  0.6766069190210251 Loss1+loss2: 0.6766069190210251\n",
      "Write summary at step 15230  Loss:  0.7565299272537231\n",
      "Write summary at step 15240  Loss:  0.5260289311408997\n",
      "Write summary at step 15250  Loss:  0.5959841012954712\n",
      "Write summary at step 15260  Loss:  0.799391508102417\n",
      "Write summary at step 15270  Loss:  0.6862339377403259\n",
      "Write summary at step 15280  Loss:  0.7626957297325134\n",
      "Write summary at step 15290  Loss:  0.7135093212127686\n",
      "Write summary at step 15300  Loss:  0.6777163743972778\n",
      "Write summary at step 15310  Loss:  0.6015629172325134\n",
      "Write summary at step 15320  Loss:  0.7063467502593994\n",
      "Write summary at step 15330  Loss:  0.8168701529502869\n",
      "Write summary at step 15340  Loss:  0.6203721165657043\n",
      "Write summary at step 15350  Loss:  0.6699082255363464\n",
      "Write summary at step 15360  Loss:  0.6318036317825317\n",
      "Write summary at step 15370  Loss:  0.607295572757721\n",
      "Write summary at step 15380  Loss:  0.7869952917098999\n",
      "Write summary at step 15390  Loss:  0.7068641781806946\n",
      "Write summary at step 15400  Loss:  0.6010646224021912\n",
      "Write summary at step 15410  Loss:  0.5579319596290588\n",
      "Write summary at step 15420  Loss:  0.7176600098609924\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5560109289617486\n",
      "Loss normal: 0.5752467150553996 Loss Control: 0.4728375251501636 Loss Patient: 0.9656817807505528 Loss balanced:  0.7192596529503582 Loss1+loss2: 0.7192596529503582\n",
      "Write summary at step 15430  Loss:  0.5579109191894531\n",
      "Write summary at step 15440  Loss:  0.6407367587089539\n",
      "Write summary at step 15450  Loss:  0.5516225695610046\n",
      "Write summary at step 15460  Loss:  0.6379400491714478\n",
      "Write summary at step 15470  Loss:  0.6199698448181152\n",
      "Write summary at step 15480  Loss:  0.6758595705032349\n",
      "Write summary at step 15490  Loss:  0.5255968570709229\n",
      "Write summary at step 15500  Loss:  0.6638023257255554\n",
      "Saved checkpoint to: result/30/panns/checkpoint_15500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.1875 Acurracy Balanced 0.5418374316939891\n",
      "Loss normal: 0.598832885424296 Loss Control: 0.5160543039196828 Loss Patient: 0.9144261802236239 Loss balanced:  0.7152402420716533 Loss1+loss2: 0.7152402420716533\n",
      "Write summary at step 15510  Loss:  0.5789890289306641\n",
      "Write summary at step 15520  Loss:  0.6889264583587646\n",
      "Write summary at step 15530  Loss:  0.6369220018386841\n",
      "Write summary at step 15540  Loss:  0.7054213285446167\n",
      "Write summary at step 15550  Loss:  0.6004601716995239\n",
      "Write summary at step 15560  Loss:  0.6180278658866882\n",
      "Write summary at step 15570  Loss:  0.7964263558387756\n",
      "Write summary at step 15580  Loss:  0.6697145104408264\n",
      "Write summary at step 15590  Loss:  0.6635592579841614\n",
      "Write summary at step 15600  Loss:  0.6096466779708862\n",
      "Write summary at step 15610  Loss:  0.5814435482025146\n",
      "Write summary at step 15620  Loss:  0.8028849363327026\n",
      "Write summary at step 15630  Loss:  0.7067916393280029\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5650614754098361\n",
      "Loss normal: 0.6430247191226843 Loss Control: 0.6081298557135577 Loss Patient: 0.7760613585511843 Loss balanced:  0.692095607132371 Loss1+loss2: 0.692095607132371\n",
      "Write summary at step 15640  Loss:  0.6657814979553223\n",
      "Write summary at step 15650  Loss:  0.5505757927894592\n",
      "Write summary at step 15660  Loss:  0.611551821231842\n",
      "Write summary at step 15670  Loss:  0.5880253314971924\n",
      "Write summary at step 15680  Loss:  0.6827260255813599\n",
      "Write summary at step 15690  Loss:  0.38736891746520996\n",
      "Write summary at step 15700  Loss:  0.6149939298629761\n",
      "Write summary at step 15710  Loss:  0.7935092449188232\n",
      "Write summary at step 15720  Loss:  0.6651074886322021\n",
      "Write summary at step 15730  Loss:  0.575863242149353\n",
      "Write summary at step 15740  Loss:  0.6720036268234253\n",
      "Write summary at step 15750  Loss:  0.5865070819854736\n",
      "Write summary at step 15760  Loss:  0.4583284854888916\n",
      "Write summary at step 15770  Loss:  0.6171679496765137\n",
      "Write summary at step 15780  Loss:  0.6817209124565125\n",
      "Write summary at step 15790  Loss:  0.666702926158905\n",
      "Write summary at step 15800  Loss:  0.7381621599197388\n",
      "Write summary at step 15810  Loss:  0.5990439653396606\n",
      "Write summary at step 15820  Loss:  0.5418202877044678\n",
      "Write summary at step 15830  Loss:  0.606876015663147\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6147186147186147 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.4791666666666667 Acurracy Balanced 0.5647199453551912\n",
      "Loss normal: 0.6787120419921298 Loss Control: 0.6723153110736054 Loss Patient: 0.703099564028283 Loss balanced:  0.6877074375509442 Loss1+loss2: 0.6877074375509442\n",
      "Write summary at step 15840  Loss:  0.7937448024749756\n",
      "Write summary at step 15850  Loss:  0.6564735174179077\n",
      "Write summary at step 15860  Loss:  0.6155470609664917\n",
      "Write summary at step 15870  Loss:  0.6427121162414551\n",
      "Write summary at step 15880  Loss:  0.6402977108955383\n",
      "Write summary at step 15890  Loss:  0.6368610858917236\n",
      "Write summary at step 15900  Loss:  0.5667581558227539\n",
      "Write summary at step 15910  Loss:  0.6597364544868469\n",
      "Write summary at step 15920  Loss:  0.60997074842453\n",
      "Write summary at step 15930  Loss:  0.7291355729103088\n",
      "Write summary at step 15940  Loss:  0.7116420865058899\n",
      "Write summary at step 15950  Loss:  0.5987555980682373\n",
      "Write summary at step 15960  Loss:  0.5858818888664246\n",
      "Write summary at step 15970  Loss:  0.5985387563705444\n",
      "Write summary at step 15980  Loss:  0.5999066233634949\n",
      "Write summary at step 15990  Loss:  0.582419753074646\n",
      "Write summary at step 16000  Loss:  0.5633581876754761\n",
      "Saved checkpoint to: result/30/panns/checkpoint_16000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5930735930735931 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.4972677595628415\n",
      "Loss normal: 0.6575663239408881 Loss Control: 0.6350734553050473 Loss Patient: 0.7433203893403212 Loss balanced:  0.6891969223226843 Loss1+loss2: 0.6891969223226843\n",
      "Write summary at step 16010  Loss:  0.7285375595092773\n",
      "Write summary at step 16020  Loss:  0.7537422776222229\n",
      "Write summary at step 16030  Loss:  0.6212476491928101\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.683982683982684 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.539275956284153\n",
      "Loss normal: 0.6304400991567801 Loss Control: 0.5845394567713711 Loss Patient: 0.8054362752785286 Loss balanced:  0.6949878660249498 Loss1+loss2: 0.6949878660249498\n",
      "Write summary at step 16040  Loss:  0.6467272043228149\n",
      "Write summary at step 16050  Loss:  0.6202831268310547\n",
      "Write summary at step 16060  Loss:  0.6405954360961914\n",
      "Write summary at step 16070  Loss:  0.7108008861541748\n",
      "Write summary at step 16080  Loss:  0.4938073456287384\n",
      "Write summary at step 16090  Loss:  0.5507882833480835\n",
      "Write summary at step 16100  Loss:  0.5082805156707764\n",
      "Write summary at step 16110  Loss:  0.5539908409118652\n",
      "Write summary at step 16120  Loss:  0.628332257270813\n",
      "Write summary at step 16130  Loss:  0.6160637140274048\n",
      "Write summary at step 16140  Loss:  0.6915972232818604\n",
      "Write summary at step 16150  Loss:  0.8884365558624268\n",
      "Write summary at step 16160  Loss:  0.5619049072265625\n",
      "Write summary at step 16170  Loss:  0.6165639162063599\n",
      "Write summary at step 16180  Loss:  0.6232149600982666\n",
      "Write summary at step 16190  Loss:  0.6431781053543091\n",
      "Write summary at step 16200  Loss:  0.5802450180053711\n",
      "Write summary at step 16210  Loss:  0.6552222967147827\n",
      "Write summary at step 16220  Loss:  0.6768028736114502\n",
      "Write summary at step 16230  Loss:  0.6413791179656982\n",
      "Write summary at step 16240  Loss:  0.7364597320556641\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.25 Acurracy Balanced 0.5266393442622951\n",
      "Loss normal: 0.623574617105129 Loss Control: 0.5652323251213532 Loss Patient: 0.8460046102603277 Loss balanced:  0.7056184676908405 Loss1+loss2: 0.7056184676908405\n",
      "Write summary at step 16250  Loss:  0.6425057649612427\n",
      "Write summary at step 16260  Loss:  0.8329233527183533\n",
      "Write summary at step 16270  Loss:  0.6888481378555298\n",
      "Write summary at step 16280  Loss:  0.6575517654418945\n",
      "Write summary at step 16290  Loss:  0.6866500377655029\n",
      "Write summary at step 16300  Loss:  0.562284529209137\n",
      "Write summary at step 16310  Loss:  0.6790320873260498\n",
      "Write summary at step 16320  Loss:  0.5944038033485413\n",
      "Write summary at step 16330  Loss:  0.6385338306427002\n",
      "Write summary at step 16340  Loss:  0.5927118062973022\n",
      "Write summary at step 16350  Loss:  0.6121609210968018\n",
      "Write summary at step 16360  Loss:  0.612922191619873\n",
      "Write summary at step 16370  Loss:  0.8300740718841553\n",
      "Write summary at step 16380  Loss:  0.5586024522781372\n",
      "Write summary at step 16390  Loss:  0.6569664478302002\n",
      "Write summary at step 16400  Loss:  0.5975689888000488\n",
      "Write summary at step 16410  Loss:  0.599246084690094\n",
      "Write summary at step 16420  Loss:  0.6934071779251099\n",
      "Write summary at step 16430  Loss:  0.5807813405990601\n",
      "Write summary at step 16440  Loss:  0.7562614679336548\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.658008658008658 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5459357923497268\n",
      "Loss normal: 0.6394269778614953 Loss Control: 0.6133695772436799 Loss Patient: 0.7387708288927873 Loss balanced:  0.6760702030682336 Loss1+loss2: 0.6760702030682336\n",
      "Write summary at step 16450  Loss:  0.5205726623535156\n",
      "Write summary at step 16460  Loss:  0.5584099292755127\n",
      "Write summary at step 16470  Loss:  0.6063033938407898\n",
      "Write summary at step 16480  Loss:  0.5323113203048706\n",
      "Write summary at step 16490  Loss:  0.7921772003173828\n",
      "Write summary at step 16500  Loss:  0.6499791741371155\n",
      "Saved checkpoint to: result/30/panns/checkpoint_16500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5677937158469946\n",
      "Loss normal: 0.6315994851000897 Loss Control: 0.5915167084157141 Loss Patient: 0.7844150755554438 Loss balanced:  0.6879658919855789 Loss1+loss2: 0.6879658919855789\n",
      "Write summary at step 16510  Loss:  0.5718015432357788\n",
      "Write summary at step 16520  Loss:  0.7014192342758179\n",
      "Write summary at step 16530  Loss:  0.7382984161376953\n",
      "Write summary at step 16540  Loss:  0.6797955632209778\n",
      "Write summary at step 16550  Loss:  0.7564524412155151\n",
      "Write summary at step 16560  Loss:  0.6117300987243652\n",
      "Write summary at step 16570  Loss:  0.5579509735107422\n",
      "Write summary at step 16580  Loss:  0.628302812576294\n",
      "Write summary at step 16590  Loss:  0.6693736910820007\n",
      "Write summary at step 16600  Loss:  0.6451458930969238\n",
      "Write summary at step 16610  Loss:  0.5821931958198547\n",
      "Write summary at step 16620  Loss:  0.6611592173576355\n",
      "Write summary at step 16630  Loss:  0.5755046606063843\n",
      "Write summary at step 16640  Loss:  0.5866045951843262\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7012987012987013 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.3125 Acurracy Balanced 0.5578893442622951\n",
      "Loss normal: 0.6112175939919112 Loss Control: 0.5461690911178381 Loss Patient: 0.8592149907102188 Loss balanced:  0.7026920409140285 Loss1+loss2: 0.7026920409140285\n",
      "Write summary at step 16650  Loss:  0.6392772793769836\n",
      "Write summary at step 16660  Loss:  0.6417443156242371\n",
      "Write summary at step 16670  Loss:  0.710913896560669\n",
      "Write summary at step 16680  Loss:  0.6566623449325562\n",
      "Write summary at step 16690  Loss:  0.8125723004341125\n",
      "Write summary at step 16700  Loss:  0.8062819242477417\n",
      "Write summary at step 16710  Loss:  0.7303426265716553\n",
      "Write summary at step 16720  Loss:  0.6123459935188293\n",
      "Write summary at step 16730  Loss:  0.691805899143219\n",
      "Write summary at step 16740  Loss:  0.550769567489624\n",
      "Write summary at step 16750  Loss:  0.5014474987983704\n",
      "Write summary at step 16760  Loss:  0.6440772414207458\n",
      "Write summary at step 16770  Loss:  0.4793993830680847\n",
      "Write summary at step 16780  Loss:  0.5902711153030396\n",
      "Write summary at step 16790  Loss:  0.5976989269256592\n",
      "Write summary at step 16800  Loss:  0.614563524723053\n",
      "Write summary at step 16810  Loss:  0.7042611837387085\n",
      "Write summary at step 16820  Loss:  0.6998764276504517\n",
      "Write summary at step 16830  Loss:  0.5299644470214844\n",
      "Write summary at step 16840  Loss:  0.6361260414123535\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.5908469945355191\n",
      "Loss normal: 0.6183096789694452 Loss Control: 0.5658557981741233 Loss Patient: 0.8182901628315449 Loss balanced:  0.6920729805028341 Loss1+loss2: 0.6920729805028341\n",
      "Write summary at step 16850  Loss:  0.7550475597381592\n",
      "Write summary at step 16860  Loss:  0.6020136475563049\n",
      "Write summary at step 16870  Loss:  0.721444845199585\n",
      "Write summary at step 16880  Loss:  0.637344479560852\n",
      "Write summary at step 16890  Loss:  0.6086657047271729\n",
      "Write summary at step 16900  Loss:  0.6589916944503784\n",
      "Write summary at step 16910  Loss:  0.8057625889778137\n",
      "Write summary at step 16920  Loss:  0.9251337051391602\n",
      "Write summary at step 16930  Loss:  0.6479225158691406\n",
      "Write summary at step 16940  Loss:  0.529443621635437\n",
      "Write summary at step 16950  Loss:  0.8420597314834595\n",
      "Write summary at step 16960  Loss:  0.7026340365409851\n",
      "Write summary at step 16970  Loss:  0.6243310570716858\n",
      "Write summary at step 16980  Loss:  0.6456782221794128\n",
      "Write summary at step 16990  Loss:  0.6537207961082458\n",
      "Write summary at step 17000  Loss:  0.6275744438171387\n",
      "Saved checkpoint to: result/30/panns/checkpoint_17000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5671106557377049\n",
      "Loss normal: 0.5984711840555266 Loss Control: 0.5327929483085382 Loss Patient: 0.8488694224506617 Loss balanced:  0.6908311853795999 Loss1+loss2: 0.6908311853795999\n",
      "Write summary at step 17010  Loss:  0.7245890498161316\n",
      "Write summary at step 17020  Loss:  0.5588514804840088\n",
      "Write summary at step 17030  Loss:  0.6517724394798279\n",
      "Write summary at step 17040  Loss:  0.582101047039032\n",
      "Write summary at step 17050  Loss:  0.8787314295768738\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7359307359307359 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5720628415300546\n",
      "Loss normal: 0.6009700693093337 Loss Control: 0.5396436358410153 Loss Patient: 0.8347770733137926 Loss balanced:  0.687210354577404 Loss1+loss2: 0.687210354577404\n",
      "Write summary at step 17060  Loss:  0.6599863767623901\n",
      "Write summary at step 17070  Loss:  0.5187929272651672\n",
      "Write summary at step 17080  Loss:  0.5280675292015076\n",
      "Write summary at step 17090  Loss:  0.5254713296890259\n",
      "Write summary at step 17100  Loss:  0.5803886651992798\n",
      "Write summary at step 17110  Loss:  0.6865242123603821\n",
      "Write summary at step 17120  Loss:  0.557841420173645\n",
      "Write summary at step 17130  Loss:  0.5404231548309326\n",
      "Write summary at step 17140  Loss:  0.7557138204574585\n",
      "Write summary at step 17150  Loss:  0.6021130084991455\n",
      "Write summary at step 17160  Loss:  0.7563480138778687\n",
      "Write summary at step 17170  Loss:  0.7947498559951782\n",
      "Write summary at step 17180  Loss:  0.6933727264404297\n",
      "Write summary at step 17190  Loss:  0.6297122240066528\n",
      "Write summary at step 17200  Loss:  0.6130878925323486\n",
      "Write summary at step 17210  Loss:  0.6538634300231934\n",
      "Write summary at step 17220  Loss:  0.6320003271102905\n",
      "Write summary at step 17230  Loss:  0.5366767048835754\n",
      "Write summary at step 17240  Loss:  0.6978698372840881\n",
      "Write summary at step 17250  Loss:  0.5460178852081299\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.5800865800865801 Acurracy Control:  0.5901639344262295 Acurracy Patient:  0.5416666666666666 Acurracy Balanced 0.5659153005464481\n",
      "Loss normal: 0.6715007246314705 Loss Control: 0.6639221750321935 Loss Patient: 0.7003939549128214 Loss balanced:  0.6821580649725074 Loss1+loss2: 0.6821580649725074\n",
      "Write summary at step 17260  Loss:  0.5748674869537354\n",
      "Write summary at step 17270  Loss:  0.5465123057365417\n",
      "Write summary at step 17280  Loss:  0.9507097601890564\n",
      "Write summary at step 17290  Loss:  0.5764931440353394\n",
      "Write summary at step 17300  Loss:  0.5275241136550903\n",
      "Write summary at step 17310  Loss:  0.7740398645401001\n",
      "Write summary at step 17320  Loss:  0.6611941456794739\n",
      "Write summary at step 17330  Loss:  0.6156671643257141\n",
      "Write summary at step 17340  Loss:  0.5788933038711548\n",
      "Write summary at step 17350  Loss:  0.6691318154335022\n",
      "Write summary at step 17360  Loss:  0.6342728137969971\n",
      "Write summary at step 17370  Loss:  0.6327006816864014\n",
      "Write summary at step 17380  Loss:  0.9396822452545166\n",
      "Write summary at step 17390  Loss:  0.6047967672348022\n",
      "Write summary at step 17400  Loss:  0.6454352140426636\n",
      "Write summary at step 17410  Loss:  0.7169099450111389\n",
      "Write summary at step 17420  Loss:  0.5932231545448303\n",
      "Write summary at step 17430  Loss:  0.6250594258308411\n",
      "Write summary at step 17440  Loss:  0.685276448726654\n",
      "Write summary at step 17450  Loss:  0.6076080203056335\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5971653005464481\n",
      "Loss normal: 0.5767819455691746 Loss Control: 0.507556101989225 Loss Patient: 0.8407054996738831 Loss balanced:  0.6741308008315541 Loss1+loss2: 0.6741308008315541\n",
      "Write summary at step 17460  Loss:  0.6548048257827759\n",
      "Write summary at step 17470  Loss:  0.6030646562576294\n",
      "Write summary at step 17480  Loss:  0.5995578765869141\n",
      "Write summary at step 17490  Loss:  0.8326435089111328\n",
      "Write summary at step 17500  Loss:  0.7265949249267578\n",
      "Saved checkpoint to: result/30/panns/checkpoint_17500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.6021174863387978\n",
      "Loss normal: 0.5555476575960845 Loss Control: 0.4664394831071135 Loss Patient: 0.8952726051211357 Loss balanced:  0.6808560441141246 Loss1+loss2: 0.6808560441141246\n",
      "Write summary at step 17510  Loss:  0.6790845394134521\n",
      "Write summary at step 17520  Loss:  0.5484333038330078\n",
      "Write summary at step 17530  Loss:  0.5411686897277832\n",
      "Write summary at step 17540  Loss:  0.7450382709503174\n",
      "Write summary at step 17550  Loss:  0.8638275861740112\n",
      "Write summary at step 17560  Loss:  0.7244841456413269\n",
      "Write summary at step 17570  Loss:  0.7675049304962158\n",
      "Write summary at step 17580  Loss:  0.7978335618972778\n",
      "Write summary at step 17590  Loss:  0.6134257316589355\n",
      "Write summary at step 17600  Loss:  0.7065452337265015\n",
      "Write summary at step 17610  Loss:  0.5123120546340942\n",
      "Write summary at step 17620  Loss:  0.8428180813789368\n",
      "Write summary at step 17630  Loss:  0.6564780473709106\n",
      "Write summary at step 17640  Loss:  0.6429309248924255\n",
      "Write summary at step 17650  Loss:  0.5767096877098083\n",
      "Write summary at step 17660  Loss:  0.7083576917648315\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7316017316017316 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.561646174863388\n",
      "Loss normal: 0.5958548435917148 Loss Control: 0.5367440809317625 Loss Patient: 0.821214676524202 Loss balanced:  0.6789793787279823 Loss1+loss2: 0.6789793787279823\n",
      "Write summary at step 17670  Loss:  0.6726847887039185\n",
      "Write summary at step 17680  Loss:  0.697157621383667\n",
      "Write summary at step 17690  Loss:  0.7881240844726562\n",
      "Write summary at step 17700  Loss:  0.5608252882957458\n",
      "Write summary at step 17710  Loss:  0.7103404402732849\n",
      "Write summary at step 17720  Loss:  0.6288032531738281\n",
      "Write summary at step 17730  Loss:  0.7492055296897888\n",
      "Write summary at step 17740  Loss:  0.727584719657898\n",
      "Write summary at step 17750  Loss:  0.6581020951271057\n",
      "Write summary at step 17760  Loss:  0.6358996033668518\n",
      "Write summary at step 17770  Loss:  0.5906029939651489\n",
      "Write summary at step 17780  Loss:  0.6993923187255859\n",
      "Write summary at step 17790  Loss:  0.6571715474128723\n",
      "Write summary at step 17800  Loss:  0.6192175149917603\n",
      "Write summary at step 17810  Loss:  0.6483005285263062\n",
      "Write summary at step 17820  Loss:  0.7342671155929565\n",
      "Write summary at step 17830  Loss:  0.6968604326248169\n",
      "Write summary at step 17840  Loss:  0.6085907816886902\n",
      "Write summary at step 17850  Loss:  0.6456015110015869\n",
      "Write summary at step 17860  Loss:  0.6205216646194458\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.375 Acurracy Balanced 0.5754781420765027\n",
      "Loss normal: 0.614094184719639 Loss Control: 0.5691429221890664 Loss Patient: 0.7854708768427372 Loss balanced:  0.6773068995159017 Loss1+loss2: 0.6773068995159017\n",
      "Write summary at step 17870  Loss:  0.7829973697662354\n",
      "Write summary at step 17880  Loss:  0.7314000129699707\n",
      "Write summary at step 17890  Loss:  0.6568195819854736\n",
      "Write summary at step 17900  Loss:  0.5216019153594971\n",
      "Write summary at step 17910  Loss:  0.6867722868919373\n",
      "Write summary at step 17920  Loss:  0.5896210670471191\n",
      "Write summary at step 17930  Loss:  0.6239314079284668\n",
      "Write summary at step 17940  Loss:  0.5486195683479309\n",
      "Write summary at step 17950  Loss:  0.5270388126373291\n",
      "Write summary at step 17960  Loss:  0.6663150191307068\n",
      "Write summary at step 17970  Loss:  0.5727578401565552\n",
      "Write summary at step 17980  Loss:  0.7685527801513672\n",
      "Write summary at step 17990  Loss:  0.5784704685211182\n",
      "Write summary at step 18000  Loss:  0.6690285205841064\n",
      "Saved checkpoint to: result/30/panns/checkpoint_18000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.25 Acurracy Balanced 0.6086065573770492\n",
      "Loss normal: 0.5514005212298719 Loss Control: 0.4448668762960069 Loss Patient: 0.9575600251555443 Loss balanced:  0.7012134507257756 Loss1+loss2: 0.7012134507257756\n",
      "Write summary at step 18010  Loss:  0.7061723470687866\n",
      "Write summary at step 18020  Loss:  0.5295963287353516\n",
      "Write summary at step 18030  Loss:  0.5691996216773987\n",
      "Write summary at step 18040  Loss:  0.6795543432235718\n",
      "Write summary at step 18050  Loss:  0.5467164516448975\n",
      "Write summary at step 18060  Loss:  0.6244028806686401\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5993852459016393\n",
      "Loss normal: 0.5709913348480736 Loss Control: 0.5034654536208168 Loss Patient: 0.828433665757378 Loss balanced:  0.6659495596890974 Loss1+loss2: 0.6659495596890974\n",
      "\n",
      " > BEST MODEL (0.66595) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 18070  Loss:  0.5829435586929321\n",
      "Write summary at step 18080  Loss:  0.6910368204116821\n",
      "Write summary at step 18090  Loss:  0.6060826778411865\n",
      "Write summary at step 18100  Loss:  0.6052806973457336\n",
      "Write summary at step 18110  Loss:  0.7614464163780212\n",
      "Write summary at step 18120  Loss:  0.7388486266136169\n",
      "Write summary at step 18130  Loss:  0.5586144924163818\n",
      "Write summary at step 18140  Loss:  0.731086790561676\n",
      "Write summary at step 18150  Loss:  0.5861470699310303\n",
      "Write summary at step 18160  Loss:  0.6626536846160889\n",
      "Write summary at step 18170  Loss:  0.5664018392562866\n",
      "Write summary at step 18180  Loss:  0.4994437098503113\n",
      "Write summary at step 18190  Loss:  0.7483443021774292\n",
      "Write summary at step 18200  Loss:  0.5240100026130676\n",
      "Write summary at step 18210  Loss:  0.4965064823627472\n",
      "Write summary at step 18220  Loss:  0.5300363898277283\n",
      "Write summary at step 18230  Loss:  0.6013690233230591\n",
      "Write summary at step 18240  Loss:  0.6703650951385498\n",
      "Write summary at step 18250  Loss:  0.5638150572776794\n",
      "Write summary at step 18260  Loss:  0.6603953838348389\n",
      "Write summary at step 18270  Loss:  0.6042852401733398\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.645021645021645 Acurracy Control:  0.6939890710382514 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.5761612021857924\n",
      "Loss normal: 0.6388048529624939 Loss Control: 0.6223923433673838 Loss Patient: 0.7013775849093994 Loss balanced:  0.6618849641383916 Loss1+loss2: 0.6618849641383916\n",
      "\n",
      " > BEST MODEL (0.66188) : result/30/panns/best_checkpoint.pt\n",
      "Write summary at step 18280  Loss:  0.5671300292015076\n",
      "Write summary at step 18290  Loss:  0.7487040162086487\n",
      "Write summary at step 18300  Loss:  0.7196990847587585\n",
      "Write summary at step 18310  Loss:  0.7242615222930908\n",
      "Write summary at step 18320  Loss:  0.5964523553848267\n",
      "Write summary at step 18330  Loss:  0.5272618532180786\n",
      "Write summary at step 18340  Loss:  0.7238102555274963\n",
      "Write summary at step 18350  Loss:  0.5536890625953674\n",
      "Write summary at step 18360  Loss:  0.6455572843551636\n",
      "Write summary at step 18370  Loss:  0.6600951552391052\n",
      "Write summary at step 18380  Loss:  0.7221550941467285\n",
      "Write summary at step 18390  Loss:  0.661481499671936\n",
      "Write summary at step 18400  Loss:  0.7394436597824097\n",
      "Write summary at step 18410  Loss:  0.5655618906021118\n",
      "Write summary at step 18420  Loss:  0.7921160459518433\n",
      "Write summary at step 18430  Loss:  0.6546835899353027\n",
      "Write summary at step 18440  Loss:  0.6620956063270569\n",
      "Write summary at step 18450  Loss:  0.6294414401054382\n",
      "Write summary at step 18460  Loss:  0.5654180645942688\n",
      "Write summary at step 18470  Loss:  0.6669353246688843\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.567964480874317\n",
      "Loss normal: 0.6423712568881708 Loss Control: 0.6050385800215716 Loss Patient: 0.7847020775079727 Loss balanced:  0.6948703287647722 Loss1+loss2: 0.6948703287647722\n",
      "Write summary at step 18480  Loss:  0.6652055978775024\n",
      "Write summary at step 18490  Loss:  0.5950393676757812\n",
      "Write summary at step 18500  Loss:  0.37656712532043457\n",
      "Saved checkpoint to: result/30/panns/checkpoint_18500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6363636363636364 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5322745901639344\n",
      "Loss normal: 0.6388952754018626 Loss Control: 0.5909933198670871 Loss Patient: 0.821521483361721 Loss balanced:  0.7062574016144041 Loss1+loss2: 0.7062574016144041\n",
      "Write summary at step 18510  Loss:  0.5736657381057739\n",
      "Write summary at step 18520  Loss:  0.7057018280029297\n",
      "Write summary at step 18530  Loss:  0.7561864852905273\n",
      "Write summary at step 18540  Loss:  0.9009284973144531\n",
      "Write summary at step 18550  Loss:  0.6557472944259644\n",
      "Write summary at step 18560  Loss:  0.5205059051513672\n",
      "Write summary at step 18570  Loss:  0.6960543394088745\n",
      "Write summary at step 18580  Loss:  0.6306814551353455\n",
      "Write summary at step 18590  Loss:  0.5700033903121948\n",
      "Write summary at step 18600  Loss:  0.600951611995697\n",
      "Write summary at step 18610  Loss:  0.7503212094306946\n",
      "Write summary at step 18620  Loss:  0.5910285711288452\n",
      "Write summary at step 18630  Loss:  0.8299316167831421\n",
      "Write summary at step 18640  Loss:  0.6641987562179565\n",
      "Write summary at step 18650  Loss:  0.5360246300697327\n",
      "Write summary at step 18660  Loss:  0.8097442388534546\n",
      "Write summary at step 18670  Loss:  0.7054359316825867\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7056277056277056 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5221994535519126\n",
      "Loss normal: 0.5857177723795821 Loss Control: 0.4692873347326706 Loss Patient: 1.0296088283260663 Loss balanced:  0.7494480815293685 Loss1+loss2: 0.7494480815293685\n",
      "Write summary at step 18680  Loss:  0.474439799785614\n",
      "Write summary at step 18690  Loss:  0.6603277921676636\n",
      "Write summary at step 18700  Loss:  0.5178190469741821\n",
      "Write summary at step 18710  Loss:  0.6772412061691284\n",
      "Write summary at step 18720  Loss:  0.4797412157058716\n",
      "Write summary at step 18730  Loss:  0.589555561542511\n",
      "Write summary at step 18740  Loss:  0.5142394304275513\n",
      "Write summary at step 18750  Loss:  0.5999577045440674\n",
      "Write summary at step 18760  Loss:  0.6855061054229736\n",
      "Write summary at step 18770  Loss:  0.7164970636367798\n",
      "Write summary at step 18780  Loss:  0.6682707071304321\n",
      "Write summary at step 18790  Loss:  0.5254570841789246\n",
      "Write summary at step 18800  Loss:  0.6370332837104797\n",
      "Write summary at step 18810  Loss:  0.9032535552978516\n",
      "Write summary at step 18820  Loss:  0.6990857124328613\n",
      "Write summary at step 18830  Loss:  0.775971531867981\n",
      "Write summary at step 18840  Loss:  0.5787787437438965\n",
      "Write summary at step 18850  Loss:  0.7716093063354492\n",
      "Write summary at step 18860  Loss:  0.5215092301368713\n",
      "Write summary at step 18870  Loss:  0.6192526817321777\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5479849726775956\n",
      "Loss normal: 0.5845637954932786 Loss Control: 0.49682622577974705 Loss Patient: 0.9190632576743761 Loss balanced:  0.7079447417270616 Loss1+loss2: 0.7079447417270616\n",
      "Write summary at step 18880  Loss:  0.5996633768081665\n",
      "Write summary at step 18890  Loss:  0.6408066153526306\n",
      "Write summary at step 18900  Loss:  0.5394096374511719\n",
      "Write summary at step 18910  Loss:  0.6692248582839966\n",
      "Write summary at step 18920  Loss:  0.49692219495773315\n",
      "Write summary at step 18930  Loss:  0.5582759976387024\n",
      "Write summary at step 18940  Loss:  0.6495056748390198\n",
      "Write summary at step 18950  Loss:  0.5992035865783691\n",
      "Write summary at step 18960  Loss:  0.7032264471054077\n",
      "Write summary at step 18970  Loss:  0.664820671081543\n",
      "Write summary at step 18980  Loss:  0.9684884548187256\n",
      "Write summary at step 18990  Loss:  0.6281462907791138\n",
      "Write summary at step 19000  Loss:  0.7089121341705322\n",
      "Saved checkpoint to: result/30/panns/checkpoint_19000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.1875 Acurracy Balanced 0.5664275956284153\n",
      "Loss normal: 0.5467565329301924 Loss Control: 0.438163173817546 Loss Patient: 0.9607686971624693 Loss balanced:  0.6994659354900077 Loss1+loss2: 0.6994659354900077\n",
      "Write summary at step 19010  Loss:  0.6251722574234009\n",
      "Write summary at step 19020  Loss:  0.6414051651954651\n",
      "Write summary at step 19030  Loss:  0.61573725938797\n",
      "Write summary at step 19040  Loss:  0.5507376194000244\n",
      "Write summary at step 19050  Loss:  0.6735827922821045\n",
      "Write summary at step 19060  Loss:  0.6822857856750488\n",
      "Write summary at step 19070  Loss:  0.7793179750442505\n",
      "Write summary at step 19080  Loss:  0.6737033128738403\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.6885245901639344 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.5525956284153005\n",
      "Loss normal: 0.6367521030562264 Loss Control: 0.6015465249780749 Loss Patient: 0.770973359545072 Loss balanced:  0.6862599422615734 Loss1+loss2: 0.6862599422615734\n",
      "Write summary at step 19090  Loss:  0.5668399930000305\n",
      "Write summary at step 19100  Loss:  0.5856263637542725\n",
      "Write summary at step 19110  Loss:  0.7056808471679688\n",
      "Write summary at step 19120  Loss:  0.7043275833129883\n",
      "Write summary at step 19130  Loss:  0.6515097618103027\n",
      "Write summary at step 19140  Loss:  0.6296525597572327\n",
      "Write summary at step 19150  Loss:  0.6320438385009766\n",
      "Write summary at step 19160  Loss:  0.5839952826499939\n",
      "Write summary at step 19170  Loss:  0.793958306312561\n",
      "Write summary at step 19180  Loss:  0.6746771335601807\n",
      "Write summary at step 19190  Loss:  0.5894954204559326\n",
      "Write summary at step 19200  Loss:  0.544513463973999\n",
      "Write summary at step 19210  Loss:  0.7067956328392029\n",
      "Write summary at step 19220  Loss:  0.7094836831092834\n",
      "Write summary at step 19230  Loss:  0.5201969742774963\n",
      "Write summary at step 19240  Loss:  0.7210071086883545\n",
      "Write summary at step 19250  Loss:  0.5995907783508301\n",
      "Write summary at step 19260  Loss:  0.6230525970458984\n",
      "Write summary at step 19270  Loss:  0.6054760217666626\n",
      "Write summary at step 19280  Loss:  0.5921401381492615\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7229437229437229 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5869193989071039\n",
      "Loss normal: 0.5969312438717136 Loss Control: 0.5341243483329732 Loss Patient: 0.8363825355966886 Loss balanced:  0.6852534419648308 Loss1+loss2: 0.6852534419648308\n",
      "Write summary at step 19290  Loss:  0.7660373449325562\n",
      "Write summary at step 19300  Loss:  0.7006328701972961\n",
      "Write summary at step 19310  Loss:  0.6759936809539795\n",
      "Write summary at step 19320  Loss:  0.5266849994659424\n",
      "Write summary at step 19330  Loss:  0.7454475164413452\n",
      "Write summary at step 19340  Loss:  0.5937005281448364\n",
      "Write summary at step 19350  Loss:  0.6111135482788086\n",
      "Write summary at step 19360  Loss:  0.6376850605010986\n",
      "Write summary at step 19370  Loss:  0.7051790952682495\n",
      "Write summary at step 19380  Loss:  0.5739875435829163\n",
      "Write summary at step 19390  Loss:  0.5252021551132202\n",
      "Write summary at step 19400  Loss:  0.6927700638771057\n",
      "Write summary at step 19410  Loss:  0.6296616196632385\n",
      "Write summary at step 19420  Loss:  0.6667047142982483\n",
      "Write summary at step 19430  Loss:  0.631931722164154\n",
      "Write summary at step 19440  Loss:  0.6216440796852112\n",
      "Write summary at step 19450  Loss:  0.6975276470184326\n",
      "Write summary at step 19460  Loss:  0.6371025443077087\n",
      "Write summary at step 19470  Loss:  0.6567296981811523\n",
      "Write summary at step 19480  Loss:  0.6989683508872986\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7186147186147186 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5611338797814208\n",
      "Loss normal: 0.5949113770222767 Loss Control: 0.5207676977082029 Loss Patient: 0.8775841761380434 Loss balanced:  0.6991759369231232 Loss1+loss2: 0.6991759369231232\n",
      "Write summary at step 19490  Loss:  0.9495763182640076\n",
      "Write summary at step 19500  Loss:  0.5599868297576904\n",
      "Saved checkpoint to: result/30/panns/checkpoint_19500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.6939890710382514 Acurracy Patient:  0.4791666666666667 Acurracy Balanced 0.586577868852459\n",
      "Loss normal: 0.6373153583053902 Loss Control: 0.6038866347628213 Loss Patient: 0.7647623615339398 Loss balanced:  0.6843244981483806 Loss1+loss2: 0.6843244981483806\n",
      "Write summary at step 19510  Loss:  0.5654735565185547\n",
      "Write summary at step 19520  Loss:  0.7051808834075928\n",
      "Write summary at step 19530  Loss:  0.6722627282142639\n",
      "Write summary at step 19540  Loss:  0.5120458602905273\n",
      "Write summary at step 19550  Loss:  0.733875036239624\n",
      "Write summary at step 19560  Loss:  0.5182609558105469\n",
      "Write summary at step 19570  Loss:  0.6392045021057129\n",
      "Write summary at step 19580  Loss:  0.8244056701660156\n",
      "Write summary at step 19590  Loss:  0.61130291223526\n",
      "Write summary at step 19600  Loss:  0.6673620343208313\n",
      "Write summary at step 19610  Loss:  0.7341674566268921\n",
      "Write summary at step 19620  Loss:  0.5395600199699402\n",
      "Write summary at step 19630  Loss:  0.5896777510643005\n",
      "Write summary at step 19640  Loss:  0.5776378512382507\n",
      "Write summary at step 19650  Loss:  0.6228297352790833\n",
      "Write summary at step 19660  Loss:  0.6456674337387085\n",
      "Write summary at step 19670  Loss:  0.7854299545288086\n",
      "Write summary at step 19680  Loss:  0.6261868476867676\n",
      "Write summary at step 19690  Loss:  0.48381558060646057\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7316017316017316 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5462773224043715\n",
      "Loss normal: 0.5869859042879823 Loss Control: 0.4816896672783002 Loss Patient: 0.9884278206154704 Loss balanced:  0.7350587439468853 Loss1+loss2: 0.7350587439468853\n",
      "Write summary at step 19700  Loss:  0.7338396310806274\n",
      "Write summary at step 19710  Loss:  0.7211309671401978\n",
      "Write summary at step 19720  Loss:  0.4898565411567688\n",
      "Write summary at step 19730  Loss:  0.6112469434738159\n",
      "Write summary at step 19740  Loss:  0.5517505407333374\n",
      "Write summary at step 19750  Loss:  0.5731152296066284\n",
      "Write summary at step 19760  Loss:  0.609820544719696\n",
      "Write summary at step 19770  Loss:  0.5729240775108337\n",
      "Write summary at step 19780  Loss:  0.658968985080719\n",
      "Write summary at step 19790  Loss:  0.6946322917938232\n",
      "Write summary at step 19800  Loss:  0.5195178985595703\n",
      "Write summary at step 19810  Loss:  0.6258251070976257\n",
      "Write summary at step 19820  Loss:  0.7822189331054688\n",
      "Write summary at step 19830  Loss:  0.6511617302894592\n",
      "Write summary at step 19840  Loss:  0.8152323961257935\n",
      "Write summary at step 19850  Loss:  0.6964430809020996\n",
      "Write summary at step 19860  Loss:  0.6814457178115845\n",
      "Write summary at step 19870  Loss:  0.45711758732795715\n",
      "Write summary at step 19880  Loss:  0.44353365898132324\n",
      "Write summary at step 19890  Loss:  0.42056548595428467\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5787226775956285\n",
      "Loss normal: 0.6067023243738975 Loss Control: 0.533744351785691 Loss Patient: 0.8848545656849941 Loss balanced:  0.7092994587353425 Loss1+loss2: 0.7092994587353425\n",
      "Write summary at step 19900  Loss:  0.5126231908798218\n",
      "Write summary at step 19910  Loss:  0.5082838535308838\n",
      "Write summary at step 19920  Loss:  0.526756763458252\n",
      "Write summary at step 19930  Loss:  0.6809146404266357\n",
      "Write summary at step 19940  Loss:  0.58571457862854\n",
      "Write summary at step 19950  Loss:  0.5614941120147705\n",
      "Write summary at step 19960  Loss:  0.566878616809845\n",
      "Write summary at step 19970  Loss:  0.6453747749328613\n",
      "Write summary at step 19980  Loss:  0.6421094536781311\n",
      "Write summary at step 19990  Loss:  0.7303078174591064\n",
      "Write summary at step 20000  Loss:  0.5555567145347595\n",
      "Saved checkpoint to: result/30/panns/checkpoint_20000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7142857142857143 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5584016393442623\n",
      "Loss normal: 0.5800525176447707 Loss Control: 0.4645066136708025 Loss Patient: 1.0205712883422773 Loss balanced:  0.7425389510065399 Loss1+loss2: 0.7425389510065399\n",
      "Write summary at step 20010  Loss:  0.6983006000518799\n",
      "Write summary at step 20020  Loss:  0.659004807472229\n",
      "Write summary at step 20030  Loss:  0.513938307762146\n",
      "Write summary at step 20040  Loss:  0.796013593673706\n",
      "Write summary at step 20050  Loss:  0.48529496788978577\n",
      "Write summary at step 20060  Loss:  0.4704647958278656\n",
      "Write summary at step 20070  Loss:  0.48530519008636475\n",
      "Write summary at step 20080  Loss:  0.7187985181808472\n",
      "Write summary at step 20090  Loss:  0.5740684270858765\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7229437229437229 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.6022882513661202\n",
      "Loss normal: 0.5952213827794764 Loss Control: 0.4990758238757243 Loss Patient: 0.9617763087153435 Loss balanced:  0.7304260662955339 Loss1+loss2: 0.7304260662955339\n",
      "Write summary at step 20100  Loss:  0.5163962244987488\n",
      "Write summary at step 20110  Loss:  0.6113305687904358\n",
      "Write summary at step 20120  Loss:  0.6417086124420166\n",
      "Write summary at step 20130  Loss:  0.5312830209732056\n",
      "Write summary at step 20140  Loss:  0.6542418003082275\n",
      "Write summary at step 20150  Loss:  0.7364897131919861\n",
      "Write summary at step 20160  Loss:  0.7239059209823608\n",
      "Write summary at step 20170  Loss:  0.5220378041267395\n",
      "Write summary at step 20180  Loss:  0.6381210088729858\n",
      "Write summary at step 20190  Loss:  0.5976355671882629\n",
      "Write summary at step 20200  Loss:  0.5453662872314453\n",
      "Write summary at step 20210  Loss:  0.8013353943824768\n",
      "Write summary at step 20220  Loss:  0.6721789836883545\n",
      "Write summary at step 20230  Loss:  0.5692712664604187\n",
      "Write summary at step 20240  Loss:  0.43647143244743347\n",
      "Write summary at step 20250  Loss:  0.6795047521591187\n",
      "Write summary at step 20260  Loss:  0.563400387763977\n",
      "Write summary at step 20270  Loss:  0.5731717348098755\n",
      "Write summary at step 20280  Loss:  0.8156384825706482\n",
      "Write summary at step 20290  Loss:  0.5126010775566101\n",
      "Write summary at step 20300  Loss:  0.7181087136268616\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5741120218579235\n",
      "Loss normal: 0.5558889112818293 Loss Control: 0.38782895254632815 Loss Patient: 1.1966174642244976 Loss balanced:  0.7922232083854128 Loss1+loss2: 0.7922232083854128\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/run/media/viblab/Markov1/Abil/Tugas Akhir/Progress 4/Github_Cough/script/train.py\", line 89, in <module>\n",
      "    print(\"SEED:\",seed, \"Best Loss:\", loss)\n",
      "NameError: name 's' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Time dim Lenght is: 1498 (+- 29.96 seconds)\n",
      "The Min Time dim Lenght is: 19 (+- 0.38 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.7041478157043457\n",
      "Write summary at step 20  Loss:  0.9344767332077026\n",
      "Write summary at step 30  Loss:  0.7532337307929993\n",
      "Write summary at step 40  Loss:  0.6251402497291565\n",
      "Write summary at step 50  Loss:  0.6870535016059875\n",
      "Write summary at step 60  Loss:  0.6722697019577026\n",
      "Write summary at step 70  Loss:  0.8001836538314819\n",
      "Write summary at step 80  Loss:  0.7304738759994507\n",
      "Write summary at step 90  Loss:  0.7108782529830933\n",
      "Write summary at step 100  Loss:  0.5695358514785767\n",
      "Write summary at step 110  Loss:  0.7670667171478271\n",
      "Write summary at step 120  Loss:  0.6786947250366211\n",
      "Write summary at step 130  Loss:  0.8272817134857178\n",
      "Write summary at step 140  Loss:  0.7533645629882812\n",
      "Write summary at step 150  Loss:  0.6896833181381226\n",
      "Write summary at step 160  Loss:  0.8088617324829102\n",
      "Write summary at step 170  Loss:  0.7277000546455383\n",
      "Write summary at step 180  Loss:  0.6437351107597351\n",
      "Write summary at step 190  Loss:  0.6761939525604248\n",
      "Write summary at step 200  Loss:  0.5919557213783264\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.00546448087431694 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.4923155737704918\n",
      "Loss normal: 0.7617243492242062 Loss Control: 0.8046602460204578 Loss Patient: 0.598031260073185 Loss balanced:  0.7013457530468215 Loss1+loss2: 0.7013457530468215\n",
      "\n",
      " > BEST MODEL (0.70135) : result/41/panns/best_checkpoint.pt\n",
      "Write summary at step 210  Loss:  0.69425368309021\n",
      "Write summary at step 220  Loss:  0.725905179977417\n",
      "Write summary at step 230  Loss:  0.6326675415039062\n",
      "Write summary at step 240  Loss:  0.7154239416122437\n",
      "Write summary at step 250  Loss:  0.8003337383270264\n",
      "Write summary at step 260  Loss:  0.7425922751426697\n",
      "Write summary at step 270  Loss:  0.5981135368347168\n",
      "Write summary at step 280  Loss:  0.666895866394043\n",
      "Write summary at step 290  Loss:  0.8735719323158264\n",
      "Write summary at step 300  Loss:  0.6248927712440491\n",
      "Write summary at step 310  Loss:  0.7138893604278564\n",
      "Write summary at step 320  Loss:  0.6839988231658936\n",
      "Write summary at step 330  Loss:  0.7242386937141418\n",
      "Write summary at step 340  Loss:  0.7695869207382202\n",
      "Write summary at step 350  Loss:  0.6109305620193481\n",
      "Write summary at step 360  Loss:  0.6777337193489075\n",
      "Write summary at step 370  Loss:  0.6382954120635986\n",
      "Write summary at step 380  Loss:  0.7066932916641235\n",
      "Write summary at step 390  Loss:  0.7121233940124512\n",
      "Write summary at step 400  Loss:  0.6729785203933716\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.49783549783549785 Acurracy Control:  0.45901639344262296 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5524248633879781\n",
      "Loss normal: 0.710344866756753 Loss Control: 0.7169462800677356 Loss Patient: 0.6851769362886747 Loss balanced:  0.7010616081782052 Loss1+loss2: 0.7010616081782052\n",
      "\n",
      " > BEST MODEL (0.70106) : result/41/panns/best_checkpoint.pt\n",
      "Write summary at step 410  Loss:  0.6750478744506836\n",
      "Write summary at step 420  Loss:  0.7144314050674438\n",
      "Write summary at step 430  Loss:  0.623274564743042\n",
      "Write summary at step 440  Loss:  0.6274725198745728\n",
      "Write summary at step 450  Loss:  0.6977437734603882\n",
      "Write summary at step 460  Loss:  0.7169935703277588\n",
      "Write summary at step 470  Loss:  0.7653980851173401\n",
      "Write summary at step 480  Loss:  0.6394631862640381\n",
      "Write summary at step 490  Loss:  0.7555041313171387\n",
      "Write summary at step 500  Loss:  1.183318018913269\n",
      "Saved checkpoint to: result/41/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 1.0717813937694995 Loss Control: 1.278486822472244 Loss Patient: 0.2837168937548995 Loss balanced:  0.7811018581135718 Loss1+loss2: 0.7811018581135718\n",
      "Write summary at step 510  Loss:  0.6133637428283691\n",
      "Write summary at step 520  Loss:  0.8427255153656006\n",
      "Write summary at step 530  Loss:  0.7338644862174988\n",
      "Write summary at step 540  Loss:  0.8050203323364258\n",
      "Write summary at step 550  Loss:  1.0150059461593628\n",
      "Write summary at step 560  Loss:  0.671345591545105\n",
      "Write summary at step 570  Loss:  0.6679017543792725\n",
      "Write summary at step 580  Loss:  0.718091607093811\n",
      "Write summary at step 590  Loss:  0.7351774573326111\n",
      "Write summary at step 600  Loss:  0.8069243431091309\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.08333333333333333 Acurracy Balanced 0.5389344262295082\n",
      "Loss normal: 0.6757087415947026 Loss Control: 0.6669102806211169 Loss Patient: 0.7092528305947781 Loss balanced:  0.6880815556079475 Loss1+loss2: 0.6880815556079475\n",
      "\n",
      " > BEST MODEL (0.68808) : result/41/panns/best_checkpoint.pt\n",
      "Write summary at step 610  Loss:  0.6755101680755615\n",
      "Write summary at step 620  Loss:  0.6987863779067993\n",
      "Write summary at step 630  Loss:  0.863404393196106\n",
      "Write summary at step 640  Loss:  0.7953425645828247\n",
      "Write summary at step 650  Loss:  0.693786084651947\n",
      "Write summary at step 660  Loss:  0.7766932249069214\n",
      "Write summary at step 670  Loss:  0.7442604899406433\n",
      "Write summary at step 680  Loss:  0.7414592504501343\n",
      "Write summary at step 690  Loss:  0.7511966228485107\n",
      "Write summary at step 700  Loss:  0.6670284271240234\n",
      "Write summary at step 710  Loss:  0.7417325973510742\n",
      "Write summary at step 720  Loss:  0.6432309150695801\n",
      "Write summary at step 730  Loss:  0.7161611318588257\n",
      "Write summary at step 740  Loss:  0.6996237635612488\n",
      "Write summary at step 750  Loss:  0.7518998384475708\n",
      "Write summary at step 760  Loss:  0.6694623231887817\n",
      "Write summary at step 770  Loss:  0.7081257104873657\n",
      "Write summary at step 780  Loss:  0.6415225863456726\n",
      "Write summary at step 790  Loss:  0.6979844570159912\n",
      "Write summary at step 800  Loss:  0.6899149417877197\n",
      "Write summary at step 810  Loss:  0.613086462020874\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.19480519480519481 Acurracy Control:  0.03278688524590164 Acurracy Patient:  0.8125 Acurracy Balanced 0.42264344262295084\n",
      "Loss normal: 0.7417821664830823 Loss Control: 0.7589720569021715 Loss Patient: 0.6762457092603048 Loss balanced:  0.7176088830812382 Loss1+loss2: 0.7176088830812382\n",
      "Write summary at step 820  Loss:  0.8023596405982971\n",
      "Write summary at step 830  Loss:  0.6876658797264099\n",
      "Write summary at step 840  Loss:  0.6763237118721008\n",
      "Write summary at step 850  Loss:  0.6979511380195618\n",
      "Write summary at step 860  Loss:  0.7360100746154785\n",
      "Write summary at step 870  Loss:  0.6641286015510559\n",
      "Write summary at step 880  Loss:  0.7277917861938477\n",
      "Write summary at step 890  Loss:  0.7219771146774292\n",
      "Write summary at step 900  Loss:  0.6725836992263794\n",
      "Write summary at step 910  Loss:  0.7288229465484619\n",
      "Write summary at step 920  Loss:  0.7481281757354736\n",
      "Write summary at step 930  Loss:  0.6955969929695129\n",
      "Write summary at step 940  Loss:  0.6772588491439819\n",
      "Write summary at step 950  Loss:  0.730494499206543\n",
      "Write summary at step 960  Loss:  0.7118746042251587\n",
      "Write summary at step 970  Loss:  0.7233328819274902\n",
      "Write summary at step 980  Loss:  0.6603676080703735\n",
      "Write summary at step 990  Loss:  0.7317813038825989\n",
      "Write summary at step 1000  Loss:  0.7165446281433105\n",
      "Saved checkpoint to: result/41/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6529312760798962 Loss Control: 0.6211195249375099 Loss Patient: 0.77421356489261 Loss balanced:  0.6976665449150599 Loss1+loss2: 0.6976665449150599\n",
      "Write summary at step 1010  Loss:  0.7314634919166565\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6636864065607905 Loss Control: 0.6410154670965477 Loss Patient: 0.7501194104552269 Loss balanced:  0.6955674387758872 Loss1+loss2: 0.6955674387758872\n",
      "Write summary at step 1020  Loss:  0.7132642865180969\n",
      "Write summary at step 1030  Loss:  0.7287458181381226\n",
      "Write summary at step 1040  Loss:  0.7402125597000122\n",
      "Write summary at step 1050  Loss:  0.6659284830093384\n",
      "Write summary at step 1060  Loss:  0.7500799298286438\n",
      "Write summary at step 1070  Loss:  0.6774786710739136\n",
      "Write summary at step 1080  Loss:  0.6864862442016602\n",
      "Write summary at step 1090  Loss:  0.6667177677154541\n",
      "Write summary at step 1100  Loss:  0.7537764310836792\n",
      "Write summary at step 1110  Loss:  0.7098879218101501\n",
      "Write summary at step 1120  Loss:  0.7202502489089966\n",
      "Write summary at step 1130  Loss:  0.659675121307373\n",
      "Write summary at step 1140  Loss:  0.637061357498169\n",
      "Write summary at step 1150  Loss:  0.7289739847183228\n",
      "Write summary at step 1160  Loss:  0.6894912123680115\n",
      "Write summary at step 1170  Loss:  0.7159823179244995\n",
      "Write summary at step 1180  Loss:  0.6458715200424194\n",
      "Write summary at step 1190  Loss:  0.7035969495773315\n",
      "Write summary at step 1200  Loss:  0.7057061791419983\n",
      "Write summary at step 1210  Loss:  0.745955228805542\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.07103825136612021 Acurracy Patient:  0.7291666666666666 Acurracy Balanced 0.4001024590163934\n",
      "Loss normal: 0.7186614326584391 Loss Control: 0.7306639229665037 Loss Patient: 0.672901893655459 Loss balanced:  0.7017829083109814 Loss1+loss2: 0.7017829083109814\n",
      "Write summary at step 1220  Loss:  0.7189885377883911\n",
      "Write summary at step 1230  Loss:  0.7043685913085938\n",
      "Write summary at step 1240  Loss:  0.7007002830505371\n",
      "Write summary at step 1250  Loss:  0.6763801574707031\n",
      "Write summary at step 1260  Loss:  0.8281338214874268\n",
      "Write summary at step 1270  Loss:  0.6903366446495056\n",
      "Write summary at step 1280  Loss:  0.7164543271064758\n",
      "Write summary at step 1290  Loss:  0.6336975693702698\n",
      "Write summary at step 1300  Loss:  0.7218924164772034\n",
      "Write summary at step 1310  Loss:  0.7536205053329468\n",
      "Write summary at step 1320  Loss:  0.683798611164093\n",
      "Write summary at step 1330  Loss:  0.7165254950523376\n",
      "Write summary at step 1340  Loss:  0.7002716064453125\n",
      "Write summary at step 1350  Loss:  0.6736593842506409\n",
      "Write summary at step 1360  Loss:  0.742862343788147\n",
      "Write summary at step 1370  Loss:  0.7327094078063965\n",
      "Write summary at step 1380  Loss:  0.7278953790664673\n",
      "Write summary at step 1390  Loss:  0.7008761167526245\n",
      "Write summary at step 1400  Loss:  0.6967097520828247\n",
      "Write summary at step 1410  Loss:  0.7168200612068176\n",
      "Write summary at step 1420  Loss:  0.6656428575515747\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21212121212121213 Acurracy Control:  0.02185792349726776 Acurracy Patient:  0.9375 Acurracy Balanced 0.4796789617486339\n",
      "Loss normal: 0.7104474486726703 Loss Control: 0.7219746555786967 Loss Patient: 0.6664999201893806 Loss balanced:  0.6942372878840386 Loss1+loss2: 0.6942372878840386\n",
      "Write summary at step 1430  Loss:  0.6656141877174377\n",
      "Write summary at step 1440  Loss:  0.7080248594284058\n",
      "Write summary at step 1450  Loss:  0.7361959218978882\n",
      "Write summary at step 1460  Loss:  0.6724873781204224\n",
      "Write summary at step 1470  Loss:  0.6605914831161499\n",
      "Write summary at step 1480  Loss:  0.6691005229949951\n",
      "Write summary at step 1490  Loss:  0.6397567391395569\n",
      "Write summary at step 1500  Loss:  0.6650503277778625\n",
      "Saved checkpoint to: result/41/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.5021645021645021 Acurracy Control:  0.5573770491803278 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.4245218579234973\n",
      "Loss normal: 0.6857731618406453 Loss Control: 0.6341715780763678 Loss Patient: 0.882504191249609 Loss balanced:  0.7583378846629885 Loss1+loss2: 0.7583378846629885\n",
      "Write summary at step 1510  Loss:  0.6985688209533691\n",
      "Write summary at step 1520  Loss:  0.6398521661758423\n",
      "Write summary at step 1530  Loss:  0.766642689704895\n",
      "Write summary at step 1540  Loss:  0.7166988849639893\n",
      "Write summary at step 1550  Loss:  0.6675266027450562\n",
      "Write summary at step 1560  Loss:  0.7350748181343079\n",
      "Write summary at step 1570  Loss:  0.7376324534416199\n",
      "Write summary at step 1580  Loss:  0.7047993540763855\n",
      "Write summary at step 1590  Loss:  0.6602404117584229\n",
      "Write summary at step 1600  Loss:  0.7155318260192871\n",
      "Write summary at step 1610  Loss:  0.7306936979293823\n",
      "Write summary at step 1620  Loss:  0.6966919302940369\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.00546448087431694 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.4923155737704918\n",
      "Loss normal: 0.7462047196569896 Loss Control: 0.7789345031878987 Loss Patient: 0.6214223516484102 Loss balanced:  0.7001784274181544 Loss1+loss2: 0.7001784274181544\n",
      "Write summary at step 1630  Loss:  0.7577747702598572\n",
      "Write summary at step 1640  Loss:  0.6875383853912354\n",
      "Write summary at step 1650  Loss:  0.6668906211853027\n",
      "Write summary at step 1660  Loss:  0.6835272908210754\n",
      "Write summary at step 1670  Loss:  0.7310782074928284\n",
      "Write summary at step 1680  Loss:  0.7144149541854858\n",
      "Write summary at step 1690  Loss:  0.6925665140151978\n",
      "Write summary at step 1700  Loss:  0.6536587476730347\n",
      "Write summary at step 1710  Loss:  0.7549337148666382\n",
      "Write summary at step 1720  Loss:  0.6947019100189209\n",
      "Write summary at step 1730  Loss:  0.6475648880004883\n",
      "Write summary at step 1740  Loss:  0.6743366718292236\n",
      "Write summary at step 1750  Loss:  0.6503455638885498\n",
      "Write summary at step 1760  Loss:  0.7173839807510376\n",
      "Write summary at step 1770  Loss:  0.7089532017707825\n",
      "Write summary at step 1780  Loss:  0.6532013416290283\n",
      "Write summary at step 1790  Loss:  0.668330192565918\n",
      "Write summary at step 1800  Loss:  0.6965227723121643\n",
      "Write summary at step 1810  Loss:  0.7002241015434265\n",
      "Write summary at step 1820  Loss:  0.6941264867782593\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3116883116883117 Acurracy Control:  0.18032786885245902 Acurracy Patient:  0.8125 Acurracy Balanced 0.4964139344262295\n",
      "Loss normal: 0.7109910675457546 Loss Control: 0.7214861681552532 Loss Patient: 0.6709785014390945 Loss balanced:  0.696232334797174 Loss1+loss2: 0.696232334797174\n",
      "Write summary at step 1830  Loss:  0.814495325088501\n",
      "Write summary at step 1840  Loss:  0.6819117069244385\n",
      "Write summary at step 1850  Loss:  0.7329261302947998\n",
      "Write summary at step 1860  Loss:  0.723764181137085\n",
      "Write summary at step 1870  Loss:  0.6910594701766968\n",
      "Write summary at step 1880  Loss:  0.7575445175170898\n",
      "Write summary at step 1890  Loss:  0.7684468030929565\n",
      "Write summary at step 1900  Loss:  0.7497653961181641\n",
      "Write summary at step 1910  Loss:  0.7245519161224365\n",
      "Write summary at step 1920  Loss:  0.7263592481613159\n",
      "Write summary at step 1930  Loss:  0.6855190992355347\n",
      "Write summary at step 1940  Loss:  0.7017571926116943\n",
      "Write summary at step 1950  Loss:  0.7134972810745239\n",
      "Write summary at step 1960  Loss:  0.7082133293151855\n",
      "Write summary at step 1970  Loss:  0.7495216727256775\n",
      "Write summary at step 1980  Loss:  0.7163853645324707\n",
      "Write summary at step 1990  Loss:  0.6559993028640747\n",
      "Write summary at step 2000  Loss:  0.7637659907341003\n",
      "Saved checkpoint to: result/41/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.48668032786885246\n",
      "Loss normal: 0.6697180366619325 Loss Control: 0.6497003905108718 Loss Patient: 0.7460352939864 Loss balanced:  0.697867842248636 Loss1+loss2: 0.697867842248636\n",
      "Write summary at step 2010  Loss:  0.7451305985450745\n",
      "Write summary at step 2020  Loss:  0.6860032081604004\n",
      "Write summary at step 2030  Loss:  0.7093155980110168\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7570896835038157 Loss Control: 0.7978278177032054 Loss Patient: 0.6017755555609862 Loss balanced:  0.6998016866320957 Loss1+loss2: 0.6998016866320957\n",
      "Write summary at step 2040  Loss:  0.6666227579116821\n",
      "Write summary at step 2050  Loss:  0.7137737274169922\n",
      "Write summary at step 2060  Loss:  0.6738426685333252\n",
      "Write summary at step 2070  Loss:  0.7618253827095032\n",
      "Write summary at step 2080  Loss:  0.7065514326095581\n",
      "Write summary at step 2090  Loss:  0.7213071584701538\n",
      "Write summary at step 2100  Loss:  0.7809320688247681\n",
      "Write summary at step 2110  Loss:  0.679877519607544\n",
      "Write summary at step 2120  Loss:  0.6546902656555176\n",
      "Write summary at step 2130  Loss:  0.7538081407546997\n",
      "Write summary at step 2140  Loss:  0.7034245133399963\n",
      "Write summary at step 2150  Loss:  0.6874040365219116\n",
      "Write summary at step 2160  Loss:  0.7596467137336731\n",
      "Write summary at step 2170  Loss:  0.6996539831161499\n",
      "Write summary at step 2180  Loss:  0.7294485569000244\n",
      "Write summary at step 2190  Loss:  0.6384949684143066\n",
      "Write summary at step 2200  Loss:  0.6851059794425964\n",
      "Write summary at step 2210  Loss:  0.6989831328392029\n",
      "Write summary at step 2220  Loss:  0.695093035697937\n",
      "Write summary at step 2230  Loss:  0.6948779821395874\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7581988258279247 Loss Control: 0.80053846562495 Loss Patient: 0.5967789553105831 Loss balanced:  0.6986587104677666 Loss1+loss2: 0.6986587104677666\n",
      "Write summary at step 2240  Loss:  0.7152256369590759\n",
      "Write summary at step 2250  Loss:  0.7177207469940186\n",
      "Write summary at step 2260  Loss:  0.6933543086051941\n",
      "Write summary at step 2270  Loss:  0.6843931674957275\n",
      "Write summary at step 2280  Loss:  0.6721877455711365\n",
      "Write summary at step 2290  Loss:  0.6874579787254333\n",
      "Write summary at step 2300  Loss:  0.687751293182373\n",
      "Write summary at step 2310  Loss:  0.6828837394714355\n",
      "Write summary at step 2320  Loss:  0.6376558542251587\n",
      "Write summary at step 2330  Loss:  0.7384552955627441\n",
      "Write summary at step 2340  Loss:  0.6733543276786804\n",
      "Write summary at step 2350  Loss:  0.6667900085449219\n",
      "Write summary at step 2360  Loss:  0.6523949503898621\n",
      "Write summary at step 2370  Loss:  0.6561733484268188\n",
      "Write summary at step 2380  Loss:  0.705500602722168\n",
      "Write summary at step 2390  Loss:  0.7343021035194397\n",
      "Write summary at step 2400  Loss:  0.7184648513793945\n",
      "Write summary at step 2410  Loss:  0.6973931193351746\n",
      "Write summary at step 2420  Loss:  0.6586068868637085\n",
      "Write summary at step 2430  Loss:  0.7151526212692261\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6760047488398366 Loss Control: 0.6636829539074924 Loss Patient: 0.7229816255470117 Loss balanced:  0.693332289727252 Loss1+loss2: 0.693332289727252\n",
      "Write summary at step 2440  Loss:  0.6872038841247559\n",
      "Write summary at step 2450  Loss:  0.7394915819168091\n",
      "Write summary at step 2460  Loss:  0.7033026218414307\n",
      "Write summary at step 2470  Loss:  0.7286637425422668\n",
      "Write summary at step 2480  Loss:  0.7093284726142883\n",
      "Write summary at step 2490  Loss:  0.685685932636261\n",
      "Write summary at step 2500  Loss:  0.6786839962005615\n",
      "Saved checkpoint to: result/41/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.24675324675324675 Acurracy Control:  0.060109289617486336 Acurracy Patient:  0.9583333333333334 Acurracy Balanced 0.5092213114754098\n",
      "Loss normal: 0.69989909754171 Loss Control: 0.7046831162249456 Loss Patient: 0.6816600089271864 Loss balanced:  0.6931715625760659 Loss1+loss2: 0.6931715625760659\n",
      "Write summary at step 2510  Loss:  0.6810498237609863\n",
      "Write summary at step 2520  Loss:  0.7397225499153137\n",
      "Write summary at step 2530  Loss:  0.672959566116333\n",
      "Write summary at step 2540  Loss:  0.7102361917495728\n",
      "Write summary at step 2550  Loss:  0.6933637261390686\n",
      "Write summary at step 2560  Loss:  0.7270396947860718\n",
      "Write summary at step 2570  Loss:  0.7656975984573364\n",
      "Write summary at step 2580  Loss:  0.7086899280548096\n",
      "Write summary at step 2590  Loss:  0.7531925439834595\n",
      "Write summary at step 2600  Loss:  0.7108232975006104\n",
      "Write summary at step 2610  Loss:  0.6831570267677307\n",
      "Write summary at step 2620  Loss:  0.6740174293518066\n",
      "Write summary at step 2630  Loss:  0.7415488958358765\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6737849567875718 Loss Control: 0.659647105170078 Loss Patient: 0.727685476342837 Loss balanced:  0.6936662907564575 Loss1+loss2: 0.6936662907564575\n",
      "Write summary at step 2640  Loss:  0.6489866971969604\n",
      "Write summary at step 2650  Loss:  0.7157163619995117\n",
      "Write summary at step 2660  Loss:  0.6698048114776611\n",
      "Write summary at step 2670  Loss:  0.6824159622192383\n",
      "Write summary at step 2680  Loss:  0.678628146648407\n",
      "Write summary at step 2690  Loss:  0.7241604328155518\n",
      "Write summary at step 2700  Loss:  0.7423310279846191\n",
      "Write summary at step 2710  Loss:  0.6767286062240601\n",
      "Write summary at step 2720  Loss:  0.6921247243881226\n",
      "Write summary at step 2730  Loss:  0.7118408679962158\n",
      "Write summary at step 2740  Loss:  0.6917059421539307\n",
      "Write summary at step 2750  Loss:  0.6695491671562195\n",
      "Write summary at step 2760  Loss:  0.7376077175140381\n",
      "Write summary at step 2770  Loss:  0.6973081231117249\n",
      "Write summary at step 2780  Loss:  0.6613239049911499\n",
      "Write summary at step 2790  Loss:  0.6917009353637695\n",
      "Write summary at step 2800  Loss:  0.6865800619125366\n",
      "Write summary at step 2810  Loss:  0.7478692531585693\n",
      "Write summary at step 2820  Loss:  0.6934677362442017\n",
      "Write summary at step 2830  Loss:  0.7045140266418457\n",
      "Write summary at step 2840  Loss:  0.6658393740653992\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7092050775821075 Loss Control: 0.7206473080186896 Loss Patient: 0.6655815343062083 Loss balanced:  0.6931144211624489 Loss1+loss2: 0.6931144211624489\n",
      "Write summary at step 2850  Loss:  0.6822426319122314\n",
      "Write summary at step 2860  Loss:  0.7143639326095581\n",
      "Write summary at step 2870  Loss:  0.6740156412124634\n",
      "Write summary at step 2880  Loss:  0.703883945941925\n",
      "Write summary at step 2890  Loss:  0.7189956307411194\n",
      "Write summary at step 2900  Loss:  0.6989462375640869\n",
      "Write summary at step 2910  Loss:  0.6722294688224792\n",
      "Write summary at step 2920  Loss:  0.7785926461219788\n",
      "Write summary at step 2930  Loss:  0.7170308232307434\n",
      "Write summary at step 2940  Loss:  0.7061371207237244\n",
      "Write summary at step 2950  Loss:  0.7092385292053223\n",
      "Write summary at step 2960  Loss:  0.7007144689559937\n",
      "Write summary at step 2970  Loss:  0.6730700731277466\n",
      "Write summary at step 2980  Loss:  0.6747909784317017\n",
      "Write summary at step 2990  Loss:  0.6961541175842285\n",
      "Write summary at step 3000  Loss:  0.6863282918930054\n",
      "Saved checkpoint to: result/41/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6796536796536796 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5058060109289617\n",
      "Loss normal: 0.6941105251188402 Loss Control: 0.6945113295414409 Loss Patient: 0.6925824570159117 Loss balanced:  0.6935468932786764 Loss1+loss2: 0.6935468932786764\n",
      "Write summary at step 3010  Loss:  0.7032355070114136\n",
      "Write summary at step 3020  Loss:  0.7156469821929932\n",
      "Write summary at step 3030  Loss:  0.6777112483978271\n",
      "Write summary at step 3040  Loss:  0.6556589603424072\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0 Acurracy Balanced 0.49453551912568305\n",
      "Loss normal: 0.6320614502543495 Loss Control: 0.5833191125770736 Loss Patient: 0.8178916126489639 Loss balanced:  0.7006053626130188 Loss1+loss2: 0.7006053626130188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 3050  Loss:  0.728434681892395\n",
      "Write summary at step 3060  Loss:  0.6762852072715759\n",
      "Write summary at step 3070  Loss:  0.6921707391738892\n",
      "Write summary at step 3080  Loss:  0.7259607315063477\n",
      "Write summary at step 3090  Loss:  0.6672065854072571\n",
      "Write summary at step 3100  Loss:  0.6807178854942322\n",
      "Write summary at step 3110  Loss:  0.7015645503997803\n",
      "Write summary at step 3120  Loss:  0.6647964715957642\n",
      "Write summary at step 3130  Loss:  0.6752189993858337\n",
      "Write summary at step 3140  Loss:  0.6605917811393738\n",
      "Write summary at step 3150  Loss:  0.7369655966758728\n",
      "Write summary at step 3160  Loss:  0.669093132019043\n",
      "Write summary at step 3170  Loss:  0.7183035612106323\n",
      "Write summary at step 3180  Loss:  0.7382819652557373\n",
      "Write summary at step 3190  Loss:  0.6999348402023315\n",
      "Write summary at step 3200  Loss:  0.6786794662475586\n",
      "Write summary at step 3210  Loss:  0.6788631081581116\n",
      "Write summary at step 3220  Loss:  0.7310298681259155\n",
      "Write summary at step 3230  Loss:  0.6721346974372864\n",
      "Write summary at step 3240  Loss:  0.7513072490692139\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.30735930735930733 Acurracy Control:  0.17486338797814208 Acurracy Patient:  0.8125 Acurracy Balanced 0.493681693989071\n",
      "Loss normal: 0.6964822643763059 Loss Control: 0.6986780378336463 Loss Patient: 0.6881108246743679 Loss balanced:  0.6933944312540071 Loss1+loss2: 0.6933944312540071\n",
      "Write summary at step 3250  Loss:  0.7042223215103149\n",
      "Write summary at step 3260  Loss:  0.6743944883346558\n",
      "Write summary at step 3270  Loss:  0.7025850415229797\n",
      "Write summary at step 3280  Loss:  0.6833366751670837\n",
      "Write summary at step 3290  Loss:  0.7009528875350952\n",
      "Write summary at step 3300  Loss:  0.6601154208183289\n",
      "Write summary at step 3310  Loss:  0.6658125519752502\n",
      "Write summary at step 3320  Loss:  0.7354768514633179\n",
      "Write summary at step 3330  Loss:  0.7084939479827881\n",
      "Write summary at step 3340  Loss:  0.6930209994316101\n",
      "Write summary at step 3350  Loss:  0.7317951917648315\n",
      "Write summary at step 3360  Loss:  0.7068954110145569\n",
      "Write summary at step 3370  Loss:  0.692046582698822\n",
      "Write summary at step 3380  Loss:  0.6709592342376709\n",
      "Write summary at step 3390  Loss:  0.7752481698989868\n",
      "Write summary at step 3400  Loss:  0.7199814319610596\n",
      "Write summary at step 3410  Loss:  0.6754971742630005\n",
      "Write summary at step 3420  Loss:  0.6962419748306274\n",
      "Write summary at step 3430  Loss:  0.7403349876403809\n",
      "Write summary at step 3440  Loss:  0.7154189348220825\n",
      "Write summary at step 3450  Loss:  0.6545331478118896\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.0625 Acurracy Balanced 0.49026639344262296\n",
      "Loss normal: 0.6815280689821615 Loss Control: 0.6725962543096698 Loss Patient: 0.7155806322892507 Loss balanced:  0.6940884432994603 Loss1+loss2: 0.6940884432994603\n",
      "Write summary at step 3460  Loss:  0.7338228225708008\n",
      "Write summary at step 3470  Loss:  0.6906487345695496\n",
      "Write summary at step 3480  Loss:  0.6629738211631775\n",
      "Write summary at step 3490  Loss:  0.7029246091842651\n",
      "Write summary at step 3500  Loss:  0.6641647815704346\n",
      "Saved checkpoint to: result/41/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.125 Acurracy Balanced 0.5242486338797814\n",
      "Loss normal: 0.6776713581828328 Loss Control: 0.6673419775207186 Loss Patient: 0.7170521728694439 Loss balanced:  0.6921970751950812 Loss1+loss2: 0.6921970751950812\n",
      "Write summary at step 3510  Loss:  0.6904832720756531\n",
      "Write summary at step 3520  Loss:  0.6946593523025513\n",
      "Write summary at step 3530  Loss:  0.7250510454177856\n",
      "Write summary at step 3540  Loss:  0.6808948516845703\n",
      "Write summary at step 3550  Loss:  0.7116552591323853\n",
      "Write summary at step 3560  Loss:  0.6801801919937134\n",
      "Write summary at step 3570  Loss:  0.7331425547599792\n",
      "Write summary at step 3580  Loss:  0.6641877293586731\n",
      "Write summary at step 3590  Loss:  0.7219228148460388\n",
      "Write summary at step 3600  Loss:  0.6817229986190796\n",
      "Write summary at step 3610  Loss:  0.7083877325057983\n",
      "Write summary at step 3620  Loss:  0.6718132495880127\n",
      "Write summary at step 3630  Loss:  0.7059304714202881\n",
      "Write summary at step 3640  Loss:  0.6840388774871826\n",
      "Write summary at step 3650  Loss:  0.6629044413566589\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6233766233766234 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5010245901639344\n",
      "Loss normal: 0.6881823895813582 Loss Control: 0.6843390393126858 Loss Patient: 0.7028352034588655 Loss balanced:  0.6935871213857756 Loss1+loss2: 0.6935871213857756\n",
      "Write summary at step 3660  Loss:  0.6992783546447754\n",
      "Write summary at step 3670  Loss:  0.6881090998649597\n",
      "Write summary at step 3680  Loss:  0.7375674247741699\n",
      "Write summary at step 3690  Loss:  0.6874073147773743\n",
      "Write summary at step 3700  Loss:  0.6871015429496765\n",
      "Write summary at step 3710  Loss:  0.6948760747909546\n",
      "Write summary at step 3720  Loss:  0.7185184359550476\n",
      "Write summary at step 3730  Loss:  0.6815886497497559\n",
      "Write summary at step 3740  Loss:  0.6979537010192871\n",
      "Write summary at step 3750  Loss:  0.7353368997573853\n",
      "Write summary at step 3760  Loss:  0.6682190299034119\n",
      "Write summary at step 3770  Loss:  0.6661046743392944\n",
      "Write summary at step 3780  Loss:  0.6891863942146301\n",
      "Write summary at step 3790  Loss:  0.6944637894630432\n",
      "Write summary at step 3800  Loss:  0.6862267851829529\n",
      "Write summary at step 3810  Loss:  0.7101787328720093\n",
      "Write summary at step 3820  Loss:  0.6689518690109253\n",
      "Write summary at step 3830  Loss:  0.7174668312072754\n",
      "Write summary at step 3840  Loss:  0.6745160818099976\n",
      "Write summary at step 3850  Loss:  0.6839727163314819\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5097336065573771\n",
      "Loss normal: 0.677804903034524 Loss Control: 0.6657455833883233 Loss Patient: 0.7237810492515564 Loss balanced:  0.6947633163199398 Loss1+loss2: 0.6947633163199398\n",
      "Write summary at step 3860  Loss:  0.694877564907074\n",
      "Write summary at step 3870  Loss:  0.713029146194458\n",
      "Write summary at step 3880  Loss:  0.7264918088912964\n",
      "Write summary at step 3890  Loss:  0.6954801082611084\n",
      "Write summary at step 3900  Loss:  0.6680780649185181\n",
      "Write summary at step 3910  Loss:  0.7151088714599609\n",
      "Write summary at step 3920  Loss:  0.6808103322982788\n",
      "Write summary at step 3930  Loss:  0.692939043045044\n",
      "Write summary at step 3940  Loss:  0.7148687243461609\n",
      "Write summary at step 3950  Loss:  0.6888037323951721\n",
      "Write summary at step 3960  Loss:  0.7184484004974365\n",
      "Write summary at step 3970  Loss:  0.6787616014480591\n",
      "Write summary at step 3980  Loss:  0.7435905337333679\n",
      "Write summary at step 3990  Loss:  0.711154580116272\n",
      "Write summary at step 4000  Loss:  0.7683266401290894\n",
      "Saved checkpoint to: result/41/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7549796893999174 Loss Control: 0.7935789328455274 Loss Patient: 0.6078200849394003 Loss balanced:  0.7006995088924639 Loss1+loss2: 0.7006995088924639\n",
      "Write summary at step 4010  Loss:  0.7149161696434021\n",
      "Write summary at step 4020  Loss:  0.7387217283248901\n",
      "Write summary at step 4030  Loss:  0.6389902830123901\n",
      "Write summary at step 4040  Loss:  0.7098727226257324\n",
      "Write summary at step 4050  Loss:  0.6925785541534424\n",
      "Write summary at step 4060  Loss:  0.6539232730865479\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7276014068942049 Loss Control: 0.7511669566722515 Loss Patient: 0.6377577558159828 Loss balanced:  0.6944623562441172 Loss1+loss2: 0.6944623562441172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 4070  Loss:  0.6723587512969971\n",
      "Write summary at step 4080  Loss:  0.7096207737922668\n",
      "Write summary at step 4090  Loss:  0.6693248152732849\n",
      "Write summary at step 4100  Loss:  0.6621236801147461\n",
      "Write summary at step 4110  Loss:  0.6989358067512512\n",
      "Write summary at step 4120  Loss:  0.7141603231430054\n",
      "Write summary at step 4130  Loss:  0.7050740718841553\n",
      "Write summary at step 4140  Loss:  0.7554851770401001\n",
      "Write summary at step 4150  Loss:  0.6749913096427917\n",
      "Write summary at step 4160  Loss:  0.6795164346694946\n",
      "Write summary at step 4170  Loss:  0.6487234234809875\n",
      "Write summary at step 4180  Loss:  0.693789005279541\n",
      "Write summary at step 4190  Loss:  0.613627552986145\n",
      "Write summary at step 4200  Loss:  0.6361311674118042\n",
      "Write summary at step 4210  Loss:  0.6968985795974731\n",
      "Write summary at step 4220  Loss:  0.673304557800293\n",
      "Write summary at step 4230  Loss:  0.6505404710769653\n",
      "Write summary at step 4240  Loss:  0.6842089295387268\n",
      "Write summary at step 4250  Loss:  0.6806710958480835\n",
      "Write summary at step 4260  Loss:  0.7048537731170654\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7180813561270247 Loss Control: 0.7348909710274368 Loss Patient: 0.6539946620663007 Loss balanced:  0.6944428165468688 Loss1+loss2: 0.6944428165468688\n",
      "Write summary at step 4270  Loss:  0.6723276972770691\n",
      "Write summary at step 4280  Loss:  0.6730286478996277\n",
      "Write summary at step 4290  Loss:  0.7182531356811523\n",
      "Write summary at step 4300  Loss:  0.6981479525566101\n",
      "Write summary at step 4310  Loss:  0.7197304368019104\n",
      "Write summary at step 4320  Loss:  0.7079915404319763\n",
      "Write summary at step 4330  Loss:  0.6831673979759216\n",
      "Write summary at step 4340  Loss:  0.6815029382705688\n",
      "Write summary at step 4350  Loss:  0.6847862005233765\n",
      "Write summary at step 4360  Loss:  0.7247734069824219\n",
      "Write summary at step 4370  Loss:  0.6732189655303955\n",
      "Write summary at step 4380  Loss:  0.6905837059020996\n",
      "Write summary at step 4390  Loss:  0.7207781672477722\n",
      "Write summary at step 4400  Loss:  0.6682316064834595\n",
      "Write summary at step 4410  Loss:  0.646171510219574\n",
      "Write summary at step 4420  Loss:  0.6908542513847351\n",
      "Write summary at step 4430  Loss:  0.695587158203125\n",
      "Write summary at step 4440  Loss:  0.6838979721069336\n",
      "Write summary at step 4450  Loss:  0.7112137079238892\n",
      "Write summary at step 4460  Loss:  0.7168716192245483\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5584415584415584 Acurracy Control:  0.6010928961748634 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.4984631147540983\n",
      "Loss normal: 0.6984360341901903 Loss Control: 0.7020721604915264 Loss Patient: 0.6845732741057873 Loss balanced:  0.6933227172986569 Loss1+loss2: 0.6933227172986569\n",
      "Write summary at step 4470  Loss:  0.6856664419174194\n",
      "Write summary at step 4480  Loss:  0.6814998388290405\n",
      "Write summary at step 4490  Loss:  0.7453876733779907\n",
      "Write summary at step 4500  Loss:  0.6943069696426392\n",
      "Saved checkpoint to: result/41/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6147186147186147 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.25 Acurracy Balanced 0.4801912568306011\n",
      "Loss normal: 0.6917713588966435 Loss Control: 0.6908862997925347 Loss Patient: 0.6951456901927789 Loss balanced:  0.6930159949926569 Loss1+loss2: 0.6930159949926569\n",
      "Write summary at step 4510  Loss:  0.6879810094833374\n",
      "Write summary at step 4520  Loss:  0.7149784564971924\n",
      "Write summary at step 4530  Loss:  0.675319492816925\n",
      "Write summary at step 4540  Loss:  0.6982671618461609\n",
      "Write summary at step 4550  Loss:  0.715156078338623\n",
      "Write summary at step 4560  Loss:  0.7338964939117432\n",
      "Write summary at step 4570  Loss:  0.6781007051467896\n",
      "Write summary at step 4580  Loss:  0.6772390604019165\n",
      "Write summary at step 4590  Loss:  0.670909583568573\n",
      "Write summary at step 4600  Loss:  0.7326079607009888\n",
      "Write summary at step 4610  Loss:  0.7544847726821899\n",
      "Write summary at step 4620  Loss:  0.598859429359436\n",
      "Write summary at step 4630  Loss:  0.6544461250305176\n",
      "Write summary at step 4640  Loss:  0.6598350405693054\n",
      "Write summary at step 4650  Loss:  0.6620142459869385\n",
      "Write summary at step 4660  Loss:  0.6805329322814941\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.10416666666666667 Acurracy Balanced 0.5165642076502732\n",
      "Loss normal: 0.6682220377447285 Loss Control: 0.6508552552572365 Loss Patient: 0.7344329183300337 Loss balanced:  0.6926440867936351 Loss1+loss2: 0.6926440867936351\n",
      "Write summary at step 4670  Loss:  0.6919934749603271\n",
      "Write summary at step 4680  Loss:  0.6600573658943176\n",
      "Write summary at step 4690  Loss:  0.7286703586578369\n",
      "Write summary at step 4700  Loss:  0.7143197059631348\n",
      "Write summary at step 4710  Loss:  0.9012620449066162\n",
      "Write summary at step 4720  Loss:  0.8167847394943237\n",
      "Write summary at step 4730  Loss:  0.741378903388977\n",
      "Write summary at step 4740  Loss:  0.6895819902420044\n",
      "Write summary at step 4750  Loss:  0.6355388164520264\n",
      "Write summary at step 4760  Loss:  0.7151802778244019\n",
      "Write summary at step 4770  Loss:  0.7275347709655762\n",
      "Write summary at step 4780  Loss:  0.7115637063980103\n",
      "Write summary at step 4790  Loss:  0.7033941745758057\n",
      "Write summary at step 4800  Loss:  0.6689907312393188\n",
      "Write summary at step 4810  Loss:  0.7815988659858704\n",
      "Write summary at step 4820  Loss:  0.7202022075653076\n",
      "Write summary at step 4830  Loss:  0.6806327104568481\n",
      "Write summary at step 4840  Loss:  0.6458178758621216\n",
      "Write summary at step 4850  Loss:  0.7252566814422607\n",
      "Write summary at step 4860  Loss:  0.6803991794586182\n",
      "Write summary at step 4870  Loss:  0.6917093396186829\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4069264069264069 Acurracy Control:  0.3005464480874317 Acurracy Patient:  0.8125 Acurracy Balanced 0.5565232240437159\n",
      "Loss normal: 0.7089372759773618 Loss Control: 0.7234723900185257 Loss Patient: 0.6535221946736177 Loss balanced:  0.6884972923460717 Loss1+loss2: 0.6884972923460717\n",
      "Write summary at step 4880  Loss:  0.7110320329666138\n",
      "Write summary at step 4890  Loss:  0.6984755992889404\n",
      "Write summary at step 4900  Loss:  0.6495177745819092\n",
      "Write summary at step 4910  Loss:  0.7712457776069641\n",
      "Write summary at step 4920  Loss:  0.629332423210144\n",
      "Write summary at step 4930  Loss:  0.6281023025512695\n",
      "Write summary at step 4940  Loss:  0.6945874691009521\n",
      "Write summary at step 4950  Loss:  0.6850711107254028\n",
      "Write summary at step 4960  Loss:  0.6931118965148926\n",
      "Write summary at step 4970  Loss:  0.715355396270752\n",
      "Write summary at step 4980  Loss:  0.7183502316474915\n",
      "Write summary at step 4990  Loss:  0.6922524571418762\n",
      "Write summary at step 5000  Loss:  0.728571355342865\n",
      "Saved checkpoint to: result/41/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.125 Acurracy Balanced 0.5379098360655737\n",
      "Loss normal: 0.6699274675154583 Loss Control: 0.6550669702675824 Loss Patient: 0.726583064844211 Loss balanced:  0.6908250175558968 Loss1+loss2: 0.6908250175558968\n",
      "Write summary at step 5010  Loss:  0.6586353778839111\n",
      "Write summary at step 5020  Loss:  0.7005424499511719\n",
      "Write summary at step 5030  Loss:  0.6904508471488953\n",
      "Write summary at step 5040  Loss:  0.7164233922958374\n",
      "Write summary at step 5050  Loss:  0.6541123390197754\n",
      "Write summary at step 5060  Loss:  0.687102198600769\n",
      "Write summary at step 5070  Loss:  0.7044646143913269\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.29004329004329005 Acurracy Control:  0.1366120218579235 Acurracy Patient:  0.875 Acurracy Balanced 0.5058060109289617\n",
      "Loss normal: 0.7202626394503044 Loss Control: 0.7419984490493607 Loss Patient: 0.637394896397988 Loss balanced:  0.6896966727236744 Loss1+loss2: 0.6896966727236744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 5080  Loss:  0.7011489272117615\n",
      "Write summary at step 5090  Loss:  0.7182519435882568\n",
      "Write summary at step 5100  Loss:  0.6750679612159729\n",
      "Write summary at step 5110  Loss:  0.648695707321167\n",
      "Write summary at step 5120  Loss:  0.6772192716598511\n",
      "Write summary at step 5130  Loss:  0.837571382522583\n",
      "Write summary at step 5140  Loss:  0.6923779249191284\n",
      "Write summary at step 5150  Loss:  0.6959105134010315\n",
      "Write summary at step 5160  Loss:  0.7317765951156616\n",
      "Write summary at step 5170  Loss:  0.7086756825447083\n",
      "Write summary at step 5180  Loss:  0.6977084279060364\n",
      "Write summary at step 5190  Loss:  0.6789747476577759\n",
      "Write summary at step 5200  Loss:  0.6773025393486023\n",
      "Write summary at step 5210  Loss:  0.669536292552948\n",
      "Write summary at step 5220  Loss:  0.7463752031326294\n",
      "Write summary at step 5230  Loss:  0.6646957397460938\n",
      "Write summary at step 5240  Loss:  0.7082564830780029\n",
      "Write summary at step 5250  Loss:  0.6658165454864502\n",
      "Write summary at step 5260  Loss:  0.6857720613479614\n",
      "Write summary at step 5270  Loss:  0.6687948107719421\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.27705627705627706 Acurracy Control:  0.12568306010928962 Acurracy Patient:  0.8541666666666666 Acurracy Balanced 0.48992486338797814\n",
      "Loss normal: 0.705752378418332 Loss Control: 0.7160259615528127 Loss Patient: 0.6665843116740385 Loss balanced:  0.6913051366134256 Loss1+loss2: 0.6913051366134256\n",
      "Write summary at step 5280  Loss:  0.6897168159484863\n",
      "Write summary at step 5290  Loss:  0.6905004978179932\n",
      "Write summary at step 5300  Loss:  0.7439340949058533\n",
      "Write summary at step 5310  Loss:  0.7146506905555725\n",
      "Write summary at step 5320  Loss:  0.7232551574707031\n",
      "Write summary at step 5330  Loss:  0.7105244994163513\n",
      "Write summary at step 5340  Loss:  0.669342041015625\n",
      "Write summary at step 5350  Loss:  0.6992744207382202\n",
      "Write summary at step 5360  Loss:  0.6951282024383545\n",
      "Write summary at step 5370  Loss:  0.7356100082397461\n",
      "Write summary at step 5380  Loss:  0.6760298609733582\n",
      "Write summary at step 5390  Loss:  0.700164794921875\n",
      "Write summary at step 5400  Loss:  0.7133440375328064\n",
      "Write summary at step 5410  Loss:  0.6772860288619995\n",
      "Write summary at step 5420  Loss:  0.7104191780090332\n",
      "Write summary at step 5430  Loss:  0.6496684551239014\n",
      "Write summary at step 5440  Loss:  0.6773607730865479\n",
      "Write summary at step 5450  Loss:  0.723450779914856\n",
      "Write summary at step 5460  Loss:  0.7083395719528198\n",
      "Write summary at step 5470  Loss:  0.6817314624786377\n",
      "Write summary at step 5480  Loss:  0.707849383354187\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.47619047619047616 Acurracy Control:  0.43169398907103823 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5387636612021858\n",
      "Loss normal: 0.6987175515719822 Loss Control: 0.7060477626128275 Loss Patient: 0.6707711281875769 Loss balanced:  0.6884094454002022 Loss1+loss2: 0.6884094454002022\n",
      "Write summary at step 5490  Loss:  0.6811693906784058\n",
      "Write summary at step 5500  Loss:  0.7045481204986572\n",
      "Saved checkpoint to: result/41/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7760682162784395 Loss Control: 0.8312207668856845 Loss Patient: 0.5657990723848343 Loss balanced:  0.6985099196352593 Loss1+loss2: 0.6985099196352593\n",
      "Write summary at step 5510  Loss:  0.7031786441802979\n",
      "Write summary at step 5520  Loss:  0.7099429965019226\n",
      "Write summary at step 5530  Loss:  0.6685969829559326\n",
      "Write summary at step 5540  Loss:  0.6901417970657349\n",
      "Write summary at step 5550  Loss:  0.6854581236839294\n",
      "Write summary at step 5560  Loss:  0.6659165620803833\n",
      "Write summary at step 5570  Loss:  0.6311140060424805\n",
      "Write summary at step 5580  Loss:  0.6723389029502869\n",
      "Write summary at step 5590  Loss:  0.7135111689567566\n",
      "Write summary at step 5600  Loss:  0.6782891750335693\n",
      "Write summary at step 5610  Loss:  0.6706701517105103\n",
      "Write summary at step 5620  Loss:  0.6985617876052856\n",
      "Write summary at step 5630  Loss:  0.7525866627693176\n",
      "Write summary at step 5640  Loss:  0.661561131477356\n",
      "Write summary at step 5650  Loss:  0.709412693977356\n",
      "Write summary at step 5660  Loss:  0.7403839826583862\n",
      "Write summary at step 5670  Loss:  0.6364607214927673\n",
      "Write summary at step 5680  Loss:  0.6617876291275024\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5670995670995671 Acurracy Control:  0.6010928961748634 Acurracy Patient:  0.4375 Acurracy Balanced 0.5192964480874317\n",
      "Loss normal: 0.6937109051328717 Loss Control: 0.6950116861061971 Loss Patient: 0.688751682639122 Loss balanced:  0.6918816843726596 Loss1+loss2: 0.6918816843726596\n",
      "Write summary at step 5690  Loss:  0.6588162183761597\n",
      "Write summary at step 5700  Loss:  0.6660832166671753\n",
      "Write summary at step 5710  Loss:  0.6966133713722229\n",
      "Write summary at step 5720  Loss:  0.7188720703125\n",
      "Write summary at step 5730  Loss:  0.6629666090011597\n",
      "Write summary at step 5740  Loss:  0.6969472765922546\n",
      "Write summary at step 5750  Loss:  0.6901003122329712\n",
      "Write summary at step 5760  Loss:  0.6958855390548706\n",
      "Write summary at step 5770  Loss:  0.6978158354759216\n",
      "Write summary at step 5780  Loss:  0.6743301153182983\n",
      "Write summary at step 5790  Loss:  0.7047991752624512\n",
      "Write summary at step 5800  Loss:  0.6822203397750854\n",
      "Write summary at step 5810  Loss:  0.6868804693222046\n",
      "Write summary at step 5820  Loss:  0.7072616815567017\n",
      "Write summary at step 5830  Loss:  0.6992693543434143\n",
      "Write summary at step 5840  Loss:  0.719312310218811\n",
      "Write summary at step 5850  Loss:  0.6985248327255249\n",
      "Write summary at step 5860  Loss:  0.6918680667877197\n",
      "Write summary at step 5870  Loss:  0.663191020488739\n",
      "Write summary at step 5880  Loss:  0.6942960023880005\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.39826839826839827 Acurracy Control:  0.29508196721311475 Acurracy Patient:  0.7916666666666666 Acurracy Balanced 0.5433743169398907\n",
      "Loss normal: 0.7354891689824852 Loss Control: 0.7633082472561487 Loss Patient: 0.6294289330641428 Loss balanced:  0.6963685901601457 Loss1+loss2: 0.6963685901601457\n",
      "Write summary at step 5890  Loss:  0.7073731422424316\n",
      "Write summary at step 5900  Loss:  0.6390050649642944\n",
      "Write summary at step 5910  Loss:  0.6939591765403748\n",
      "Write summary at step 5920  Loss:  0.7509087324142456\n",
      "Write summary at step 5930  Loss:  0.7046571969985962\n",
      "Write summary at step 5940  Loss:  0.74729323387146\n",
      "Write summary at step 5950  Loss:  0.669342041015625\n",
      "Write summary at step 5960  Loss:  0.709294319152832\n",
      "Write summary at step 5970  Loss:  0.6821537017822266\n",
      "Write summary at step 5980  Loss:  0.6462364792823792\n",
      "Write summary at step 5990  Loss:  0.6835803985595703\n",
      "Write summary at step 6000  Loss:  0.728999137878418\n",
      "Saved checkpoint to: result/41/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.736382825292034 Loss Control: 0.7633951586452338 Loss Patient: 0.6333982907235622 Loss balanced:  0.6983967246843981 Loss1+loss2: 0.6983967246843981\n",
      "Write summary at step 6010  Loss:  0.6876908540725708\n",
      "Write summary at step 6020  Loss:  0.6619859933853149\n",
      "Write summary at step 6030  Loss:  0.6978472471237183\n",
      "Write summary at step 6040  Loss:  0.6953454613685608\n",
      "Write summary at step 6050  Loss:  0.666541337966919\n",
      "Write summary at step 6060  Loss:  0.6871598362922668\n",
      "Write summary at step 6070  Loss:  0.6934515833854675\n",
      "Write summary at step 6080  Loss:  0.670589029788971\n",
      "Write summary at step 6090  Loss:  0.6864675283432007\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.696969696969697 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.1875 Acurracy Balanced 0.5090505464480874\n",
      "Loss normal: 0.6722928024989702 Loss Control: 0.6563685920720543 Loss Patient: 0.7330038224657377 Loss balanced:  0.694686207268896 Loss1+loss2: 0.694686207268896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 6100  Loss:  0.6711510419845581\n",
      "Write summary at step 6110  Loss:  0.7063751220703125\n",
      "Write summary at step 6120  Loss:  0.6917886734008789\n",
      "Write summary at step 6130  Loss:  0.6905568838119507\n",
      "Write summary at step 6140  Loss:  0.7169054746627808\n",
      "Write summary at step 6150  Loss:  0.7132089138031006\n",
      "Write summary at step 6160  Loss:  0.6414807438850403\n",
      "Write summary at step 6170  Loss:  0.6798213124275208\n",
      "Write summary at step 6180  Loss:  0.7068905830383301\n",
      "Write summary at step 6190  Loss:  0.7304317355155945\n",
      "Write summary at step 6200  Loss:  0.6999702453613281\n",
      "Write summary at step 6210  Loss:  0.6814277172088623\n",
      "Write summary at step 6220  Loss:  0.6620941162109375\n",
      "Write summary at step 6230  Loss:  0.7140651941299438\n",
      "Write summary at step 6240  Loss:  0.6321739554405212\n",
      "Write summary at step 6250  Loss:  0.7430981397628784\n",
      "Write summary at step 6260  Loss:  0.7054685354232788\n",
      "Write summary at step 6270  Loss:  0.7540849447250366\n",
      "Write summary at step 6280  Loss:  0.6950316429138184\n",
      "Write summary at step 6290  Loss:  0.6788989305496216\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5324675324675324 Acurracy Control:  0.5683060109289617 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.4820696721311475\n",
      "Loss normal: 0.7028935964489396 Loss Control: 0.7091442206518246 Loss Patient: 0.6790631276865801 Loss balanced:  0.6941036741692024 Loss1+loss2: 0.6941036741692024\n",
      "Write summary at step 6300  Loss:  0.7018221020698547\n",
      "Write summary at step 6310  Loss:  0.6650807857513428\n",
      "Write summary at step 6320  Loss:  0.6997004747390747\n",
      "Write summary at step 6330  Loss:  0.6519063711166382\n",
      "Write summary at step 6340  Loss:  0.7478389143943787\n",
      "Write summary at step 6350  Loss:  0.7119728326797485\n",
      "Write summary at step 6360  Loss:  0.6807368993759155\n",
      "Write summary at step 6370  Loss:  0.7001714110374451\n",
      "Write summary at step 6380  Loss:  0.7056552171707153\n",
      "Write summary at step 6390  Loss:  0.7164592146873474\n",
      "Write summary at step 6400  Loss:  0.6919775009155273\n",
      "Write summary at step 6410  Loss:  0.683778703212738\n",
      "Write summary at step 6420  Loss:  0.7078562378883362\n",
      "Write summary at step 6430  Loss:  0.6870140433311462\n",
      "Write summary at step 6440  Loss:  0.7216637134552002\n",
      "Write summary at step 6450  Loss:  0.7138170003890991\n",
      "Write summary at step 6460  Loss:  0.7100303769111633\n",
      "Write summary at step 6470  Loss:  0.6744989156723022\n",
      "Write summary at step 6480  Loss:  0.7228282690048218\n",
      "Write summary at step 6490  Loss:  0.6982690691947937\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.01639344262295082 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.49778005464480873\n",
      "Loss normal: 0.702237898395175 Loss Control: 0.7085274389532746 Loss Patient: 0.6782589852809906 Loss balanced:  0.6933932121171327 Loss1+loss2: 0.6933932121171327\n",
      "Write summary at step 6500  Loss:  0.6639002561569214\n",
      "Saved checkpoint to: result/41/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.01092896174863388 Acurracy Patient:  1.0 Acurracy Balanced 0.505464480874317\n",
      "Loss normal: 0.7136997005124113 Loss Control: 0.7278954350883192 Loss Patient: 0.659578467408816 Loss balanced:  0.6937369512485676 Loss1+loss2: 0.6937369512485676\n",
      "Write summary at step 6510  Loss:  0.6753562092781067\n",
      "Write summary at step 6520  Loss:  0.7421059608459473\n",
      "Write summary at step 6530  Loss:  0.6848633885383606\n",
      "Write summary at step 6540  Loss:  0.6934930086135864\n",
      "Write summary at step 6550  Loss:  0.7466075420379639\n",
      "Write summary at step 6560  Loss:  0.6664863228797913\n",
      "Write summary at step 6570  Loss:  0.7084922194480896\n",
      "Write summary at step 6580  Loss:  0.6452017426490784\n",
      "Write summary at step 6590  Loss:  0.6687009930610657\n",
      "Write summary at step 6600  Loss:  0.6411058902740479\n",
      "Write summary at step 6610  Loss:  0.7150145173072815\n",
      "Write summary at step 6620  Loss:  0.7075441479682922\n",
      "Write summary at step 6630  Loss:  0.6865932941436768\n",
      "Write summary at step 6640  Loss:  0.7131593227386475\n",
      "Write summary at step 6650  Loss:  0.7270546555519104\n",
      "Write summary at step 6660  Loss:  0.7201645374298096\n",
      "Write summary at step 6670  Loss:  0.6947163939476013\n",
      "Write summary at step 6680  Loss:  0.6895325779914856\n",
      "Write summary at step 6690  Loss:  0.7316372394561768\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21212121212121213 Acurracy Control:  0.00546448087431694 Acurracy Patient:  1.0 Acurracy Balanced 0.5027322404371585\n",
      "Loss normal: 0.7149945830369925 Loss Control: 0.7302337940273389 Loss Patient: 0.6568950737516085 Loss balanced:  0.6935644338894738 Loss1+loss2: 0.6935644338894738\n",
      "Write summary at step 6700  Loss:  0.6781848669052124\n",
      "Write summary at step 6710  Loss:  0.6978485584259033\n",
      "Write summary at step 6720  Loss:  0.6932620406150818\n",
      "Write summary at step 6730  Loss:  0.6791806221008301\n",
      "Write summary at step 6740  Loss:  0.6974049806594849\n",
      "Write summary at step 6750  Loss:  0.6899730563163757\n",
      "Write summary at step 6760  Loss:  0.6748322248458862\n",
      "Write summary at step 6770  Loss:  0.7021815180778503\n",
      "Write summary at step 6780  Loss:  0.7184659242630005\n",
      "Write summary at step 6790  Loss:  0.6799151301383972\n",
      "Write summary at step 6800  Loss:  0.7161343097686768\n",
      "Write summary at step 6810  Loss:  0.7212766408920288\n",
      "Write summary at step 6820  Loss:  0.6942024230957031\n",
      "Write summary at step 6830  Loss:  0.69684898853302\n",
      "Write summary at step 6840  Loss:  0.7169127464294434\n",
      "Write summary at step 6850  Loss:  0.7032382488250732\n",
      "Write summary at step 6860  Loss:  0.7000401020050049\n",
      "Write summary at step 6870  Loss:  0.688612699508667\n",
      "Write summary at step 6880  Loss:  0.6909291744232178\n",
      "Write summary at step 6890  Loss:  0.7205138206481934\n",
      "Write summary at step 6900  Loss:  0.7023468613624573\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5194805194805194 Acurracy Control:  0.5355191256830601 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.49692622950819676\n",
      "Loss normal: 0.6925110649236869 Loss Control: 0.6926942728256267 Loss Patient: 0.6918126332263151 Loss balanced:  0.692253453025971 Loss1+loss2: 0.692253453025971\n",
      "Write summary at step 6910  Loss:  0.7122182846069336\n",
      "Write summary at step 6920  Loss:  0.743817925453186\n",
      "Write summary at step 6930  Loss:  0.6330078840255737\n",
      "Write summary at step 6940  Loss:  0.6848393678665161\n",
      "Write summary at step 6950  Loss:  0.6587424278259277\n",
      "Write summary at step 6960  Loss:  0.6846749782562256\n",
      "Write summary at step 6970  Loss:  0.7469077110290527\n",
      "Write summary at step 6980  Loss:  0.6665016412734985\n",
      "Write summary at step 6990  Loss:  0.6953458786010742\n",
      "Write summary at step 7000  Loss:  0.7312489748001099\n",
      "Saved checkpoint to: result/41/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.08333333333333333 Acurracy Balanced 0.514344262295082\n",
      "Loss normal: 0.6575227403021479 Loss Control: 0.6316527994604059 Loss Patient: 0.7561518860359987 Loss balanced:  0.6939023427482023 Loss1+loss2: 0.6939023427482023\n",
      "Write summary at step 7010  Loss:  0.7040094137191772\n",
      "Write summary at step 7020  Loss:  0.6678034067153931\n",
      "Write summary at step 7030  Loss:  0.7195447683334351\n",
      "Write summary at step 7040  Loss:  0.6696310639381409\n",
      "Write summary at step 7050  Loss:  0.7065425515174866\n",
      "Write summary at step 7060  Loss:  0.7170225381851196\n",
      "Write summary at step 7070  Loss:  0.6928274631500244\n",
      "Write summary at step 7080  Loss:  0.6706557273864746\n",
      "Write summary at step 7090  Loss:  0.6638317108154297\n",
      "Write summary at step 7100  Loss:  0.6874279975891113\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7348819674351514 Loss Control: 0.7631427873679197 Loss Patient: 0.6271376758813858 Loss balanced:  0.6951402316246528 Loss1+loss2: 0.6951402316246528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 7110  Loss:  0.6852098703384399\n",
      "Write summary at step 7120  Loss:  0.7115066051483154\n",
      "Write summary at step 7130  Loss:  0.6970518827438354\n",
      "Write summary at step 7140  Loss:  0.7017982006072998\n",
      "Write summary at step 7150  Loss:  0.677675187587738\n",
      "Write summary at step 7160  Loss:  0.6965775489807129\n",
      "Write summary at step 7170  Loss:  0.6853777170181274\n",
      "Write summary at step 7180  Loss:  0.7171773314476013\n",
      "Write summary at step 7190  Loss:  0.700218677520752\n",
      "Write summary at step 7200  Loss:  0.7252461910247803\n",
      "Write summary at step 7210  Loss:  0.6874337196350098\n",
      "Write summary at step 7220  Loss:  0.7422976493835449\n",
      "Write summary at step 7230  Loss:  0.6786653995513916\n",
      "Write summary at step 7240  Loss:  0.7124570608139038\n",
      "Write summary at step 7250  Loss:  0.7041122913360596\n",
      "Write summary at step 7260  Loss:  0.6817828416824341\n",
      "Write summary at step 7270  Loss:  0.6776468753814697\n",
      "Write summary at step 7280  Loss:  0.6925705671310425\n",
      "Write summary at step 7290  Loss:  0.6718361973762512\n",
      "Write summary at step 7300  Loss:  0.668319046497345\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.37662337662337664 Acurracy Control:  0.2677595628415301 Acurracy Patient:  0.7916666666666666 Acurracy Balanced 0.5297131147540983\n",
      "Loss normal: 0.726188248370117 Loss Control: 0.7503786262918691 Loss Patient: 0.6339624499281248 Loss balanced:  0.692170538109997 Loss1+loss2: 0.692170538109997\n",
      "Write summary at step 7310  Loss:  0.6839472055435181\n",
      "Write summary at step 7320  Loss:  0.7103396654129028\n",
      "Write summary at step 7330  Loss:  0.7001528739929199\n",
      "Write summary at step 7340  Loss:  0.7007410526275635\n",
      "Write summary at step 7350  Loss:  0.704474925994873\n",
      "Write summary at step 7360  Loss:  0.7062932848930359\n",
      "Write summary at step 7370  Loss:  0.658571720123291\n",
      "Write summary at step 7380  Loss:  0.7249146103858948\n",
      "Write summary at step 7390  Loss:  0.6680495142936707\n",
      "Write summary at step 7400  Loss:  0.7314001321792603\n",
      "Write summary at step 7410  Loss:  0.7029345035552979\n",
      "Write summary at step 7420  Loss:  0.6966184377670288\n",
      "Write summary at step 7430  Loss:  0.7095553874969482\n",
      "Write summary at step 7440  Loss:  0.6135066747665405\n",
      "Write summary at step 7450  Loss:  0.6502411365509033\n",
      "Write summary at step 7460  Loss:  0.7079814672470093\n",
      "Write summary at step 7470  Loss:  0.6675512790679932\n",
      "Write summary at step 7480  Loss:  0.7221847772598267\n",
      "Write summary at step 7490  Loss:  0.6364591121673584\n",
      "Write summary at step 7500  Loss:  0.6643431186676025\n",
      "Saved checkpoint to: result/41/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6375625933403577 Loss Control: 0.5945878374120577 Loss Patient: 0.8014038490752379 Loss balanced:  0.6979958432436477 Loss1+loss2: 0.6979958432436477\n",
      "Write summary at step 7510  Loss:  0.7676492929458618\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.0 Acurracy Balanced 0.4972677595628415\n",
      "Loss normal: 0.6487089787726794 Loss Control: 0.6141430973355236 Loss Patient: 0.7804913856089115 Loss balanced:  0.6973172414722175 Loss1+loss2: 0.6973172414722175\n",
      "Write summary at step 7520  Loss:  0.7183337211608887\n",
      "Write summary at step 7530  Loss:  0.6913516521453857\n",
      "Write summary at step 7540  Loss:  0.698583722114563\n",
      "Write summary at step 7550  Loss:  0.7196437120437622\n",
      "Write summary at step 7560  Loss:  0.6970039010047913\n",
      "Write summary at step 7570  Loss:  0.707567572593689\n",
      "Write summary at step 7580  Loss:  0.644700288772583\n",
      "Write summary at step 7590  Loss:  0.6840088367462158\n",
      "Write summary at step 7600  Loss:  0.7068878412246704\n",
      "Write summary at step 7610  Loss:  0.6961121559143066\n",
      "Write summary at step 7620  Loss:  0.7026337385177612\n",
      "Write summary at step 7630  Loss:  0.680732250213623\n",
      "Write summary at step 7640  Loss:  0.6838629245758057\n",
      "Write summary at step 7650  Loss:  0.7009326815605164\n",
      "Write summary at step 7660  Loss:  0.6704623699188232\n",
      "Write summary at step 7670  Loss:  0.6998768448829651\n",
      "Write summary at step 7680  Loss:  0.700506865978241\n",
      "Write summary at step 7690  Loss:  0.715179443359375\n",
      "Write summary at step 7700  Loss:  0.6839861869812012\n",
      "Write summary at step 7710  Loss:  0.6836838126182556\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.01639344262295082 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.49778005464480873\n",
      "Loss normal: 0.7270981960998469 Loss Control: 0.7504701581809039 Loss Patient: 0.6379925906658173 Loss balanced:  0.6942313744233606 Loss1+loss2: 0.6942313744233606\n",
      "Write summary at step 7720  Loss:  0.6679815649986267\n",
      "Write summary at step 7730  Loss:  0.7164658308029175\n",
      "Write summary at step 7740  Loss:  0.7142360806465149\n",
      "Write summary at step 7750  Loss:  0.6983822584152222\n",
      "Write summary at step 7760  Loss:  0.6871020793914795\n",
      "Write summary at step 7770  Loss:  0.693412721157074\n",
      "Write summary at step 7780  Loss:  0.7011156678199768\n",
      "Write summary at step 7790  Loss:  0.7266231775283813\n",
      "Write summary at step 7800  Loss:  0.7083470821380615\n",
      "Write summary at step 7810  Loss:  0.665245771408081\n",
      "Write summary at step 7820  Loss:  0.6618567705154419\n",
      "Write summary at step 7830  Loss:  0.6599358320236206\n",
      "Write summary at step 7840  Loss:  0.7108562588691711\n",
      "Write summary at step 7850  Loss:  0.679038405418396\n",
      "Write summary at step 7860  Loss:  0.6996054649353027\n",
      "Write summary at step 7870  Loss:  0.6646575331687927\n",
      "Write summary at step 7880  Loss:  0.7585768103599548\n",
      "Write summary at step 7890  Loss:  0.6825852394104004\n",
      "Write summary at step 7900  Loss:  0.7382063865661621\n",
      "Write summary at step 7910  Loss:  0.6885115504264832\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.26406926406926406 Acurracy Control:  0.09289617486338798 Acurracy Patient:  0.9166666666666666 Acurracy Balanced 0.5047814207650273\n",
      "Loss normal: 0.7846661408742269 Loss Control: 0.8402531329399902 Loss Patient: 0.5727406727770964 Loss balanced:  0.7064969028585433 Loss1+loss2: 0.7064969028585433\n",
      "Write summary at step 7920  Loss:  0.6398655772209167\n",
      "Write summary at step 7930  Loss:  0.7086644768714905\n",
      "Write summary at step 7940  Loss:  0.654857873916626\n",
      "Write summary at step 7950  Loss:  0.7460397481918335\n",
      "Write summary at step 7960  Loss:  0.7599896192550659\n",
      "Write summary at step 7970  Loss:  0.6758276224136353\n",
      "Write summary at step 7980  Loss:  0.7096960544586182\n",
      "Write summary at step 7990  Loss:  0.6822359561920166\n",
      "Write summary at step 8000  Loss:  0.6749953031539917\n",
      "Saved checkpoint to: result/41/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.42424242424242425 Acurracy Control:  0.40437158469945356 Acurracy Patient:  0.5 Acurracy Balanced 0.4521857923497268\n",
      "Loss normal: 0.7123390242650911 Loss Control: 0.7233716317864715 Loss Patient: 0.6702772205074629 Loss balanced:  0.6968244261469672 Loss1+loss2: 0.6968244261469672\n",
      "Write summary at step 8010  Loss:  0.6990441083908081\n",
      "Write summary at step 8020  Loss:  0.685904860496521\n",
      "Write summary at step 8030  Loss:  0.7026286125183105\n",
      "Write summary at step 8040  Loss:  0.7811622619628906\n",
      "Write summary at step 8050  Loss:  0.6757211089134216\n",
      "Write summary at step 8060  Loss:  0.7085083723068237\n",
      "Write summary at step 8070  Loss:  0.7138789892196655\n",
      "Write summary at step 8080  Loss:  0.6919873952865601\n",
      "Write summary at step 8090  Loss:  0.7150064706802368\n",
      "Write summary at step 8100  Loss:  0.7017101049423218\n",
      "Write summary at step 8110  Loss:  0.7029480934143066\n",
      "Write summary at step 8120  Loss:  0.6865332126617432\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.42424242424242425 Acurracy Control:  0.37158469945355194 Acurracy Patient:  0.625 Acurracy Balanced 0.49829234972677594\n",
      "Loss normal: 0.7129498361509083 Loss Control: 0.7260262676275493 Loss Patient: 0.663095892717441 Loss balanced:  0.6945610801724951 Loss1+loss2: 0.6945610801724951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 8130  Loss:  0.726252555847168\n",
      "Write summary at step 8140  Loss:  0.6938043832778931\n",
      "Write summary at step 8150  Loss:  0.7214969396591187\n",
      "Write summary at step 8160  Loss:  0.6537063717842102\n",
      "Write summary at step 8170  Loss:  0.6965631246566772\n",
      "Write summary at step 8180  Loss:  0.7178434133529663\n",
      "Write summary at step 8190  Loss:  0.6732597351074219\n",
      "Write summary at step 8200  Loss:  0.6723636984825134\n",
      "Write summary at step 8210  Loss:  0.6764485239982605\n",
      "Write summary at step 8220  Loss:  0.700265645980835\n",
      "Write summary at step 8230  Loss:  0.7107996940612793\n",
      "Write summary at step 8240  Loss:  0.7125041484832764\n",
      "Write summary at step 8250  Loss:  0.6722979545593262\n",
      "Write summary at step 8260  Loss:  0.7226231098175049\n",
      "Write summary at step 8270  Loss:  0.7230149507522583\n",
      "Write summary at step 8280  Loss:  0.7079406976699829\n",
      "Write summary at step 8290  Loss:  0.6716991662979126\n",
      "Write summary at step 8300  Loss:  0.704519510269165\n",
      "Write summary at step 8310  Loss:  0.6841856241226196\n",
      "Write summary at step 8320  Loss:  0.6919651627540588\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4199134199134199 Acurracy Control:  0.37158469945355194 Acurracy Patient:  0.6041666666666666 Acurracy Balanced 0.4878756830601093\n",
      "Loss normal: 0.725082094535167 Loss Control: 0.7441029398819137 Loss Patient: 0.6525651787718137 Loss balanced:  0.6983340593268637 Loss1+loss2: 0.6983340593268637\n",
      "Write summary at step 8330  Loss:  0.6982667446136475\n",
      "Write summary at step 8340  Loss:  0.6696592569351196\n",
      "Write summary at step 8350  Loss:  0.691670298576355\n",
      "Write summary at step 8360  Loss:  0.6884133815765381\n",
      "Write summary at step 8370  Loss:  0.6980771422386169\n",
      "Write summary at step 8380  Loss:  0.7183734178543091\n",
      "Write summary at step 8390  Loss:  0.7209721803665161\n",
      "Write summary at step 8400  Loss:  0.6992539167404175\n",
      "Write summary at step 8410  Loss:  0.6905518770217896\n",
      "Write summary at step 8420  Loss:  0.6903172135353088\n",
      "Write summary at step 8430  Loss:  0.696073055267334\n",
      "Write summary at step 8440  Loss:  0.704383134841919\n",
      "Write summary at step 8450  Loss:  0.6760208010673523\n",
      "Write summary at step 8460  Loss:  0.6780316829681396\n",
      "Write summary at step 8470  Loss:  0.7197277545928955\n",
      "Write summary at step 8480  Loss:  0.6862102746963501\n",
      "Write summary at step 8490  Loss:  0.685109555721283\n",
      "Write summary at step 8500  Loss:  0.6897050142288208\n",
      "Saved checkpoint to: result/41/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.3125 Acurracy Balanced 0.5141734972677596\n",
      "Loss normal: 0.6825564439162547 Loss Control: 0.6746225676249936 Loss Patient: 0.7128042752544085 Loss balanced:  0.693713421439701 Loss1+loss2: 0.693713421439701\n",
      "Write summary at step 8510  Loss:  0.6867203712463379\n",
      "Write summary at step 8520  Loss:  0.6763668656349182\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5800865800865801 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.3125 Acurracy Balanced 0.4813866120218579\n",
      "Loss normal: 0.6866110065282681 Loss Control: 0.6812718894963707 Loss Patient: 0.7069663753112158 Loss balanced:  0.6941191324037932 Loss1+loss2: 0.6941191324037932\n",
      "Write summary at step 8530  Loss:  0.7107536792755127\n",
      "Write summary at step 8540  Loss:  0.6558749675750732\n",
      "Write summary at step 8550  Loss:  0.7212386131286621\n",
      "Write summary at step 8560  Loss:  0.6785719394683838\n",
      "Write summary at step 8570  Loss:  0.6436705589294434\n",
      "Write summary at step 8580  Loss:  0.6412709951400757\n",
      "Write summary at step 8590  Loss:  0.7471216320991516\n",
      "Write summary at step 8600  Loss:  0.6997350454330444\n",
      "Write summary at step 8610  Loss:  0.7111605405807495\n",
      "Write summary at step 8620  Loss:  0.6633007526397705\n",
      "Write summary at step 8630  Loss:  0.6900478601455688\n",
      "Write summary at step 8640  Loss:  0.6880080699920654\n",
      "Write summary at step 8650  Loss:  0.692591667175293\n",
      "Write summary at step 8660  Loss:  0.7586593627929688\n",
      "Write summary at step 8670  Loss:  0.6692894697189331\n",
      "Write summary at step 8680  Loss:  0.6233869194984436\n",
      "Write summary at step 8690  Loss:  0.6706529855728149\n",
      "Write summary at step 8700  Loss:  0.6763579845428467\n",
      "Write summary at step 8710  Loss:  0.680821418762207\n",
      "Write summary at step 8720  Loss:  0.6292732954025269\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3246753246753247 Acurracy Control:  0.21311475409836064 Acurracy Patient:  0.75 Acurracy Balanced 0.48155737704918034\n",
      "Loss normal: 0.7441053635630257 Loss Control: 0.773438586237652 Loss Patient: 0.6322724496324857 Loss balanced:  0.7028555179350688 Loss1+loss2: 0.7028555179350688\n",
      "Write summary at step 8730  Loss:  0.6516436338424683\n",
      "Write summary at step 8740  Loss:  0.6986876726150513\n",
      "Write summary at step 8750  Loss:  0.653613269329071\n",
      "Write summary at step 8760  Loss:  0.6790993213653564\n",
      "Write summary at step 8770  Loss:  0.705269992351532\n",
      "Write summary at step 8780  Loss:  0.7078092098236084\n",
      "Write summary at step 8790  Loss:  0.7056083679199219\n",
      "Write summary at step 8800  Loss:  0.7297825813293457\n",
      "Write summary at step 8810  Loss:  0.6798383593559265\n",
      "Write summary at step 8820  Loss:  0.7011232376098633\n",
      "Write summary at step 8830  Loss:  0.9201818108558655\n",
      "Write summary at step 8840  Loss:  0.6984872221946716\n",
      "Write summary at step 8850  Loss:  0.6947634220123291\n",
      "Write summary at step 8860  Loss:  0.7203781604766846\n",
      "Write summary at step 8870  Loss:  0.6856111288070679\n",
      "Write summary at step 8880  Loss:  0.6568339467048645\n",
      "Write summary at step 8890  Loss:  0.7131229043006897\n",
      "Write summary at step 8900  Loss:  0.738192617893219\n",
      "Write summary at step 8910  Loss:  0.6850944757461548\n",
      "Write summary at step 8920  Loss:  0.702582597732544\n",
      "Write summary at step 8930  Loss:  0.6999634504318237\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7056277056277056 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.25 Acurracy Balanced 0.537568306010929\n",
      "Loss normal: 0.6664527910096305 Loss Control: 0.6498290192885477 Loss Patient: 0.7298308896521727 Loss balanced:  0.6898299544703602 Loss1+loss2: 0.6898299544703602\n",
      "Write summary at step 8940  Loss:  0.7210290431976318\n",
      "Write summary at step 8950  Loss:  0.6796551942825317\n",
      "Write summary at step 8960  Loss:  0.6896467208862305\n",
      "Write summary at step 8970  Loss:  0.6914747953414917\n",
      "Write summary at step 8980  Loss:  0.6628353595733643\n",
      "Write summary at step 8990  Loss:  0.6899208426475525\n",
      "Write summary at step 9000  Loss:  0.6841846704483032\n",
      "Saved checkpoint to: result/41/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.08333333333333333 Acurracy Balanced 0.5034153005464481\n",
      "Loss normal: 0.6727375308156529 Loss Control: 0.6589155933244633 Loss Patient: 0.7254336439073086 Loss balanced:  0.6921746186158859 Loss1+loss2: 0.6921746186158859\n",
      "Write summary at step 9010  Loss:  0.6886558532714844\n",
      "Write summary at step 9020  Loss:  0.696560800075531\n",
      "Write summary at step 9030  Loss:  0.6915323734283447\n",
      "Write summary at step 9040  Loss:  0.6951198577880859\n",
      "Write summary at step 9050  Loss:  0.7243805527687073\n",
      "Write summary at step 9060  Loss:  0.6959226131439209\n",
      "Write summary at step 9070  Loss:  0.6872439980506897\n",
      "Write summary at step 9080  Loss:  0.7201864719390869\n",
      "Write summary at step 9090  Loss:  0.6775677800178528\n",
      "Write summary at step 9100  Loss:  0.6941666603088379\n",
      "Write summary at step 9110  Loss:  0.6910139322280884\n",
      "Write summary at step 9120  Loss:  0.7054623961448669\n",
      "Write summary at step 9130  Loss:  0.7613097429275513\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  1.0 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5104166666666666\n",
      "Loss normal: 0.6797309311437401 Loss Control: 0.6704544418496512 Loss Patient: 0.7150975714127222 Loss balanced:  0.6927760066311868 Loss1+loss2: 0.6927760066311868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 9140  Loss:  0.6717236042022705\n",
      "Write summary at step 9150  Loss:  0.7347031831741333\n",
      "Write summary at step 9160  Loss:  0.6795011758804321\n",
      "Write summary at step 9170  Loss:  0.7224573493003845\n",
      "Write summary at step 9180  Loss:  0.6744906902313232\n",
      "Write summary at step 9190  Loss:  0.7162179350852966\n",
      "Write summary at step 9200  Loss:  0.6913272142410278\n",
      "Write summary at step 9210  Loss:  0.7012957334518433\n",
      "Write summary at step 9220  Loss:  0.7673692107200623\n",
      "Write summary at step 9230  Loss:  0.7355960011482239\n",
      "Write summary at step 9240  Loss:  0.6585401296615601\n",
      "Write summary at step 9250  Loss:  0.6800276041030884\n",
      "Write summary at step 9260  Loss:  0.6971701383590698\n",
      "Write summary at step 9270  Loss:  0.6665672659873962\n",
      "Write summary at step 9280  Loss:  0.7356648445129395\n",
      "Write summary at step 9290  Loss:  0.6852799654006958\n",
      "Write summary at step 9300  Loss:  0.689781129360199\n",
      "Write summary at step 9310  Loss:  0.67893385887146\n",
      "Write summary at step 9320  Loss:  0.7355028390884399\n",
      "Write summary at step 9330  Loss:  0.6801304817199707\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6843089752899104 Loss Control: 0.677940489164467 Loss Patient: 0.7085887317856153 Loss balanced:  0.6932646104750412 Loss1+loss2: 0.6932646104750412\n",
      "Write summary at step 9340  Loss:  0.7228022217750549\n",
      "Write summary at step 9350  Loss:  0.6716232299804688\n",
      "Write summary at step 9360  Loss:  0.7318366765975952\n",
      "Write summary at step 9370  Loss:  0.68559730052948\n",
      "Write summary at step 9380  Loss:  0.6781778335571289\n",
      "Write summary at step 9390  Loss:  0.7082942724227905\n",
      "Write summary at step 9400  Loss:  0.7105914950370789\n",
      "Write summary at step 9410  Loss:  0.6970826387405396\n",
      "Write summary at step 9420  Loss:  0.639693021774292\n",
      "Write summary at step 9430  Loss:  0.6972399950027466\n",
      "Write summary at step 9440  Loss:  0.6800495386123657\n",
      "Write summary at step 9450  Loss:  0.6956152319908142\n",
      "Write summary at step 9460  Loss:  0.6486927270889282\n",
      "Write summary at step 9470  Loss:  0.6333301067352295\n",
      "Write summary at step 9480  Loss:  0.669188380241394\n",
      "Write summary at step 9490  Loss:  0.6905496120452881\n",
      "Write summary at step 9500  Loss:  0.7121178507804871\n",
      "Saved checkpoint to: result/41/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6816040318765682 Loss Control: 0.6732519852007673 Loss Patient: 0.7134462719162306 Loss balanced:  0.693349128558499 Loss1+loss2: 0.693349128558499\n",
      "Write summary at step 9510  Loss:  0.7020527720451355\n",
      "Write summary at step 9520  Loss:  0.7169276475906372\n",
      "Write summary at step 9530  Loss:  0.6863939166069031\n",
      "Write summary at step 9540  Loss:  0.7028506398200989\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.0 Acurracy Balanced 0.49453551912568305\n",
      "Loss normal: 0.6814149832312679 Loss Control: 0.6727792047412018 Loss Patient: 0.7143388750652472 Loss balanced:  0.6935590399032245 Loss1+loss2: 0.6935590399032245\n",
      "Write summary at step 9550  Loss:  0.6875623464584351\n",
      "Write summary at step 9560  Loss:  0.6824091672897339\n",
      "Write summary at step 9570  Loss:  0.688457727432251\n",
      "Write summary at step 9580  Loss:  0.6837864518165588\n",
      "Write summary at step 9590  Loss:  0.7186223268508911\n",
      "Write summary at step 9600  Loss:  0.7035322189331055\n",
      "Write summary at step 9610  Loss:  0.6798336505889893\n",
      "Write summary at step 9620  Loss:  0.7154295444488525\n",
      "Write summary at step 9630  Loss:  0.6803879737854004\n",
      "Write summary at step 9640  Loss:  0.6890442371368408\n",
      "Write summary at step 9650  Loss:  0.6998199224472046\n",
      "Write summary at step 9660  Loss:  0.7511153817176819\n",
      "Write summary at step 9670  Loss:  0.7264298796653748\n",
      "Write summary at step 9680  Loss:  0.6828657388687134\n",
      "Write summary at step 9690  Loss:  0.6959595680236816\n",
      "Write summary at step 9700  Loss:  0.6988499164581299\n",
      "Write summary at step 9710  Loss:  0.7344494462013245\n",
      "Write summary at step 9720  Loss:  0.6984847784042358\n",
      "Write summary at step 9730  Loss:  0.6728061437606812\n",
      "Write summary at step 9740  Loss:  0.6937929391860962\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6933423850959514 Loss Control: 0.6934811466378592 Loss Patient: 0.6928133306403955 Loss balanced:  0.6931472386391273 Loss1+loss2: 0.6931472386391273\n",
      "Write summary at step 9750  Loss:  0.671008288860321\n",
      "Write summary at step 9760  Loss:  0.6984368562698364\n",
      "Write summary at step 9770  Loss:  0.6886723637580872\n",
      "Write summary at step 9780  Loss:  0.6784223318099976\n",
      "Write summary at step 9790  Loss:  0.6975848078727722\n",
      "Write summary at step 9800  Loss:  0.7172240614891052\n",
      "Write summary at step 9810  Loss:  0.6942298412322998\n",
      "Write summary at step 9820  Loss:  0.7170675992965698\n",
      "Write summary at step 9830  Loss:  0.6806225776672363\n",
      "Write summary at step 9840  Loss:  0.6963437795639038\n",
      "Write summary at step 9850  Loss:  0.7205939888954163\n",
      "Write summary at step 9860  Loss:  0.6728653907775879\n",
      "Write summary at step 9870  Loss:  0.6961590051651001\n",
      "Write summary at step 9880  Loss:  0.7056435346603394\n",
      "Write summary at step 9890  Loss:  0.6757022142410278\n",
      "Write summary at step 9900  Loss:  0.6793590784072876\n",
      "Write summary at step 9910  Loss:  0.7105176448822021\n",
      "Write summary at step 9920  Loss:  0.734567403793335\n",
      "Write summary at step 9930  Loss:  0.6763061881065369\n",
      "Write summary at step 9940  Loss:  0.7598564028739929\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.73727581769357 Loss Control: 0.7668563140546037 Loss Patient: 0.6245001020530859 Loss balanced:  0.6956782080538448 Loss1+loss2: 0.6956782080538448\n",
      "Write summary at step 9950  Loss:  0.6631150245666504\n",
      "Write summary at step 9960  Loss:  0.6583216190338135\n",
      "Write summary at step 9970  Loss:  0.7550007104873657\n",
      "Write summary at step 9980  Loss:  0.6914260983467102\n",
      "Write summary at step 9990  Loss:  0.7121859788894653\n",
      "Write summary at step 10000  Loss:  0.6910994648933411\n",
      "Saved checkpoint to: result/41/panns/checkpoint_10000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7413078523301458 Loss Control: 0.7734326446642641 Loss Patient: 0.6188320455451807 Loss balanced:  0.6961323451047223 Loss1+loss2: 0.6961323451047223\n",
      "Write summary at step 10010  Loss:  0.6869534254074097\n",
      "Write summary at step 10020  Loss:  0.6950441002845764\n",
      "Write summary at step 10030  Loss:  0.6914398670196533\n",
      "Write summary at step 10040  Loss:  0.7256722450256348\n",
      "Write summary at step 10050  Loss:  0.6851884722709656\n",
      "Write summary at step 10060  Loss:  0.6928417682647705\n",
      "Write summary at step 10070  Loss:  0.6783207654953003\n",
      "Write summary at step 10080  Loss:  0.7027422189712524\n",
      "Write summary at step 10090  Loss:  0.7022400498390198\n",
      "Write summary at step 10100  Loss:  0.6696707010269165\n",
      "Write summary at step 10110  Loss:  0.6947171688079834\n",
      "Write summary at step 10120  Loss:  0.7105675339698792\n",
      "Write summary at step 10130  Loss:  0.7023181319236755\n",
      "Write summary at step 10140  Loss:  0.6616970896720886\n",
      "Write summary at step 10150  Loss:  0.6930230855941772\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6941000899195156 Loss Control: 0.6947767734527588 Loss Patient: 0.6915202140808105 Loss balanced:  0.6931484937667847 Loss1+loss2: 0.6931484937667847\n",
      "Write summary at step 10160  Loss:  0.7352161407470703\n",
      "Write summary at step 10170  Loss:  0.6718106865882874\n",
      "Write summary at step 10180  Loss:  0.698501467704773\n",
      "Write summary at step 10190  Loss:  0.7143024206161499\n",
      "Write summary at step 10200  Loss:  0.7302199602127075\n",
      "Write summary at step 10210  Loss:  0.695145845413208\n",
      "Write summary at step 10220  Loss:  0.6716353893280029\n",
      "Write summary at step 10230  Loss:  0.6864026188850403\n",
      "Write summary at step 10240  Loss:  0.6860671043395996\n",
      "Write summary at step 10250  Loss:  0.6990066766738892\n",
      "Write summary at step 10260  Loss:  0.6748647093772888\n",
      "Write summary at step 10270  Loss:  0.6898308992385864\n",
      "Write summary at step 10280  Loss:  0.670620858669281\n",
      "Write summary at step 10290  Loss:  0.6659901738166809\n",
      "Write summary at step 10300  Loss:  0.6911747455596924\n",
      "Write summary at step 10310  Loss:  0.7181483507156372\n",
      "Write summary at step 10320  Loss:  0.6708954572677612\n",
      "Write summary at step 10330  Loss:  0.7183384895324707\n",
      "Write summary at step 10340  Loss:  0.6116881370544434\n",
      "Write summary at step 10350  Loss:  0.711643397808075\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6879696002254239 Loss Control: 0.6842594879572509 Loss Patient: 0.7021145820617676 Loss balanced:  0.6931870350095093 Loss1+loss2: 0.6931870350095093\n",
      "Write summary at step 10360  Loss:  0.6930298805236816\n",
      "Write summary at step 10370  Loss:  0.690854549407959\n",
      "Write summary at step 10380  Loss:  0.674064576625824\n",
      "Write summary at step 10390  Loss:  0.6867375373840332\n",
      "Write summary at step 10400  Loss:  0.7131381034851074\n",
      "Write summary at step 10410  Loss:  0.662613034248352\n",
      "Write summary at step 10420  Loss:  0.7195764780044556\n",
      "Write summary at step 10430  Loss:  0.686646580696106\n",
      "Write summary at step 10440  Loss:  0.7177508473396301\n",
      "Write summary at step 10450  Loss:  0.7302201986312866\n",
      "Write summary at step 10460  Loss:  0.7071860432624817\n",
      "Write summary at step 10470  Loss:  0.7005712985992432\n",
      "Write summary at step 10480  Loss:  0.6876668930053711\n",
      "Write summary at step 10490  Loss:  0.6927266716957092\n",
      "Write summary at step 10500  Loss:  0.7073596715927124\n",
      "Saved checkpoint to: result/41/panns/checkpoint_10500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6893388592835629 Loss Control: 0.6866154068154715 Loss Patient: 0.6997218790153662 Loss balanced:  0.6931686429154189 Loss1+loss2: 0.6931686429154189\n",
      "Write summary at step 10510  Loss:  0.6778821349143982\n",
      "Write summary at step 10520  Loss:  0.7405173778533936\n",
      "Write summary at step 10530  Loss:  0.696597695350647\n",
      "Write summary at step 10540  Loss:  0.6928709745407104\n",
      "Write summary at step 10550  Loss:  0.6790260076522827\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7275044605845497 Loss Control: 0.7508179538888358 Loss Patient: 0.6386217412849268 Loss balanced:  0.6947198475868812 Loss1+loss2: 0.6947198475868812\n",
      "Write summary at step 10560  Loss:  0.6595056056976318\n",
      "Write summary at step 10570  Loss:  0.7068711519241333\n",
      "Write summary at step 10580  Loss:  0.7068874835968018\n",
      "Write summary at step 10590  Loss:  0.7541844844818115\n",
      "Write summary at step 10600  Loss:  0.7112655639648438\n",
      "Write summary at step 10610  Loss:  0.7086769938468933\n",
      "Write summary at step 10620  Loss:  0.7049369215965271\n",
      "Write summary at step 10630  Loss:  0.6970160603523254\n",
      "Write summary at step 10640  Loss:  0.686403751373291\n",
      "Write summary at step 10650  Loss:  0.6938725113868713\n",
      "Write summary at step 10660  Loss:  0.7008395791053772\n",
      "Write summary at step 10670  Loss:  0.700543224811554\n",
      "Write summary at step 10680  Loss:  0.7149437665939331\n",
      "Write summary at step 10690  Loss:  0.6909551620483398\n",
      "Write summary at step 10700  Loss:  0.7238302230834961\n",
      "Write summary at step 10710  Loss:  0.702716052532196\n",
      "Write summary at step 10720  Loss:  0.7026667594909668\n",
      "Write summary at step 10730  Loss:  0.6925928592681885\n",
      "Write summary at step 10740  Loss:  0.6905930042266846\n",
      "Write summary at step 10750  Loss:  0.7028422355651855\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7097087817274647 Loss Control: 0.7212093465966605 Loss Patient: 0.6658629924058914 Loss balanced:  0.693536169501276 Loss1+loss2: 0.693536169501276\n",
      "Write summary at step 10760  Loss:  0.718274712562561\n",
      "Write summary at step 10770  Loss:  0.6998840570449829\n",
      "Write summary at step 10780  Loss:  0.7092090845108032\n",
      "Write summary at step 10790  Loss:  0.6771163940429688\n",
      "Write summary at step 10800  Loss:  0.685361921787262\n",
      "Write summary at step 10810  Loss:  0.6900220513343811\n",
      "Write summary at step 10820  Loss:  0.6823151111602783\n",
      "Write summary at step 10830  Loss:  0.6970029473304749\n",
      "Write summary at step 10840  Loss:  0.7145202159881592\n",
      "Write summary at step 10850  Loss:  0.6949913501739502\n",
      "Write summary at step 10860  Loss:  0.6968883275985718\n",
      "Write summary at step 10870  Loss:  0.7026457190513611\n",
      "Write summary at step 10880  Loss:  0.6922659277915955\n",
      "Write summary at step 10890  Loss:  0.7049850821495056\n",
      "Write summary at step 10900  Loss:  0.7009094953536987\n",
      "Write summary at step 10910  Loss:  0.6933730840682983\n",
      "Write summary at step 10920  Loss:  0.6802284717559814\n",
      "Write summary at step 10930  Loss:  0.6855473518371582\n",
      "Write summary at step 10940  Loss:  0.7114105820655823\n",
      "Write summary at step 10950  Loss:  0.6713637113571167\n",
      "Write summary at step 10960  Loss:  0.6739495992660522\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6759600727073042 Loss Control: 0.6634141206741333 Loss Patient: 0.7237914676467577 Loss balanced:  0.6936027941604455 Loss1+loss2: 0.6936027941604455\n",
      "Write summary at step 10970  Loss:  0.700641393661499\n",
      "Write summary at step 10980  Loss:  0.7113221287727356\n",
      "Write summary at step 10990  Loss:  0.6975234150886536\n",
      "Write summary at step 11000  Loss:  0.7376206517219543\n",
      "Saved checkpoint to: result/41/panns/checkpoint_11000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6721862564871321 Loss Control: 0.6567929983139038 Loss Patient: 0.730872935305039 Loss balanced:  0.6938329668094714 Loss1+loss2: 0.6938329668094714\n",
      "Write summary at step 11010  Loss:  0.704124391078949\n",
      "Write summary at step 11020  Loss:  0.6917421221733093\n",
      "Write summary at step 11030  Loss:  0.6691198348999023\n",
      "Write summary at step 11040  Loss:  0.735855758190155\n",
      "Write summary at step 11050  Loss:  0.6620371341705322\n",
      "Write summary at step 11060  Loss:  0.6748953461647034\n",
      "Write summary at step 11070  Loss:  0.6819402575492859\n",
      "Write summary at step 11080  Loss:  0.6760251522064209\n",
      "Write summary at step 11090  Loss:  0.7001571655273438\n",
      "Write summary at step 11100  Loss:  0.6683784127235413\n",
      "Write summary at step 11110  Loss:  0.7011913657188416\n",
      "Write summary at step 11120  Loss:  0.6548442840576172\n",
      "Write summary at step 11130  Loss:  0.7134310007095337\n",
      "Write summary at step 11140  Loss:  0.6766818761825562\n",
      "Write summary at step 11150  Loss:  0.6785035133361816\n",
      "Write summary at step 11160  Loss:  0.7111843824386597\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7072360755561234 Loss Control: 0.7170563476984618 Loss Patient: 0.6697963352004687 Loss balanced:  0.6934263414494652 Loss1+loss2: 0.6934263414494652\n",
      "Write summary at step 11170  Loss:  0.6836898326873779\n",
      "Write summary at step 11180  Loss:  0.6783967018127441\n",
      "Write summary at step 11190  Loss:  0.7147628664970398\n",
      "Write summary at step 11200  Loss:  0.7334108352661133\n",
      "Write summary at step 11210  Loss:  0.7117229700088501\n",
      "Write summary at step 11220  Loss:  0.6987347602844238\n",
      "Write summary at step 11230  Loss:  0.7257792949676514\n",
      "Write summary at step 11240  Loss:  0.7194349765777588\n",
      "Write summary at step 11250  Loss:  0.6708998680114746\n",
      "Write summary at step 11260  Loss:  0.6949635744094849\n",
      "Write summary at step 11270  Loss:  0.6526628732681274\n",
      "Write summary at step 11280  Loss:  0.7179410457611084\n",
      "Write summary at step 11290  Loss:  0.7065539956092834\n",
      "Write summary at step 11300  Loss:  0.712321400642395\n",
      "Write summary at step 11310  Loss:  0.7015460729598999\n",
      "Write summary at step 11320  Loss:  0.6972503066062927\n",
      "Write summary at step 11330  Loss:  0.6457959413528442\n",
      "Write summary at step 11340  Loss:  0.6647763252258301\n",
      "Write summary at step 11350  Loss:  0.6732759475708008\n",
      "Write summary at step 11360  Loss:  0.6775527000427246\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6765020115550978 Loss Control: 0.6643620729446411 Loss Patient: 0.722785604496797 Loss balanced:  0.6935738387207191 Loss1+loss2: 0.6935738387207191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 11370  Loss:  0.6786186695098877\n",
      "Write summary at step 11380  Loss:  0.6703123450279236\n",
      "Write summary at step 11390  Loss:  0.7094283103942871\n",
      "Write summary at step 11400  Loss:  0.687877893447876\n",
      "Write summary at step 11410  Loss:  0.6851415038108826\n",
      "Write summary at step 11420  Loss:  0.6992077231407166\n",
      "Write summary at step 11430  Loss:  0.6895740032196045\n",
      "Write summary at step 11440  Loss:  0.686394214630127\n",
      "Write summary at step 11450  Loss:  0.7040847539901733\n",
      "Write summary at step 11460  Loss:  0.6905848383903503\n",
      "Write summary at step 11470  Loss:  0.6887068748474121\n",
      "Write summary at step 11480  Loss:  0.7030700445175171\n",
      "Write summary at step 11490  Loss:  0.6863895058631897\n",
      "Write summary at step 11500  Loss:  0.6788526177406311\n",
      "Saved checkpoint to: result/41/panns/checkpoint_11500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6940229839576787 Loss Control: 0.694645001262915 Loss Patient: 0.6916516485313574 Loss balanced:  0.6931483248971362 Loss1+loss2: 0.6931483248971362\n",
      "Write summary at step 11510  Loss:  0.6942117810249329\n",
      "Write summary at step 11520  Loss:  0.6816891431808472\n",
      "Write summary at step 11530  Loss:  0.7065141201019287\n",
      "Write summary at step 11540  Loss:  0.6776862740516663\n",
      "Write summary at step 11550  Loss:  0.6916303038597107\n",
      "Write summary at step 11560  Loss:  0.6733676791191101\n",
      "Write summary at step 11570  Loss:  0.6843112707138062\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6986719767252604 Loss Control: 0.7025694847106934 Loss Patient: 0.6838127908607324 Loss balanced:  0.693191137785713 Loss1+loss2: 0.693191137785713\n",
      "Write summary at step 11580  Loss:  0.6982991099357605\n",
      "Write summary at step 11590  Loss:  0.6947413682937622\n",
      "Write summary at step 11600  Loss:  0.7032800912857056\n",
      "Write summary at step 11610  Loss:  0.7209858894348145\n",
      "Write summary at step 11620  Loss:  0.7181395292282104\n",
      "Write summary at step 11630  Loss:  0.6808562278747559\n",
      "Write summary at step 11640  Loss:  0.6805288195610046\n",
      "Write summary at step 11650  Loss:  0.6635546684265137\n",
      "Write summary at step 11660  Loss:  0.7185057401657104\n",
      "Write summary at step 11670  Loss:  0.6949515342712402\n",
      "Write summary at step 11680  Loss:  0.6721498370170593\n",
      "Write summary at step 11690  Loss:  0.6727766990661621\n",
      "Write summary at step 11700  Loss:  0.6956131458282471\n",
      "Write summary at step 11710  Loss:  0.7153000831604004\n",
      "Write summary at step 11720  Loss:  0.7032731175422668\n",
      "Write summary at step 11730  Loss:  0.6907762289047241\n",
      "Write summary at step 11740  Loss:  0.7025085091590881\n",
      "Write summary at step 11750  Loss:  0.6979631185531616\n",
      "Write summary at step 11760  Loss:  0.6719789505004883\n",
      "Write summary at step 11770  Loss:  0.7115590572357178\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6972483195267715 Loss Control: 0.7001473903656006 Loss Patient: 0.6861956119537354 Loss balanced:  0.693171501159668 Loss1+loss2: 0.693171501159668\n",
      "Write summary at step 11780  Loss:  0.7024901509284973\n",
      "Write summary at step 11790  Loss:  0.6806192398071289\n",
      "Write summary at step 11800  Loss:  0.6854935884475708\n",
      "Write summary at step 11810  Loss:  0.6646385192871094\n",
      "Write summary at step 11820  Loss:  0.7080950736999512\n",
      "Write summary at step 11830  Loss:  0.6796225309371948\n",
      "Write summary at step 11840  Loss:  0.6933515667915344\n",
      "Write summary at step 11850  Loss:  0.6892364025115967\n",
      "Write summary at step 11860  Loss:  0.6887941956520081\n",
      "Write summary at step 11870  Loss:  0.6852066516876221\n",
      "Write summary at step 11880  Loss:  0.7186288833618164\n",
      "Write summary at step 11890  Loss:  0.700629472732544\n",
      "Write summary at step 11900  Loss:  0.6987268328666687\n",
      "Write summary at step 11910  Loss:  0.7010102272033691\n",
      "Write summary at step 11920  Loss:  0.6625379323959351\n",
      "Write summary at step 11930  Loss:  0.6614813804626465\n",
      "Write summary at step 11940  Loss:  0.6665908098220825\n",
      "Write summary at step 11950  Loss:  0.6866759657859802\n",
      "Write summary at step 11960  Loss:  0.7017625570297241\n",
      "Write summary at step 11970  Loss:  0.7179354429244995\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7166672294790094 Loss Control: 0.7328534132795907 Loss Patient: 0.6549575328826904 Loss balanced:  0.6939054730811406 Loss1+loss2: 0.6939054730811406\n",
      "Write summary at step 11980  Loss:  0.6834080219268799\n",
      "Write summary at step 11990  Loss:  0.7003397941589355\n",
      "Write summary at step 12000  Loss:  0.6944587826728821\n",
      "Saved checkpoint to: result/41/panns/checkpoint_12000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7154891181301761 Loss Control: 0.7308886051177979 Loss Patient: 0.6567785081764063 Loss balanced:  0.6938335566471021 Loss1+loss2: 0.6938335566471021\n",
      "Write summary at step 12010  Loss:  0.7078097462654114\n",
      "Write summary at step 12020  Loss:  0.7352856993675232\n",
      "Write summary at step 12030  Loss:  0.7008110284805298\n",
      "Write summary at step 12040  Loss:  0.6977438926696777\n",
      "Write summary at step 12050  Loss:  0.68773353099823\n",
      "Write summary at step 12060  Loss:  0.6874306201934814\n",
      "Write summary at step 12070  Loss:  0.6934916973114014\n",
      "Write summary at step 12080  Loss:  0.696632981300354\n",
      "Write summary at step 12090  Loss:  0.7161105871200562\n",
      "Write summary at step 12100  Loss:  0.6929551362991333\n",
      "Write summary at step 12110  Loss:  0.7035176157951355\n",
      "Write summary at step 12120  Loss:  0.6840351819992065\n",
      "Write summary at step 12130  Loss:  0.6767032146453857\n",
      "Write summary at step 12140  Loss:  0.6617792844772339\n",
      "Write summary at step 12150  Loss:  0.691917896270752\n",
      "Write summary at step 12160  Loss:  0.6891604065895081\n",
      "Write summary at step 12170  Loss:  0.6671829223632812\n",
      "Write summary at step 12180  Loss:  0.7068356275558472\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6771557599435121 Loss Control: 0.6654980182647705 Loss Patient: 0.7216009000937144 Loss balanced:  0.6935494591792424 Loss1+loss2: 0.6935494591792424\n",
      "Write summary at step 12190  Loss:  0.749004602432251\n",
      "Write summary at step 12200  Loss:  0.7308536767959595\n",
      "Write summary at step 12210  Loss:  0.7175638675689697\n",
      "Write summary at step 12220  Loss:  0.7211896777153015\n",
      "Write summary at step 12230  Loss:  0.7017450332641602\n",
      "Write summary at step 12240  Loss:  0.7140848636627197\n",
      "Write summary at step 12250  Loss:  0.7062674760818481\n",
      "Write summary at step 12260  Loss:  0.6876112818717957\n",
      "Write summary at step 12270  Loss:  0.7053470611572266\n",
      "Write summary at step 12280  Loss:  0.6839431524276733\n",
      "Write summary at step 12290  Loss:  0.6800334453582764\n",
      "Write summary at step 12300  Loss:  0.7029557824134827\n",
      "Write summary at step 12310  Loss:  0.6948723793029785\n",
      "Write summary at step 12320  Loss:  0.7039144039154053\n",
      "Write summary at step 12330  Loss:  0.6898976564407349\n",
      "Write summary at step 12340  Loss:  0.6903054714202881\n",
      "Write summary at step 12350  Loss:  0.6931850910186768\n",
      "Write summary at step 12360  Loss:  0.7030349373817444\n",
      "Write summary at step 12370  Loss:  0.6948303580284119\n",
      "Write summary at step 12380  Loss:  0.687721848487854\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6827165946299896 Loss Control: 0.6751823425292969 Loss Patient: 0.7114407358070215 Loss balanced:  0.6933115391681592 Loss1+loss2: 0.6933115391681592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 12390  Loss:  0.708590567111969\n",
      "Write summary at step 12400  Loss:  0.6868042945861816\n",
      "Write summary at step 12410  Loss:  0.6692193746566772\n",
      "Write summary at step 12420  Loss:  0.7050782442092896\n",
      "Write summary at step 12430  Loss:  0.6707867383956909\n",
      "Write summary at step 12440  Loss:  0.7276913523674011\n",
      "Write summary at step 12450  Loss:  0.6656562089920044\n",
      "Write summary at step 12460  Loss:  0.6863663196563721\n",
      "Write summary at step 12470  Loss:  0.6904534101486206\n",
      "Write summary at step 12480  Loss:  0.7096892595291138\n",
      "Write summary at step 12490  Loss:  0.695252537727356\n",
      "Write summary at step 12500  Loss:  0.7060481905937195\n",
      "Saved checkpoint to: result/41/panns/checkpoint_12500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6797600006644344 Loss Control: 0.6700460308236502 Loss Patient: 0.7167946224411329 Loss balanced:  0.6934203266323915 Loss1+loss2: 0.6934203266323915\n",
      "Write summary at step 12510  Loss:  0.6955946683883667\n",
      "Write summary at step 12520  Loss:  0.6968551874160767\n",
      "Write summary at step 12530  Loss:  0.6944360733032227\n",
      "Write summary at step 12540  Loss:  0.7026265859603882\n",
      "Write summary at step 12550  Loss:  0.6865873336791992\n",
      "Write summary at step 12560  Loss:  0.6963530778884888\n",
      "Write summary at step 12570  Loss:  0.6834391951560974\n",
      "Write summary at step 12580  Loss:  0.6843611001968384\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6695979056936322 Loss Control: 0.6522310382681467 Loss Patient: 0.7358091535667578 Loss balanced:  0.6940200959174523 Loss1+loss2: 0.6940200959174523\n",
      "Write summary at step 12590  Loss:  0.675102949142456\n",
      "Write summary at step 12600  Loss:  0.6906594038009644\n",
      "Write summary at step 12610  Loss:  0.6680675148963928\n",
      "Write summary at step 12620  Loss:  0.6537367701530457\n",
      "Write summary at step 12630  Loss:  0.67833411693573\n",
      "Write summary at step 12640  Loss:  0.6755818128585815\n",
      "Write summary at step 12650  Loss:  0.6870450377464294\n",
      "Write summary at step 12660  Loss:  0.6992945671081543\n",
      "Write summary at step 12670  Loss:  0.6738194227218628\n",
      "Write summary at step 12680  Loss:  0.6979968547821045\n",
      "Write summary at step 12690  Loss:  0.6770844459533691\n",
      "Write summary at step 12700  Loss:  0.6766177415847778\n",
      "Write summary at step 12710  Loss:  0.6580609083175659\n",
      "Write summary at step 12720  Loss:  0.7030155658721924\n",
      "Write summary at step 12730  Loss:  0.7086431980133057\n",
      "Write summary at step 12740  Loss:  0.6760287284851074\n",
      "Write summary at step 12750  Loss:  0.673973798751831\n",
      "Write summary at step 12760  Loss:  0.7213767766952515\n",
      "Write summary at step 12770  Loss:  0.7119607925415039\n",
      "Write summary at step 12780  Loss:  0.6998121738433838\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6821891273254956 Loss Control: 0.6742675906973459 Loss Patient: 0.7123900117973486 Loss balanced:  0.6933288012473473 Loss1+loss2: 0.6933288012473473\n",
      "Write summary at step 12790  Loss:  0.6901084184646606\n",
      "Write summary at step 12800  Loss:  0.6847594976425171\n",
      "Write summary at step 12810  Loss:  0.7138060331344604\n",
      "Write summary at step 12820  Loss:  0.6982882618904114\n",
      "Write summary at step 12830  Loss:  0.7274848222732544\n",
      "Write summary at step 12840  Loss:  0.7066888809204102\n",
      "Write summary at step 12850  Loss:  0.7012695074081421\n",
      "Write summary at step 12860  Loss:  0.68595290184021\n",
      "Write summary at step 12870  Loss:  0.67005455493927\n",
      "Write summary at step 12880  Loss:  0.6802651882171631\n",
      "Write summary at step 12890  Loss:  0.711546778678894\n",
      "Write summary at step 12900  Loss:  0.6916515827178955\n",
      "Write summary at step 12910  Loss:  0.6850294470787048\n",
      "Write summary at step 12920  Loss:  0.6930831074714661\n",
      "Write summary at step 12930  Loss:  0.7007606029510498\n",
      "Write summary at step 12940  Loss:  0.6912099123001099\n",
      "Write summary at step 12950  Loss:  0.6989791393280029\n",
      "Write summary at step 12960  Loss:  0.6693045496940613\n",
      "Write summary at step 12970  Loss:  0.7173150777816772\n",
      "Write summary at step 12980  Loss:  0.6578067541122437\n",
      "Write summary at step 12990  Loss:  0.7003406286239624\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7093606248046412 Loss Control: 0.7206288589154436 Loss Patient: 0.6664006051917871 Loss balanced:  0.6935147320536154 Loss1+loss2: 0.6935147320536154\n",
      "Write summary at step 13000  Loss:  0.6956666111946106\n",
      "Saved checkpoint to: result/41/panns/checkpoint_13000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7001231839130451 Loss Control: 0.705034182697046 Loss Patient: 0.6813998222351074 Loss balanced:  0.6932170024660766 Loss1+loss2: 0.6932170024660766\n",
      "Write summary at step 13010  Loss:  0.6979721784591675\n",
      "Write summary at step 13020  Loss:  0.6805785894393921\n",
      "Write summary at step 13030  Loss:  0.6845822334289551\n",
      "Write summary at step 13040  Loss:  0.7130189538002014\n",
      "Write summary at step 13050  Loss:  0.6830732226371765\n",
      "Write summary at step 13060  Loss:  0.7165202498435974\n",
      "Write summary at step 13070  Loss:  0.6660285592079163\n",
      "Write summary at step 13080  Loss:  0.7592993974685669\n",
      "Write summary at step 13090  Loss:  0.7149232625961304\n",
      "Write summary at step 13100  Loss:  0.6950531005859375\n",
      "Write summary at step 13110  Loss:  0.6834867596626282\n",
      "Write summary at step 13120  Loss:  0.732218861579895\n",
      "Write summary at step 13130  Loss:  0.71107017993927\n",
      "Write summary at step 13140  Loss:  0.7078467607498169\n",
      "Write summary at step 13150  Loss:  0.6831701993942261\n",
      "Write summary at step 13160  Loss:  0.6749815940856934\n",
      "Write summary at step 13170  Loss:  0.6752830743789673\n",
      "Write summary at step 13180  Loss:  0.6929223537445068\n",
      "Write summary at step 13190  Loss:  0.7180924415588379\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7154862238215162 Loss Control: 0.7308837764901541 Loss Patient: 0.6567829847335815 Loss balanced:  0.6938333806118678 Loss1+loss2: 0.6938333806118678\n",
      "Write summary at step 13200  Loss:  0.6996564865112305\n",
      "Write summary at step 13210  Loss:  0.7109975814819336\n",
      "Write summary at step 13220  Loss:  0.6910017728805542\n",
      "Write summary at step 13230  Loss:  0.6947975158691406\n",
      "Write summary at step 13240  Loss:  0.6902270913124084\n",
      "Write summary at step 13250  Loss:  0.6973520517349243\n",
      "Write summary at step 13260  Loss:  0.7097501158714294\n",
      "Write summary at step 13270  Loss:  0.6947304606437683\n",
      "Write summary at step 13280  Loss:  0.7030707001686096\n",
      "Write summary at step 13290  Loss:  0.7042391300201416\n",
      "Write summary at step 13300  Loss:  0.7099140882492065\n",
      "Write summary at step 13310  Loss:  0.6982265710830688\n",
      "Write summary at step 13320  Loss:  0.6895029544830322\n",
      "Write summary at step 13330  Loss:  0.6716293096542358\n",
      "Write summary at step 13340  Loss:  0.7068244814872742\n",
      "Write summary at step 13350  Loss:  0.7058941125869751\n",
      "Write summary at step 13360  Loss:  0.686387836933136\n",
      "Write summary at step 13370  Loss:  0.6727675199508667\n",
      "Write summary at step 13380  Loss:  0.6883364915847778\n",
      "Write summary at step 13390  Loss:  0.7278031706809998\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7250400422971486 Loss Control: 0.7467495792550467 Loss Patient: 0.6422724065681299 Loss balanced:  0.6945109929115882 Loss1+loss2: 0.6945109929115882\n",
      "Write summary at step 13400  Loss:  0.6811685562133789\n",
      "Write summary at step 13410  Loss:  0.6828060150146484\n",
      "Write summary at step 13420  Loss:  0.6828668117523193\n",
      "Write summary at step 13430  Loss:  0.7062051892280579\n",
      "Write summary at step 13440  Loss:  0.6808085441589355\n",
      "Write summary at step 13450  Loss:  0.7068415284156799\n",
      "Write summary at step 13460  Loss:  0.7172029614448547\n",
      "Write summary at step 13470  Loss:  0.6915642619132996\n",
      "Write summary at step 13480  Loss:  0.6929910182952881\n",
      "Write summary at step 13490  Loss:  0.6925857067108154\n",
      "Write summary at step 13500  Loss:  0.692177414894104\n",
      "Saved checkpoint to: result/41/panns/checkpoint_13500.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6993558541004792 Loss Control: 0.7037315368652344 Loss Patient: 0.6826736268897852 Loss balanced:  0.6932025818775098 Loss1+loss2: 0.6932025818775098\n",
      "Write summary at step 13510  Loss:  0.6926813721656799\n",
      "Write summary at step 13520  Loss:  0.6923969984054565\n",
      "Write summary at step 13530  Loss:  0.7002897262573242\n",
      "Write summary at step 13540  Loss:  0.6925379633903503\n",
      "Write summary at step 13550  Loss:  0.696474552154541\n",
      "Write summary at step 13560  Loss:  0.6963099837303162\n",
      "Write summary at step 13570  Loss:  0.715497612953186\n",
      "Write summary at step 13580  Loss:  0.6983121633529663\n",
      "Write summary at step 13590  Loss:  0.6783018708229065\n",
      "Write summary at step 13600  Loss:  0.6895806789398193\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7017690588385512 Loss Control: 0.70782470703125 Loss Patient: 0.6786819820602735 Loss balanced:  0.6932533445457618 Loss1+loss2: 0.6932533445457618\n",
      "Write summary at step 13610  Loss:  0.6786906719207764\n",
      "Write summary at step 13620  Loss:  0.6723232269287109\n",
      "Write summary at step 13630  Loss:  0.672288179397583\n",
      "Write summary at step 13640  Loss:  0.6570781469345093\n",
      "Write summary at step 13650  Loss:  0.7111333012580872\n",
      "Write summary at step 13660  Loss:  0.6969094276428223\n",
      "Write summary at step 13670  Loss:  0.6706230044364929\n",
      "Write summary at step 13680  Loss:  0.6641082763671875\n",
      "Write summary at step 13690  Loss:  0.6903011798858643\n",
      "Write summary at step 13700  Loss:  0.6732430458068848\n",
      "Write summary at step 13710  Loss:  0.6720499992370605\n",
      "Write summary at step 13720  Loss:  0.6897543668746948\n",
      "Write summary at step 13730  Loss:  0.6767311096191406\n",
      "Write summary at step 13740  Loss:  0.7582705020904541\n",
      "Write summary at step 13750  Loss:  0.6686420440673828\n",
      "Write summary at step 13760  Loss:  0.6489417552947998\n",
      "Write summary at step 13770  Loss:  0.742767333984375\n",
      "Write summary at step 13780  Loss:  0.7162365317344666\n",
      "Write summary at step 13790  Loss:  0.6998051404953003\n",
      "Write summary at step 13800  Loss:  0.6981301307678223\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6837655370369619 Loss Control: 0.6769999724919679 Loss Patient: 0.709559308985869 Loss balanced:  0.6932796407389185 Loss1+loss2: 0.6932796407389185\n",
      "Write summary at step 13810  Loss:  0.6998226046562195\n",
      "Write summary at step 13820  Loss:  0.7051786184310913\n",
      "Write summary at step 13830  Loss:  0.7145211696624756\n",
      "Write summary at step 13840  Loss:  0.697993278503418\n",
      "Write summary at step 13850  Loss:  0.7110653519630432\n",
      "Write summary at step 13860  Loss:  0.6885660886764526\n",
      "Write summary at step 13870  Loss:  0.6935977935791016\n",
      "Write summary at step 13880  Loss:  0.7015029191970825\n",
      "Write summary at step 13890  Loss:  0.686210036277771\n",
      "Write summary at step 13900  Loss:  0.6908585429191589\n",
      "Write summary at step 13910  Loss:  0.6941172480583191\n",
      "Write summary at step 13920  Loss:  0.7013545632362366\n",
      "Write summary at step 13930  Loss:  0.688477635383606\n",
      "Write summary at step 13940  Loss:  0.6875578165054321\n",
      "Write summary at step 13950  Loss:  0.7255682945251465\n",
      "Write summary at step 13960  Loss:  0.7116761803627014\n",
      "Write summary at step 13970  Loss:  0.6832402944564819\n",
      "Write summary at step 13980  Loss:  0.6935534477233887\n",
      "Write summary at step 13990  Loss:  0.6764075756072998\n",
      "Write summary at step 14000  Loss:  0.6942598223686218\n",
      "Saved checkpoint to: result/41/panns/checkpoint_14000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7194412993146228 Loss Control: 0.7374499156826833 Loss Patient: 0.6507834593454996 Loss balanced:  0.6941166875140914 Loss1+loss2: 0.6941166875140914\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7167176072731679 Loss Control: 0.7329086485456248 Loss Patient: 0.6549893282353878 Loss balanced:  0.6939489883905063 Loss1+loss2: 0.6939489883905063\n",
      "Write summary at step 14010  Loss:  0.6749789714813232\n",
      "Write summary at step 14020  Loss:  0.7584781050682068\n",
      "Write summary at step 14030  Loss:  0.664445161819458\n",
      "Write summary at step 14040  Loss:  0.6944296956062317\n",
      "Write summary at step 14050  Loss:  0.7027459144592285\n",
      "Write summary at step 14060  Loss:  0.6755207180976868\n",
      "Write summary at step 14070  Loss:  0.6760483980178833\n",
      "Write summary at step 14080  Loss:  0.6931240558624268\n",
      "Write summary at step 14090  Loss:  0.7009528875350952\n",
      "Write summary at step 14100  Loss:  0.6960081458091736\n",
      "Write summary at step 14110  Loss:  0.6941424608230591\n",
      "Write summary at step 14120  Loss:  0.680227518081665\n",
      "Write summary at step 14130  Loss:  0.6897554397583008\n",
      "Write summary at step 14140  Loss:  0.670813262462616\n",
      "Write summary at step 14150  Loss:  0.6981413960456848\n",
      "Write summary at step 14160  Loss:  0.6969864368438721\n",
      "Write summary at step 14170  Loss:  0.6485245227813721\n",
      "Write summary at step 14180  Loss:  0.6939911246299744\n",
      "Write summary at step 14190  Loss:  0.7019994854927063\n",
      "Write summary at step 14200  Loss:  0.6723389625549316\n",
      "Write summary at step 14210  Loss:  0.6753787994384766\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6845617769084451 Loss Control: 0.6783767319767853 Loss Patient: 0.7081423848867416 Loss balanced:  0.6932595584317635 Loss1+loss2: 0.6932595584317635\n",
      "Write summary at step 14220  Loss:  0.6694449186325073\n",
      "Write summary at step 14230  Loss:  0.7218636870384216\n",
      "Write summary at step 14240  Loss:  0.6597387790679932\n",
      "Write summary at step 14250  Loss:  0.6925212144851685\n",
      "Write summary at step 14260  Loss:  0.6971396207809448\n",
      "Write summary at step 14270  Loss:  0.7191815376281738\n",
      "Write summary at step 14280  Loss:  0.6796572208404541\n",
      "Write summary at step 14290  Loss:  0.7047348022460938\n",
      "Write summary at step 14300  Loss:  0.6780439615249634\n",
      "Write summary at step 14310  Loss:  0.6807466149330139\n",
      "Write summary at step 14320  Loss:  0.6826647520065308\n",
      "Write summary at step 14330  Loss:  0.680496335029602\n",
      "Write summary at step 14340  Loss:  0.7024201154708862\n",
      "Write summary at step 14350  Loss:  0.7168446183204651\n",
      "Write summary at step 14360  Loss:  0.7150014638900757\n",
      "Write summary at step 14370  Loss:  0.7293843626976013\n",
      "Write summary at step 14380  Loss:  0.7066210508346558\n",
      "Write summary at step 14390  Loss:  0.6804897785186768\n",
      "Write summary at step 14400  Loss:  0.6953399181365967\n",
      "Write summary at step 14410  Loss:  0.6993088722229004\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7111488642630639 Loss Control: 0.7236294270864602 Loss Patient: 0.663566761960586 Loss balanced:  0.6935980945235231 Loss1+loss2: 0.6935980945235231\n",
      "Write summary at step 14420  Loss:  0.6584988832473755\n",
      "Write summary at step 14430  Loss:  0.6684319972991943\n",
      "Write summary at step 14440  Loss:  0.6995970010757446\n",
      "Write summary at step 14450  Loss:  0.6855403184890747\n",
      "Write summary at step 14460  Loss:  0.6692217588424683\n",
      "Write summary at step 14470  Loss:  0.6967369318008423\n",
      "Write summary at step 14480  Loss:  0.68939208984375\n",
      "Write summary at step 14490  Loss:  0.6850020885467529\n",
      "Write summary at step 14500  Loss:  0.6893763542175293\n",
      "Saved checkpoint to: result/41/panns/checkpoint_14500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6972451104230178 Loss Control: 0.7001418334538819 Loss Patient: 0.6862010955810547 Loss balanced:  0.6931714645174682 Loss1+loss2: 0.6931714645174682\n",
      "Write summary at step 14510  Loss:  0.6580255627632141\n",
      "Write summary at step 14520  Loss:  0.6918387413024902\n",
      "Write summary at step 14530  Loss:  0.7365982532501221\n",
      "Write summary at step 14540  Loss:  0.6804156303405762\n",
      "Write summary at step 14550  Loss:  0.6851418018341064\n",
      "Write summary at step 14560  Loss:  0.6864892244338989\n",
      "Write summary at step 14570  Loss:  0.6998833417892456\n",
      "Write summary at step 14580  Loss:  0.6705712676048279\n",
      "Write summary at step 14590  Loss:  0.7111013531684875\n",
      "Write summary at step 14600  Loss:  0.6909777522087097\n",
      "Write summary at step 14610  Loss:  0.727289080619812\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7041417716385482 Loss Control: 0.7118382453918457 Loss Patient: 0.6747990312675635 Loss balanced:  0.6933186383297045 Loss1+loss2: 0.6933186383297045\n",
      "Write summary at step 14620  Loss:  0.6904324293136597\n",
      "Write summary at step 14630  Loss:  0.6787421703338623\n",
      "Write summary at step 14640  Loss:  0.6968065500259399\n",
      "Write summary at step 14650  Loss:  0.6938400268554688\n",
      "Write summary at step 14660  Loss:  0.6814879775047302\n",
      "Write summary at step 14670  Loss:  0.6653441190719604\n",
      "Write summary at step 14680  Loss:  0.6708977222442627\n",
      "Write summary at step 14690  Loss:  0.7038245797157288\n",
      "Write summary at step 14700  Loss:  0.6802223920822144\n",
      "Write summary at step 14710  Loss:  0.7075906991958618\n",
      "Write summary at step 14720  Loss:  0.6806219816207886\n",
      "Write summary at step 14730  Loss:  0.708044171333313\n",
      "Write summary at step 14740  Loss:  0.6901633739471436\n",
      "Write summary at step 14750  Loss:  0.6781981587409973\n",
      "Write summary at step 14760  Loss:  0.707546591758728\n",
      "Write summary at step 14770  Loss:  0.6891187429428101\n",
      "Write summary at step 14780  Loss:  0.6913819909095764\n",
      "Write summary at step 14790  Loss:  0.701281726360321\n",
      "Write summary at step 14800  Loss:  0.6978878974914551\n",
      "Write summary at step 14810  Loss:  0.6756320595741272\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6933657934655358 Loss Control: 0.6935212009591483 Loss Patient: 0.6927732763191065 Loss balanced:  0.6931472386391273 Loss1+loss2: 0.6931472386391273\n",
      "Write summary at step 14820  Loss:  0.6947920918464661\n",
      "Write summary at step 14830  Loss:  0.6901355385780334\n",
      "Write summary at step 14840  Loss:  0.687780499458313\n",
      "Write summary at step 14850  Loss:  0.6776965856552124\n",
      "Write summary at step 14860  Loss:  0.6920128464698792\n",
      "Write summary at step 14870  Loss:  0.6959558725357056\n",
      "Write summary at step 14880  Loss:  0.6838223338127136\n",
      "Write summary at step 14890  Loss:  0.6870976090431213\n",
      "Write summary at step 14900  Loss:  0.6745806932449341\n",
      "Write summary at step 14910  Loss:  0.6815586090087891\n",
      "Write summary at step 14920  Loss:  0.705653727054596\n",
      "Write summary at step 14930  Loss:  0.695716917514801\n",
      "Write summary at step 14940  Loss:  0.6917952299118042\n",
      "Write summary at step 14950  Loss:  0.6935396194458008\n",
      "Write summary at step 14960  Loss:  0.6919711232185364\n",
      "Write summary at step 14970  Loss:  0.6615922451019287\n",
      "Write summary at step 14980  Loss:  0.6656522750854492\n",
      "Write summary at step 14990  Loss:  0.6897027492523193\n",
      "Write summary at step 15000  Loss:  0.7172657251358032\n",
      "Saved checkpoint to: result/41/panns/checkpoint_15000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6647901960781643 Loss Control: 0.6437109119253732 Loss Patient: 0.745155015339454 Loss balanced:  0.6944329636324136 Loss1+loss2: 0.6944329636324136\n",
      "Write summary at step 15010  Loss:  0.6882679462432861\n",
      "Write summary at step 15020  Loss:  0.7002797722816467\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6889011369639145 Loss Control: 0.6858628844954276 Loss Patient: 0.7004843155543009 Loss balanced:  0.6931736000248643 Loss1+loss2: 0.6931736000248643\n",
      "Write summary at step 15030  Loss:  0.6909167766571045\n",
      "Write summary at step 15040  Loss:  0.693168580532074\n",
      "Write summary at step 15050  Loss:  0.6791431903839111\n",
      "Write summary at step 15060  Loss:  0.6709846258163452\n",
      "Write summary at step 15070  Loss:  0.7036483287811279\n",
      "Write summary at step 15080  Loss:  0.7063717842102051\n",
      "Write summary at step 15090  Loss:  0.6922609806060791\n",
      "Write summary at step 15100  Loss:  0.681167721748352\n",
      "Write summary at step 15110  Loss:  0.6834825277328491\n",
      "Write summary at step 15120  Loss:  0.7252312898635864\n",
      "Write summary at step 15130  Loss:  0.6925218105316162\n",
      "Write summary at step 15140  Loss:  0.6847515106201172\n",
      "Write summary at step 15150  Loss:  0.6691073179244995\n",
      "Write summary at step 15160  Loss:  0.6971157789230347\n",
      "Write summary at step 15170  Loss:  0.667725682258606\n",
      "Write summary at step 15180  Loss:  0.6876867413520813\n",
      "Write summary at step 15190  Loss:  0.6790919303894043\n",
      "Write summary at step 15200  Loss:  0.6961298584938049\n",
      "Write summary at step 15210  Loss:  0.6812317967414856\n",
      "Write summary at step 15220  Loss:  0.7215019464492798\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6995522021215199 Loss Control: 0.7040649795792794 Loss Patient: 0.682347297668457 Loss balanced:  0.6932061386238682 Loss1+loss2: 0.6932061386238682\n",
      "Write summary at step 15230  Loss:  0.6863164901733398\n",
      "Write summary at step 15240  Loss:  0.6876948475837708\n",
      "Write summary at step 15250  Loss:  0.6961331367492676\n",
      "Write summary at step 15260  Loss:  0.7316595315933228\n",
      "Write summary at step 15270  Loss:  0.6918052434921265\n",
      "Write summary at step 15280  Loss:  0.692543089389801\n",
      "Write summary at step 15290  Loss:  0.6884773969650269\n",
      "Write summary at step 15300  Loss:  0.7122498750686646\n",
      "Write summary at step 15310  Loss:  0.7008131146430969\n",
      "Write summary at step 15320  Loss:  0.7003233432769775\n",
      "Write summary at step 15330  Loss:  0.6818983554840088\n",
      "Write summary at step 15340  Loss:  0.6913553476333618\n",
      "Write summary at step 15350  Loss:  0.684008002281189\n",
      "Write summary at step 15360  Loss:  0.6843146085739136\n",
      "Write summary at step 15370  Loss:  0.6905497312545776\n",
      "Write summary at step 15380  Loss:  0.6887216567993164\n",
      "Write summary at step 15390  Loss:  0.6926159262657166\n",
      "Write summary at step 15400  Loss:  0.6855767369270325\n",
      "Write summary at step 15410  Loss:  0.7169901132583618\n",
      "Write summary at step 15420  Loss:  0.6999295353889465\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6841690375175311 Loss Control: 0.6776983737945557 Loss Patient: 0.7088384628295898 Loss balanced:  0.6932684183120728 Loss1+loss2: 0.6932684183120728\n",
      "Write summary at step 15430  Loss:  0.6873558759689331\n",
      "Write summary at step 15440  Loss:  0.6709058284759521\n",
      "Write summary at step 15450  Loss:  0.7047598361968994\n",
      "Write summary at step 15460  Loss:  0.6933405995368958\n",
      "Write summary at step 15470  Loss:  0.7042468786239624\n",
      "Write summary at step 15480  Loss:  0.6787134408950806\n",
      "Write summary at step 15490  Loss:  0.6921120882034302\n",
      "Write summary at step 15500  Loss:  0.677734375\n",
      "Saved checkpoint to: result/41/panns/checkpoint_15500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6937470784435025 Loss Control: 0.694173275772991 Loss Patient: 0.6921221551795801 Loss balanced:  0.6931477154762855 Loss1+loss2: 0.6931477154762855\n",
      "Write summary at step 15510  Loss:  0.6857303977012634\n",
      "Write summary at step 15520  Loss:  0.704068660736084\n",
      "Write summary at step 15530  Loss:  0.6822489500045776\n",
      "Write summary at step 15540  Loss:  0.7050532698631287\n",
      "Write summary at step 15550  Loss:  0.6897428035736084\n",
      "Write summary at step 15560  Loss:  0.7116634845733643\n",
      "Write summary at step 15570  Loss:  0.6863159537315369\n",
      "Write summary at step 15580  Loss:  0.7048329710960388\n",
      "Write summary at step 15590  Loss:  0.6898381114006042\n",
      "Write summary at step 15600  Loss:  0.6845536231994629\n",
      "Write summary at step 15610  Loss:  0.7283152937889099\n",
      "Write summary at step 15620  Loss:  0.7051767110824585\n",
      "Write summary at step 15630  Loss:  0.6910082101821899\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7134954593914412 Loss Control: 0.7275582564984514 Loss Patient: 0.6598809423545996 Loss balanced:  0.6937195994265255 Loss1+loss2: 0.6937195994265255\n",
      "Write summary at step 15640  Loss:  0.6969364285469055\n",
      "Write summary at step 15650  Loss:  0.7178361415863037\n",
      "Write summary at step 15660  Loss:  0.7001790404319763\n",
      "Write summary at step 15670  Loss:  0.713430643081665\n",
      "Write summary at step 15680  Loss:  0.6889000535011292\n",
      "Write summary at step 15690  Loss:  0.7032966613769531\n",
      "Write summary at step 15700  Loss:  0.6983038187026978\n",
      "Write summary at step 15710  Loss:  0.6999002695083618\n",
      "Write summary at step 15720  Loss:  0.6717569828033447\n",
      "Write summary at step 15730  Loss:  0.723910927772522\n",
      "Write summary at step 15740  Loss:  0.7290318608283997\n",
      "Write summary at step 15750  Loss:  0.6877559423446655\n",
      "Write summary at step 15760  Loss:  0.6910065412521362\n",
      "Write summary at step 15770  Loss:  0.7050020694732666\n",
      "Write summary at step 15780  Loss:  0.6980286836624146\n",
      "Write summary at step 15790  Loss:  0.6753461360931396\n",
      "Write summary at step 15800  Loss:  0.6777017116546631\n",
      "Write summary at step 15810  Loss:  0.6904873847961426\n",
      "Write summary at step 15820  Loss:  0.7081828713417053\n",
      "Write summary at step 15830  Loss:  0.6822032332420349\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6887157020114717 Loss Control: 0.6855436706803536 Loss Patient: 0.7008090019226074 Loss balanced:  0.6931763363014805 Loss1+loss2: 0.6931763363014805\n",
      "Write summary at step 15840  Loss:  0.6916475892066956\n",
      "Write summary at step 15850  Loss:  0.6897528171539307\n",
      "Write summary at step 15860  Loss:  0.6981877684593201\n",
      "Write summary at step 15870  Loss:  0.6870388984680176\n",
      "Write summary at step 15880  Loss:  0.6931016445159912\n",
      "Write summary at step 15890  Loss:  0.6984130144119263\n",
      "Write summary at step 15900  Loss:  0.6758968830108643\n",
      "Write summary at step 15910  Loss:  0.694434642791748\n",
      "Write summary at step 15920  Loss:  0.6982342004776001\n",
      "Write summary at step 15930  Loss:  0.6960142254829407\n",
      "Write summary at step 15940  Loss:  0.6845533847808838\n",
      "Write summary at step 15950  Loss:  0.7043954730033875\n",
      "Write summary at step 15960  Loss:  0.6685879230499268\n",
      "Write summary at step 15970  Loss:  0.6810106635093689\n",
      "Write summary at step 15980  Loss:  0.7082446813583374\n",
      "Write summary at step 15990  Loss:  0.6866785287857056\n",
      "Write summary at step 16000  Loss:  0.6969850063323975\n",
      "Saved checkpoint to: result/41/panns/checkpoint_16000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7187998367078376 Loss Control: 0.7364039421081543 Loss Patient: 0.6516841314733028 Loss balanced:  0.6940440367907286 Loss1+loss2: 0.6940440367907286\n",
      "Write summary at step 16010  Loss:  0.6959623694419861\n",
      "Write summary at step 16020  Loss:  0.7163821458816528\n",
      "Write summary at step 16030  Loss:  0.6978470087051392\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7085730585701022 Loss Control: 0.7193055152893066 Loss Patient: 0.6676556964715322 Loss balanced:  0.6934806058804195 Loss1+loss2: 0.6934806058804195\n",
      "Write summary at step 16040  Loss:  0.7151939868927002\n",
      "Write summary at step 16050  Loss:  0.6975651383399963\n",
      "Write summary at step 16060  Loss:  0.7058330774307251\n",
      "Write summary at step 16070  Loss:  0.6797788143157959\n",
      "Write summary at step 16080  Loss:  0.6942348480224609\n",
      "Write summary at step 16090  Loss:  0.6871618628501892\n",
      "Write summary at step 16100  Loss:  0.6671545505523682\n",
      "Write summary at step 16110  Loss:  0.6772481799125671\n",
      "Write summary at step 16120  Loss:  0.6754932999610901\n",
      "Write summary at step 16130  Loss:  0.688017725944519\n",
      "Write summary at step 16140  Loss:  0.7328207492828369\n",
      "Write summary at step 16150  Loss:  0.7109938859939575\n",
      "Write summary at step 16160  Loss:  0.6778953075408936\n",
      "Write summary at step 16170  Loss:  0.677873969078064\n",
      "Write summary at step 16180  Loss:  0.7075548768043518\n",
      "Write summary at step 16190  Loss:  0.7011461853981018\n",
      "Write summary at step 16200  Loss:  0.7000632882118225\n",
      "Write summary at step 16210  Loss:  0.6803716421127319\n",
      "Write summary at step 16220  Loss:  0.7050098180770874\n",
      "Write summary at step 16230  Loss:  0.6992181539535522\n",
      "Write summary at step 16240  Loss:  0.7300564646720886\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6870754350831498 Loss Control: 0.6827186935586356 Loss Patient: 0.7036854612330595 Loss balanced:  0.6932020773958476 Loss1+loss2: 0.6932020773958476\n",
      "Write summary at step 16250  Loss:  0.7018822431564331\n",
      "Write summary at step 16260  Loss:  0.7076280117034912\n",
      "Write summary at step 16270  Loss:  0.7093454599380493\n",
      "Write summary at step 16280  Loss:  0.708033561706543\n",
      "Write summary at step 16290  Loss:  0.6909328103065491\n",
      "Write summary at step 16300  Loss:  0.6936198472976685\n",
      "Write summary at step 16310  Loss:  0.6974811553955078\n",
      "Write summary at step 16320  Loss:  0.7051724195480347\n",
      "Write summary at step 16330  Loss:  0.6899224519729614\n",
      "Write summary at step 16340  Loss:  0.700208842754364\n",
      "Write summary at step 16350  Loss:  0.6949204802513123\n",
      "Write summary at step 16360  Loss:  0.7035467028617859\n",
      "Write summary at step 16370  Loss:  0.6762608289718628\n",
      "Write summary at step 16380  Loss:  0.6942521929740906\n",
      "Write summary at step 16390  Loss:  0.6900942325592041\n",
      "Write summary at step 16400  Loss:  0.7258433103561401\n",
      "Write summary at step 16410  Loss:  0.6823166012763977\n",
      "Write summary at step 16420  Loss:  0.6890220046043396\n",
      "Write summary at step 16430  Loss:  0.710435152053833\n",
      "Write summary at step 16440  Loss:  0.728853166103363\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6796350481706265 Loss Control: 0.6698284882013915 Loss Patient: 0.7170226573944092 Loss balanced:  0.6934255727979004 Loss1+loss2: 0.6934255727979004\n",
      "Write summary at step 16450  Loss:  0.6921036839485168\n",
      "Write summary at step 16460  Loss:  0.6995134353637695\n",
      "Write summary at step 16470  Loss:  0.7109277248382568\n",
      "Write summary at step 16480  Loss:  0.6978098154067993\n",
      "Write summary at step 16490  Loss:  0.6888691782951355\n",
      "Write summary at step 16500  Loss:  0.6933088302612305\n",
      "Saved checkpoint to: result/41/panns/checkpoint_16500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6717818565182871 Loss Control: 0.6560813778085135 Loss Patient: 0.7316399278740088 Loss balanced:  0.6938606528412612 Loss1+loss2: 0.6938606528412612\n",
      "Write summary at step 16510  Loss:  0.6722819805145264\n",
      "Write summary at step 16520  Loss:  0.7021898031234741\n",
      "Write summary at step 16530  Loss:  0.6924744844436646\n",
      "Write summary at step 16540  Loss:  0.6817119121551514\n",
      "Write summary at step 16550  Loss:  0.70025634765625\n",
      "Write summary at step 16560  Loss:  0.6849442720413208\n",
      "Write summary at step 16570  Loss:  0.6981295943260193\n",
      "Write summary at step 16580  Loss:  0.6950088739395142\n",
      "Write summary at step 16590  Loss:  0.6986502408981323\n",
      "Write summary at step 16600  Loss:  0.7021667957305908\n",
      "Write summary at step 16610  Loss:  0.6962170600891113\n",
      "Write summary at step 16620  Loss:  0.6907556653022766\n",
      "Write summary at step 16630  Loss:  0.7074430584907532\n",
      "Write summary at step 16640  Loss:  0.6861563920974731\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7217605511347452 Loss Control: 0.7413204895342634 Loss Patient: 0.6471882524589697 Loss balanced:  0.6942543709966166 Loss1+loss2: 0.6942543709966166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 16650  Loss:  0.6516455411911011\n",
      "Write summary at step 16660  Loss:  0.6809689998626709\n",
      "Write summary at step 16670  Loss:  0.6963049173355103\n",
      "Write summary at step 16680  Loss:  0.7143898010253906\n",
      "Write summary at step 16690  Loss:  0.7134261131286621\n",
      "Write summary at step 16700  Loss:  0.6774200201034546\n",
      "Write summary at step 16710  Loss:  0.6887456774711609\n",
      "Write summary at step 16720  Loss:  0.7004169225692749\n",
      "Write summary at step 16730  Loss:  0.7113375663757324\n",
      "Write summary at step 16740  Loss:  0.6909733414649963\n",
      "Write summary at step 16750  Loss:  0.6864802837371826\n",
      "Write summary at step 16760  Loss:  0.7004262804985046\n",
      "Write summary at step 16770  Loss:  0.6905888319015503\n",
      "Write summary at step 16780  Loss:  0.7024091482162476\n",
      "Write summary at step 16790  Loss:  0.6782054305076599\n",
      "Write summary at step 16800  Loss:  0.6820740699768066\n",
      "Write summary at step 16810  Loss:  0.7004395723342896\n",
      "Write summary at step 16820  Loss:  0.7047944664955139\n",
      "Write summary at step 16830  Loss:  0.6904000043869019\n",
      "Write summary at step 16840  Loss:  0.6817107200622559\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7111183817768509 Loss Control: 0.7235783325518416 Loss Patient: 0.6636148157219092 Loss balanced:  0.6935965741368754 Loss1+loss2: 0.6935965741368754\n",
      "Write summary at step 16850  Loss:  0.6756668090820312\n",
      "Write summary at step 16860  Loss:  0.683314323425293\n",
      "Write summary at step 16870  Loss:  0.6999948024749756\n",
      "Write summary at step 16880  Loss:  0.7729425430297852\n",
      "Write summary at step 16890  Loss:  0.674765408039093\n",
      "Write summary at step 16900  Loss:  0.7093172073364258\n",
      "Write summary at step 16910  Loss:  0.7306076288223267\n",
      "Write summary at step 16920  Loss:  0.6850772500038147\n",
      "Write summary at step 16930  Loss:  0.6887995600700378\n",
      "Write summary at step 16940  Loss:  0.702816367149353\n",
      "Write summary at step 16950  Loss:  0.691504180431366\n",
      "Write summary at step 16960  Loss:  0.6937800645828247\n",
      "Write summary at step 16970  Loss:  0.6858984231948853\n",
      "Write summary at step 16980  Loss:  0.7000088691711426\n",
      "Write summary at step 16990  Loss:  0.6882192492485046\n",
      "Write summary at step 17000  Loss:  0.7116531133651733\n",
      "Saved checkpoint to: result/41/panns/checkpoint_17000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6980209123520624 Loss Control: 0.7014622688293457 Loss Patient: 0.6849006290237108 Loss balanced:  0.6931814489265282 Loss1+loss2: 0.6931814489265282\n",
      "Write summary at step 17010  Loss:  0.6953414678573608\n",
      "Write summary at step 17020  Loss:  0.6885875463485718\n",
      "Write summary at step 17030  Loss:  0.7089525461196899\n",
      "Write summary at step 17040  Loss:  0.7157665491104126\n",
      "Write summary at step 17050  Loss:  0.7089602947235107\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7044641311034495 Loss Control: 0.7123826592346358 Loss Patient: 0.6742747488121191 Loss balanced:  0.6933287040233775 Loss1+loss2: 0.6933287040233775\n",
      "Write summary at step 17060  Loss:  0.6787816286087036\n",
      "Write summary at step 17070  Loss:  0.7005581855773926\n",
      "Write summary at step 17080  Loss:  0.7159037590026855\n",
      "Write summary at step 17090  Loss:  0.6987783908843994\n",
      "Write summary at step 17100  Loss:  0.7037050724029541\n",
      "Write summary at step 17110  Loss:  0.6991713047027588\n",
      "Write summary at step 17120  Loss:  0.6836664080619812\n",
      "Write summary at step 17130  Loss:  0.6962268352508545\n",
      "Write summary at step 17140  Loss:  0.6874725818634033\n",
      "Write summary at step 17150  Loss:  0.6952800154685974\n",
      "Write summary at step 17160  Loss:  0.692322850227356\n",
      "Write summary at step 17170  Loss:  0.7033811807632446\n",
      "Write summary at step 17180  Loss:  0.6979465484619141\n",
      "Write summary at step 17190  Loss:  0.6881045699119568\n",
      "Write summary at step 17200  Loss:  0.702954888343811\n",
      "Write summary at step 17210  Loss:  0.6915923357009888\n",
      "Write summary at step 17220  Loss:  0.6920104026794434\n",
      "Write summary at step 17230  Loss:  0.6846516728401184\n",
      "Write summary at step 17240  Loss:  0.6943798065185547\n",
      "Write summary at step 17250  Loss:  0.7077128887176514\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6840338144467507 Loss Control: 0.6774643646563338 Loss Patient: 0.7090799150367578 Loss balanced:  0.6932721398465458 Loss1+loss2: 0.6932721398465458\n",
      "Write summary at step 17260  Loss:  0.691950798034668\n",
      "Write summary at step 17270  Loss:  0.7186219692230225\n",
      "Write summary at step 17280  Loss:  0.7040177583694458\n",
      "Write summary at step 17290  Loss:  0.6742810010910034\n",
      "Write summary at step 17300  Loss:  0.6981679797172546\n",
      "Write summary at step 17310  Loss:  0.699531078338623\n",
      "Write summary at step 17320  Loss:  0.6942681074142456\n",
      "Write summary at step 17330  Loss:  0.692028820514679\n",
      "Write summary at step 17340  Loss:  0.7276512384414673\n",
      "Write summary at step 17350  Loss:  0.6969691514968872\n",
      "Write summary at step 17360  Loss:  0.6897664070129395\n",
      "Write summary at step 17370  Loss:  0.6777676343917847\n",
      "Write summary at step 17380  Loss:  0.6669474840164185\n",
      "Write summary at step 17390  Loss:  0.7065186500549316\n",
      "Write summary at step 17400  Loss:  0.6837247610092163\n",
      "Write summary at step 17410  Loss:  0.6972646713256836\n",
      "Write summary at step 17420  Loss:  0.7079834938049316\n",
      "Write summary at step 17430  Loss:  0.7002890110015869\n",
      "Write summary at step 17440  Loss:  0.6923255324363708\n",
      "Write summary at step 17450  Loss:  0.6965299248695374\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6757206328503498 Loss Control: 0.6629951000213623 Loss Patient: 0.7242367925743262 Loss balanced:  0.6936159462978442 Loss1+loss2: 0.6936159462978442\n",
      "Write summary at step 17460  Loss:  0.6832753419876099\n",
      "Write summary at step 17470  Loss:  0.7059059739112854\n",
      "Write summary at step 17480  Loss:  0.7124075889587402\n",
      "Write summary at step 17490  Loss:  0.6870385408401489\n",
      "Write summary at step 17500  Loss:  0.7041240930557251\n",
      "Saved checkpoint to: result/41/panns/checkpoint_17500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6738232098100505 Loss Control: 0.6596693390054129 Loss Patient: 0.7277847652633985 Loss balanced:  0.6937270521344057 Loss1+loss2: 0.6937270521344057\n",
      "Write summary at step 17510  Loss:  0.7037332057952881\n",
      "Write summary at step 17520  Loss:  0.6916201710700989\n",
      "Write summary at step 17530  Loss:  0.6864042282104492\n",
      "Write summary at step 17540  Loss:  0.692536473274231\n",
      "Write summary at step 17550  Loss:  0.6884244084358215\n",
      "Write summary at step 17560  Loss:  0.6681748628616333\n",
      "Write summary at step 17570  Loss:  0.711891770362854\n",
      "Write summary at step 17580  Loss:  0.7112290859222412\n",
      "Write summary at step 17590  Loss:  0.6789870858192444\n",
      "Write summary at step 17600  Loss:  0.6959006190299988\n",
      "Write summary at step 17610  Loss:  0.6977498531341553\n",
      "Write summary at step 17620  Loss:  0.7056128978729248\n",
      "Write summary at step 17630  Loss:  0.6951248645782471\n",
      "Write summary at step 17640  Loss:  0.6863343715667725\n",
      "Write summary at step 17650  Loss:  0.6829484701156616\n",
      "Write summary at step 17660  Loss:  0.6908227801322937\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6960947338120762 Loss Control: 0.6981821060180664 Loss Patient: 0.6881365614632765 Loss balanced:  0.6931593337406714 Loss1+loss2: 0.6931593337406714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 17670  Loss:  0.6955145597457886\n",
      "Write summary at step 17680  Loss:  0.6829115152359009\n",
      "Write summary at step 17690  Loss:  0.6832404732704163\n",
      "Write summary at step 17700  Loss:  0.6990703344345093\n",
      "Write summary at step 17710  Loss:  0.6869871020317078\n",
      "Write summary at step 17720  Loss:  0.6938201189041138\n",
      "Write summary at step 17730  Loss:  0.7117109894752502\n",
      "Write summary at step 17740  Loss:  0.6777195930480957\n",
      "Write summary at step 17750  Loss:  0.7016745805740356\n",
      "Write summary at step 17760  Loss:  0.6831175088882446\n",
      "Write summary at step 17770  Loss:  0.6906037330627441\n",
      "Write summary at step 17780  Loss:  0.71348637342453\n",
      "Write summary at step 17790  Loss:  0.7016463279724121\n",
      "Write summary at step 17800  Loss:  0.6923313140869141\n",
      "Write summary at step 17810  Loss:  0.702092170715332\n",
      "Write summary at step 17820  Loss:  0.6976439952850342\n",
      "Write summary at step 17830  Loss:  0.7110752463340759\n",
      "Write summary at step 17840  Loss:  0.691950798034668\n",
      "Write summary at step 17850  Loss:  0.7028796076774597\n",
      "Write summary at step 17860  Loss:  0.6908608675003052\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6896904596002587 Loss Control: 0.6872195464665772 Loss Patient: 0.6991106184820334 Loss balanced:  0.6931650824743053 Loss1+loss2: 0.6931650824743053\n",
      "Write summary at step 17870  Loss:  0.6954931616783142\n",
      "Write summary at step 17880  Loss:  0.6891219615936279\n",
      "Write summary at step 17890  Loss:  0.6953368782997131\n",
      "Write summary at step 17900  Loss:  0.7021957039833069\n",
      "Write summary at step 17910  Loss:  0.6977543830871582\n",
      "Write summary at step 17920  Loss:  0.6978317499160767\n",
      "Write summary at step 17930  Loss:  0.6851322650909424\n",
      "Write summary at step 17940  Loss:  0.6832723617553711\n",
      "Write summary at step 17950  Loss:  0.6894888281822205\n",
      "Write summary at step 17960  Loss:  0.6883294582366943\n",
      "Write summary at step 17970  Loss:  0.6859990358352661\n",
      "Write summary at step 17980  Loss:  0.6925326585769653\n",
      "Write summary at step 17990  Loss:  0.7257250547409058\n",
      "Write summary at step 18000  Loss:  0.6653802394866943\n",
      "Saved checkpoint to: result/41/panns/checkpoint_18000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6911097016685452 Loss Control: 0.6896564960479736 Loss Patient: 0.6966500940422217 Loss balanced:  0.6931532950450976 Loss1+loss2: 0.6931532950450976\n",
      "Write summary at step 18010  Loss:  0.7009037733078003\n",
      "Write summary at step 18020  Loss:  0.6881903409957886\n",
      "Write summary at step 18030  Loss:  0.6883295774459839\n",
      "Write summary at step 18040  Loss:  0.6804996132850647\n",
      "Write summary at step 18050  Loss:  0.6642842292785645\n",
      "Write summary at step 18060  Loss:  0.7388539910316467\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.709724333121147 Loss Control: 0.7212395065469168 Loss Patient: 0.6658225866655508 Loss balanced:  0.6935310466062339 Loss1+loss2: 0.6935310466062339\n",
      "Write summary at step 18070  Loss:  0.6878610849380493\n",
      "Write summary at step 18080  Loss:  0.6661510467529297\n",
      "Write summary at step 18090  Loss:  0.679662823677063\n",
      "Write summary at step 18100  Loss:  0.710932731628418\n",
      "Write summary at step 18110  Loss:  0.6960792541503906\n",
      "Write summary at step 18120  Loss:  0.7239210605621338\n",
      "Write summary at step 18130  Loss:  0.687544047832489\n",
      "Write summary at step 18140  Loss:  0.7017416954040527\n",
      "Write summary at step 18150  Loss:  0.6887461543083191\n",
      "Write summary at step 18160  Loss:  0.6966145038604736\n",
      "Write summary at step 18170  Loss:  0.6932401657104492\n",
      "Write summary at step 18180  Loss:  0.6843725442886353\n",
      "Write summary at step 18190  Loss:  0.6915580034255981\n",
      "Write summary at step 18200  Loss:  0.6876653432846069\n",
      "Write summary at step 18210  Loss:  0.7035535573959351\n",
      "Write summary at step 18220  Loss:  0.6888278722763062\n",
      "Write summary at step 18230  Loss:  0.6765888333320618\n",
      "Write summary at step 18240  Loss:  0.7097364664077759\n",
      "Write summary at step 18250  Loss:  0.7058834433555603\n",
      "Write summary at step 18260  Loss:  0.6793731451034546\n",
      "Write summary at step 18270  Loss:  0.7111225128173828\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6953282805232258 Loss Control: 0.6968744980181502 Loss Patient: 0.6894333784778913 Loss balanced:  0.6931539382480207 Loss1+loss2: 0.6931539382480207\n",
      "Write summary at step 18280  Loss:  0.7104601263999939\n",
      "Write summary at step 18290  Loss:  0.6881521940231323\n",
      "Write summary at step 18300  Loss:  0.6973145008087158\n",
      "Write summary at step 18310  Loss:  0.6918967962265015\n",
      "Write summary at step 18320  Loss:  0.6974802613258362\n",
      "Write summary at step 18330  Loss:  0.6907739639282227\n",
      "Write summary at step 18340  Loss:  0.6778424382209778\n",
      "Write summary at step 18350  Loss:  0.6800590753555298\n",
      "Write summary at step 18360  Loss:  0.6903611421585083\n",
      "Write summary at step 18370  Loss:  0.6951217651367188\n",
      "Write summary at step 18380  Loss:  0.699236273765564\n",
      "Write summary at step 18390  Loss:  0.6830487251281738\n",
      "Write summary at step 18400  Loss:  0.6935704350471497\n",
      "Write summary at step 18410  Loss:  0.6534836292266846\n",
      "Write summary at step 18420  Loss:  0.6716409921646118\n",
      "Write summary at step 18430  Loss:  0.6999250650405884\n",
      "Write summary at step 18440  Loss:  0.6993753910064697\n",
      "Write summary at step 18450  Loss:  0.6912120580673218\n",
      "Write summary at step 18460  Loss:  0.6677835583686829\n",
      "Write summary at step 18470  Loss:  0.6773256659507751\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6903669733505744 Loss Control: 0.68838315094755 Loss Patient: 0.6979303484161695 Loss balanced:  0.6931567496818598 Loss1+loss2: 0.6931567496818598\n",
      "Write summary at step 18480  Loss:  0.692011296749115\n",
      "Write summary at step 18490  Loss:  0.7049334049224854\n",
      "Write summary at step 18500  Loss:  0.6922767758369446\n",
      "Saved checkpoint to: result/41/panns/checkpoint_18500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6862781685152095 Loss Control: 0.6813435303708895 Loss Patient: 0.7050915211439133 Loss balanced:  0.6932175257574014 Loss1+loss2: 0.6932175257574014\n",
      "Write summary at step 18510  Loss:  0.6949031352996826\n",
      "Write summary at step 18520  Loss:  0.6849398612976074\n",
      "Write summary at step 18530  Loss:  0.6863654851913452\n",
      "Write summary at step 18540  Loss:  0.6772940158843994\n",
      "Write summary at step 18550  Loss:  0.7039031982421875\n",
      "Write summary at step 18560  Loss:  0.714577317237854\n",
      "Write summary at step 18570  Loss:  0.6771412491798401\n",
      "Write summary at step 18580  Loss:  0.694889485836029\n",
      "Write summary at step 18590  Loss:  0.6806782484054565\n",
      "Write summary at step 18600  Loss:  0.6935309171676636\n",
      "Write summary at step 18610  Loss:  0.7154197692871094\n",
      "Write summary at step 18620  Loss:  0.7065416574478149\n",
      "Write summary at step 18630  Loss:  0.6881862282752991\n",
      "Write summary at step 18640  Loss:  0.6998361349105835\n",
      "Write summary at step 18650  Loss:  0.6996852159500122\n",
      "Write summary at step 18660  Loss:  0.6676987409591675\n",
      "Write summary at step 18670  Loss:  0.6844464540481567\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6955946799996612 Loss Control: 0.6973299429716309 Loss Patient: 0.6889790619413058 Loss balanced:  0.6931545024564683 Loss1+loss2: 0.6931545024564683\n",
      "Write summary at step 18680  Loss:  0.7052866220474243\n",
      "Write summary at step 18690  Loss:  0.7044557929039001\n",
      "Write summary at step 18700  Loss:  0.6740710139274597\n",
      "Write summary at step 18710  Loss:  0.6763550639152527\n",
      "Write summary at step 18720  Loss:  0.6805943250656128\n",
      "Write summary at step 18730  Loss:  0.687883198261261\n",
      "Write summary at step 18740  Loss:  0.7009080648422241\n",
      "Write summary at step 18750  Loss:  0.6949573755264282\n",
      "Write summary at step 18760  Loss:  0.7143257260322571\n",
      "Write summary at step 18770  Loss:  0.6775330305099487\n",
      "Write summary at step 18780  Loss:  0.6919021010398865\n",
      "Write summary at step 18790  Loss:  0.6717609763145447\n",
      "Write summary at step 18800  Loss:  0.6825581789016724\n",
      "Write summary at step 18810  Loss:  0.7080685496330261\n",
      "Write summary at step 18820  Loss:  0.701726496219635\n",
      "Write summary at step 18830  Loss:  0.6856541633605957\n",
      "Write summary at step 18840  Loss:  0.7016688585281372\n",
      "Write summary at step 18850  Loss:  0.6848536729812622\n",
      "Write summary at step 18860  Loss:  0.7059352993965149\n",
      "Write summary at step 18870  Loss:  0.7172654271125793\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6742750568823381 Loss Control: 0.6604344874131874 Loss Patient: 0.7270422217746576 Loss balanced:  0.6937383545939225 Loss1+loss2: 0.6937383545939225\n",
      "Write summary at step 18880  Loss:  0.7071880102157593\n",
      "Write summary at step 18890  Loss:  0.699342668056488\n",
      "Write summary at step 18900  Loss:  0.6916674971580505\n",
      "Write summary at step 18910  Loss:  0.6862736940383911\n",
      "Write summary at step 18920  Loss:  0.6874912977218628\n",
      "Write summary at step 18930  Loss:  0.7012940645217896\n",
      "Write summary at step 18940  Loss:  0.7195271253585815\n",
      "Write summary at step 18950  Loss:  0.6884040832519531\n",
      "Write summary at step 18960  Loss:  0.7196533679962158\n",
      "Write summary at step 18970  Loss:  0.7005537152290344\n",
      "Write summary at step 18980  Loss:  0.7228010296821594\n",
      "Write summary at step 18990  Loss:  0.6656211018562317\n",
      "Write summary at step 19000  Loss:  0.7031334638595581\n",
      "Saved checkpoint to: result/41/panns/checkpoint_19000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6981503210026464 Loss Control: 0.701526047753506 Loss Patient: 0.6852803031603495 Loss balanced:  0.6934031754569278 Loss1+loss2: 0.6934031754569278\n",
      "Write summary at step 19010  Loss:  0.6938687562942505\n",
      "Write summary at step 19020  Loss:  0.7176533341407776\n",
      "Write summary at step 19030  Loss:  0.6815455555915833\n",
      "Write summary at step 19040  Loss:  0.7142736911773682\n",
      "Write summary at step 19050  Loss:  0.6992273926734924\n",
      "Write summary at step 19060  Loss:  0.6980125904083252\n",
      "Write summary at step 19070  Loss:  0.6895976066589355\n",
      "Write summary at step 19080  Loss:  0.7029375433921814\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.696969696969697 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5244193989071039\n",
      "Loss normal: 0.6939576982935786 Loss Control: 0.6944318443048195 Loss Patient: 0.6921500464280447 Loss balanced:  0.6932909453664321 Loss1+loss2: 0.6932909453664321\n",
      "Write summary at step 19090  Loss:  0.6850732564926147\n",
      "Write summary at step 19100  Loss:  0.673815906047821\n",
      "Write summary at step 19110  Loss:  0.7095274329185486\n",
      "Write summary at step 19120  Loss:  0.6963443756103516\n",
      "Write summary at step 19130  Loss:  0.6910422444343567\n",
      "Write summary at step 19140  Loss:  0.6494120359420776\n",
      "Write summary at step 19150  Loss:  0.7020632028579712\n",
      "Write summary at step 19160  Loss:  0.7106621265411377\n",
      "Write summary at step 19170  Loss:  0.7108114957809448\n",
      "Write summary at step 19180  Loss:  0.7417429685592651\n",
      "Write summary at step 19190  Loss:  0.696669340133667\n",
      "Write summary at step 19200  Loss:  0.6852046847343445\n",
      "Write summary at step 19210  Loss:  0.676711916923523\n",
      "Write summary at step 19220  Loss:  0.6994041204452515\n",
      "Write summary at step 19230  Loss:  0.7024636268615723\n",
      "Write summary at step 19240  Loss:  0.6961417198181152\n",
      "Write summary at step 19250  Loss:  0.6944828629493713\n",
      "Write summary at step 19260  Loss:  0.6846745610237122\n",
      "Write summary at step 19270  Loss:  0.6916846036911011\n",
      "Write summary at step 19280  Loss:  0.7012150287628174\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.041666666666666664 Acurracy Balanced 0.49897540983606553\n",
      "Loss normal: 0.6810020151592436 Loss Control: 0.6724162609850775 Loss Patient: 0.7137352079153061 Loss balanced:  0.6930757344501918 Loss1+loss2: 0.6930757344501918\n",
      "Write summary at step 19290  Loss:  0.6834705471992493\n",
      "Write summary at step 19300  Loss:  0.6828298568725586\n",
      "Write summary at step 19310  Loss:  0.6751625537872314\n",
      "Write summary at step 19320  Loss:  0.696761965751648\n",
      "Write summary at step 19330  Loss:  0.6880013942718506\n",
      "Write summary at step 19340  Loss:  0.6871150135993958\n",
      "Write summary at step 19350  Loss:  0.6913868188858032\n",
      "Write summary at step 19360  Loss:  0.6948933601379395\n",
      "Write summary at step 19370  Loss:  0.6866533160209656\n",
      "Write summary at step 19380  Loss:  0.7166532874107361\n",
      "Write summary at step 19390  Loss:  0.7088285088539124\n",
      "Write summary at step 19400  Loss:  0.6944133043289185\n",
      "Write summary at step 19410  Loss:  0.6983368396759033\n",
      "Write summary at step 19420  Loss:  0.7118719816207886\n",
      "Write summary at step 19430  Loss:  0.6925736665725708\n",
      "Write summary at step 19440  Loss:  0.7030559182167053\n",
      "Write summary at step 19450  Loss:  0.6749956607818604\n",
      "Write summary at step 19460  Loss:  0.7003784775733948\n",
      "Write summary at step 19470  Loss:  0.7093346118927002\n",
      "Write summary at step 19480  Loss:  0.6847671866416931\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5064935064935064 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.375 Acurracy Balanced 0.45799180327868855\n",
      "Loss normal: 0.7016465307830216 Loss Control: 0.7070877258894873 Loss Patient: 0.6809019483625889 Loss balanced:  0.693994837126038 Loss1+loss2: 0.693994837126038\n",
      "Write summary at step 19490  Loss:  0.6915042400360107\n",
      "Write summary at step 19500  Loss:  0.7247068881988525\n",
      "Saved checkpoint to: result/41/panns/checkpoint_19500.pt\n",
      "Validation:\n",
      "Acurracy:  0.38095238095238093 Acurracy Control:  0.36065573770491804 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.4094945355191257\n",
      "Loss normal: 0.7057895087576532 Loss Control: 0.7129019290371671 Loss Patient: 0.6786734213431677 Loss balanced:  0.6957876751901674 Loss1+loss2: 0.6957876751901674\n",
      "Write summary at step 19510  Loss:  0.6895641088485718\n",
      "Write summary at step 19520  Loss:  0.7008517980575562\n",
      "Write summary at step 19530  Loss:  0.6946786046028137\n",
      "Write summary at step 19540  Loss:  0.6854584217071533\n",
      "Write summary at step 19550  Loss:  0.7053024768829346\n",
      "Write summary at step 19560  Loss:  0.6865566968917847\n",
      "Write summary at step 19570  Loss:  0.709010124206543\n",
      "Write summary at step 19580  Loss:  0.6747567653656006\n",
      "Write summary at step 19590  Loss:  0.6861181259155273\n",
      "Write summary at step 19600  Loss:  0.6654267311096191\n",
      "Write summary at step 19610  Loss:  0.6890287399291992\n",
      "Write summary at step 19620  Loss:  0.7416110038757324\n",
      "Write summary at step 19630  Loss:  0.6725773215293884\n",
      "Write summary at step 19640  Loss:  0.6601170897483826\n",
      "Write summary at step 19650  Loss:  0.6906179785728455\n",
      "Write summary at step 19660  Loss:  0.7110627293586731\n",
      "Write summary at step 19670  Loss:  0.689389705657959\n",
      "Write summary at step 19680  Loss:  0.6746487617492676\n",
      "Write summary at step 19690  Loss:  0.701086163520813\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6489015967298896 Loss Control: 0.615113204945632 Loss Patient: 0.7777198168138663 Loss balanced:  0.6964165108797491 Loss1+loss2: 0.6964165108797491\n",
      "Write summary at step 19700  Loss:  0.6832765340805054\n",
      "Write summary at step 19710  Loss:  0.6755315065383911\n",
      "Write summary at step 19720  Loss:  0.6802088022232056\n",
      "Write summary at step 19730  Loss:  0.6685029864311218\n",
      "Write summary at step 19740  Loss:  0.7279435396194458\n",
      "Write summary at step 19750  Loss:  0.6969819068908691\n",
      "Write summary at step 19760  Loss:  0.6978751420974731\n",
      "Write summary at step 19770  Loss:  0.6766542792320251\n",
      "Write summary at step 19780  Loss:  0.6939918994903564\n",
      "Write summary at step 19790  Loss:  0.6684736013412476\n",
      "Write summary at step 19800  Loss:  0.7111626863479614\n",
      "Write summary at step 19810  Loss:  0.6838841438293457\n",
      "Write summary at step 19820  Loss:  0.6892433166503906\n",
      "Write summary at step 19830  Loss:  0.6571403741836548\n",
      "Write summary at step 19840  Loss:  0.6946951150894165\n",
      "Write summary at step 19850  Loss:  0.6668176651000977\n",
      "Write summary at step 19860  Loss:  0.7024475932121277\n",
      "Write summary at step 19870  Loss:  0.6973505020141602\n",
      "Write summary at step 19880  Loss:  0.7112679481506348\n",
      "Write summary at step 19890  Loss:  0.6781838536262512\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7619047619047619 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5423497267759563\n",
      "Loss normal: 0.6815262674253224 Loss Control: 0.6741172221840405 Loss Patient: 0.7097732288142046 Loss balanced:  0.6919452254991225 Loss1+loss2: 0.6919452254991225\n",
      "Write summary at step 19900  Loss:  0.6759152412414551\n",
      "Write summary at step 19910  Loss:  0.6748825311660767\n",
      "Write summary at step 19920  Loss:  0.7092432379722595\n",
      "Write summary at step 19930  Loss:  0.6640834212303162\n",
      "Write summary at step 19940  Loss:  0.6833470463752747\n",
      "Write summary at step 19950  Loss:  0.6777709126472473\n",
      "Write summary at step 19960  Loss:  0.6781476140022278\n",
      "Write summary at step 19970  Loss:  0.6827571392059326\n",
      "Write summary at step 19980  Loss:  0.6943639516830444\n",
      "Write summary at step 19990  Loss:  0.6875365972518921\n",
      "Write summary at step 20000  Loss:  0.6804253458976746\n",
      "Saved checkpoint to: result/41/panns/checkpoint_20000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7012987012987013 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.3125 Acurracy Balanced 0.5578893442622951\n",
      "Loss normal: 0.6852760247853927 Loss Control: 0.6821793408993163 Loss Patient: 0.6970821830133597 Loss balanced:  0.689630761956338 Loss1+loss2: 0.689630761956338\n",
      "Write summary at step 20010  Loss:  0.6877780556678772\n",
      "Write summary at step 20020  Loss:  0.7080880403518677\n",
      "Write summary at step 20030  Loss:  0.6759668588638306\n",
      "Write summary at step 20040  Loss:  0.6771892309188843\n",
      "Write summary at step 20050  Loss:  0.673501193523407\n",
      "Write summary at step 20060  Loss:  0.6993153095245361\n",
      "Write summary at step 20070  Loss:  0.6943206787109375\n",
      "Write summary at step 20080  Loss:  0.6884603500366211\n",
      "Write summary at step 20090  Loss:  0.702067494392395\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2510822510822511 Acurracy Control:  0.09836065573770492 Acurracy Patient:  0.8333333333333334 Acurracy Balanced 0.46584699453551914\n",
      "Loss normal: 0.7027278013559647 Loss Control: 0.7097038682041272 Loss Patient: 0.6761315576732159 Loss balanced:  0.6929177129386715 Loss1+loss2: 0.6929177129386715\n",
      "Write summary at step 20100  Loss:  0.6829907894134521\n",
      "Write summary at step 20110  Loss:  0.7080217003822327\n",
      "Write summary at step 20120  Loss:  0.7058039307594299\n",
      "Write summary at step 20130  Loss:  0.6902022361755371\n",
      "Write summary at step 20140  Loss:  0.6902722120285034\n",
      "Write summary at step 20150  Loss:  0.708301305770874\n",
      "Write summary at step 20160  Loss:  0.6897335052490234\n",
      "Write summary at step 20170  Loss:  0.694645345211029\n",
      "Write summary at step 20180  Loss:  0.7066176533699036\n",
      "Write summary at step 20190  Loss:  0.6986915469169617\n",
      "Write summary at step 20200  Loss:  0.6549974083900452\n",
      "Write summary at step 20210  Loss:  0.7266280651092529\n",
      "Write summary at step 20220  Loss:  0.6547116637229919\n",
      "Write summary at step 20230  Loss:  0.7209703922271729\n",
      "Write summary at step 20240  Loss:  0.6987140774726868\n",
      "Write summary at step 20250  Loss:  0.7046024799346924\n",
      "Write summary at step 20260  Loss:  0.6870533227920532\n",
      "Write summary at step 20270  Loss:  0.6745262145996094\n",
      "Write summary at step 20280  Loss:  0.6812283992767334\n",
      "Write summary at step 20290  Loss:  0.6532597541809082\n",
      "Write summary at step 20300  Loss:  0.7012078762054443\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5367965367965368 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.5309084699453552\n",
      "Loss normal: 0.6959048034824851 Loss Control: 0.7002731483490741 Loss Patient: 0.6792504315574964 Loss balanced:  0.6897617899532853 Loss1+loss2: 0.6897617899532853\n",
      "------------------------------\n",
      "SEED: 41 Best Loss: 0.6880815556079475\n",
      "______________________________\n",
      "The Max Time dim Lenght is: 1498 (+- 29.96 seconds)\n",
      "The Min Time dim Lenght is: 19 (+- 0.38 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.7778714895248413\n",
      "Write summary at step 20  Loss:  0.914600670337677\n",
      "Write summary at step 30  Loss:  0.7990350723266602\n",
      "Write summary at step 40  Loss:  0.7980402112007141\n",
      "Write summary at step 50  Loss:  0.6867424249649048\n",
      "Write summary at step 60  Loss:  0.7178879976272583\n",
      "Write summary at step 70  Loss:  0.7176734209060669\n",
      "Write summary at step 80  Loss:  0.6993709802627563\n",
      "Write summary at step 90  Loss:  0.8046162128448486\n",
      "Write summary at step 100  Loss:  0.6587122678756714\n",
      "Write summary at step 110  Loss:  0.750012218952179\n",
      "Write summary at step 120  Loss:  0.608062207698822\n",
      "Write summary at step 130  Loss:  0.6867896318435669\n",
      "Write summary at step 140  Loss:  0.763872504234314\n",
      "Write summary at step 150  Loss:  0.7617288827896118\n",
      "Write summary at step 160  Loss:  0.6694085597991943\n",
      "Write summary at step 170  Loss:  0.7391451597213745\n",
      "Write summary at step 180  Loss:  0.6830199956893921\n",
      "Write summary at step 190  Loss:  0.6820266842842102\n",
      "Write summary at step 200  Loss:  0.6557407975196838\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6041219639571714 Loss Control: 0.5102219037670906 Loss Patient: 0.9621159260471662 Loss balanced:  0.7361689149071284 Loss1+loss2: 0.7361689149071284\n",
      "\n",
      " > BEST MODEL (0.73617) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 210  Loss:  0.728182852268219\n",
      "Write summary at step 220  Loss:  0.7153575420379639\n",
      "Write summary at step 230  Loss:  0.6490210294723511\n",
      "Write summary at step 240  Loss:  0.6352556943893433\n",
      "Write summary at step 250  Loss:  0.8957036733627319\n",
      "Write summary at step 260  Loss:  0.7607158422470093\n",
      "Write summary at step 270  Loss:  0.6864784955978394\n",
      "Write summary at step 280  Loss:  0.7172627449035645\n",
      "Write summary at step 290  Loss:  0.5767697095870972\n",
      "Write summary at step 300  Loss:  0.8939259648323059\n",
      "Write summary at step 310  Loss:  0.6788911819458008\n",
      "Write summary at step 320  Loss:  0.667701005935669\n",
      "Write summary at step 330  Loss:  0.643165111541748\n",
      "Write summary at step 340  Loss:  0.8327803611755371\n",
      "Write summary at step 350  Loss:  0.6460753679275513\n",
      "Write summary at step 360  Loss:  0.7296788692474365\n",
      "Write summary at step 370  Loss:  0.7439367175102234\n",
      "Write summary at step 380  Loss:  0.6299164295196533\n",
      "Write summary at step 390  Loss:  0.9659533500671387\n",
      "Write summary at step 400  Loss:  0.5937452912330627\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.24242424242424243 Acurracy Control:  0.06557377049180328 Acurracy Patient:  0.9166666666666666 Acurracy Balanced 0.49112021857923494\n",
      "Loss normal: 0.7619109076338929 Loss Control: 0.8062622618805515 Loss Patient: 0.5928213894367218 Loss balanced:  0.6995418256586367 Loss1+loss2: 0.6995418256586367\n",
      "\n",
      " > BEST MODEL (0.69954) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 410  Loss:  0.7546249628067017\n",
      "Write summary at step 420  Loss:  0.8854208588600159\n",
      "Write summary at step 430  Loss:  0.6835095882415771\n",
      "Write summary at step 440  Loss:  0.9159500598907471\n",
      "Write summary at step 450  Loss:  0.678059995174408\n",
      "Write summary at step 460  Loss:  0.8466963768005371\n",
      "Write summary at step 470  Loss:  1.2443045377731323\n",
      "Write summary at step 480  Loss:  0.8011005520820618\n",
      "Write summary at step 490  Loss:  0.7052022814750671\n",
      "Write summary at step 500  Loss:  0.5694252848625183\n",
      "Saved checkpoint to: result/42/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6615192531507252 Loss Control: 0.6378699550863172 Loss Patient: 0.7516822218894958 Loss balanced:  0.6947760884879065 Loss1+loss2: 0.6947760884879065\n",
      "\n",
      " > BEST MODEL (0.69478) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 510  Loss:  0.5754982233047485\n",
      "Write summary at step 520  Loss:  0.6934125423431396\n",
      "Write summary at step 530  Loss:  0.6124366521835327\n",
      "Write summary at step 540  Loss:  0.9111880660057068\n",
      "Write summary at step 550  Loss:  0.8467779159545898\n",
      "Write summary at step 560  Loss:  0.634781002998352\n",
      "Write summary at step 570  Loss:  0.7831400632858276\n",
      "Write summary at step 580  Loss:  0.6636812686920166\n",
      "Write summary at step 590  Loss:  0.6467950344085693\n",
      "Write summary at step 600  Loss:  0.7123063802719116\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7060043613115946 Loss Control: 0.7149805081346647 Loss Patient: 0.6717828388015429 Loss balanced:  0.6933816734681038 Loss1+loss2: 0.6933816734681038\n",
      "\n",
      " > BEST MODEL (0.69338) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 610  Loss:  0.7213437557220459\n",
      "Write summary at step 620  Loss:  0.7259963750839233\n",
      "Write summary at step 630  Loss:  0.7586263418197632\n",
      "Write summary at step 640  Loss:  0.6854974031448364\n",
      "Write summary at step 650  Loss:  0.6781297922134399\n",
      "Write summary at step 660  Loss:  0.6852297782897949\n",
      "Write summary at step 670  Loss:  0.726161539554596\n",
      "Write summary at step 680  Loss:  0.8054727911949158\n",
      "Write summary at step 690  Loss:  0.7033182382583618\n",
      "Write summary at step 700  Loss:  0.8155152797698975\n",
      "Write summary at step 710  Loss:  0.6456977128982544\n",
      "Write summary at step 720  Loss:  0.7450627088546753\n",
      "Write summary at step 730  Loss:  0.8600389361381531\n",
      "Write summary at step 740  Loss:  0.5576793551445007\n",
      "Write summary at step 750  Loss:  0.7163577079772949\n",
      "Write summary at step 760  Loss:  0.7397616505622864\n",
      "Write summary at step 770  Loss:  0.7440914511680603\n",
      "Write summary at step 780  Loss:  0.6459254026412964\n",
      "Write summary at step 790  Loss:  0.6408646106719971\n",
      "Write summary at step 800  Loss:  0.6982022523880005\n",
      "Write summary at step 810  Loss:  0.6916795969009399\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7213545800287486 Loss Control: 0.7406378971422957 Loss Patient: 0.6478369583686193 Loss balanced:  0.6942374277554575 Loss1+loss2: 0.6942374277554575\n",
      "Write summary at step 820  Loss:  0.641343355178833\n",
      "Write summary at step 830  Loss:  0.87342369556427\n",
      "Write summary at step 840  Loss:  0.6046978831291199\n",
      "Write summary at step 850  Loss:  0.6656229496002197\n",
      "Write summary at step 860  Loss:  0.6892513036727905\n",
      "Write summary at step 870  Loss:  0.7928081750869751\n",
      "Write summary at step 880  Loss:  0.74566650390625\n",
      "Write summary at step 890  Loss:  0.7591637372970581\n",
      "Write summary at step 900  Loss:  0.7170122265815735\n",
      "Write summary at step 910  Loss:  0.699570894241333\n",
      "Write summary at step 920  Loss:  0.7379399538040161\n",
      "Write summary at step 930  Loss:  0.7058522701263428\n",
      "Write summary at step 940  Loss:  0.6935700178146362\n",
      "Write summary at step 950  Loss:  0.704164445400238\n",
      "Write summary at step 960  Loss:  0.7093119621276855\n",
      "Write summary at step 970  Loss:  0.7539405822753906\n",
      "Write summary at step 980  Loss:  0.6987216472625732\n",
      "Write summary at step 990  Loss:  0.7092218399047852\n",
      "Write summary at step 1000  Loss:  0.6780486106872559\n",
      "Saved checkpoint to: result/42/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6554299223990667 Loss Control: 0.626934559293132 Loss Patient: 0.7640686010320982 Loss balanced:  0.6955015801626151 Loss1+loss2: 0.6955015801626151\n",
      "Write summary at step 1010  Loss:  0.7139900922775269\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7313659769116025 Loss Control: 0.7571715123015024 Loss Patient: 0.6329822962482771 Loss balanced:  0.6950769042748897 Loss1+loss2: 0.6950769042748897\n",
      "Write summary at step 1020  Loss:  0.6974570751190186\n",
      "Write summary at step 1030  Loss:  0.7430763244628906\n",
      "Write summary at step 1040  Loss:  0.6229491233825684\n",
      "Write summary at step 1050  Loss:  0.6713199019432068\n",
      "Write summary at step 1060  Loss:  0.6388949155807495\n",
      "Write summary at step 1070  Loss:  0.6668460369110107\n",
      "Write summary at step 1080  Loss:  0.6861839294433594\n",
      "Write summary at step 1090  Loss:  0.6958767175674438\n",
      "Write summary at step 1100  Loss:  0.704619288444519\n",
      "Write summary at step 1110  Loss:  0.6587135791778564\n",
      "Write summary at step 1120  Loss:  0.6291693449020386\n",
      "Write summary at step 1130  Loss:  0.6971706748008728\n",
      "Write summary at step 1140  Loss:  0.7209898233413696\n",
      "Write summary at step 1150  Loss:  0.7099589705467224\n",
      "Write summary at step 1160  Loss:  0.68107670545578\n",
      "Write summary at step 1170  Loss:  0.7957839369773865\n",
      "Write summary at step 1180  Loss:  0.677731454372406\n",
      "Write summary at step 1190  Loss:  0.61082923412323\n",
      "Write summary at step 1200  Loss:  0.686327338218689\n",
      "Write summary at step 1210  Loss:  0.710515558719635\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6674074953768676 Loss Control: 0.6483561162088738 Loss Patient: 0.7400409107406934 Loss balanced:  0.6941985134747837 Loss1+loss2: 0.6941985134747837\n",
      "Write summary at step 1220  Loss:  0.7681174278259277\n",
      "Write summary at step 1230  Loss:  0.7216660380363464\n",
      "Write summary at step 1240  Loss:  0.6946513652801514\n",
      "Write summary at step 1250  Loss:  0.7363705635070801\n",
      "Write summary at step 1260  Loss:  0.5848894715309143\n",
      "Write summary at step 1270  Loss:  0.6490718722343445\n",
      "Write summary at step 1280  Loss:  0.6985024809837341\n",
      "Write summary at step 1290  Loss:  0.6466288566589355\n",
      "Write summary at step 1300  Loss:  0.7478591799736023\n",
      "Write summary at step 1310  Loss:  0.735565185546875\n",
      "Write summary at step 1320  Loss:  0.7208446264266968\n",
      "Write summary at step 1330  Loss:  0.7444254159927368\n",
      "Write summary at step 1340  Loss:  0.6870477199554443\n",
      "Write summary at step 1350  Loss:  0.7604227662086487\n",
      "Write summary at step 1360  Loss:  0.6639662384986877\n",
      "Write summary at step 1370  Loss:  0.703035831451416\n",
      "Write summary at step 1380  Loss:  0.7235713601112366\n",
      "Write summary at step 1390  Loss:  0.7104345560073853\n",
      "Write summary at step 1400  Loss:  0.7295513153076172\n",
      "Write summary at step 1410  Loss:  0.6955585479736328\n",
      "Write summary at step 1420  Loss:  0.6459609270095825\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6608632555255642 Loss Control: 0.6367050357203666 Loss Patient: 0.7529665765662988 Loss balanced:  0.6948358061433327 Loss1+loss2: 0.6948358061433327\n",
      "Write summary at step 1430  Loss:  0.6852903366088867\n",
      "Write summary at step 1440  Loss:  0.6723767518997192\n",
      "Write summary at step 1450  Loss:  0.6616686582565308\n",
      "Write summary at step 1460  Loss:  0.7419127821922302\n",
      "Write summary at step 1470  Loss:  0.6515603065490723\n",
      "Write summary at step 1480  Loss:  0.758000373840332\n",
      "Write summary at step 1490  Loss:  0.7117562294006348\n",
      "Write summary at step 1500  Loss:  0.6754754781723022\n",
      "Saved checkpoint to: result/42/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7149170817750873 Loss Control: 0.7299337334971611 Loss Patient: 0.6576660337547461 Loss balanced:  0.6937998836259536 Loss1+loss2: 0.6937998836259536\n",
      "Write summary at step 1510  Loss:  0.6841739416122437\n",
      "Write summary at step 1520  Loss:  0.6916162967681885\n",
      "Write summary at step 1530  Loss:  0.6428987383842468\n",
      "Write summary at step 1540  Loss:  0.7522302865982056\n",
      "Write summary at step 1550  Loss:  0.6833435893058777\n",
      "Write summary at step 1560  Loss:  0.738926887512207\n",
      "Write summary at step 1570  Loss:  0.675273060798645\n",
      "Write summary at step 1580  Loss:  0.6828519105911255\n",
      "Write summary at step 1590  Loss:  0.6980263590812683\n",
      "Write summary at step 1600  Loss:  0.679440438747406\n",
      "Write summary at step 1610  Loss:  0.7020467519760132\n",
      "Write summary at step 1620  Loss:  0.6992113590240479\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6530061333210437 Loss Control: 0.6225540035409354 Loss Patient: 0.7691048259536425 Loss balanced:  0.695829414747289 Loss1+loss2: 0.695829414747289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 1630  Loss:  0.7489781379699707\n",
      "Write summary at step 1640  Loss:  0.7083156704902649\n",
      "Write summary at step 1650  Loss:  0.6852085590362549\n",
      "Write summary at step 1660  Loss:  0.7344980835914612\n",
      "Write summary at step 1670  Loss:  0.7251105904579163\n",
      "Write summary at step 1680  Loss:  0.6780823469161987\n",
      "Write summary at step 1690  Loss:  0.7313027381896973\n",
      "Write summary at step 1700  Loss:  0.718264639377594\n",
      "Write summary at step 1710  Loss:  0.6446746587753296\n",
      "Write summary at step 1720  Loss:  0.7024391889572144\n",
      "Write summary at step 1730  Loss:  0.6712460517883301\n",
      "Write summary at step 1740  Loss:  0.6919499635696411\n",
      "Write summary at step 1750  Loss:  0.7086470127105713\n",
      "Write summary at step 1760  Loss:  0.6614428162574768\n",
      "Write summary at step 1770  Loss:  0.6818189024925232\n",
      "Write summary at step 1780  Loss:  0.754205584526062\n",
      "Write summary at step 1790  Loss:  0.6759482026100159\n",
      "Write summary at step 1800  Loss:  0.7316205501556396\n",
      "Write summary at step 1810  Loss:  0.6640844345092773\n",
      "Write summary at step 1820  Loss:  0.6694608330726624\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6808096041411033 Loss Control: 0.671871793726103 Loss Patient: 0.7148849306007227 Loss balanced:  0.6933783621634129 Loss1+loss2: 0.6933783621634129\n",
      "\n",
      " > BEST MODEL (0.69338) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1830  Loss:  0.706731915473938\n",
      "Write summary at step 1840  Loss:  0.6761269569396973\n",
      "Write summary at step 1850  Loss:  0.6717214584350586\n",
      "Write summary at step 1860  Loss:  0.6607407927513123\n",
      "Write summary at step 1870  Loss:  0.7190860509872437\n",
      "Write summary at step 1880  Loss:  0.728036642074585\n",
      "Write summary at step 1890  Loss:  0.7000465393066406\n",
      "Write summary at step 1900  Loss:  0.6894940137863159\n",
      "Write summary at step 1910  Loss:  0.7120914459228516\n",
      "Write summary at step 1920  Loss:  0.6655004024505615\n",
      "Write summary at step 1930  Loss:  0.6986244916915894\n",
      "Write summary at step 1940  Loss:  0.7124600410461426\n",
      "Write summary at step 1950  Loss:  0.6678423881530762\n",
      "Write summary at step 1960  Loss:  0.6903582811355591\n",
      "Write summary at step 1970  Loss:  0.7597922086715698\n",
      "Write summary at step 1980  Loss:  0.6486541032791138\n",
      "Write summary at step 1990  Loss:  0.6250230073928833\n",
      "Write summary at step 2000  Loss:  0.725820004940033\n",
      "Saved checkpoint to: result/42/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7194386710336198 Loss Control: 0.7374659789715959 Loss Patient: 0.6507095098495483 Loss balanced:  0.6940877444105722 Loss1+loss2: 0.6940877444105722\n",
      "Write summary at step 2010  Loss:  0.7238372564315796\n",
      "Write summary at step 2020  Loss:  0.6860537528991699\n",
      "Write summary at step 2030  Loss:  0.6988343000411987\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6603507621463759 Loss Control: 0.6357874267739676 Loss Patient: 0.7539984111984571 Loss balanced:  0.6948929189862123 Loss1+loss2: 0.6948929189862123\n",
      "Write summary at step 2040  Loss:  0.7089920043945312\n",
      "Write summary at step 2050  Loss:  0.7244436740875244\n",
      "Write summary at step 2060  Loss:  0.683036208152771\n",
      "Write summary at step 2070  Loss:  0.7300593852996826\n",
      "Write summary at step 2080  Loss:  0.6582157611846924\n",
      "Write summary at step 2090  Loss:  0.6965936422348022\n",
      "Write summary at step 2100  Loss:  0.6882826685905457\n",
      "Write summary at step 2110  Loss:  0.6794257164001465\n",
      "Write summary at step 2120  Loss:  0.6575114130973816\n",
      "Write summary at step 2130  Loss:  0.6618927121162415\n",
      "Write summary at step 2140  Loss:  0.7000277042388916\n",
      "Write summary at step 2150  Loss:  0.6903293132781982\n",
      "Write summary at step 2160  Loss:  0.7634931802749634\n",
      "Write summary at step 2170  Loss:  0.7488130331039429\n",
      "Write summary at step 2180  Loss:  0.6342126131057739\n",
      "Write summary at step 2190  Loss:  0.661960244178772\n",
      "Write summary at step 2200  Loss:  0.7001791000366211\n",
      "Write summary at step 2210  Loss:  0.7025020122528076\n",
      "Write summary at step 2220  Loss:  0.7048263549804688\n",
      "Write summary at step 2230  Loss:  0.7026260495185852\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.669685398087357 Loss Control: 0.6523855335074045 Loss Patient: 0.7356411752601465 Loss balanced:  0.6940133543837754 Loss1+loss2: 0.6940133543837754\n",
      "Write summary at step 2240  Loss:  0.6942848563194275\n",
      "Write summary at step 2250  Loss:  0.7163524627685547\n",
      "Write summary at step 2260  Loss:  0.6834245920181274\n",
      "Write summary at step 2270  Loss:  0.6600268483161926\n",
      "Write summary at step 2280  Loss:  0.6887062788009644\n",
      "Write summary at step 2290  Loss:  0.7068745493888855\n",
      "Write summary at step 2300  Loss:  0.7277394533157349\n",
      "Write summary at step 2310  Loss:  0.6667129993438721\n",
      "Write summary at step 2320  Loss:  0.7170947790145874\n",
      "Write summary at step 2330  Loss:  0.6917067766189575\n",
      "Write summary at step 2340  Loss:  0.7023159265518188\n",
      "Write summary at step 2350  Loss:  0.7055009603500366\n",
      "Write summary at step 2360  Loss:  0.6969348788261414\n",
      "Write summary at step 2370  Loss:  0.6834419965744019\n",
      "Write summary at step 2380  Loss:  0.6832787990570068\n",
      "Write summary at step 2390  Loss:  0.6796973943710327\n",
      "Write summary at step 2400  Loss:  0.7357280850410461\n",
      "Write summary at step 2410  Loss:  0.676250696182251\n",
      "Write summary at step 2420  Loss:  0.7376683950424194\n",
      "Write summary at step 2430  Loss:  0.6910988092422485\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6889859032837343 Loss Control: 0.68600852665354 Loss Patient: 0.7003372783462206 Loss balanced:  0.6931729024998803 Loss1+loss2: 0.6931729024998803\n",
      "\n",
      " > BEST MODEL (0.69317) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2440  Loss:  0.71416175365448\n",
      "Write summary at step 2450  Loss:  0.6736108660697937\n",
      "Write summary at step 2460  Loss:  0.6626805663108826\n",
      "Write summary at step 2470  Loss:  0.6999486684799194\n",
      "Write summary at step 2480  Loss:  0.6937974095344543\n",
      "Write summary at step 2490  Loss:  0.7138880491256714\n",
      "Write summary at step 2500  Loss:  0.7177948951721191\n",
      "Saved checkpoint to: result/42/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6764363618124098 Loss Control: 0.6642474222704361 Loss Patient: 0.7229066553215185 Loss balanced:  0.6935770387959773 Loss1+loss2: 0.6935770387959773\n",
      "Write summary at step 2510  Loss:  0.6830567717552185\n",
      "Write summary at step 2520  Loss:  0.6581103801727295\n",
      "Write summary at step 2530  Loss:  0.708930492401123\n",
      "Write summary at step 2540  Loss:  0.6656668186187744\n",
      "Write summary at step 2550  Loss:  0.6717929840087891\n",
      "Write summary at step 2560  Loss:  0.7021758556365967\n",
      "Write summary at step 2570  Loss:  0.7037370204925537\n",
      "Write summary at step 2580  Loss:  0.739107608795166\n",
      "Write summary at step 2590  Loss:  0.6923890113830566\n",
      "Write summary at step 2600  Loss:  0.6773737668991089\n",
      "Write summary at step 2610  Loss:  0.7256373763084412\n",
      "Write summary at step 2620  Loss:  0.7263080477714539\n",
      "Write summary at step 2630  Loss:  0.7020390033721924\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6849877684663385 Loss Control: 0.6791144622479631 Loss Patient: 0.7073796453575293 Loss balanced:  0.6932470538027462 Loss1+loss2: 0.6932470538027462\n",
      "Write summary at step 2640  Loss:  0.6595258712768555\n",
      "Write summary at step 2650  Loss:  0.6917698979377747\n",
      "Write summary at step 2660  Loss:  0.6720561385154724\n",
      "Write summary at step 2670  Loss:  0.7120452523231506\n",
      "Write summary at step 2680  Loss:  0.7037767171859741\n",
      "Write summary at step 2690  Loss:  0.6836034059524536\n",
      "Write summary at step 2700  Loss:  0.6611266136169434\n",
      "Write summary at step 2710  Loss:  0.7042959332466125\n",
      "Write summary at step 2720  Loss:  0.7115897536277771\n",
      "Write summary at step 2730  Loss:  0.6492310762405396\n",
      "Write summary at step 2740  Loss:  0.7094752788543701\n",
      "Write summary at step 2750  Loss:  0.6988173723220825\n",
      "Write summary at step 2760  Loss:  0.7190540432929993\n",
      "Write summary at step 2770  Loss:  0.6917728185653687\n",
      "Write summary at step 2780  Loss:  0.7227799892425537\n",
      "Write summary at step 2790  Loss:  0.7015489935874939\n",
      "Write summary at step 2800  Loss:  0.6522723436355591\n",
      "Write summary at step 2810  Loss:  0.7202546000480652\n",
      "Write summary at step 2820  Loss:  0.7487910985946655\n",
      "Write summary at step 2830  Loss:  0.7233855128288269\n",
      "Write summary at step 2840  Loss:  0.6795603036880493\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7100380705548571 Loss Control: 0.7217662334442139 Loss Patient: 0.6653244495391846 Loss balanced:  0.6935453414916992 Loss1+loss2: 0.6935453414916992\n",
      "Write summary at step 2850  Loss:  0.7053829431533813\n",
      "Write summary at step 2860  Loss:  0.713129997253418\n",
      "Write summary at step 2870  Loss:  0.7825636863708496\n",
      "Write summary at step 2880  Loss:  0.7395608425140381\n",
      "Write summary at step 2890  Loss:  0.6910063028335571\n",
      "Write summary at step 2900  Loss:  0.7040317058563232\n",
      "Write summary at step 2910  Loss:  0.7003506422042847\n",
      "Write summary at step 2920  Loss:  0.6807906627655029\n",
      "Write summary at step 2930  Loss:  0.6974728107452393\n",
      "Write summary at step 2940  Loss:  0.7261233329772949\n",
      "Write summary at step 2950  Loss:  0.6854568719863892\n",
      "Write summary at step 2960  Loss:  0.6540533304214478\n",
      "Write summary at step 2970  Loss:  0.7356286644935608\n",
      "Write summary at step 2980  Loss:  0.6667931079864502\n",
      "Write summary at step 2990  Loss:  0.6161884665489197\n",
      "Write summary at step 3000  Loss:  0.6436057686805725\n",
      "Saved checkpoint to: result/42/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.644662552581721 Loss Control: 0.6073172092437744 Loss Patient: 0.7870415983100733 Loss balanced:  0.6971794037769239 Loss1+loss2: 0.6971794037769239\n",
      "Write summary at step 3010  Loss:  0.6932736039161682\n",
      "Write summary at step 3020  Loss:  0.690034806728363\n",
      "Write summary at step 3030  Loss:  0.691616415977478\n",
      "Write summary at step 3040  Loss:  0.6851227283477783\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6915901424564841 Loss Control: 0.6904803527508928 Loss Patient: 0.6958211536208788 Loss balanced:  0.6931507531858858 Loss1+loss2: 0.6931507531858858\n",
      "\n",
      " > BEST MODEL (0.69315) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 3050  Loss:  0.7030202746391296\n",
      "Write summary at step 3060  Loss:  0.7185186147689819\n",
      "Write summary at step 3070  Loss:  0.6740310788154602\n",
      "Write summary at step 3080  Loss:  0.6911617517471313\n",
      "Write summary at step 3090  Loss:  0.6712267398834229\n",
      "Write summary at step 3100  Loss:  0.6863274574279785\n",
      "Write summary at step 3110  Loss:  0.7292251586914062\n",
      "Write summary at step 3120  Loss:  0.7780196666717529\n",
      "Write summary at step 3130  Loss:  0.7052814960479736\n",
      "Write summary at step 3140  Loss:  0.7520161867141724\n",
      "Write summary at step 3150  Loss:  0.6706680059432983\n",
      "Write summary at step 3160  Loss:  0.6859481334686279\n",
      "Write summary at step 3170  Loss:  0.6892577409744263\n",
      "Write summary at step 3180  Loss:  0.702389121055603\n",
      "Write summary at step 3190  Loss:  0.6631563305854797\n",
      "Write summary at step 3200  Loss:  0.725308895111084\n",
      "Write summary at step 3210  Loss:  0.6920324563980103\n",
      "Write summary at step 3220  Loss:  0.7070412635803223\n",
      "Write summary at step 3230  Loss:  0.6972653865814209\n",
      "Write summary at step 3240  Loss:  0.6581690311431885\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6715997723273901 Loss Control: 0.6557608383600829 Loss Patient: 0.7319858074188232 Loss balanced:  0.6938733228894531 Loss1+loss2: 0.6938733228894531\n",
      "Write summary at step 3250  Loss:  0.704592227935791\n",
      "Write summary at step 3260  Loss:  0.6572790145874023\n",
      "Write summary at step 3270  Loss:  0.6843723058700562\n",
      "Write summary at step 3280  Loss:  0.7961209416389465\n",
      "Write summary at step 3290  Loss:  0.700387716293335\n",
      "Write summary at step 3300  Loss:  0.6929394006729126\n",
      "Write summary at step 3310  Loss:  0.6927575469017029\n",
      "Write summary at step 3320  Loss:  0.6868845224380493\n",
      "Write summary at step 3330  Loss:  0.6915370225906372\n",
      "Write summary at step 3340  Loss:  0.7368761301040649\n",
      "Write summary at step 3350  Loss:  0.6909036636352539\n",
      "Write summary at step 3360  Loss:  0.7200959920883179\n",
      "Write summary at step 3370  Loss:  0.6761590242385864\n",
      "Write summary at step 3380  Loss:  0.71370929479599\n",
      "Write summary at step 3390  Loss:  0.6227277517318726\n",
      "Write summary at step 3400  Loss:  0.6928080916404724\n",
      "Write summary at step 3410  Loss:  0.6856410503387451\n",
      "Write summary at step 3420  Loss:  0.6894837021827698\n",
      "Write summary at step 3430  Loss:  0.6840093731880188\n",
      "Write summary at step 3440  Loss:  0.7116237878799438\n",
      "Write summary at step 3450  Loss:  0.6872749328613281\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7140197072710309 Loss Control: 0.7284346825438119 Loss Patient: 0.6590625581641992 Loss balanced:  0.6937486203540055 Loss1+loss2: 0.6937486203540055\n",
      "Write summary at step 3460  Loss:  0.6876162886619568\n",
      "Write summary at step 3470  Loss:  0.7044699192047119\n",
      "Write summary at step 3480  Loss:  0.6921539306640625\n",
      "Write summary at step 3490  Loss:  0.6795612573623657\n",
      "Write summary at step 3500  Loss:  0.7489965558052063\n",
      "Saved checkpoint to: result/42/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7383781635400021 Loss Control: 0.7686567306518555 Loss Patient: 0.6229411897559961 Loss balanced:  0.6957989602039258 Loss1+loss2: 0.6957989602039258\n",
      "Write summary at step 3510  Loss:  0.6595131158828735\n",
      "Write summary at step 3520  Loss:  0.6925579905509949\n",
      "Write summary at step 3530  Loss:  0.6749213933944702\n",
      "Write summary at step 3540  Loss:  0.7267496585845947\n",
      "Write summary at step 3550  Loss:  0.7295729517936707\n",
      "Write summary at step 3560  Loss:  0.6866171360015869\n",
      "Write summary at step 3570  Loss:  0.7201046943664551\n",
      "Write summary at step 3580  Loss:  0.7092130184173584\n",
      "Write summary at step 3590  Loss:  0.6987260580062866\n",
      "Write summary at step 3600  Loss:  0.732041597366333\n",
      "Write summary at step 3610  Loss:  0.7052215337753296\n",
      "Write summary at step 3620  Loss:  0.6940121650695801\n",
      "Write summary at step 3630  Loss:  0.6535757780075073\n",
      "Write summary at step 3640  Loss:  0.7510726451873779\n",
      "Write summary at step 3650  Loss:  0.6667571067810059\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6648270557453106 Loss Control: 0.6437764167785645 Loss Patient: 0.7450826826194922 Loss balanced:  0.6944295496990283 Loss1+loss2: 0.6944295496990283\n",
      "Write summary at step 3660  Loss:  0.6386623382568359\n",
      "Write summary at step 3670  Loss:  0.6878260970115662\n",
      "Write summary at step 3680  Loss:  0.6452486515045166\n",
      "Write summary at step 3690  Loss:  0.7056237459182739\n",
      "Write summary at step 3700  Loss:  0.684445858001709\n",
      "Write summary at step 3710  Loss:  0.6961041688919067\n",
      "Write summary at step 3720  Loss:  0.6928228735923767\n",
      "Write summary at step 3730  Loss:  0.6847487688064575\n",
      "Write summary at step 3740  Loss:  0.6673669815063477\n",
      "Write summary at step 3750  Loss:  0.6811891198158264\n",
      "Write summary at step 3760  Loss:  0.7012701034545898\n",
      "Write summary at step 3770  Loss:  0.7325182557106018\n",
      "Write summary at step 3780  Loss:  0.704035758972168\n",
      "Write summary at step 3790  Loss:  0.7345215082168579\n",
      "Write summary at step 3800  Loss:  0.691994309425354\n",
      "Write summary at step 3810  Loss:  0.7051417827606201\n",
      "Write summary at step 3820  Loss:  0.7170546054840088\n",
      "Write summary at step 3830  Loss:  0.6846346259117126\n",
      "Write summary at step 3840  Loss:  0.6852279901504517\n",
      "Write summary at step 3850  Loss:  0.6905491948127747\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6793718379297298 Loss Control: 0.669370174407959 Loss Patient: 0.717503243436416 Loss balanced:  0.6934367089221876 Loss1+loss2: 0.6934367089221876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 3860  Loss:  0.7038064002990723\n",
      "Write summary at step 3870  Loss:  0.6547338962554932\n",
      "Write summary at step 3880  Loss:  0.6881608963012695\n",
      "Write summary at step 3890  Loss:  0.6907896995544434\n",
      "Write summary at step 3900  Loss:  0.7046637535095215\n",
      "Write summary at step 3910  Loss:  0.7139588594436646\n",
      "Write summary at step 3920  Loss:  0.6923511028289795\n",
      "Write summary at step 3930  Loss:  0.7202032804489136\n",
      "Write summary at step 3940  Loss:  0.6939405202865601\n",
      "Write summary at step 3950  Loss:  0.6918554902076721\n",
      "Write summary at step 3960  Loss:  0.7309451103210449\n",
      "Write summary at step 3970  Loss:  0.7152705192565918\n",
      "Write summary at step 3980  Loss:  0.6750369071960449\n",
      "Write summary at step 3990  Loss:  0.6743823289871216\n",
      "Write summary at step 4000  Loss:  0.6369959115982056\n",
      "Saved checkpoint to: result/42/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7090089042465408 Loss Control: 0.7200379371643066 Loss Patient: 0.6669606504340967 Loss balanced:  0.6934992937992017 Loss1+loss2: 0.6934992937992017\n",
      "Write summary at step 4010  Loss:  0.7266383171081543\n",
      "Write summary at step 4020  Loss:  0.676829993724823\n",
      "Write summary at step 4030  Loss:  0.7188944816589355\n",
      "Write summary at step 4040  Loss:  0.6997935771942139\n",
      "Write summary at step 4050  Loss:  0.6932510733604431\n",
      "Write summary at step 4060  Loss:  0.7032825946807861\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7166306446124981 Loss Control: 0.7327923774719238 Loss Patient: 0.6550139722724756 Loss balanced:  0.6939031748721998 Loss1+loss2: 0.6939031748721998\n",
      "Write summary at step 4070  Loss:  0.7229230999946594\n",
      "Write summary at step 4080  Loss:  0.7213962078094482\n",
      "Write summary at step 4090  Loss:  0.6712712049484253\n",
      "Write summary at step 4100  Loss:  0.7046295404434204\n",
      "Write summary at step 4110  Loss:  0.6718865036964417\n",
      "Write summary at step 4120  Loss:  0.7177680134773254\n",
      "Write summary at step 4130  Loss:  0.7016971111297607\n",
      "Write summary at step 4140  Loss:  0.7007856369018555\n",
      "Write summary at step 4150  Loss:  0.6818751096725464\n",
      "Write summary at step 4160  Loss:  0.6993513703346252\n",
      "Write summary at step 4170  Loss:  0.6605043411254883\n",
      "Write summary at step 4180  Loss:  0.6848834753036499\n",
      "Write summary at step 4190  Loss:  0.7041482925415039\n",
      "Write summary at step 4200  Loss:  0.7121673226356506\n",
      "Write summary at step 4210  Loss:  0.6579184532165527\n",
      "Write summary at step 4220  Loss:  0.6916927099227905\n",
      "Write summary at step 4230  Loss:  0.7048349380493164\n",
      "Write summary at step 4240  Loss:  0.7352099418640137\n",
      "Write summary at step 4250  Loss:  0.690159022808075\n",
      "Write summary at step 4260  Loss:  0.6759364008903503\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6627051858674913 Loss Control: 0.639996455341089 Loss Patient: 0.7492821874717871 Loss balanced:  0.694639321406438 Loss1+loss2: 0.694639321406438\n",
      "Write summary at step 4270  Loss:  0.6976207494735718\n",
      "Write summary at step 4280  Loss:  0.7122383117675781\n",
      "Write summary at step 4290  Loss:  0.7061702013015747\n",
      "Write summary at step 4300  Loss:  0.6892305612564087\n",
      "Write summary at step 4310  Loss:  0.7099072933197021\n",
      "Write summary at step 4320  Loss:  0.7369894981384277\n",
      "Write summary at step 4330  Loss:  0.70691978931427\n",
      "Write summary at step 4340  Loss:  0.7290012836456299\n",
      "Write summary at step 4350  Loss:  0.6918245553970337\n",
      "Write summary at step 4360  Loss:  0.6778234243392944\n",
      "Write summary at step 4370  Loss:  0.674037754535675\n",
      "Write summary at step 4380  Loss:  0.6969472169876099\n",
      "Write summary at step 4390  Loss:  0.6954584121704102\n",
      "Write summary at step 4400  Loss:  0.7095004320144653\n",
      "Write summary at step 4410  Loss:  0.6967706680297852\n",
      "Write summary at step 4420  Loss:  0.7303388118743896\n",
      "Write summary at step 4430  Loss:  0.7229771018028259\n",
      "Write summary at step 4440  Loss:  0.7044495344161987\n",
      "Write summary at step 4450  Loss:  0.6857256889343262\n",
      "Write summary at step 4460  Loss:  0.7097613215446472\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6458002063103052 Loss Control: 0.6094083053166749 Loss Patient: 0.7845443362991015 Loss balanced:  0.6969763208078882 Loss1+loss2: 0.6969763208078882\n",
      "Write summary at step 4470  Loss:  0.6740652322769165\n",
      "Write summary at step 4480  Loss:  0.6478283405303955\n",
      "Write summary at step 4490  Loss:  0.6776858568191528\n",
      "Write summary at step 4500  Loss:  0.6786569356918335\n",
      "Saved checkpoint to: result/42/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7122203253564381 Loss Control: 0.7254240959068465 Loss Patient: 0.6618809041877588 Loss balanced:  0.6936525000473026 Loss1+loss2: 0.6936525000473026\n",
      "Write summary at step 4510  Loss:  0.6972479820251465\n",
      "Write summary at step 4520  Loss:  0.7178072929382324\n",
      "Write summary at step 4530  Loss:  0.6896103620529175\n",
      "Write summary at step 4540  Loss:  0.650073766708374\n",
      "Write summary at step 4550  Loss:  0.6750807762145996\n",
      "Write summary at step 4560  Loss:  0.6904004812240601\n",
      "Write summary at step 4570  Loss:  0.6936815977096558\n",
      "Write summary at step 4580  Loss:  0.6684349775314331\n",
      "Write summary at step 4590  Loss:  0.7176156640052795\n",
      "Write summary at step 4600  Loss:  0.6306960582733154\n",
      "Write summary at step 4610  Loss:  0.7191677093505859\n",
      "Write summary at step 4620  Loss:  0.6678504943847656\n",
      "Write summary at step 4630  Loss:  0.6846297979354858\n",
      "Write summary at step 4640  Loss:  0.6857333183288574\n",
      "Write summary at step 4650  Loss:  0.6783964037895203\n",
      "Write summary at step 4660  Loss:  0.7281231880187988\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.668356863967268 Loss Control: 0.6500363069805292 Loss Patient: 0.7382040359079838 Loss balanced:  0.6941201714442564 Loss1+loss2: 0.6941201714442564\n",
      "Write summary at step 4670  Loss:  0.691866934299469\n",
      "Write summary at step 4680  Loss:  0.7255774140357971\n",
      "Write summary at step 4690  Loss:  0.6871517896652222\n",
      "Write summary at step 4700  Loss:  0.6945354342460632\n",
      "Write summary at step 4710  Loss:  0.6714276075363159\n",
      "Write summary at step 4720  Loss:  0.7045900821685791\n",
      "Write summary at step 4730  Loss:  0.7013608813285828\n",
      "Write summary at step 4740  Loss:  0.705008864402771\n",
      "Write summary at step 4750  Loss:  0.6998841166496277\n",
      "Write summary at step 4760  Loss:  0.6769049167633057\n",
      "Write summary at step 4770  Loss:  0.7050171494483948\n",
      "Write summary at step 4780  Loss:  0.7469910383224487\n",
      "Write summary at step 4790  Loss:  0.6745892763137817\n",
      "Write summary at step 4800  Loss:  0.7019743323326111\n",
      "Write summary at step 4810  Loss:  0.6969788670539856\n",
      "Write summary at step 4820  Loss:  0.6785248517990112\n",
      "Write summary at step 4830  Loss:  0.7171862125396729\n",
      "Write summary at step 4840  Loss:  0.6890425682067871\n",
      "Write summary at step 4850  Loss:  0.7086135149002075\n",
      "Write summary at step 4860  Loss:  0.6728870868682861\n",
      "Write summary at step 4870  Loss:  0.7003369331359863\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.0 Acurracy Balanced 0.4972677595628415\n",
      "Loss normal: 0.6848475969198978 Loss Control: 0.6787661939370827 Loss Patient: 0.7080330029129982 Loss balanced:  0.6933995984250405 Loss1+loss2: 0.6933995984250405\n",
      "Write summary at step 4880  Loss:  0.6839369535446167\n",
      "Write summary at step 4890  Loss:  0.7227444648742676\n",
      "Write summary at step 4900  Loss:  0.6377801299095154\n",
      "Write summary at step 4910  Loss:  0.7124860286712646\n",
      "Write summary at step 4920  Loss:  0.6857072114944458\n",
      "Write summary at step 4930  Loss:  0.6897827386856079\n",
      "Write summary at step 4940  Loss:  0.688569962978363\n",
      "Write summary at step 4950  Loss:  0.7016839981079102\n",
      "Write summary at step 4960  Loss:  0.6799864172935486\n",
      "Write summary at step 4970  Loss:  0.6836574077606201\n",
      "Write summary at step 4980  Loss:  0.6897491812705994\n",
      "Write summary at step 4990  Loss:  0.6704318523406982\n",
      "Write summary at step 5000  Loss:  0.7273561358451843\n",
      "Saved checkpoint to: result/42/panns/checkpoint_5000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7587857994682345 Loss Control: 0.7982409905866196 Loss Patient: 0.6083628696699938 Loss balanced:  0.7033019301283067 Loss1+loss2: 0.7033019301283067\n",
      "Write summary at step 5010  Loss:  0.6587422490119934\n",
      "Write summary at step 5020  Loss:  0.6626331210136414\n",
      "Write summary at step 5030  Loss:  0.6770646572113037\n",
      "Write summary at step 5040  Loss:  0.7155972719192505\n",
      "Write summary at step 5050  Loss:  0.6909933686256409\n",
      "Write summary at step 5060  Loss:  0.6886740922927856\n",
      "Write summary at step 5070  Loss:  0.7148548364639282\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.69969684375829 Loss Control: 0.7042140302762308 Loss Patient: 0.6824750428398451 Loss balanced:  0.693344536558038 Loss1+loss2: 0.693344536558038\n",
      "Write summary at step 5080  Loss:  0.7124903202056885\n",
      "Write summary at step 5090  Loss:  0.7232636213302612\n",
      "Write summary at step 5100  Loss:  0.7039214372634888\n",
      "Write summary at step 5110  Loss:  0.6719528436660767\n",
      "Write summary at step 5120  Loss:  0.6808608770370483\n",
      "Write summary at step 5130  Loss:  0.6902776956558228\n",
      "Write summary at step 5140  Loss:  0.7043876647949219\n",
      "Write summary at step 5150  Loss:  0.7113237380981445\n",
      "Write summary at step 5160  Loss:  0.7006807327270508\n",
      "Write summary at step 5170  Loss:  0.7031866312026978\n",
      "Write summary at step 5180  Loss:  0.6793255805969238\n",
      "Write summary at step 5190  Loss:  0.7167890071868896\n",
      "Write summary at step 5200  Loss:  0.7083699107170105\n",
      "Write summary at step 5210  Loss:  0.6804419755935669\n",
      "Write summary at step 5220  Loss:  0.6602141261100769\n",
      "Write summary at step 5230  Loss:  0.7167862057685852\n",
      "Write summary at step 5240  Loss:  0.6945750117301941\n",
      "Write summary at step 5250  Loss:  0.6717087626457214\n",
      "Write summary at step 5260  Loss:  0.7150064706802368\n",
      "Write summary at step 5270  Loss:  0.6696199178695679\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.24675324675324675 Acurracy Control:  0.08196721311475409 Acurracy Patient:  0.875 Acurracy Balanced 0.47848360655737704\n",
      "Loss normal: 0.7578633972060629 Loss Control: 0.7978597462502985 Loss Patient: 0.6053773338596026 Loss balanced:  0.7016185400549506 Loss1+loss2: 0.7016185400549506\n",
      "Write summary at step 5280  Loss:  0.6762483716011047\n",
      "Write summary at step 5290  Loss:  0.6646169424057007\n",
      "Write summary at step 5300  Loss:  0.6592521667480469\n",
      "Write summary at step 5310  Loss:  0.6934691667556763\n",
      "Write summary at step 5320  Loss:  0.7254925966262817\n",
      "Write summary at step 5330  Loss:  0.6772042512893677\n",
      "Write summary at step 5340  Loss:  0.6831939816474915\n",
      "Write summary at step 5350  Loss:  0.7088772058486938\n",
      "Write summary at step 5360  Loss:  0.6864454746246338\n",
      "Write summary at step 5370  Loss:  0.6539909839630127\n",
      "Write summary at step 5380  Loss:  0.6741929650306702\n",
      "Write summary at step 5390  Loss:  0.6834856867790222\n",
      "Write summary at step 5400  Loss:  0.6508238315582275\n",
      "Write summary at step 5410  Loss:  0.6595117449760437\n",
      "Write summary at step 5420  Loss:  0.6619596481323242\n",
      "Write summary at step 5430  Loss:  0.6859289407730103\n",
      "Write summary at step 5440  Loss:  0.7433682084083557\n",
      "Write summary at step 5450  Loss:  0.7105394601821899\n",
      "Write summary at step 5460  Loss:  0.7006361484527588\n",
      "Write summary at step 5470  Loss:  0.6922060251235962\n",
      "Write summary at step 5480  Loss:  0.7051352858543396\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.8100460708399355 Loss Control: 0.8777740441384863 Loss Patient: 0.5518331589798132 Loss balanced:  0.7148036015591497 Loss1+loss2: 0.7148036015591497\n",
      "Write summary at step 5490  Loss:  0.714491605758667\n",
      "Write summary at step 5500  Loss:  0.705083429813385\n",
      "Saved checkpoint to: result/42/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.8145311268377098 Loss Control: 0.8848658738240518 Loss Patient: 0.5463798977434635 Loss balanced:  0.7156228857837577 Loss1+loss2: 0.7156228857837577\n",
      "Write summary at step 5510  Loss:  0.6654870510101318\n",
      "Write summary at step 5520  Loss:  0.6943535804748535\n",
      "Write summary at step 5530  Loss:  0.7216836214065552\n",
      "Write summary at step 5540  Loss:  0.7474318146705627\n",
      "Write summary at step 5550  Loss:  0.6464790105819702\n",
      "Write summary at step 5560  Loss:  0.6486507654190063\n",
      "Write summary at step 5570  Loss:  0.696010172367096\n",
      "Write summary at step 5580  Loss:  0.7433552742004395\n",
      "Write summary at step 5590  Loss:  0.7022406458854675\n",
      "Write summary at step 5600  Loss:  0.6923894882202148\n",
      "Write summary at step 5610  Loss:  0.6787011027336121\n",
      "Write summary at step 5620  Loss:  0.6707665920257568\n",
      "Write summary at step 5630  Loss:  0.709418535232544\n",
      "Write summary at step 5640  Loss:  0.6932888031005859\n",
      "Write summary at step 5650  Loss:  0.7208924293518066\n",
      "Write summary at step 5660  Loss:  0.6748616695404053\n",
      "Write summary at step 5670  Loss:  0.6879041194915771\n",
      "Write summary at step 5680  Loss:  0.699983537197113\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7446665769015556 Loss Control: 0.777627739749971 Loss Patient: 0.6190021187067032 Loss balanced:  0.698314929228337 Loss1+loss2: 0.698314929228337\n",
      "Write summary at step 5690  Loss:  0.6978841423988342\n",
      "Write summary at step 5700  Loss:  0.6971099376678467\n",
      "Write summary at step 5710  Loss:  0.671039342880249\n",
      "Write summary at step 5720  Loss:  0.6906300783157349\n",
      "Write summary at step 5730  Loss:  0.6852132081985474\n",
      "Write summary at step 5740  Loss:  0.6902140378952026\n",
      "Write summary at step 5750  Loss:  0.7070846557617188\n",
      "Write summary at step 5760  Loss:  0.6391265988349915\n",
      "Write summary at step 5770  Loss:  0.7053356766700745\n",
      "Write summary at step 5780  Loss:  0.7415220737457275\n",
      "Write summary at step 5790  Loss:  0.7045087814331055\n",
      "Write summary at step 5800  Loss:  0.7002303600311279\n",
      "Write summary at step 5810  Loss:  0.6932281255722046\n",
      "Write summary at step 5820  Loss:  0.6944602727890015\n",
      "Write summary at step 5830  Loss:  0.7014495730400085\n",
      "Write summary at step 5840  Loss:  0.6624947786331177\n",
      "Write summary at step 5850  Loss:  0.7047619819641113\n",
      "Write summary at step 5860  Loss:  0.6679978370666504\n",
      "Write summary at step 5870  Loss:  0.7017277479171753\n",
      "Write summary at step 5880  Loss:  0.6820976138114929\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2683982683982684 Acurracy Control:  0.1092896174863388 Acurracy Patient:  0.875 Acurracy Balanced 0.4921448087431694\n",
      "Loss normal: 0.7241443622679937 Loss Control: 0.7459218938493989 Loss Patient: 0.6411175541579723 Loss balanced:  0.6935197240036857 Loss1+loss2: 0.6935197240036857\n",
      "Write summary at step 5890  Loss:  0.7517935037612915\n",
      "Write summary at step 5900  Loss:  0.6507285833358765\n",
      "Write summary at step 5910  Loss:  0.6494879722595215\n",
      "Write summary at step 5920  Loss:  0.6995968818664551\n",
      "Write summary at step 5930  Loss:  0.6869873404502869\n",
      "Write summary at step 5940  Loss:  0.6949781775474548\n",
      "Write summary at step 5950  Loss:  0.7063271999359131\n",
      "Write summary at step 5960  Loss:  0.6933407783508301\n",
      "Write summary at step 5970  Loss:  0.6886500716209412\n",
      "Write summary at step 5980  Loss:  0.6978657245635986\n",
      "Write summary at step 5990  Loss:  0.6644961833953857\n",
      "Write summary at step 6000  Loss:  0.6844804286956787\n",
      "Saved checkpoint to: result/42/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.24242424242424243 Acurracy Control:  0.04918032786885246 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.5141734972677595\n",
      "Loss normal: 0.7556484741565985 Loss Control: 0.7976466417312622 Loss Patient: 0.595530537267526 Loss balanced:  0.6965885894993942 Loss1+loss2: 0.6965885894993942\n",
      "Write summary at step 6010  Loss:  0.7589377760887146\n",
      "Write summary at step 6020  Loss:  0.7059141397476196\n",
      "Write summary at step 6030  Loss:  0.7354799509048462\n",
      "Write summary at step 6040  Loss:  0.7182739973068237\n",
      "Write summary at step 6050  Loss:  0.7032991051673889\n",
      "Write summary at step 6060  Loss:  0.7040305137634277\n",
      "Write summary at step 6070  Loss:  0.72905433177948\n",
      "Write summary at step 6080  Loss:  0.6961555480957031\n",
      "Write summary at step 6090  Loss:  0.6960532069206238\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7370866183594708 Loss Control: 0.7665715377187469 Loss Patient: 0.6246754042804241 Loss balanced:  0.6956234709995854 Loss1+loss2: 0.6956234709995854\n",
      "Write summary at step 6100  Loss:  0.6827809810638428\n",
      "Write summary at step 6110  Loss:  0.7153162956237793\n",
      "Write summary at step 6120  Loss:  0.6932836174964905\n",
      "Write summary at step 6130  Loss:  0.68477463722229\n",
      "Write summary at step 6140  Loss:  0.6490020751953125\n",
      "Write summary at step 6150  Loss:  0.7178427577018738\n",
      "Write summary at step 6160  Loss:  0.6904745101928711\n",
      "Write summary at step 6170  Loss:  0.684571385383606\n",
      "Write summary at step 6180  Loss:  0.6779397130012512\n",
      "Write summary at step 6190  Loss:  0.6675629019737244\n",
      "Write summary at step 6200  Loss:  0.7246313691139221\n",
      "Write summary at step 6210  Loss:  0.7053598165512085\n",
      "Write summary at step 6220  Loss:  0.710304856300354\n",
      "Write summary at step 6230  Loss:  0.6806986331939697\n",
      "Write summary at step 6240  Loss:  0.6741570234298706\n",
      "Write summary at step 6250  Loss:  0.7071443796157837\n",
      "Write summary at step 6260  Loss:  0.6989544034004211\n",
      "Write summary at step 6270  Loss:  0.6808943748474121\n",
      "Write summary at step 6280  Loss:  0.7079305648803711\n",
      "Write summary at step 6290  Loss:  0.669633686542511\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5497835497835498 Acurracy Control:  0.5519125683060109 Acurracy Patient:  0.5416666666666666 Acurracy Balanced 0.5467896174863387\n",
      "Loss normal: 0.6906359525986048 Loss Control: 0.689837665505748 Loss Patient: 0.6936794010301431 Loss balanced:  0.6917585332679456 Loss1+loss2: 0.6917585332679456\n",
      "\n",
      " > BEST MODEL (0.69176) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 6300  Loss:  0.6825135946273804\n",
      "Write summary at step 6310  Loss:  0.7076762318611145\n",
      "Write summary at step 6320  Loss:  0.6928524971008301\n",
      "Write summary at step 6330  Loss:  0.7050201892852783\n",
      "Write summary at step 6340  Loss:  0.6946907043457031\n",
      "Write summary at step 6350  Loss:  0.7010858058929443\n",
      "Write summary at step 6360  Loss:  0.6905211806297302\n",
      "Write summary at step 6370  Loss:  0.7114942073822021\n",
      "Write summary at step 6380  Loss:  0.6858241558074951\n",
      "Write summary at step 6390  Loss:  0.6818736791610718\n",
      "Write summary at step 6400  Loss:  0.6996737718582153\n",
      "Write summary at step 6410  Loss:  0.6883020997047424\n",
      "Write summary at step 6420  Loss:  0.6754013299942017\n",
      "Write summary at step 6430  Loss:  0.6838263869285583\n",
      "Write summary at step 6440  Loss:  0.7165102958679199\n",
      "Write summary at step 6450  Loss:  0.6932274103164673\n",
      "Write summary at step 6460  Loss:  0.6681147813796997\n",
      "Write summary at step 6470  Loss:  0.6935619115829468\n",
      "Write summary at step 6480  Loss:  0.6596566438674927\n",
      "Write summary at step 6490  Loss:  0.7443581819534302\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5373975409836066\n",
      "Loss normal: 0.6720590415971104 Loss Control: 0.657617210690441 Loss Patient: 0.7271185405552387 Loss balanced:  0.6923678756228399 Loss1+loss2: 0.6923678756228399\n",
      "Write summary at step 6500  Loss:  0.6877955198287964\n",
      "Saved checkpoint to: result/42/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5264685792349727\n",
      "Loss normal: 0.6748964373683517 Loss Control: 0.6627995160108056 Loss Patient: 0.7210159401098887 Loss balanced:  0.6919077280603472 Loss1+loss2: 0.6919077280603472\n",
      "Write summary at step 6510  Loss:  0.7072294354438782\n",
      "Write summary at step 6520  Loss:  0.6877074241638184\n",
      "Write summary at step 6530  Loss:  0.6991861462593079\n",
      "Write summary at step 6540  Loss:  0.7194905281066895\n",
      "Write summary at step 6550  Loss:  0.7107846736907959\n",
      "Write summary at step 6560  Loss:  0.6863172054290771\n",
      "Write summary at step 6570  Loss:  0.6759079694747925\n",
      "Write summary at step 6580  Loss:  0.6906659007072449\n",
      "Write summary at step 6590  Loss:  0.6916217803955078\n",
      "Write summary at step 6600  Loss:  0.6879798173904419\n",
      "Write summary at step 6610  Loss:  0.7180442810058594\n",
      "Write summary at step 6620  Loss:  0.7529168725013733\n",
      "Write summary at step 6630  Loss:  0.7299854755401611\n",
      "Write summary at step 6640  Loss:  0.7616077661514282\n",
      "Write summary at step 6650  Loss:  0.714616060256958\n",
      "Write summary at step 6660  Loss:  0.6951088905334473\n",
      "Write summary at step 6670  Loss:  0.6998534202575684\n",
      "Write summary at step 6680  Loss:  0.701278567314148\n",
      "Write summary at step 6690  Loss:  0.6788066029548645\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.31601731601731603 Acurracy Control:  0.16939890710382513 Acurracy Patient:  0.875 Acurracy Balanced 0.5221994535519126\n",
      "Loss normal: 0.6992894421408187 Loss Control: 0.704274352782411 Loss Patient: 0.6802844976385435 Loss balanced:  0.6922794252104773 Loss1+loss2: 0.6922794252104773\n",
      "Write summary at step 6700  Loss:  0.672669529914856\n",
      "Write summary at step 6710  Loss:  0.6196802258491516\n",
      "Write summary at step 6720  Loss:  0.7003931999206543\n",
      "Write summary at step 6730  Loss:  0.6790708303451538\n",
      "Write summary at step 6740  Loss:  0.6926372051239014\n",
      "Write summary at step 6750  Loss:  0.7209044694900513\n",
      "Write summary at step 6760  Loss:  0.7465453743934631\n",
      "Write summary at step 6770  Loss:  0.7095596194267273\n",
      "Write summary at step 6780  Loss:  0.6800587773323059\n",
      "Write summary at step 6790  Loss:  0.7066628336906433\n",
      "Write summary at step 6800  Loss:  0.688569188117981\n",
      "Write summary at step 6810  Loss:  0.693668007850647\n",
      "Write summary at step 6820  Loss:  0.6792250871658325\n",
      "Write summary at step 6830  Loss:  0.6832069158554077\n",
      "Write summary at step 6840  Loss:  0.6828775405883789\n",
      "Write summary at step 6850  Loss:  0.6894906163215637\n",
      "Write summary at step 6860  Loss:  0.6843322515487671\n",
      "Write summary at step 6870  Loss:  0.6995887756347656\n",
      "Write summary at step 6880  Loss:  0.6594480276107788\n",
      "Write summary at step 6890  Loss:  0.6810175180435181\n",
      "Write summary at step 6900  Loss:  0.6477487087249756\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7377006372848114 Loss Control: 0.7679507478338773 Loss Patient: 0.6223720585306486 Loss balanced:  0.6951614031822629 Loss1+loss2: 0.6951614031822629\n",
      "Write summary at step 6910  Loss:  0.7187774181365967\n",
      "Write summary at step 6920  Loss:  0.7287492156028748\n",
      "Write summary at step 6930  Loss:  0.7335408926010132\n",
      "Write summary at step 6940  Loss:  0.6893810033798218\n",
      "Write summary at step 6950  Loss:  0.7217917442321777\n",
      "Write summary at step 6960  Loss:  0.694992184638977\n",
      "Write summary at step 6970  Loss:  0.6787362098693848\n",
      "Write summary at step 6980  Loss:  0.6981618404388428\n",
      "Write summary at step 6990  Loss:  0.7098215818405151\n",
      "Write summary at step 7000  Loss:  0.6590585708618164\n",
      "Saved checkpoint to: result/42/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5584415584415584 Acurracy Control:  0.5901639344262295 Acurracy Patient:  0.4375 Acurracy Balanced 0.5138319672131147\n",
      "Loss normal: 0.6892514210758787 Loss Control: 0.6864757632297245 Loss Patient: 0.6998335967461268 Loss balanced:  0.6931546799879256 Loss1+loss2: 0.6931546799879256\n",
      "Write summary at step 7010  Loss:  0.6859267354011536\n",
      "Write summary at step 7020  Loss:  0.6772371530532837\n",
      "Write summary at step 7030  Loss:  0.659619927406311\n",
      "Write summary at step 7040  Loss:  0.7219072580337524\n",
      "Write summary at step 7050  Loss:  0.7465475797653198\n",
      "Write summary at step 7060  Loss:  0.6982059478759766\n",
      "Write summary at step 7070  Loss:  0.6864223480224609\n",
      "Write summary at step 7080  Loss:  0.6830811500549316\n",
      "Write summary at step 7090  Loss:  0.6818625926971436\n",
      "Write summary at step 7100  Loss:  0.6802530288696289\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6190476190476191 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.536714480874317\n",
      "Loss normal: 0.6867727874677418 Loss Control: 0.682317266373035 Loss Patient: 0.7037594839930534 Loss balanced:  0.6930383751830442 Loss1+loss2: 0.6930383751830442\n",
      "Write summary at step 7110  Loss:  0.6981586813926697\n",
      "Write summary at step 7120  Loss:  0.6772511005401611\n",
      "Write summary at step 7130  Loss:  0.6816026568412781\n",
      "Write summary at step 7140  Loss:  0.6915382146835327\n",
      "Write summary at step 7150  Loss:  0.7172813415527344\n",
      "Write summary at step 7160  Loss:  0.7102584838867188\n",
      "Write summary at step 7170  Loss:  0.7117182016372681\n",
      "Write summary at step 7180  Loss:  0.7054643034934998\n",
      "Write summary at step 7190  Loss:  0.6955981254577637\n",
      "Write summary at step 7200  Loss:  0.6856892704963684\n",
      "Write summary at step 7210  Loss:  0.6695164442062378\n",
      "Write summary at step 7220  Loss:  0.6939663887023926\n",
      "Write summary at step 7230  Loss:  0.6779420375823975\n",
      "Write summary at step 7240  Loss:  0.7055656313896179\n",
      "Write summary at step 7250  Loss:  0.7184803485870361\n",
      "Write summary at step 7260  Loss:  0.7050549983978271\n",
      "Write summary at step 7270  Loss:  0.6864426136016846\n",
      "Write summary at step 7280  Loss:  0.7046149969100952\n",
      "Write summary at step 7290  Loss:  0.6870416402816772\n",
      "Write summary at step 7300  Loss:  0.679831326007843\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5238095238095238 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.49965846994535523\n",
      "Loss normal: 0.6959734863533086 Loss Control: 0.6978380553057937 Loss Patient: 0.6888648221890131 Loss balanced:  0.6933514387474033 Loss1+loss2: 0.6933514387474033\n",
      "Write summary at step 7310  Loss:  0.6904815435409546\n",
      "Write summary at step 7320  Loss:  0.7001649141311646\n",
      "Write summary at step 7330  Loss:  0.662479043006897\n",
      "Write summary at step 7340  Loss:  0.7151361703872681\n",
      "Write summary at step 7350  Loss:  0.7218788266181946\n",
      "Write summary at step 7360  Loss:  0.6949403285980225\n",
      "Write summary at step 7370  Loss:  0.7155864238739014\n",
      "Write summary at step 7380  Loss:  0.7008033990859985\n",
      "Write summary at step 7390  Loss:  0.7044402956962585\n",
      "Write summary at step 7400  Loss:  0.7151986360549927\n",
      "Write summary at step 7410  Loss:  0.6887308955192566\n",
      "Write summary at step 7420  Loss:  0.7199958562850952\n",
      "Write summary at step 7430  Loss:  0.6894291043281555\n",
      "Write summary at step 7440  Loss:  0.7192862629890442\n",
      "Write summary at step 7450  Loss:  0.7377234697341919\n",
      "Write summary at step 7460  Loss:  0.7230967283248901\n",
      "Write summary at step 7470  Loss:  0.6953980922698975\n",
      "Write summary at step 7480  Loss:  0.7285863161087036\n",
      "Write summary at step 7490  Loss:  0.6951541900634766\n",
      "Write summary at step 7500  Loss:  0.7268396019935608\n",
      "Saved checkpoint to: result/42/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.5411255411255411 Acurracy Control:  0.5519125683060109 Acurracy Patient:  0.5 Acurracy Balanced 0.5259562841530054\n",
      "Loss normal: 0.697674238320553 Loss Control: 0.7008858678119431 Loss Patient: 0.6854299418628216 Loss balanced:  0.6931579048373824 Loss1+loss2: 0.6931579048373824\n",
      "Write summary at step 7510  Loss:  0.7166985273361206\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7071844587078342 Loss Control: 0.7162553645222565 Loss Patient: 0.6726016476750374 Loss balanced:  0.6944285060986469 Loss1+loss2: 0.6944285060986469\n",
      "Write summary at step 7520  Loss:  0.6681564450263977\n",
      "Write summary at step 7530  Loss:  0.6934775114059448\n",
      "Write summary at step 7540  Loss:  0.693474292755127\n",
      "Write summary at step 7550  Loss:  0.6626818180084229\n",
      "Write summary at step 7560  Loss:  0.6946688294410706\n",
      "Write summary at step 7570  Loss:  0.6848232746124268\n",
      "Write summary at step 7580  Loss:  0.665600061416626\n",
      "Write summary at step 7590  Loss:  0.7221370935440063\n",
      "Write summary at step 7600  Loss:  0.7493847608566284\n",
      "Write summary at step 7610  Loss:  0.6756945848464966\n",
      "Write summary at step 7620  Loss:  0.6665366888046265\n",
      "Write summary at step 7630  Loss:  0.6836706399917603\n",
      "Write summary at step 7640  Loss:  0.707493245601654\n",
      "Write summary at step 7650  Loss:  0.7014283537864685\n",
      "Write summary at step 7660  Loss:  0.7332426309585571\n",
      "Write summary at step 7670  Loss:  0.6978822946548462\n",
      "Write summary at step 7680  Loss:  0.7149118185043335\n",
      "Write summary at step 7690  Loss:  0.6888594627380371\n",
      "Write summary at step 7700  Loss:  0.7178090810775757\n",
      "Write summary at step 7710  Loss:  0.6939729452133179\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.70245809369273 Loss Control: 0.7091594589212553 Loss Patient: 0.6769091772536436 Loss balanced:  0.6930343180874494 Loss1+loss2: 0.6930343180874494\n",
      "Write summary at step 7720  Loss:  0.7069405913352966\n",
      "Write summary at step 7730  Loss:  0.7255451679229736\n",
      "Write summary at step 7740  Loss:  0.6512738466262817\n",
      "Write summary at step 7750  Loss:  0.7517249584197998\n",
      "Write summary at step 7760  Loss:  0.7159380316734314\n",
      "Write summary at step 7770  Loss:  0.6804566383361816\n",
      "Write summary at step 7780  Loss:  0.7151561975479126\n",
      "Write summary at step 7790  Loss:  0.6885475516319275\n",
      "Write summary at step 7800  Loss:  0.6905542612075806\n",
      "Write summary at step 7810  Loss:  0.7051823139190674\n",
      "Write summary at step 7820  Loss:  0.6854261159896851\n",
      "Write summary at step 7830  Loss:  0.6561822891235352\n",
      "Write summary at step 7840  Loss:  0.7014942169189453\n",
      "Write summary at step 7850  Loss:  0.6995484828948975\n",
      "Write summary at step 7860  Loss:  0.6803742051124573\n",
      "Write summary at step 7870  Loss:  0.6714086532592773\n",
      "Write summary at step 7880  Loss:  0.7308264970779419\n",
      "Write summary at step 7890  Loss:  0.6795459985733032\n",
      "Write summary at step 7900  Loss:  0.694935142993927\n",
      "Write summary at step 7910  Loss:  0.6752583980560303\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.41125541125541126 Acurracy Control:  0.33879781420765026 Acurracy Patient:  0.6875 Acurracy Balanced 0.5131489071038251\n",
      "Loss normal: 0.6964050448818124 Loss Control: 0.701961930983705 Loss Patient: 0.6752194402118524 Loss balanced:  0.6885906855977787 Loss1+loss2: 0.6885906855977787\n",
      "\n",
      " > BEST MODEL (0.68859) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 7920  Loss:  0.6998782753944397\n",
      "Write summary at step 7930  Loss:  0.6803387999534607\n",
      "Write summary at step 7940  Loss:  0.6834437251091003\n",
      "Write summary at step 7950  Loss:  0.7063466906547546\n",
      "Write summary at step 7960  Loss:  0.6695730090141296\n",
      "Write summary at step 7970  Loss:  0.7134407758712769\n",
      "Write summary at step 7980  Loss:  0.6695245504379272\n",
      "Write summary at step 7990  Loss:  0.7176195383071899\n",
      "Write summary at step 8000  Loss:  0.7056457996368408\n",
      "Saved checkpoint to: result/42/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7372372026567335 Loss Control: 0.7670268504346003 Loss Patient: 0.6236641009648641 Loss balanced:  0.6953454756997322 Loss1+loss2: 0.6953454756997322\n",
      "Write summary at step 8010  Loss:  0.6910313367843628\n",
      "Write summary at step 8020  Loss:  0.6734621524810791\n",
      "Write summary at step 8030  Loss:  0.6965084075927734\n",
      "Write summary at step 8040  Loss:  0.6829137802124023\n",
      "Write summary at step 8050  Loss:  0.6984111666679382\n",
      "Write summary at step 8060  Loss:  0.7080687284469604\n",
      "Write summary at step 8070  Loss:  0.6973176598548889\n",
      "Write summary at step 8080  Loss:  0.6676471829414368\n",
      "Write summary at step 8090  Loss:  0.7464814186096191\n",
      "Write summary at step 8100  Loss:  0.6657637357711792\n",
      "Write summary at step 8110  Loss:  0.6729627847671509\n",
      "Write summary at step 8120  Loss:  0.6631884574890137\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.5367965367965368 Acurracy Control:  0.5683060109289617 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.4924863387978142\n",
      "Loss normal: 0.6899223712099579 Loss Control: 0.6872519681362507 Loss Patient: 0.7001032593349615 Loss balanced:  0.6936776137356061 Loss1+loss2: 0.6936776137356061\n",
      "Write summary at step 8130  Loss:  0.6614603996276855\n",
      "Write summary at step 8140  Loss:  0.7142190933227539\n",
      "Write summary at step 8150  Loss:  0.6810215711593628\n",
      "Write summary at step 8160  Loss:  0.7337408661842346\n",
      "Write summary at step 8170  Loss:  0.7029076814651489\n",
      "Write summary at step 8180  Loss:  0.6530713438987732\n",
      "Write summary at step 8190  Loss:  0.6553013324737549\n",
      "Write summary at step 8200  Loss:  0.6755560040473938\n",
      "Write summary at step 8210  Loss:  0.6917492747306824\n",
      "Write summary at step 8220  Loss:  0.6411448121070862\n",
      "Write summary at step 8230  Loss:  0.6627732515335083\n",
      "Write summary at step 8240  Loss:  0.7079038619995117\n",
      "Write summary at step 8250  Loss:  0.736540675163269\n",
      "Write summary at step 8260  Loss:  0.6849688291549683\n",
      "Write summary at step 8270  Loss:  0.7231761813163757\n",
      "Write summary at step 8280  Loss:  0.7147815227508545\n",
      "Write summary at step 8290  Loss:  0.692552924156189\n",
      "Write summary at step 8300  Loss:  0.6993070244789124\n",
      "Write summary at step 8310  Loss:  0.6750991940498352\n",
      "Write summary at step 8320  Loss:  0.6873649954795837\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3246753246753247 Acurracy Control:  0.18032786885245902 Acurracy Patient:  0.875 Acurracy Balanced 0.5276639344262295\n",
      "Loss normal: 0.7186766483566978 Loss Control: 0.7363485987069177 Loss Patient: 0.6513023724158605 Loss balanced:  0.6938254855613891 Loss1+loss2: 0.6938254855613891\n",
      "Write summary at step 8330  Loss:  0.6947811841964722\n",
      "Write summary at step 8340  Loss:  0.7066956758499146\n",
      "Write summary at step 8350  Loss:  0.6966676712036133\n",
      "Write summary at step 8360  Loss:  0.7002403140068054\n",
      "Write summary at step 8370  Loss:  0.6730283498764038\n",
      "Write summary at step 8380  Loss:  0.7203779220581055\n",
      "Write summary at step 8390  Loss:  0.6960956454277039\n",
      "Write summary at step 8400  Loss:  0.7102950215339661\n",
      "Write summary at step 8410  Loss:  0.6924905776977539\n",
      "Write summary at step 8420  Loss:  0.7013575434684753\n",
      "Write summary at step 8430  Loss:  0.6774839162826538\n",
      "Write summary at step 8440  Loss:  0.687748908996582\n",
      "Write summary at step 8450  Loss:  0.678138017654419\n",
      "Write summary at step 8460  Loss:  0.6969258785247803\n",
      "Write summary at step 8470  Loss:  0.6996850967407227\n",
      "Write summary at step 8480  Loss:  0.6811891794204712\n",
      "Write summary at step 8490  Loss:  0.683086633682251\n",
      "Write summary at step 8500  Loss:  0.6922677755355835\n",
      "Saved checkpoint to: result/42/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.5281385281385281 Acurracy Control:  0.5355191256830601 Acurracy Patient:  0.5 Acurracy Balanced 0.5177595628415301\n",
      "Loss normal: 0.696416556319117 Loss Control: 0.6976061320044303 Loss Patient: 0.6918812667330106 Loss balanced:  0.6947436993687205 Loss1+loss2: 0.6947436993687205\n",
      "Write summary at step 8510  Loss:  0.6664203405380249\n",
      "Write summary at step 8520  Loss:  0.6975462436676025\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3593073593073593 Acurracy Control:  0.25136612021857924 Acurracy Patient:  0.7708333333333334 Acurracy Balanced 0.5110997267759563\n",
      "Loss normal: 0.7160622645250131 Loss Control: 0.7315847645691835 Loss Patient: 0.6568827244142691 Loss balanced:  0.6942337444917264 Loss1+loss2: 0.6942337444917264\n",
      "Write summary at step 8530  Loss:  0.6710403561592102\n",
      "Write summary at step 8540  Loss:  0.7144410610198975\n",
      "Write summary at step 8550  Loss:  0.6819908618927002\n",
      "Write summary at step 8560  Loss:  0.6870321035385132\n",
      "Write summary at step 8570  Loss:  0.6832848787307739\n",
      "Write summary at step 8580  Loss:  0.7059803009033203\n",
      "Write summary at step 8590  Loss:  0.7362613677978516\n",
      "Write summary at step 8600  Loss:  0.7257816195487976\n",
      "Write summary at step 8610  Loss:  0.68764728307724\n",
      "Write summary at step 8620  Loss:  0.7212005257606506\n",
      "Write summary at step 8630  Loss:  0.6924099326133728\n",
      "Write summary at step 8640  Loss:  0.7302930355072021\n",
      "Write summary at step 8650  Loss:  0.7478559017181396\n",
      "Write summary at step 8660  Loss:  0.6872671842575073\n",
      "Write summary at step 8670  Loss:  0.6769157648086548\n",
      "Write summary at step 8680  Loss:  0.6896682381629944\n",
      "Write summary at step 8690  Loss:  0.6792254447937012\n",
      "Write summary at step 8700  Loss:  0.7015714049339294\n",
      "Write summary at step 8710  Loss:  0.6622182130813599\n",
      "Write summary at step 8720  Loss:  0.6895599365234375\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6522295051838929 Loss Control: 0.6226208561756572 Loss Patient: 0.7651124335825443 Loss balanced:  0.6938666448791008 Loss1+loss2: 0.6938666448791008\n",
      "Write summary at step 8730  Loss:  0.6708139777183533\n",
      "Write summary at step 8740  Loss:  0.5873123407363892\n",
      "Write summary at step 8750  Loss:  0.6724900007247925\n",
      "Write summary at step 8760  Loss:  0.719308078289032\n",
      "Write summary at step 8770  Loss:  0.7042536735534668\n",
      "Write summary at step 8780  Loss:  0.6320309638977051\n",
      "Write summary at step 8790  Loss:  0.6842321157455444\n",
      "Write summary at step 8800  Loss:  0.7304511666297913\n",
      "Write summary at step 8810  Loss:  0.6614381074905396\n",
      "Write summary at step 8820  Loss:  0.7012530565261841\n",
      "Write summary at step 8830  Loss:  0.736153244972229\n",
      "Write summary at step 8840  Loss:  0.6988749504089355\n",
      "Write summary at step 8850  Loss:  0.6823160648345947\n",
      "Write summary at step 8860  Loss:  0.6758525371551514\n",
      "Write summary at step 8870  Loss:  0.6780160665512085\n",
      "Write summary at step 8880  Loss:  0.6753064393997192\n",
      "Write summary at step 8890  Loss:  0.676505446434021\n",
      "Write summary at step 8900  Loss:  0.6902422904968262\n",
      "Write summary at step 8910  Loss:  0.714699387550354\n",
      "Write summary at step 8920  Loss:  0.7129892110824585\n",
      "Write summary at step 8930  Loss:  0.6980447769165039\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2987012987012987 Acurracy Control:  0.1366120218579235 Acurracy Patient:  0.9166666666666666 Acurracy Balanced 0.5266393442622951\n",
      "Loss normal: 0.7375390336110994 Loss Control: 0.7686841191489839 Loss Patient: 0.6187984049320221 Loss balanced:  0.693741262040503 Loss1+loss2: 0.693741262040503\n",
      "Write summary at step 8940  Loss:  0.7002691626548767\n",
      "Write summary at step 8950  Loss:  0.7238187193870544\n",
      "Write summary at step 8960  Loss:  0.6978291273117065\n",
      "Write summary at step 8970  Loss:  0.7083407044410706\n",
      "Write summary at step 8980  Loss:  0.6861013770103455\n",
      "Write summary at step 8990  Loss:  0.6940106749534607\n",
      "Write summary at step 9000  Loss:  0.7037048935890198\n",
      "Saved checkpoint to: result/42/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.3463203463203463 Acurracy Control:  0.20765027322404372 Acurracy Patient:  0.875 Acurracy Balanced 0.5413251366120219\n",
      "Loss normal: 0.7083637342824565 Loss Control: 0.7196430208904495 Loss Patient: 0.6653614565730095 Loss balanced:  0.6925022387317294 Loss1+loss2: 0.6925022387317294\n",
      "Write summary at step 9010  Loss:  0.7173070311546326\n",
      "Write summary at step 9020  Loss:  0.7036457061767578\n",
      "Write summary at step 9030  Loss:  0.7174288034439087\n",
      "Write summary at step 9040  Loss:  0.6828885078430176\n",
      "Write summary at step 9050  Loss:  0.6886401772499084\n",
      "Write summary at step 9060  Loss:  0.7253822088241577\n",
      "Write summary at step 9070  Loss:  0.7084684371948242\n",
      "Write summary at step 9080  Loss:  0.6911646127700806\n",
      "Write summary at step 9090  Loss:  0.7448745965957642\n",
      "Write summary at step 9100  Loss:  0.6839205026626587\n",
      "Write summary at step 9110  Loss:  0.6978534460067749\n",
      "Write summary at step 9120  Loss:  0.6644302606582642\n",
      "Write summary at step 9130  Loss:  0.6840794086456299\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.35064935064935066 Acurracy Control:  0.2185792349726776 Acurracy Patient:  0.8541666666666666 Acurracy Balanced 0.5363729508196721\n",
      "Loss normal: 0.723642148238756 Loss Control: 0.7447858446282767 Loss Patient: 0.6430317883690199 Loss balanced:  0.6939088164986482 Loss1+loss2: 0.6939088164986482\n",
      "Write summary at step 9140  Loss:  0.6900122165679932\n",
      "Write summary at step 9150  Loss:  0.7315266132354736\n",
      "Write summary at step 9160  Loss:  0.7125096321105957\n",
      "Write summary at step 9170  Loss:  0.6852662563323975\n",
      "Write summary at step 9180  Loss:  0.7930996417999268\n",
      "Write summary at step 9190  Loss:  0.7047362923622131\n",
      "Write summary at step 9200  Loss:  0.7622690200805664\n",
      "Write summary at step 9210  Loss:  0.7207886576652527\n",
      "Write summary at step 9220  Loss:  0.7137756943702698\n",
      "Write summary at step 9230  Loss:  0.6705667972564697\n",
      "Write summary at step 9240  Loss:  0.7334282398223877\n",
      "Write summary at step 9250  Loss:  0.7027559280395508\n",
      "Write summary at step 9260  Loss:  0.6571717858314514\n",
      "Write summary at step 9270  Loss:  0.7316308617591858\n",
      "Write summary at step 9280  Loss:  0.6987806558609009\n",
      "Write summary at step 9290  Loss:  0.6782481670379639\n",
      "Write summary at step 9300  Loss:  0.6798867583274841\n",
      "Write summary at step 9310  Loss:  0.6180137991905212\n",
      "Write summary at step 9320  Loss:  0.6698395609855652\n",
      "Write summary at step 9330  Loss:  0.6971007585525513\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2943722943722944 Acurracy Control:  0.14207650273224043 Acurracy Patient:  0.875 Acurracy Balanced 0.5085382513661202\n",
      "Loss normal: 0.7545582819810678 Loss Control: 0.7943223415176726 Loss Patient: 0.6029578646024069 Loss balanced:  0.6986401030600398 Loss1+loss2: 0.6986401030600398\n",
      "Write summary at step 9340  Loss:  0.6964459419250488\n",
      "Write summary at step 9350  Loss:  0.7233158349990845\n",
      "Write summary at step 9360  Loss:  0.7003594636917114\n",
      "Write summary at step 9370  Loss:  0.7527601718902588\n",
      "Write summary at step 9380  Loss:  0.686057984828949\n",
      "Write summary at step 9390  Loss:  0.705277681350708\n",
      "Write summary at step 9400  Loss:  0.6838697791099548\n",
      "Write summary at step 9410  Loss:  0.6691564321517944\n",
      "Write summary at step 9420  Loss:  0.68503737449646\n",
      "Write summary at step 9430  Loss:  0.6935720443725586\n",
      "Write summary at step 9440  Loss:  0.6411899328231812\n",
      "Write summary at step 9450  Loss:  0.7130866646766663\n",
      "Write summary at step 9460  Loss:  0.6573673486709595\n",
      "Write summary at step 9470  Loss:  0.7015666961669922\n",
      "Write summary at step 9480  Loss:  0.6586021184921265\n",
      "Write summary at step 9490  Loss:  0.7111409306526184\n",
      "Write summary at step 9500  Loss:  0.7057719230651855\n",
      "Saved checkpoint to: result/42/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.37662337662337664 Acurracy Control:  0.3114754098360656 Acurracy Patient:  0.625 Acurracy Balanced 0.4682377049180328\n",
      "Loss normal: 0.7136095960934957 Loss Control: 0.7251935184327631 Loss Patient: 0.6694458425045013 Loss balanced:  0.6973196804686322 Loss1+loss2: 0.6973196804686322\n",
      "Write summary at step 9510  Loss:  0.7106325626373291\n",
      "Write summary at step 9520  Loss:  0.7210239171981812\n",
      "Write summary at step 9530  Loss:  0.66556715965271\n",
      "Write summary at step 9540  Loss:  0.7154615521430969\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.341991341991342 Acurracy Control:  0.23497267759562843 Acurracy Patient:  0.75 Acurracy Balanced 0.4924863387978142\n",
      "Loss normal: 0.7409677172636057 Loss Control: 0.7688851275079237 Loss Patient: 0.6345325826356808 Loss balanced:  0.7017088550718023 Loss1+loss2: 0.7017088550718023\n",
      "Write summary at step 9550  Loss:  0.6946009397506714\n",
      "Write summary at step 9560  Loss:  0.7098315954208374\n",
      "Write summary at step 9570  Loss:  0.7194835543632507\n",
      "Write summary at step 9580  Loss:  0.6965144872665405\n",
      "Write summary at step 9590  Loss:  0.6941900253295898\n",
      "Write summary at step 9600  Loss:  0.6782577037811279\n",
      "Write summary at step 9610  Loss:  0.7241761088371277\n",
      "Write summary at step 9620  Loss:  0.6739403605461121\n",
      "Write summary at step 9630  Loss:  0.6896722316741943\n",
      "Write summary at step 9640  Loss:  0.7157756686210632\n",
      "Write summary at step 9650  Loss:  0.6987401843070984\n",
      "Write summary at step 9660  Loss:  0.6944797039031982\n",
      "Write summary at step 9670  Loss:  0.6754442453384399\n",
      "Write summary at step 9680  Loss:  0.6691276431083679\n",
      "Write summary at step 9690  Loss:  0.656333327293396\n",
      "Write summary at step 9700  Loss:  0.6676949858665466\n",
      "Write summary at step 9710  Loss:  0.7115305662155151\n",
      "Write summary at step 9720  Loss:  0.724173367023468\n",
      "Write summary at step 9730  Loss:  0.7211438417434692\n",
      "Write summary at step 9740  Loss:  0.6896821856498718\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2943722943722944 Acurracy Control:  0.16393442622950818 Acurracy Patient:  0.7916666666666666 Acurracy Balanced 0.4778005464480874\n",
      "Loss normal: 0.8001938353885304 Loss Control: 0.8614973725516939 Loss Patient: 0.566474008684357 Loss balanced:  0.7139856906180255 Loss1+loss2: 0.7139856906180255\n",
      "Write summary at step 9750  Loss:  0.695176362991333\n",
      "Write summary at step 9760  Loss:  0.6848914623260498\n",
      "Write summary at step 9770  Loss:  0.5724492073059082\n",
      "Write summary at step 9780  Loss:  0.6798366904258728\n",
      "Write summary at step 9790  Loss:  0.660050630569458\n",
      "Write summary at step 9800  Loss:  0.6951332688331604\n",
      "Write summary at step 9810  Loss:  0.6570292711257935\n",
      "Write summary at step 9820  Loss:  0.680866003036499\n",
      "Write summary at step 9830  Loss:  0.6798967123031616\n",
      "Write summary at step 9840  Loss:  0.7563639879226685\n",
      "Write summary at step 9850  Loss:  0.6493934988975525\n",
      "Write summary at step 9860  Loss:  0.704172670841217\n",
      "Write summary at step 9870  Loss:  0.7009592056274414\n",
      "Write summary at step 9880  Loss:  0.7120121717453003\n",
      "Write summary at step 9890  Loss:  0.6829681396484375\n",
      "Write summary at step 9900  Loss:  0.6841779947280884\n",
      "Write summary at step 9910  Loss:  0.7911585569381714\n",
      "Write summary at step 9920  Loss:  0.656930685043335\n",
      "Write summary at step 9930  Loss:  0.656934380531311\n",
      "Write summary at step 9940  Loss:  0.6273018717765808\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3246753246753247 Acurracy Control:  0.21311475409836064 Acurracy Patient:  0.75 Acurracy Balanced 0.48155737704918034\n",
      "Loss normal: 0.7535561973398383 Loss Control: 0.7904468644512156 Loss Patient: 0.6129105358074108 Loss balanced:  0.7016787001293132 Loss1+loss2: 0.7016787001293132\n",
      "Write summary at step 9950  Loss:  0.7527801990509033\n",
      "Write summary at step 9960  Loss:  0.6856139302253723\n",
      "Write summary at step 9970  Loss:  0.6965756416320801\n",
      "Write summary at step 9980  Loss:  0.6673604249954224\n",
      "Write summary at step 9990  Loss:  0.6573296785354614\n",
      "Write summary at step 10000  Loss:  0.6651598215103149\n",
      "Saved checkpoint to: result/42/panns/checkpoint_10000.pt\n",
      "Validation:\n",
      "Acurracy:  0.38095238095238093 Acurracy Control:  0.29508196721311475 Acurracy Patient:  0.7083333333333334 Acurracy Balanced 0.5017076502732241\n",
      "Loss normal: 0.7263422711587055 Loss Control: 0.7484085804126301 Loss Patient: 0.6422145031392574 Loss balanced:  0.6953115417759438 Loss1+loss2: 0.6953115417759438\n",
      "Write summary at step 10010  Loss:  0.6928240060806274\n",
      "Write summary at step 10020  Loss:  0.766907811164856\n",
      "Write summary at step 10030  Loss:  0.6930173635482788\n",
      "Write summary at step 10040  Loss:  0.6642158031463623\n",
      "Write summary at step 10050  Loss:  0.7021967768669128\n",
      "Write summary at step 10060  Loss:  0.6278662085533142\n",
      "Write summary at step 10070  Loss:  0.6993684768676758\n",
      "Write summary at step 10080  Loss:  0.6680083274841309\n",
      "Write summary at step 10090  Loss:  0.6959743499755859\n",
      "Write summary at step 10100  Loss:  0.6271528005599976\n",
      "Write summary at step 10110  Loss:  0.687463641166687\n",
      "Write summary at step 10120  Loss:  0.6599822640419006\n",
      "Write summary at step 10130  Loss:  0.7465154528617859\n",
      "Write summary at step 10140  Loss:  0.6736326217651367\n",
      "Write summary at step 10150  Loss:  0.6693669557571411\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.3125 Acurracy Balanced 0.5141734972677596\n",
      "Loss normal: 0.6724407254875481 Loss Control: 0.6592265354479597 Loss Patient: 0.7228198647499084 Loss balanced:  0.691023200098934 Loss1+loss2: 0.691023200098934\n",
      "Write summary at step 10160  Loss:  0.6649966239929199\n",
      "Write summary at step 10170  Loss:  0.688130259513855\n",
      "Write summary at step 10180  Loss:  0.6526317000389099\n",
      "Write summary at step 10190  Loss:  0.7469079494476318\n",
      "Write summary at step 10200  Loss:  0.6381874680519104\n",
      "Write summary at step 10210  Loss:  0.6489660143852234\n",
      "Write summary at step 10220  Loss:  0.7376548051834106\n",
      "Write summary at step 10230  Loss:  0.6464893817901611\n",
      "Write summary at step 10240  Loss:  0.6729626655578613\n",
      "Write summary at step 10250  Loss:  0.7052366137504578\n",
      "Write summary at step 10260  Loss:  0.7328078746795654\n",
      "Write summary at step 10270  Loss:  0.7442946434020996\n",
      "Write summary at step 10280  Loss:  0.6616268157958984\n",
      "Write summary at step 10290  Loss:  0.7246946692466736\n",
      "Write summary at step 10300  Loss:  0.6888134479522705\n",
      "Write summary at step 10310  Loss:  0.7030627131462097\n",
      "Write summary at step 10320  Loss:  0.6765168905258179\n",
      "Write summary at step 10330  Loss:  0.718768835067749\n",
      "Write summary at step 10340  Loss:  0.7112225294113159\n",
      "Write summary at step 10350  Loss:  0.6744745969772339\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5151515151515151 Acurracy Control:  0.5027322404371585 Acurracy Patient:  0.5625 Acurracy Balanced 0.5326161202185793\n",
      "Loss normal: 0.6914683446223602 Loss Control: 0.691694841358831 Loss Patient: 0.6906047699352106 Loss balanced:  0.6911498056470208 Loss1+loss2: 0.6911498056470208\n",
      "Write summary at step 10360  Loss:  0.6882683038711548\n",
      "Write summary at step 10370  Loss:  0.7015811204910278\n",
      "Write summary at step 10380  Loss:  0.7366323471069336\n",
      "Write summary at step 10390  Loss:  0.6856086254119873\n",
      "Write summary at step 10400  Loss:  0.707237958908081\n",
      "Write summary at step 10410  Loss:  0.6732815504074097\n",
      "Write summary at step 10420  Loss:  0.7487705945968628\n",
      "Write summary at step 10430  Loss:  0.6924523115158081\n",
      "Write summary at step 10440  Loss:  0.7172417640686035\n",
      "Write summary at step 10450  Loss:  0.6957869529724121\n",
      "Write summary at step 10460  Loss:  0.6781642436981201\n",
      "Write summary at step 10470  Loss:  0.6817809343338013\n",
      "Write summary at step 10480  Loss:  0.7282484769821167\n",
      "Write summary at step 10490  Loss:  0.7049509286880493\n",
      "Write summary at step 10500  Loss:  0.6557877659797668\n",
      "Saved checkpoint to: result/42/panns/checkpoint_10500.pt\n",
      "Validation:\n",
      "Acurracy:  0.41125541125541126 Acurracy Control:  0.31693989071038253 Acurracy Patient:  0.7708333333333334 Acurracy Balanced 0.543886612021858\n",
      "Loss normal: 0.7128132669440596 Loss Control: 0.7269247359916812 Loss Patient: 0.6590132849911848 Loss balanced:  0.692969010491433 Loss1+loss2: 0.692969010491433\n",
      "Write summary at step 10510  Loss:  0.6468706727027893\n",
      "Write summary at step 10520  Loss:  0.7030347585678101\n",
      "Write summary at step 10530  Loss:  0.6739501953125\n",
      "Write summary at step 10540  Loss:  0.7070518732070923\n",
      "Write summary at step 10550  Loss:  0.7093146443367004\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3116883116883117 Acurracy Control:  0.18032786885245902 Acurracy Patient:  0.8125 Acurracy Balanced 0.4964139344262295\n",
      "Loss normal: 0.7595995437531244 Loss Control: 0.801620913984997 Loss Patient: 0.5993930970629057 Loss balanced:  0.7005070055239513 Loss1+loss2: 0.7005070055239513\n",
      "Write summary at step 10560  Loss:  0.6976593732833862\n",
      "Write summary at step 10570  Loss:  0.748931884765625\n",
      "Write summary at step 10580  Loss:  0.7416373491287231\n",
      "Write summary at step 10590  Loss:  0.6542219519615173\n",
      "Write summary at step 10600  Loss:  0.6641311645507812\n",
      "Write summary at step 10610  Loss:  0.699003279209137\n",
      "Write summary at step 10620  Loss:  0.7194116711616516\n",
      "Write summary at step 10630  Loss:  0.6847841143608093\n",
      "Write summary at step 10640  Loss:  0.6472254991531372\n",
      "Write summary at step 10650  Loss:  0.6649818420410156\n",
      "Write summary at step 10660  Loss:  0.6933516263961792\n",
      "Write summary at step 10670  Loss:  0.6828892230987549\n",
      "Write summary at step 10680  Loss:  0.7463604807853699\n",
      "Write summary at step 10690  Loss:  0.6953725814819336\n",
      "Write summary at step 10700  Loss:  0.6958825588226318\n",
      "Write summary at step 10710  Loss:  0.7029426097869873\n",
      "Write summary at step 10720  Loss:  0.7111555337905884\n",
      "Write summary at step 10730  Loss:  0.7221606373786926\n",
      "Write summary at step 10740  Loss:  0.7147620320320129\n",
      "Write summary at step 10750  Loss:  0.7970430850982666\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.23376623376623376 Acurracy Control:  0.0546448087431694 Acurracy Patient:  0.9166666666666666 Acurracy Balanced 0.485655737704918\n",
      "Loss normal: 0.8231821194355622 Loss Control: 0.8999334749628286 Loss Patient: 0.5305675528943539 Loss balanced:  0.7152505139285912 Loss1+loss2: 0.7152505139285912\n",
      "Write summary at step 10760  Loss:  0.6782258152961731\n",
      "Write summary at step 10770  Loss:  0.6996139287948608\n",
      "Write summary at step 10780  Loss:  0.6658105850219727\n",
      "Write summary at step 10790  Loss:  0.6860229969024658\n",
      "Write summary at step 10800  Loss:  0.693143904209137\n",
      "Write summary at step 10810  Loss:  0.646715521812439\n",
      "Write summary at step 10820  Loss:  0.653719425201416\n",
      "Write summary at step 10830  Loss:  0.6359737515449524\n",
      "Write summary at step 10840  Loss:  0.6447248458862305\n",
      "Write summary at step 10850  Loss:  0.6893437504768372\n",
      "Write summary at step 10860  Loss:  0.6453060507774353\n",
      "Write summary at step 10870  Loss:  0.7052393555641174\n",
      "Write summary at step 10880  Loss:  0.7183792591094971\n",
      "Write summary at step 10890  Loss:  0.6939977407455444\n",
      "Write summary at step 10900  Loss:  0.6329222321510315\n",
      "Write summary at step 10910  Loss:  0.7538891434669495\n",
      "Write summary at step 10920  Loss:  0.6812857389450073\n",
      "Write summary at step 10930  Loss:  0.7139368057250977\n",
      "Write summary at step 10940  Loss:  0.6551976799964905\n",
      "Write summary at step 10950  Loss:  0.7339860796928406\n",
      "Write summary at step 10960  Loss:  0.693785548210144\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.26406926406926406 Acurracy Control:  0.1092896174863388 Acurracy Patient:  0.8541666666666666 Acurracy Balanced 0.4817281420765027\n",
      "Loss normal: 0.7462080074595167 Loss Control: 0.7788560615211236 Loss Patient: 0.6217373528828224 Loss balanced:  0.700296707201973 Loss1+loss2: 0.700296707201973\n",
      "Write summary at step 10970  Loss:  0.6724258661270142\n",
      "Write summary at step 10980  Loss:  0.6349372863769531\n",
      "Write summary at step 10990  Loss:  0.7027710676193237\n",
      "Write summary at step 11000  Loss:  0.6771376132965088\n",
      "Saved checkpoint to: result/42/panns/checkpoint_11000.pt\n",
      "Validation:\n",
      "Acurracy:  0.4329004329004329 Acurracy Control:  0.3879781420765027 Acurracy Patient:  0.6041666666666666 Acurracy Balanced 0.4960724043715847\n",
      "Loss normal: 0.7012901437747014 Loss Control: 0.7058917795374093 Loss Patient: 0.6837463416159153 Loss balanced:  0.6948190605766623 Loss1+loss2: 0.6948190605766623\n",
      "Write summary at step 11010  Loss:  0.6844882965087891\n",
      "Write summary at step 11020  Loss:  0.6268553733825684\n",
      "Write summary at step 11030  Loss:  0.7174034118652344\n",
      "Write summary at step 11040  Loss:  0.7244302034378052\n",
      "Write summary at step 11050  Loss:  0.723945677280426\n",
      "Write summary at step 11060  Loss:  0.6367660760879517\n",
      "Write summary at step 11070  Loss:  0.6678029298782349\n",
      "Write summary at step 11080  Loss:  0.6892943382263184\n",
      "Write summary at step 11090  Loss:  0.7421602010726929\n",
      "Write summary at step 11100  Loss:  0.6419416666030884\n",
      "Write summary at step 11110  Loss:  0.6899145841598511\n",
      "Write summary at step 11120  Loss:  0.6853071451187134\n",
      "Write summary at step 11130  Loss:  0.7018657922744751\n",
      "Write summary at step 11140  Loss:  0.7692951560020447\n",
      "Write summary at step 11150  Loss:  0.6873640418052673\n",
      "Write summary at step 11160  Loss:  0.6483186483383179\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.42857142857142855 Acurracy Control:  0.37158469945355194 Acurracy Patient:  0.6458333333333334 Acurracy Balanced 0.5087090163934427\n",
      "Loss normal: 0.7105181983539036 Loss Control: 0.7248641197147265 Loss Patient: 0.6558243812372287 Loss balanced:  0.6903442504759776 Loss1+loss2: 0.6903442504759776\n",
      "Write summary at step 11170  Loss:  0.8273886442184448\n",
      "Write summary at step 11180  Loss:  0.7010053396224976\n",
      "Write summary at step 11190  Loss:  0.7114367485046387\n",
      "Write summary at step 11200  Loss:  0.6964442729949951\n",
      "Write summary at step 11210  Loss:  0.6900796890258789\n",
      "Write summary at step 11220  Loss:  0.6174987554550171\n",
      "Write summary at step 11230  Loss:  0.6795943975448608\n",
      "Write summary at step 11240  Loss:  0.6807069778442383\n",
      "Write summary at step 11250  Loss:  0.7533111572265625\n",
      "Write summary at step 11260  Loss:  0.7058759927749634\n",
      "Write summary at step 11270  Loss:  0.6226820945739746\n",
      "Write summary at step 11280  Loss:  0.7315793037414551\n",
      "Write summary at step 11290  Loss:  0.6490549445152283\n",
      "Write summary at step 11300  Loss:  0.6706225275993347\n",
      "Write summary at step 11310  Loss:  0.6668895483016968\n",
      "Write summary at step 11320  Loss:  0.6198351383209229\n",
      "Write summary at step 11330  Loss:  0.5948129892349243\n",
      "Write summary at step 11340  Loss:  0.7185736894607544\n",
      "Write summary at step 11350  Loss:  0.6309157609939575\n",
      "Write summary at step 11360  Loss:  0.6613187789916992\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6233766233766234 Acurracy Control:  0.6721311475409836 Acurracy Patient:  0.4375 Acurracy Balanced 0.5548155737704918\n",
      "Loss normal: 0.6730526969546363 Loss Control: 0.6645778515299813 Loss Patient: 0.7053630910813808 Loss balanced:  0.684970471305681 Loss1+loss2: 0.684970471305681\n",
      "\n",
      " > BEST MODEL (0.68497) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 11370  Loss:  0.6804827451705933\n",
      "Write summary at step 11380  Loss:  0.7005791068077087\n",
      "Write summary at step 11390  Loss:  0.7210525274276733\n",
      "Write summary at step 11400  Loss:  0.770421028137207\n",
      "Write summary at step 11410  Loss:  0.7517520189285278\n",
      "Write summary at step 11420  Loss:  0.6978954672813416\n",
      "Write summary at step 11430  Loss:  0.6987253427505493\n",
      "Write summary at step 11440  Loss:  0.6426432132720947\n",
      "Write summary at step 11450  Loss:  0.6761740446090698\n",
      "Write summary at step 11460  Loss:  0.6991062760353088\n",
      "Write summary at step 11470  Loss:  0.723304271697998\n",
      "Write summary at step 11480  Loss:  0.6404995918273926\n",
      "Write summary at step 11490  Loss:  0.671430766582489\n",
      "Write summary at step 11500  Loss:  0.678890585899353\n",
      "Saved checkpoint to: result/42/panns/checkpoint_11500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6623376623376623 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5409836065573771\n",
      "Loss normal: 0.6691747751586881 Loss Control: 0.653745482853853 Loss Patient: 0.7279989744226137 Loss balanced:  0.6908722286382334 Loss1+loss2: 0.6908722286382334\n",
      "Write summary at step 11510  Loss:  0.6908200979232788\n",
      "Write summary at step 11520  Loss:  0.6718466877937317\n",
      "Write summary at step 11530  Loss:  0.7167628407478333\n",
      "Write summary at step 11540  Loss:  0.7060457468032837\n",
      "Write summary at step 11550  Loss:  0.6914783716201782\n",
      "Write summary at step 11560  Loss:  0.7169046401977539\n",
      "Write summary at step 11570  Loss:  0.6905882954597473\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5899931693989071\n",
      "Loss normal: 0.6434505184491476 Loss Control: 0.6174332955495907 Loss Patient: 0.7426411571602026 Loss balanced:  0.6800372263548966 Loss1+loss2: 0.6800372263548966\n",
      "\n",
      " > BEST MODEL (0.68004) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 11580  Loss:  0.6433472633361816\n",
      "Write summary at step 11590  Loss:  0.7126200199127197\n",
      "Write summary at step 11600  Loss:  0.6516619324684143\n",
      "Write summary at step 11610  Loss:  0.7049083113670349\n",
      "Write summary at step 11620  Loss:  0.6538376808166504\n",
      "Write summary at step 11630  Loss:  0.6376804113388062\n",
      "Write summary at step 11640  Loss:  0.6828643083572388\n",
      "Write summary at step 11650  Loss:  0.8087694644927979\n",
      "Write summary at step 11660  Loss:  0.6104755401611328\n",
      "Write summary at step 11670  Loss:  0.7510229349136353\n",
      "Write summary at step 11680  Loss:  0.6529045104980469\n",
      "Write summary at step 11690  Loss:  0.6925023794174194\n",
      "Write summary at step 11700  Loss:  0.7239599227905273\n",
      "Write summary at step 11710  Loss:  0.7484868764877319\n",
      "Write summary at step 11720  Loss:  0.7434060573577881\n",
      "Write summary at step 11730  Loss:  0.6852335333824158\n",
      "Write summary at step 11740  Loss:  0.6406176686286926\n",
      "Write summary at step 11750  Loss:  0.6875066757202148\n",
      "Write summary at step 11760  Loss:  0.6043084859848022\n",
      "Write summary at step 11770  Loss:  0.6664102077484131\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5064935064935064 Acurracy Control:  0.48633879781420764 Acurracy Patient:  0.5833333333333334 Acurracy Balanced 0.5348360655737705\n",
      "Loss normal: 0.6926515992585714 Loss Control: 0.701437193513568 Loss Patient: 0.6591565584143003 Loss balanced:  0.6802968759639342 Loss1+loss2: 0.6802968759639342\n",
      "Write summary at step 11780  Loss:  0.7288943529129028\n",
      "Write summary at step 11790  Loss:  0.7179543375968933\n",
      "Write summary at step 11800  Loss:  0.7191734313964844\n",
      "Write summary at step 11810  Loss:  0.6460679769515991\n",
      "Write summary at step 11820  Loss:  0.7031880617141724\n",
      "Write summary at step 11830  Loss:  0.7349171042442322\n",
      "Write summary at step 11840  Loss:  0.6747503280639648\n",
      "Write summary at step 11850  Loss:  0.7033692002296448\n",
      "Write summary at step 11860  Loss:  0.7666493654251099\n",
      "Write summary at step 11870  Loss:  0.670912504196167\n",
      "Write summary at step 11880  Loss:  0.690531849861145\n",
      "Write summary at step 11890  Loss:  0.7524852156639099\n",
      "Write summary at step 11900  Loss:  0.6884511709213257\n",
      "Write summary at step 11910  Loss:  0.7213647365570068\n",
      "Write summary at step 11920  Loss:  0.6047964692115784\n",
      "Write summary at step 11930  Loss:  0.6407692432403564\n",
      "Write summary at step 11940  Loss:  0.7429654598236084\n",
      "Write summary at step 11950  Loss:  0.802085280418396\n",
      "Write summary at step 11960  Loss:  0.5719050168991089\n",
      "Write summary at step 11970  Loss:  0.7206203937530518\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8138528138528138 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5905054644808743\n",
      "Loss normal: 0.6258100813085382 Loss Control: 0.5895617451172709 Loss Patient: 0.7640068506201109 Loss balanced:  0.6767842978686909 Loss1+loss2: 0.6767842978686909\n",
      "\n",
      " > BEST MODEL (0.67678) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 11980  Loss:  0.6168643236160278\n",
      "Write summary at step 11990  Loss:  0.633806586265564\n",
      "Write summary at step 12000  Loss:  0.7831209897994995\n",
      "Saved checkpoint to: result/42/panns/checkpoint_12000.pt\n",
      "Validation:\n",
      "Acurracy:  0.670995670995671 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5464480874316939\n",
      "Loss normal: 0.6584869065842072 Loss Control: 0.6521109511943463 Loss Patient: 0.682795250788331 Loss balanced:  0.6674531009913387 Loss1+loss2: 0.6674531009913387\n",
      "\n",
      " > BEST MODEL (0.66745) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 12010  Loss:  0.7296974658966064\n",
      "Write summary at step 12020  Loss:  0.6208398342132568\n",
      "Write summary at step 12030  Loss:  0.6515961289405823\n",
      "Write summary at step 12040  Loss:  0.7047627568244934\n",
      "Write summary at step 12050  Loss:  0.7042465209960938\n",
      "Write summary at step 12060  Loss:  0.6786402463912964\n",
      "Write summary at step 12070  Loss:  0.6788246035575867\n",
      "Write summary at step 12080  Loss:  0.6223888397216797\n",
      "Write summary at step 12090  Loss:  0.6506285667419434\n",
      "Write summary at step 12100  Loss:  0.6578322649002075\n",
      "Write summary at step 12110  Loss:  0.7333968281745911\n",
      "Write summary at step 12120  Loss:  0.6644090414047241\n",
      "Write summary at step 12130  Loss:  0.6190111637115479\n",
      "Write summary at step 12140  Loss:  0.6569763422012329\n",
      "Write summary at step 12150  Loss:  0.7266753315925598\n",
      "Write summary at step 12160  Loss:  0.6752025485038757\n",
      "Write summary at step 12170  Loss:  0.7104225158691406\n",
      "Write summary at step 12180  Loss:  0.6620967388153076\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8311688311688312 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.6091188524590164\n",
      "Loss normal: 0.6296625129588238 Loss Control: 0.5986555928740996 Loss Patient: 0.7478764193753401 Loss balanced:  0.6732660061247199 Loss1+loss2: 0.6732660061247199\n",
      "Write summary at step 12190  Loss:  0.7263822555541992\n",
      "Write summary at step 12200  Loss:  0.7110393643379211\n",
      "Write summary at step 12210  Loss:  0.6820598840713501\n",
      "Write summary at step 12220  Loss:  0.7185587286949158\n",
      "Write summary at step 12230  Loss:  0.6797727346420288\n",
      "Write summary at step 12240  Loss:  0.6894190907478333\n",
      "Write summary at step 12250  Loss:  0.652256965637207\n",
      "Write summary at step 12260  Loss:  0.6516649723052979\n",
      "Write summary at step 12270  Loss:  0.6791867017745972\n",
      "Write summary at step 12280  Loss:  0.640527606010437\n",
      "Write summary at step 12290  Loss:  0.7027149200439453\n",
      "Write summary at step 12300  Loss:  0.6984080076217651\n",
      "Write summary at step 12310  Loss:  0.671726405620575\n",
      "Write summary at step 12320  Loss:  0.6305280923843384\n",
      "Write summary at step 12330  Loss:  0.6143894791603088\n",
      "Write summary at step 12340  Loss:  0.6176304221153259\n",
      "Write summary at step 12350  Loss:  0.6518904566764832\n",
      "Write summary at step 12360  Loss:  0.7265636920928955\n",
      "Write summary at step 12370  Loss:  0.7083085775375366\n",
      "Write summary at step 12380  Loss:  0.7014541029930115\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.47186147186147187 Acurracy Control:  0.4918032786885246 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.443818306010929\n",
      "Loss normal: 0.6934503835517091 Loss Control: 0.6904524203206672 Loss Patient: 0.7048801394800345 Loss balanced:  0.6976662799003508 Loss1+loss2: 0.6976662799003508\n",
      "Write summary at step 12390  Loss:  0.7367854714393616\n",
      "Write summary at step 12400  Loss:  0.6734300851821899\n",
      "Write summary at step 12410  Loss:  0.658341109752655\n",
      "Write summary at step 12420  Loss:  0.6772390604019165\n",
      "Write summary at step 12430  Loss:  0.6739649176597595\n",
      "Write summary at step 12440  Loss:  0.7048462629318237\n",
      "Write summary at step 12450  Loss:  0.6756226420402527\n",
      "Write summary at step 12460  Loss:  0.767982542514801\n",
      "Write summary at step 12470  Loss:  0.6957560181617737\n",
      "Write summary at step 12480  Loss:  0.657835841178894\n",
      "Write summary at step 12490  Loss:  0.725929856300354\n",
      "Write summary at step 12500  Loss:  0.6324832439422607\n",
      "Saved checkpoint to: result/42/panns/checkpoint_12500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5850409836065573\n",
      "Loss normal: 0.6447069309490584 Loss Control: 0.6160447082884325 Loss Patient: 0.7539816498756409 Loss balanced:  0.6850131790820366 Loss1+loss2: 0.6850131790820366\n",
      "Write summary at step 12510  Loss:  0.6543676853179932\n",
      "Write summary at step 12520  Loss:  0.6155918836593628\n",
      "Write summary at step 12530  Loss:  0.6680902242660522\n",
      "Write summary at step 12540  Loss:  0.6213629245758057\n",
      "Write summary at step 12550  Loss:  0.6935864090919495\n",
      "Write summary at step 12560  Loss:  0.6582356691360474\n",
      "Write summary at step 12570  Loss:  0.6858112215995789\n",
      "Write summary at step 12580  Loss:  0.6552627086639404\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.670995670995671 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5464480874316939\n",
      "Loss normal: 0.6574191004682929 Loss Control: 0.6432685682682392 Loss Patient: 0.7113679945468903 Loss balanced:  0.6773182814075647 Loss1+loss2: 0.6773182814075647\n",
      "Write summary at step 12590  Loss:  0.7390857934951782\n",
      "Write summary at step 12600  Loss:  0.7340050935745239\n",
      "Write summary at step 12610  Loss:  0.7376257181167603\n",
      "Write summary at step 12620  Loss:  0.6705932021141052\n",
      "Write summary at step 12630  Loss:  0.6643270254135132\n",
      "Write summary at step 12640  Loss:  0.6625963449478149\n",
      "Write summary at step 12650  Loss:  0.6808385848999023\n",
      "Write summary at step 12660  Loss:  0.6647344827651978\n",
      "Write summary at step 12670  Loss:  0.6758662462234497\n",
      "Write summary at step 12680  Loss:  0.6721056699752808\n",
      "Write summary at step 12690  Loss:  0.7321536540985107\n",
      "Write summary at step 12700  Loss:  0.7351358532905579\n",
      "Write summary at step 12710  Loss:  0.6472156047821045\n",
      "Write summary at step 12720  Loss:  0.6329948902130127\n",
      "Write summary at step 12730  Loss:  0.6890004277229309\n",
      "Write summary at step 12740  Loss:  0.6586610078811646\n",
      "Write summary at step 12750  Loss:  0.7769812345504761\n",
      "Write summary at step 12760  Loss:  0.7599797248840332\n",
      "Write summary at step 12770  Loss:  0.618309497833252\n",
      "Write summary at step 12780  Loss:  0.6856546401977539\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.37662337662337664 Acurracy Control:  0.3224043715846995 Acurracy Patient:  0.5833333333333334 Acurracy Balanced 0.4528688524590164\n",
      "Loss normal: 0.7540152219982891 Loss Control: 0.7790844964850796 Loss Patient: 0.6584385323027769 Loss balanced:  0.7187615143939283 Loss1+loss2: 0.7187615143939283\n",
      "Write summary at step 12790  Loss:  0.6779149770736694\n",
      "Write summary at step 12800  Loss:  0.6570079326629639\n",
      "Write summary at step 12810  Loss:  0.6674232482910156\n",
      "Write summary at step 12820  Loss:  0.6295388340950012\n",
      "Write summary at step 12830  Loss:  0.6404794454574585\n",
      "Write summary at step 12840  Loss:  0.7360559701919556\n",
      "Write summary at step 12850  Loss:  0.8629873991012573\n",
      "Write summary at step 12860  Loss:  0.7486182451248169\n",
      "Write summary at step 12870  Loss:  0.6563374996185303\n",
      "Write summary at step 12880  Loss:  0.6825308799743652\n",
      "Write summary at step 12890  Loss:  0.6745452880859375\n",
      "Write summary at step 12900  Loss:  0.6207078695297241\n",
      "Write summary at step 12910  Loss:  0.6739718914031982\n",
      "Write summary at step 12920  Loss:  0.6954723596572876\n",
      "Write summary at step 12930  Loss:  0.7516031265258789\n",
      "Write summary at step 12940  Loss:  0.7256679534912109\n",
      "Write summary at step 12950  Loss:  0.7098586559295654\n",
      "Write summary at step 12960  Loss:  0.8025413751602173\n",
      "Write summary at step 12970  Loss:  0.6525074243545532\n",
      "Write summary at step 12980  Loss:  0.6689282655715942\n",
      "Write summary at step 12990  Loss:  0.6979103088378906\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4069264069264069 Acurracy Control:  0.37158469945355194 Acurracy Patient:  0.5416666666666666 Acurracy Balanced 0.4566256830601093\n",
      "Loss normal: 0.7491293766281821 Loss Control: 0.7744542897724714 Loss Patient: 0.6525781458864609 Loss balanced:  0.7135162178294662 Loss1+loss2: 0.7135162178294662\n",
      "Write summary at step 13000  Loss:  0.6243019700050354\n",
      "Saved checkpoint to: result/42/panns/checkpoint_13000.pt\n",
      "Validation:\n",
      "Acurracy:  0.4588744588744589 Acurracy Control:  0.4644808743169399 Acurracy Patient:  0.4375 Acurracy Balanced 0.45099043715847\n",
      "Loss normal: 0.7188672903296235 Loss Control: 0.7253647850510853 Loss Patient: 0.6940955625226101 Loss balanced:  0.7097301737868477 Loss1+loss2: 0.7097301737868477\n",
      "Write summary at step 13010  Loss:  0.7108945846557617\n",
      "Write summary at step 13020  Loss:  0.6955184936523438\n",
      "Write summary at step 13030  Loss:  0.6190512180328369\n",
      "Write summary at step 13040  Loss:  0.6215782165527344\n",
      "Write summary at step 13050  Loss:  0.7330300211906433\n",
      "Write summary at step 13060  Loss:  0.6606695652008057\n",
      "Write summary at step 13070  Loss:  0.6535476446151733\n",
      "Write summary at step 13080  Loss:  0.6904648542404175\n",
      "Write summary at step 13090  Loss:  0.6505074501037598\n",
      "Write summary at step 13100  Loss:  0.6898432970046997\n",
      "Write summary at step 13110  Loss:  0.7283560037612915\n",
      "Write summary at step 13120  Loss:  0.6212376356124878\n",
      "Write summary at step 13130  Loss:  0.7322804927825928\n",
      "Write summary at step 13140  Loss:  0.6502313017845154\n",
      "Write summary at step 13150  Loss:  0.7099882364273071\n",
      "Write summary at step 13160  Loss:  0.6150692701339722\n",
      "Write summary at step 13170  Loss:  0.7745747566223145\n",
      "Write summary at step 13180  Loss:  0.6355819702148438\n",
      "Write summary at step 13190  Loss:  0.6459351778030396\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7056277056277056 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5298838797814208\n",
      "Loss normal: 0.6532196926348137 Loss Control: 0.6297834284318601 Loss Patient: 0.742570503304402 Loss balanced:  0.686176965868131 Loss1+loss2: 0.686176965868131\n",
      "Write summary at step 13200  Loss:  0.6809811592102051\n",
      "Write summary at step 13210  Loss:  0.7084949016571045\n",
      "Write summary at step 13220  Loss:  0.6709616780281067\n",
      "Write summary at step 13230  Loss:  0.704230010509491\n",
      "Write summary at step 13240  Loss:  0.702521026134491\n",
      "Write summary at step 13250  Loss:  0.7602382898330688\n",
      "Write summary at step 13260  Loss:  0.6581686735153198\n",
      "Write summary at step 13270  Loss:  0.647100567817688\n",
      "Write summary at step 13280  Loss:  0.6271865367889404\n",
      "Write summary at step 13290  Loss:  0.7240347862243652\n",
      "Write summary at step 13300  Loss:  0.6433991193771362\n",
      "Write summary at step 13310  Loss:  0.6872081756591797\n",
      "Write summary at step 13320  Loss:  0.7875003814697266\n",
      "Write summary at step 13330  Loss:  0.646819531917572\n",
      "Write summary at step 13340  Loss:  0.7015718221664429\n",
      "Write summary at step 13350  Loss:  0.7529140710830688\n",
      "Write summary at step 13360  Loss:  0.7005053758621216\n",
      "Write summary at step 13370  Loss:  0.7287324070930481\n",
      "Write summary at step 13380  Loss:  0.7325513362884521\n",
      "Write summary at step 13390  Loss:  0.6256650686264038\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7316017316017316 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5462773224043715\n",
      "Loss normal: 0.6443249952225458 Loss Control: 0.6164373791282945 Loss Patient: 0.750646543999513 Loss balanced:  0.6835419615639038 Loss1+loss2: 0.6835419615639038\n",
      "Write summary at step 13400  Loss:  0.7007735967636108\n",
      "Write summary at step 13410  Loss:  0.6358762979507446\n",
      "Write summary at step 13420  Loss:  0.7178399562835693\n",
      "Write summary at step 13430  Loss:  0.8046239614486694\n",
      "Write summary at step 13440  Loss:  0.6963918209075928\n",
      "Write summary at step 13450  Loss:  0.7044376134872437\n",
      "Write summary at step 13460  Loss:  0.670563817024231\n",
      "Write summary at step 13470  Loss:  0.6871649026870728\n",
      "Write summary at step 13480  Loss:  0.7350598573684692\n",
      "Write summary at step 13490  Loss:  0.7083116769790649\n",
      "Write summary at step 13500  Loss:  0.6970227956771851\n",
      "Saved checkpoint to: result/42/panns/checkpoint_13500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8225108225108225 Acurracy Control:  1.0 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5729166666666666\n",
      "Loss normal: 0.6150253428009166 Loss Control: 0.5652191430493131 Loss Patient: 0.8049114632109801 Loss balanced:  0.6850653031301466 Loss1+loss2: 0.6850653031301466\n",
      "Write summary at step 13510  Loss:  0.6784125566482544\n",
      "Write summary at step 13520  Loss:  0.6434999108314514\n",
      "Write summary at step 13530  Loss:  0.7427482604980469\n",
      "Write summary at step 13540  Loss:  0.6103272438049316\n",
      "Write summary at step 13550  Loss:  0.6675602793693542\n",
      "Write summary at step 13560  Loss:  0.7079346776008606\n",
      "Write summary at step 13570  Loss:  0.5842734575271606\n",
      "Write summary at step 13580  Loss:  0.72447669506073\n",
      "Write summary at step 13590  Loss:  0.6338285207748413\n",
      "Write summary at step 13600  Loss:  0.6691581010818481\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7012987012987013 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.25 Acurracy Balanced 0.5348360655737705\n",
      "Loss normal: 0.6536913823771786 Loss Control: 0.6442654025359232 Loss Patient: 0.6896279168625673 Loss balanced:  0.6669466596992453 Loss1+loss2: 0.6669466596992453\n",
      "\n",
      " > BEST MODEL (0.66695) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 13610  Loss:  0.6182448267936707\n",
      "Write summary at step 13620  Loss:  0.7145035266876221\n",
      "Write summary at step 13630  Loss:  0.5524132251739502\n",
      "Write summary at step 13640  Loss:  0.6166946887969971\n",
      "Write summary at step 13650  Loss:  0.6676912307739258\n",
      "Write summary at step 13660  Loss:  0.6482340097427368\n",
      "Write summary at step 13670  Loss:  0.7092169523239136\n",
      "Write summary at step 13680  Loss:  0.6622675657272339\n",
      "Write summary at step 13690  Loss:  0.6997958421707153\n",
      "Write summary at step 13700  Loss:  0.6034784317016602\n",
      "Write summary at step 13710  Loss:  0.71719890832901\n",
      "Write summary at step 13720  Loss:  0.6492444276809692\n",
      "Write summary at step 13730  Loss:  0.6499522924423218\n",
      "Write summary at step 13740  Loss:  0.6662861704826355\n",
      "Write summary at step 13750  Loss:  0.7161677479743958\n",
      "Write summary at step 13760  Loss:  0.5878331065177917\n",
      "Write summary at step 13770  Loss:  0.5931682586669922\n",
      "Write summary at step 13780  Loss:  0.7184153199195862\n",
      "Write summary at step 13790  Loss:  0.5660297870635986\n",
      "Write summary at step 13800  Loss:  0.7003122568130493\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5844155844155844 Acurracy Control:  0.639344262295082 Acurracy Patient:  0.375 Acurracy Balanced 0.507172131147541\n",
      "Loss normal: 0.6785237722066574 Loss Control: 0.6819880914166977 Loss Patient: 0.6653160965070128 Loss balanced:  0.6736520939618553 Loss1+loss2: 0.6736520939618553\n",
      "Write summary at step 13810  Loss:  0.7739004492759705\n",
      "Write summary at step 13820  Loss:  0.7063496112823486\n",
      "Write summary at step 13830  Loss:  0.7126622796058655\n",
      "Write summary at step 13840  Loss:  0.6550458669662476\n",
      "Write summary at step 13850  Loss:  0.6867985725402832\n",
      "Write summary at step 13860  Loss:  0.8603053092956543\n",
      "Write summary at step 13870  Loss:  0.6779911518096924\n",
      "Write summary at step 13880  Loss:  0.6690281629562378\n",
      "Write summary at step 13890  Loss:  0.6864615082740784\n",
      "Write summary at step 13900  Loss:  0.6394756436347961\n",
      "Write summary at step 13910  Loss:  0.6893466711044312\n",
      "Write summary at step 13920  Loss:  0.6555318236351013\n",
      "Write summary at step 13930  Loss:  0.610467791557312\n",
      "Write summary at step 13940  Loss:  0.6159294247627258\n",
      "Write summary at step 13950  Loss:  0.7228928208351135\n",
      "Write summary at step 13960  Loss:  0.675817608833313\n",
      "Write summary at step 13970  Loss:  0.637631893157959\n",
      "Write summary at step 13980  Loss:  0.6582996845245361\n",
      "Write summary at step 13990  Loss:  0.6855080723762512\n",
      "Write summary at step 14000  Loss:  0.6837821006774902\n",
      "Saved checkpoint to: result/42/panns/checkpoint_14000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8268398268398268 Acurracy Control:  1.0 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5833333333333334\n",
      "Loss normal: 0.6080537575147885 Loss Control: 0.5645375121486643 Loss Patient: 0.7739594702919325 Loss balanced:  0.6692484912202984 Loss1+loss2: 0.6692484912202984\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8138528138528138 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.1875 Acurracy Balanced 0.5828210382513661\n",
      "Loss normal: 0.6151987667723652 Loss Control: 0.5786161784265862 Loss Patient: 0.7546698985000452 Loss balanced:  0.6666430384633157 Loss1+loss2: 0.6666430384633157\n",
      "\n",
      " > BEST MODEL (0.66664) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 14010  Loss:  0.6965868473052979\n",
      "Write summary at step 14020  Loss:  0.68463534116745\n",
      "Write summary at step 14030  Loss:  0.6875748634338379\n",
      "Write summary at step 14040  Loss:  0.8931915760040283\n",
      "Write summary at step 14050  Loss:  0.7489815354347229\n",
      "Write summary at step 14060  Loss:  0.5460101366043091\n",
      "Write summary at step 14070  Loss:  0.7042664289474487\n",
      "Write summary at step 14080  Loss:  0.7050307989120483\n",
      "Write summary at step 14090  Loss:  0.6970891952514648\n",
      "Write summary at step 14100  Loss:  0.6200441718101501\n",
      "Write summary at step 14110  Loss:  0.7189592719078064\n",
      "Write summary at step 14120  Loss:  0.6948357820510864\n",
      "Write summary at step 14130  Loss:  0.6508406400680542\n",
      "Write summary at step 14140  Loss:  0.6412113904953003\n",
      "Write summary at step 14150  Loss:  0.7059863209724426\n",
      "Write summary at step 14160  Loss:  0.6693832874298096\n",
      "Write summary at step 14170  Loss:  0.6699934005737305\n",
      "Write summary at step 14180  Loss:  0.6438429355621338\n",
      "Write summary at step 14190  Loss:  0.6233527660369873\n",
      "Write summary at step 14200  Loss:  0.6631331443786621\n",
      "Write summary at step 14210  Loss:  0.6885223388671875\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4458874458874459 Acurracy Control:  0.45901639344262296 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.42742486338797814\n",
      "Loss normal: 0.6969755622215601 Loss Control: 0.6997348399110179 Loss Patient: 0.686455766359965 Loss balanced:  0.6930953031354914 Loss1+loss2: 0.6930953031354914\n",
      "Write summary at step 14220  Loss:  0.6378411054611206\n",
      "Write summary at step 14230  Loss:  0.6819750070571899\n",
      "Write summary at step 14240  Loss:  0.6652716398239136\n",
      "Write summary at step 14250  Loss:  0.6307778358459473\n",
      "Write summary at step 14260  Loss:  0.6908514499664307\n",
      "Write summary at step 14270  Loss:  0.7948356866836548\n",
      "Write summary at step 14280  Loss:  0.7050806283950806\n",
      "Write summary at step 14290  Loss:  0.696544885635376\n",
      "Write summary at step 14300  Loss:  0.7007553577423096\n",
      "Write summary at step 14310  Loss:  0.6770803928375244\n",
      "Write summary at step 14320  Loss:  0.711711049079895\n",
      "Write summary at step 14330  Loss:  0.6516674757003784\n",
      "Write summary at step 14340  Loss:  0.715280294418335\n",
      "Write summary at step 14350  Loss:  0.6174226999282837\n",
      "Write summary at step 14360  Loss:  0.7338642477989197\n",
      "Write summary at step 14370  Loss:  0.6818886995315552\n",
      "Write summary at step 14380  Loss:  0.7070696949958801\n",
      "Write summary at step 14390  Loss:  0.6457983255386353\n",
      "Write summary at step 14400  Loss:  0.7191349267959595\n",
      "Write summary at step 14410  Loss:  0.7180438041687012\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7229437229437229 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.51775956284153\n",
      "Loss normal: 0.6311154510035659 Loss Control: 0.5896840707851889 Loss Patient: 0.7890725210309029 Loss balanced:  0.6893782959080459 Loss1+loss2: 0.6893782959080459\n",
      "Write summary at step 14420  Loss:  0.7728468179702759\n",
      "Write summary at step 14430  Loss:  0.6612732410430908\n",
      "Write summary at step 14440  Loss:  0.7559140920639038\n",
      "Write summary at step 14450  Loss:  0.7368944883346558\n",
      "Write summary at step 14460  Loss:  0.7097843289375305\n",
      "Write summary at step 14470  Loss:  0.6605831384658813\n",
      "Write summary at step 14480  Loss:  0.6863064765930176\n",
      "Write summary at step 14490  Loss:  0.6683326959609985\n",
      "Write summary at step 14500  Loss:  0.6493682861328125\n",
      "Saved checkpoint to: result/42/panns/checkpoint_14500.pt\n",
      "Validation:\n",
      "Acurracy:  0.645021645021645 Acurracy Control:  0.7431693989071039 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5070013661202186\n",
      "Loss normal: 0.6548254582789037 Loss Control: 0.628268265333332 Loss Patient: 0.7560747936367989 Loss balanced:  0.6921715294850654 Loss1+loss2: 0.6921715294850654\n",
      "Write summary at step 14510  Loss:  0.7101664543151855\n",
      "Write summary at step 14520  Loss:  0.6991077065467834\n",
      "Write summary at step 14530  Loss:  0.6210814714431763\n",
      "Write summary at step 14540  Loss:  0.7237569093704224\n",
      "Write summary at step 14550  Loss:  0.7470620274543762\n",
      "Write summary at step 14560  Loss:  0.7142882943153381\n",
      "Write summary at step 14570  Loss:  0.6875467300415039\n",
      "Write summary at step 14580  Loss:  0.6492925882339478\n",
      "Write summary at step 14590  Loss:  0.695831835269928\n",
      "Write summary at step 14600  Loss:  0.6390748620033264\n",
      "Write summary at step 14610  Loss:  0.6890692114830017\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.658008658008658 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5459357923497268\n",
      "Loss normal: 0.6495007364264814 Loss Control: 0.6288119912798938 Loss Patient: 0.7283765878528357 Loss balanced:  0.6785942895663648 Loss1+loss2: 0.6785942895663648\n",
      "Write summary at step 14620  Loss:  0.6374720335006714\n",
      "Write summary at step 14630  Loss:  0.6949920654296875\n",
      "Write summary at step 14640  Loss:  0.756618082523346\n",
      "Write summary at step 14650  Loss:  0.677985668182373\n",
      "Write summary at step 14660  Loss:  0.6079268455505371\n",
      "Write summary at step 14670  Loss:  0.6247808337211609\n",
      "Write summary at step 14680  Loss:  0.6544132232666016\n",
      "Write summary at step 14690  Loss:  0.7510462999343872\n",
      "Write summary at step 14700  Loss:  0.7332630157470703\n",
      "Write summary at step 14710  Loss:  0.6533744931221008\n",
      "Write summary at step 14720  Loss:  0.6798751354217529\n",
      "Write summary at step 14730  Loss:  0.6042715311050415\n",
      "Write summary at step 14740  Loss:  0.7142714262008667\n",
      "Write summary at step 14750  Loss:  0.6565653085708618\n",
      "Write summary at step 14760  Loss:  0.6549607515335083\n",
      "Write summary at step 14770  Loss:  0.6299508810043335\n",
      "Write summary at step 14780  Loss:  0.6518011093139648\n",
      "Write summary at step 14790  Loss:  0.6784869432449341\n",
      "Write summary at step 14800  Loss:  0.6892863512039185\n",
      "Write summary at step 14810  Loss:  0.6282635927200317\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.683982683982684 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5623292349726776\n",
      "Loss normal: 0.6246420604325992 Loss Control: 0.5879301412509439 Loss Patient: 0.7646063050876061 Loss balanced:  0.6762682231692749 Loss1+loss2: 0.6762682231692749\n",
      "Write summary at step 14820  Loss:  0.7313127517700195\n",
      "Write summary at step 14830  Loss:  0.6640449166297913\n",
      "Write summary at step 14840  Loss:  0.6328298449516296\n",
      "Write summary at step 14850  Loss:  0.5901817083358765\n",
      "Write summary at step 14860  Loss:  0.9277139902114868\n",
      "Write summary at step 14870  Loss:  0.6860184073448181\n",
      "Write summary at step 14880  Loss:  0.6536213159561157\n",
      "Write summary at step 14890  Loss:  0.8060824275016785\n",
      "Write summary at step 14900  Loss:  0.5955306887626648\n",
      "Write summary at step 14910  Loss:  0.6819806694984436\n",
      "Write summary at step 14920  Loss:  0.787733793258667\n",
      "Write summary at step 14930  Loss:  0.646198034286499\n",
      "Write summary at step 14940  Loss:  0.7239923477172852\n",
      "Write summary at step 14950  Loss:  0.7299574613571167\n",
      "Write summary at step 14960  Loss:  0.7228259444236755\n",
      "Write summary at step 14970  Loss:  0.7086708545684814\n",
      "Write summary at step 14980  Loss:  0.6966683268547058\n",
      "Write summary at step 14990  Loss:  0.6669909954071045\n",
      "Write summary at step 15000  Loss:  0.7472261190414429\n",
      "Saved checkpoint to: result/42/panns/checkpoint_15000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6406926406926406 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5119535519125683\n",
      "Loss normal: 0.6460210193287242 Loss Control: 0.6015084115533881 Loss Patient: 0.8157252818346024 Loss balanced:  0.7086168466939953 Loss1+loss2: 0.7086168466939953\n",
      "Write summary at step 15010  Loss:  0.75174880027771\n",
      "Write summary at step 15020  Loss:  0.7219210267066956\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5326161202185793\n",
      "Loss normal: 0.6169528971502791 Loss Control: 0.5426227121405263 Loss Patient: 0.900336696455876 Loss balanced:  0.7214797042982011 Loss1+loss2: 0.7214797042982011\n",
      "Write summary at step 15030  Loss:  0.635947585105896\n",
      "Write summary at step 15040  Loss:  0.6139805316925049\n",
      "Write summary at step 15050  Loss:  0.6405631899833679\n",
      "Write summary at step 15060  Loss:  0.7691975235939026\n",
      "Write summary at step 15070  Loss:  0.599068284034729\n",
      "Write summary at step 15080  Loss:  0.856542706489563\n",
      "Write summary at step 15090  Loss:  0.7045975923538208\n",
      "Write summary at step 15100  Loss:  0.5875957608222961\n",
      "Write summary at step 15110  Loss:  0.6514236927032471\n",
      "Write summary at step 15120  Loss:  0.6398005485534668\n",
      "Write summary at step 15130  Loss:  0.6300904154777527\n",
      "Write summary at step 15140  Loss:  0.6968898773193359\n",
      "Write summary at step 15150  Loss:  0.593385636806488\n",
      "Write summary at step 15160  Loss:  0.5839300155639648\n",
      "Write summary at step 15170  Loss:  0.7332315444946289\n",
      "Write summary at step 15180  Loss:  0.6301339864730835\n",
      "Write summary at step 15190  Loss:  0.6424146294593811\n",
      "Write summary at step 15200  Loss:  0.7033320069313049\n",
      "Write summary at step 15210  Loss:  0.6971598267555237\n",
      "Write summary at step 15220  Loss:  0.6059703826904297\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7012987012987013 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.25 Acurracy Balanced 0.5348360655737705\n",
      "Loss normal: 0.6266509086796732 Loss Control: 0.5531435017703009 Loss Patient: 0.9068979062139988 Loss balanced:  0.7300207039921498 Loss1+loss2: 0.7300207039921498\n",
      "Write summary at step 15230  Loss:  0.6575389504432678\n",
      "Write summary at step 15240  Loss:  0.6915620565414429\n",
      "Write summary at step 15250  Loss:  0.748167872428894\n",
      "Write summary at step 15260  Loss:  0.682827353477478\n",
      "Write summary at step 15270  Loss:  0.6521772742271423\n",
      "Write summary at step 15280  Loss:  0.6432663202285767\n",
      "Write summary at step 15290  Loss:  0.6945887207984924\n",
      "Write summary at step 15300  Loss:  0.6497691869735718\n",
      "Write summary at step 15310  Loss:  0.5672181844711304\n",
      "Write summary at step 15320  Loss:  0.6093103885650635\n",
      "Write summary at step 15330  Loss:  0.6078836917877197\n",
      "Write summary at step 15340  Loss:  0.6733022928237915\n",
      "Write summary at step 15350  Loss:  0.6633220911026001\n",
      "Write summary at step 15360  Loss:  0.5774152278900146\n",
      "Write summary at step 15370  Loss:  0.7083353996276855\n",
      "Write summary at step 15380  Loss:  0.6780306100845337\n",
      "Write summary at step 15390  Loss:  0.6638556718826294\n",
      "Write summary at step 15400  Loss:  0.7502837181091309\n",
      "Write summary at step 15410  Loss:  0.7537999153137207\n",
      "Write summary at step 15420  Loss:  0.6507583856582642\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5930735930735931 Acurracy Control:  0.6666666666666666 Acurracy Patient:  0.3125 Acurracy Balanced 0.4895833333333333\n",
      "Loss normal: 0.6617287855385702 Loss Control: 0.6302627173603558 Loss Patient: 0.781693177918593 Loss balanced:  0.7059779476394744 Loss1+loss2: 0.7059779476394744\n",
      "Write summary at step 15430  Loss:  0.7050418853759766\n",
      "Write summary at step 15440  Loss:  0.6736725568771362\n",
      "Write summary at step 15450  Loss:  0.7307837009429932\n",
      "Write summary at step 15460  Loss:  0.5796595811843872\n",
      "Write summary at step 15470  Loss:  0.6350231170654297\n",
      "Write summary at step 15480  Loss:  0.7213865518569946\n",
      "Write summary at step 15490  Loss:  0.7335269451141357\n",
      "Write summary at step 15500  Loss:  0.652288556098938\n",
      "Saved checkpoint to: result/42/panns/checkpoint_15500.pt\n",
      "Validation:\n",
      "Acurracy:  0.658008658008658 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5151980874316939\n",
      "Loss normal: 0.6382296601415196 Loss Control: 0.5997096580234381 Loss Patient: 0.7850871589034796 Loss balanced:  0.6923984084634589 Loss1+loss2: 0.6923984084634589\n",
      "Write summary at step 15510  Loss:  0.6915414929389954\n",
      "Write summary at step 15520  Loss:  0.7633193731307983\n",
      "Write summary at step 15530  Loss:  0.626535952091217\n",
      "Write summary at step 15540  Loss:  0.708783745765686\n",
      "Write summary at step 15550  Loss:  0.6039144992828369\n",
      "Write summary at step 15560  Loss:  0.7035582661628723\n",
      "Write summary at step 15570  Loss:  0.6836539506912231\n",
      "Write summary at step 15580  Loss:  0.7054615020751953\n",
      "Write summary at step 15590  Loss:  0.6048682928085327\n",
      "Write summary at step 15600  Loss:  0.701716423034668\n",
      "Write summary at step 15610  Loss:  0.7490072250366211\n",
      "Write summary at step 15620  Loss:  0.6883628964424133\n",
      "Write summary at step 15630  Loss:  0.6813522577285767\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5993852459016393\n",
      "Loss normal: 0.5848479070962765 Loss Control: 0.5097675527054104 Loss Patient: 0.8710917811840773 Loss balanced:  0.6904296669447438 Loss1+loss2: 0.6904296669447438\n",
      "Write summary at step 15640  Loss:  0.7053760886192322\n",
      "Write summary at step 15650  Loss:  0.5958309173583984\n",
      "Write summary at step 15660  Loss:  0.667352557182312\n",
      "Write summary at step 15670  Loss:  0.6041346788406372\n",
      "Write summary at step 15680  Loss:  0.6994577646255493\n",
      "Write summary at step 15690  Loss:  0.792695164680481\n",
      "Write summary at step 15700  Loss:  0.6288458704948425\n",
      "Write summary at step 15710  Loss:  0.6324516534805298\n",
      "Write summary at step 15720  Loss:  0.7518360614776611\n",
      "Write summary at step 15730  Loss:  0.6791979074478149\n",
      "Write summary at step 15740  Loss:  0.7095922231674194\n",
      "Write summary at step 15750  Loss:  0.7113856077194214\n",
      "Write summary at step 15760  Loss:  0.6918653845787048\n",
      "Write summary at step 15770  Loss:  0.6313768625259399\n",
      "Write summary at step 15780  Loss:  0.5831419825553894\n",
      "Write summary at step 15790  Loss:  0.8053873777389526\n",
      "Write summary at step 15800  Loss:  0.6975295543670654\n",
      "Write summary at step 15810  Loss:  0.6115199327468872\n",
      "Write summary at step 15820  Loss:  0.6891571283340454\n",
      "Write summary at step 15830  Loss:  0.7196124792098999\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5724043715846995\n",
      "Loss normal: 0.5446270041135483 Loss Control: 0.33408013751598004 Loss Patient: 1.3473369466761749 Loss balanced:  0.8407085420960775 Loss1+loss2: 0.8407085420960775\n",
      "Write summary at step 15840  Loss:  0.6222285628318787\n",
      "Write summary at step 15850  Loss:  0.6971380710601807\n",
      "Write summary at step 15860  Loss:  0.6485711336135864\n",
      "Write summary at step 15870  Loss:  0.7847479581832886\n",
      "Write summary at step 15880  Loss:  0.6317375898361206\n",
      "Write summary at step 15890  Loss:  0.7006199955940247\n",
      "Write summary at step 15900  Loss:  0.689058244228363\n",
      "Write summary at step 15910  Loss:  0.6747803688049316\n",
      "Write summary at step 15920  Loss:  0.6669381856918335\n",
      "Write summary at step 15930  Loss:  0.6266586780548096\n",
      "Write summary at step 15940  Loss:  0.7699116468429565\n",
      "Write summary at step 15950  Loss:  0.660496711730957\n",
      "Write summary at step 15960  Loss:  0.6421347856521606\n",
      "Write summary at step 15970  Loss:  0.6738025546073914\n",
      "Write summary at step 15980  Loss:  0.6001945734024048\n",
      "Write summary at step 15990  Loss:  0.7091680765151978\n",
      "Write summary at step 16000  Loss:  0.7149341106414795\n",
      "Saved checkpoint to: result/42/panns/checkpoint_16000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8225108225108225 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5959699453551912\n",
      "Loss normal: 0.5443462743645623 Loss Control: 0.41466620401606535 Loss Patient: 1.0387515785793464 Loss balanced:  0.7267088912977059 Loss1+loss2: 0.7267088912977059\n",
      "Write summary at step 16010  Loss:  0.6973917484283447\n",
      "Write summary at step 16020  Loss:  0.8525153398513794\n",
      "Write summary at step 16030  Loss:  0.6515738368034363\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5701844262295082\n",
      "Loss normal: 0.530926205637135 Loss Control: 0.3718812475438978 Loss Patient: 1.1372851158181827 Loss balanced:  0.7545831816810402 Loss1+loss2: 0.7545831816810402\n",
      "Write summary at step 16040  Loss:  0.6712685823440552\n",
      "Write summary at step 16050  Loss:  0.6436794996261597\n",
      "Write summary at step 16060  Loss:  0.6962267160415649\n",
      "Write summary at step 16070  Loss:  0.597476601600647\n",
      "Write summary at step 16080  Loss:  0.6430834531784058\n",
      "Write summary at step 16090  Loss:  0.6791707873344421\n",
      "Write summary at step 16100  Loss:  0.606063187122345\n",
      "Write summary at step 16110  Loss:  0.6947619915008545\n",
      "Write summary at step 16120  Loss:  0.7088510394096375\n",
      "Write summary at step 16130  Loss:  0.7144370079040527\n",
      "Write summary at step 16140  Loss:  0.7571403980255127\n",
      "Write summary at step 16150  Loss:  0.6732735633850098\n",
      "Write summary at step 16160  Loss:  0.6230047941207886\n",
      "Write summary at step 16170  Loss:  0.6015956401824951\n",
      "Write summary at step 16180  Loss:  0.6941045522689819\n",
      "Write summary at step 16190  Loss:  0.6804908514022827\n",
      "Write summary at step 16200  Loss:  0.6766060590744019\n",
      "Write summary at step 16210  Loss:  0.6242455244064331\n",
      "Write summary at step 16220  Loss:  0.6983475685119629\n",
      "Write summary at step 16230  Loss:  0.6461698412895203\n",
      "Write summary at step 16240  Loss:  0.6172946095466614\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5954576502732241\n",
      "Loss normal: 0.5596283549096162 Loss Control: 0.4503162576526892 Loss Patient: 0.9763806983828545 Loss balanced:  0.7133484780177718 Loss1+loss2: 0.7133484780177718\n",
      "Write summary at step 16250  Loss:  0.5827876329421997\n",
      "Write summary at step 16260  Loss:  0.6996035575866699\n",
      "Write summary at step 16270  Loss:  0.7007473111152649\n",
      "Write summary at step 16280  Loss:  0.8390728235244751\n",
      "Write summary at step 16290  Loss:  0.5505690574645996\n",
      "Write summary at step 16300  Loss:  0.6453217267990112\n",
      "Write summary at step 16310  Loss:  0.746858537197113\n",
      "Write summary at step 16320  Loss:  0.6816158294677734\n",
      "Write summary at step 16330  Loss:  0.6576008796691895\n",
      "Write summary at step 16340  Loss:  0.6304473280906677\n",
      "Write summary at step 16350  Loss:  0.6092692613601685\n",
      "Write summary at step 16360  Loss:  0.6209812164306641\n",
      "Write summary at step 16370  Loss:  0.6835740208625793\n",
      "Write summary at step 16380  Loss:  0.5851514935493469\n",
      "Write summary at step 16390  Loss:  0.7844869494438171\n",
      "Write summary at step 16400  Loss:  0.7085225582122803\n",
      "Write summary at step 16410  Loss:  0.6669772863388062\n",
      "Write summary at step 16420  Loss:  0.7138117551803589\n",
      "Write summary at step 16430  Loss:  0.6852257251739502\n",
      "Write summary at step 16440  Loss:  0.7134573459625244\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.696969696969697 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.25 Acurracy Balanced 0.532103825136612\n",
      "Loss normal: 0.6156887275315982 Loss Control: 0.552960414052661 Loss Patient: 0.8548404239118099 Loss balanced:  0.7039004189822355 Loss1+loss2: 0.7039004189822355\n",
      "Write summary at step 16450  Loss:  0.5910865664482117\n",
      "Write summary at step 16460  Loss:  0.6556744575500488\n",
      "Write summary at step 16470  Loss:  0.6292897462844849\n",
      "Write summary at step 16480  Loss:  0.6608753204345703\n",
      "Write summary at step 16490  Loss:  0.5683774948120117\n",
      "Write summary at step 16500  Loss:  0.6385167837142944\n",
      "Saved checkpoint to: result/42/panns/checkpoint_16500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5778688524590164\n",
      "Loss normal: 0.5114794119353935 Loss Control: 0.30139131575334266 Loss Patient: 1.3124402662118275 Loss balanced:  0.806915790982585 Loss1+loss2: 0.806915790982585\n",
      "Write summary at step 16510  Loss:  0.6262712478637695\n",
      "Write summary at step 16520  Loss:  0.5465314388275146\n",
      "Write summary at step 16530  Loss:  0.602199912071228\n",
      "Write summary at step 16540  Loss:  0.6777375936508179\n",
      "Write summary at step 16550  Loss:  0.717684268951416\n",
      "Write summary at step 16560  Loss:  0.7678501605987549\n",
      "Write summary at step 16570  Loss:  0.7504837512969971\n",
      "Write summary at step 16580  Loss:  0.6261497735977173\n",
      "Write summary at step 16590  Loss:  0.6060425043106079\n",
      "Write summary at step 16600  Loss:  0.5345989465713501\n",
      "Write summary at step 16610  Loss:  0.7354956269264221\n",
      "Write summary at step 16620  Loss:  0.7678926587104797\n",
      "Write summary at step 16630  Loss:  0.7464781999588013\n",
      "Write summary at step 16640  Loss:  0.6953127980232239\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5845286885245902\n",
      "Loss normal: 0.5576632189286219 Loss Control: 0.43000827346994575 Loss Patient: 1.044347696006298 Loss balanced:  0.7371779847381219 Loss1+loss2: 0.7371779847381219\n",
      "Write summary at step 16650  Loss:  0.5881879925727844\n",
      "Write summary at step 16660  Loss:  0.620969831943512\n",
      "Write summary at step 16670  Loss:  0.6396433711051941\n",
      "Write summary at step 16680  Loss:  0.6592759490013123\n",
      "Write summary at step 16690  Loss:  0.6337102651596069\n",
      "Write summary at step 16700  Loss:  0.6701323986053467\n",
      "Write summary at step 16710  Loss:  0.678022027015686\n",
      "Write summary at step 16720  Loss:  0.6371866464614868\n",
      "Write summary at step 16730  Loss:  0.6672320365905762\n",
      "Write summary at step 16740  Loss:  0.5932040214538574\n",
      "Write summary at step 16750  Loss:  0.7653417587280273\n",
      "Write summary at step 16760  Loss:  0.6437374949455261\n",
      "Write summary at step 16770  Loss:  0.7350903749465942\n",
      "Write summary at step 16780  Loss:  0.7005302309989929\n",
      "Write summary at step 16790  Loss:  0.6612071394920349\n",
      "Write summary at step 16800  Loss:  0.7194879651069641\n",
      "Write summary at step 16810  Loss:  0.7906661033630371\n",
      "Write summary at step 16820  Loss:  0.742196798324585\n",
      "Write summary at step 16830  Loss:  0.750224232673645\n",
      "Write summary at step 16840  Loss:  0.573611855506897\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5671106557377049\n",
      "Loss normal: 0.5685911154076134 Loss Control: 0.4565208826234432 Loss Patient: 0.9958588679631551 Loss balanced:  0.7261898752932991 Loss1+loss2: 0.7261898752932991\n",
      "Write summary at step 16850  Loss:  0.6487984657287598\n",
      "Write summary at step 16860  Loss:  0.7110660672187805\n",
      "Write summary at step 16870  Loss:  0.6575528383255005\n",
      "Write summary at step 16880  Loss:  0.6412667036056519\n",
      "Write summary at step 16890  Loss:  0.6097108125686646\n",
      "Write summary at step 16900  Loss:  0.6477494835853577\n",
      "Write summary at step 16910  Loss:  0.6682747006416321\n",
      "Write summary at step 16920  Loss:  0.6029791831970215\n",
      "Write summary at step 16930  Loss:  0.86616051197052\n",
      "Write summary at step 16940  Loss:  0.6169919967651367\n",
      "Write summary at step 16950  Loss:  0.6560620069503784\n",
      "Write summary at step 16960  Loss:  0.8005368709564209\n",
      "Write summary at step 16970  Loss:  0.8688755035400391\n",
      "Write summary at step 16980  Loss:  0.7270032167434692\n",
      "Write summary at step 16990  Loss:  0.5912364721298218\n",
      "Write summary at step 17000  Loss:  0.7698283195495605\n",
      "Saved checkpoint to: result/42/panns/checkpoint_17000.pt\n",
      "Validation:\n",
      "Acurracy:  0.683982683982684 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.539275956284153\n",
      "Loss normal: 0.5934393674264222 Loss Control: 0.4722998389780847 Loss Patient: 1.05528383081158 Loss balanced:  0.7637918348948323 Loss1+loss2: 0.7637918348948323\n",
      "Write summary at step 17010  Loss:  0.568789005279541\n",
      "Write summary at step 17020  Loss:  0.5918275713920593\n",
      "Write summary at step 17030  Loss:  0.762870192527771\n",
      "Write summary at step 17040  Loss:  0.6625854969024658\n",
      "Write summary at step 17050  Loss:  0.6848740577697754\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6493506493506493 Acurracy Control:  0.7431693989071039 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5174180327868853\n",
      "Loss normal: 0.5986761486891544 Loss Control: 0.5157454857409326 Loss Patient: 0.9148492726186911 Loss balanced:  0.7152973791798118 Loss1+loss2: 0.7152973791798118\n",
      "Write summary at step 17060  Loss:  0.7264432311058044\n",
      "Write summary at step 17070  Loss:  0.7167388200759888\n",
      "Write summary at step 17080  Loss:  0.6742278337478638\n",
      "Write summary at step 17090  Loss:  0.6861042976379395\n",
      "Write summary at step 17100  Loss:  0.6088383793830872\n",
      "Write summary at step 17110  Loss:  0.6307182312011719\n",
      "Write summary at step 17120  Loss:  0.7095919251441956\n",
      "Write summary at step 17130  Loss:  0.7323207259178162\n",
      "Write summary at step 17140  Loss:  0.7101197242736816\n",
      "Write summary at step 17150  Loss:  0.7225637435913086\n",
      "Write summary at step 17160  Loss:  0.6577876806259155\n",
      "Write summary at step 17170  Loss:  0.7009106874465942\n",
      "Write summary at step 17180  Loss:  0.5709517002105713\n",
      "Write summary at step 17190  Loss:  0.6672596335411072\n",
      "Write summary at step 17200  Loss:  0.6071714162826538\n",
      "Write summary at step 17210  Loss:  0.5810670852661133\n",
      "Write summary at step 17220  Loss:  0.6940458416938782\n",
      "Write summary at step 17230  Loss:  0.5955148935317993\n",
      "Write summary at step 17240  Loss:  0.6823707818984985\n",
      "Write summary at step 17250  Loss:  0.6238665580749512\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8268398268398268 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5987021857923497\n",
      "Loss normal: 0.5297652876480318 Loss Control: 0.3203101166284801 Loss Patient: 1.3283130923906963 Loss balanced:  0.8243116045095882 Loss1+loss2: 0.8243116045095882\n",
      "Write summary at step 17260  Loss:  0.6887069940567017\n",
      "Write summary at step 17270  Loss:  0.6323827505111694\n",
      "Write summary at step 17280  Loss:  0.6627253293991089\n",
      "Write summary at step 17290  Loss:  0.5746496915817261\n",
      "Write summary at step 17300  Loss:  0.6894946098327637\n",
      "Write summary at step 17310  Loss:  0.740918755531311\n",
      "Write summary at step 17320  Loss:  0.6776351928710938\n",
      "Write summary at step 17330  Loss:  0.6896755695343018\n",
      "Write summary at step 17340  Loss:  0.6590361595153809\n",
      "Write summary at step 17350  Loss:  0.7038973569869995\n",
      "Write summary at step 17360  Loss:  0.6770645380020142\n",
      "Write summary at step 17370  Loss:  0.6166160702705383\n",
      "Write summary at step 17380  Loss:  0.6290303468704224\n",
      "Write summary at step 17390  Loss:  0.6964293122291565\n",
      "Write summary at step 17400  Loss:  0.6659285426139832\n",
      "Write summary at step 17410  Loss:  0.678412675857544\n",
      "Write summary at step 17420  Loss:  0.6854913234710693\n",
      "Write summary at step 17430  Loss:  0.6520653963088989\n",
      "Write summary at step 17440  Loss:  0.66559898853302\n",
      "Write summary at step 17450  Loss:  0.5788692235946655\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5151515151515151 Acurracy Control:  0.5737704918032787 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.4327185792349727\n",
      "Loss normal: 0.6578229224527037 Loss Control: 0.5998056895745908 Loss Patient: 0.8790136408060789 Loss balanced:  0.7394096651903348 Loss1+loss2: 0.7394096651903348\n",
      "Write summary at step 17460  Loss:  0.6796718835830688\n",
      "Write summary at step 17470  Loss:  0.7549577951431274\n",
      "Write summary at step 17480  Loss:  0.7522742748260498\n",
      "Write summary at step 17490  Loss:  0.6620203256607056\n",
      "Write summary at step 17500  Loss:  0.6658241152763367\n",
      "Saved checkpoint to: result/42/panns/checkpoint_17500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5216871584699454\n",
      "Loss normal: 0.6083529383847208 Loss Control: 0.5160582516688467 Loss Patient: 0.9602264538407326 Loss balanced:  0.7381423527547897 Loss1+loss2: 0.7381423527547897\n",
      "Write summary at step 17510  Loss:  0.643671989440918\n",
      "Write summary at step 17520  Loss:  0.6547541618347168\n",
      "Write summary at step 17530  Loss:  0.7653911113739014\n",
      "Write summary at step 17540  Loss:  0.6892927885055542\n",
      "Write summary at step 17550  Loss:  0.664209246635437\n",
      "Write summary at step 17560  Loss:  0.7208291292190552\n",
      "Write summary at step 17570  Loss:  0.6722707748413086\n",
      "Write summary at step 17580  Loss:  0.67928546667099\n",
      "Write summary at step 17590  Loss:  0.7356137633323669\n",
      "Write summary at step 17600  Loss:  0.8027215600013733\n",
      "Write summary at step 17610  Loss:  0.7010650038719177\n",
      "Write summary at step 17620  Loss:  0.6132972240447998\n",
      "Write summary at step 17630  Loss:  0.8522688150405884\n",
      "Write summary at step 17640  Loss:  0.648404598236084\n",
      "Write summary at step 17650  Loss:  0.6022741794586182\n",
      "Write summary at step 17660  Loss:  0.7288146018981934\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8354978354978355 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.6118510928961749\n",
      "Loss normal: 0.551363539644134 Loss Control: 0.42886087184395294 Loss Patient: 1.0184049494564533 Loss balanced:  0.7236329106502031 Loss1+loss2: 0.7236329106502031\n",
      "Write summary at step 17670  Loss:  0.6758622527122498\n",
      "Write summary at step 17680  Loss:  0.7079963088035583\n",
      "Write summary at step 17690  Loss:  0.6246991157531738\n",
      "Write summary at step 17700  Loss:  0.6434045433998108\n",
      "Write summary at step 17710  Loss:  0.5880886912345886\n",
      "Write summary at step 17720  Loss:  0.7027354836463928\n",
      "Write summary at step 17730  Loss:  0.7180109024047852\n",
      "Write summary at step 17740  Loss:  0.7327147722244263\n",
      "Write summary at step 17750  Loss:  0.6532527208328247\n",
      "Write summary at step 17760  Loss:  0.6101951599121094\n",
      "Write summary at step 17770  Loss:  0.6723155379295349\n",
      "Write summary at step 17780  Loss:  0.7454191446304321\n",
      "Write summary at step 17790  Loss:  0.7637274861335754\n",
      "Write summary at step 17800  Loss:  0.6504688262939453\n",
      "Write summary at step 17810  Loss:  0.8100945353507996\n",
      "Write summary at step 17820  Loss:  0.7161328196525574\n",
      "Write summary at step 17830  Loss:  0.6215265989303589\n",
      "Write summary at step 17840  Loss:  0.8064248561859131\n",
      "Write summary at step 17850  Loss:  0.7043126821517944\n",
      "Write summary at step 17860  Loss:  0.6630934476852417\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8268398268398268 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.606386612021858\n",
      "Loss normal: 0.5095743165387736 Loss Control: 0.26803971932885423 Loss Patient: 1.430424955363075 Loss balanced:  0.8492323373459646 Loss1+loss2: 0.8492323373459646\n",
      "Write summary at step 17870  Loss:  0.7392404079437256\n",
      "Write summary at step 17880  Loss:  0.6791455745697021\n",
      "Write summary at step 17890  Loss:  0.7584620714187622\n",
      "Write summary at step 17900  Loss:  0.6314384937286377\n",
      "Write summary at step 17910  Loss:  0.8535932898521423\n",
      "Write summary at step 17920  Loss:  0.6139726042747498\n",
      "Write summary at step 17930  Loss:  0.8340775370597839\n",
      "Write summary at step 17940  Loss:  0.6150867938995361\n",
      "Write summary at step 17950  Loss:  0.7065266966819763\n",
      "Write summary at step 17960  Loss:  0.6503958702087402\n",
      "Write summary at step 17970  Loss:  0.6169732213020325\n",
      "Write summary at step 17980  Loss:  0.6759737730026245\n",
      "Write summary at step 17990  Loss:  0.6688226461410522\n",
      "Write summary at step 18000  Loss:  0.7659146785736084\n",
      "Saved checkpoint to: result/42/panns/checkpoint_18000.pt\n",
      "Validation:\n",
      "Acurracy:  0.5714285714285714 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.46823770491803285\n",
      "Loss normal: 0.6534033368676255 Loss Control: 0.6051604435092113 Loss Patient: 0.837329393873612 Loss balanced:  0.7212449186914116 Loss1+loss2: 0.7212449186914116\n",
      "Write summary at step 18010  Loss:  0.6555591821670532\n",
      "Write summary at step 18020  Loss:  0.6398987770080566\n",
      "Write summary at step 18030  Loss:  0.5846585631370544\n",
      "Write summary at step 18040  Loss:  0.7168093919754028\n",
      "Write summary at step 18050  Loss:  0.602340817451477\n",
      "Write summary at step 18060  Loss:  0.6551536917686462\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.25 Acurracy Balanced 0.5594262295081966\n",
      "Loss normal: 0.5808716060279252 Loss Control: 0.4493215738749895 Loss Patient: 1.0824060769130786 Loss balanced:  0.765863825394034 Loss1+loss2: 0.765863825394034\n",
      "Write summary at step 18070  Loss:  0.6715285181999207\n",
      "Write summary at step 18080  Loss:  0.6041408777236938\n",
      "Write summary at step 18090  Loss:  0.6702687740325928\n",
      "Write summary at step 18100  Loss:  0.7434345483779907\n",
      "Write summary at step 18110  Loss:  0.5784714818000793\n",
      "Write summary at step 18120  Loss:  0.5774304866790771\n",
      "Write summary at step 18130  Loss:  0.7357156872749329\n",
      "Write summary at step 18140  Loss:  0.7334672808647156\n",
      "Write summary at step 18150  Loss:  0.57022625207901\n",
      "Write summary at step 18160  Loss:  0.6904165148735046\n",
      "Write summary at step 18170  Loss:  0.7342523336410522\n",
      "Write summary at step 18180  Loss:  0.5831407904624939\n",
      "Write summary at step 18190  Loss:  0.7296727895736694\n",
      "Write summary at step 18200  Loss:  0.6208300590515137\n",
      "Write summary at step 18210  Loss:  0.745125412940979\n",
      "Write summary at step 18220  Loss:  0.5657882690429688\n",
      "Write summary at step 18230  Loss:  0.6695272922515869\n",
      "Write summary at step 18240  Loss:  0.7283450365066528\n",
      "Write summary at step 18250  Loss:  0.6346924304962158\n",
      "Write summary at step 18260  Loss:  0.6526544094085693\n",
      "Write summary at step 18270  Loss:  0.6445711851119995\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8268398268398268 Acurracy Control:  1.0 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5833333333333334\n",
      "Loss normal: 0.4842663015122021 Loss Control: 0.22930512304514483 Loss Patient: 1.456305779516697 Loss balanced:  0.8428054512809209 Loss1+loss2: 0.8428054512809209\n",
      "Write summary at step 18280  Loss:  0.6492645740509033\n",
      "Write summary at step 18290  Loss:  0.7839926481246948\n",
      "Write summary at step 18300  Loss:  0.7207402586936951\n",
      "Write summary at step 18310  Loss:  0.6747473478317261\n",
      "Write summary at step 18320  Loss:  0.5822448134422302\n",
      "Write summary at step 18330  Loss:  0.7033853530883789\n",
      "Write summary at step 18340  Loss:  0.683647096157074\n",
      "Write summary at step 18350  Loss:  0.6586087942123413\n",
      "Write summary at step 18360  Loss:  0.7389121651649475\n",
      "Write summary at step 18370  Loss:  0.7631985545158386\n",
      "Write summary at step 18380  Loss:  0.8364487886428833\n",
      "Write summary at step 18390  Loss:  0.7297141551971436\n",
      "Write summary at step 18400  Loss:  0.6473000645637512\n",
      "Write summary at step 18410  Loss:  0.5800551176071167\n",
      "Write summary at step 18420  Loss:  0.6215188503265381\n",
      "Write summary at step 18430  Loss:  0.6460394859313965\n",
      "Write summary at step 18440  Loss:  0.6087868213653564\n",
      "Write summary at step 18450  Loss:  0.702974796295166\n",
      "Write summary at step 18460  Loss:  0.6416633129119873\n",
      "Write summary at step 18470  Loss:  0.5559855699539185\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.1875 Acurracy Balanced 0.5773565573770492\n",
      "Loss normal: 0.5230124912736736 Loss Control: 0.3585156713678537 Loss Patient: 1.1501566283404827 Loss balanced:  0.7543361498541682 Loss1+loss2: 0.7543361498541682\n",
      "Write summary at step 18480  Loss:  0.5598669052124023\n",
      "Write summary at step 18490  Loss:  0.6911746263504028\n",
      "Write summary at step 18500  Loss:  0.6534903049468994\n",
      "Saved checkpoint to: result/42/panns/checkpoint_18500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.1875 Acurracy Balanced 0.5773565573770492\n",
      "Loss normal: 0.5425494835748301 Loss Control: 0.4144268184086013 Loss Patient: 1.0310171643892925 Loss balanced:  0.7227219913989469 Loss1+loss2: 0.7227219913989469\n",
      "Write summary at step 18510  Loss:  0.6216169595718384\n",
      "Write summary at step 18520  Loss:  0.6701436042785645\n",
      "Write summary at step 18530  Loss:  0.6686981916427612\n",
      "Write summary at step 18540  Loss:  0.5673261284828186\n",
      "Write summary at step 18550  Loss:  0.6499917507171631\n",
      "Write summary at step 18560  Loss:  0.7128926515579224\n",
      "Write summary at step 18570  Loss:  0.6064186096191406\n",
      "Write summary at step 18580  Loss:  0.5558217763900757\n",
      "Write summary at step 18590  Loss:  0.6014077067375183\n",
      "Write summary at step 18600  Loss:  0.722074568271637\n",
      "Write summary at step 18610  Loss:  0.6171448826789856\n",
      "Write summary at step 18620  Loss:  0.6154291033744812\n",
      "Write summary at step 18630  Loss:  0.8274890184402466\n",
      "Write summary at step 18640  Loss:  0.6718317270278931\n",
      "Write summary at step 18650  Loss:  0.7989281415939331\n",
      "Write summary at step 18660  Loss:  0.5866527557373047\n",
      "Write summary at step 18670  Loss:  0.6635802984237671\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5411255411255411 Acurracy Control:  0.5573770491803278 Acurracy Patient:  0.4791666666666667 Acurracy Balanced 0.5182718579234973\n",
      "Loss normal: 0.6655904353955091 Loss Control: 0.6392191882993354 Loss Patient: 0.7661308559278647 Loss balanced:  0.7026750221136 Loss1+loss2: 0.7026750221136\n",
      "Write summary at step 18680  Loss:  0.5808426141738892\n",
      "Write summary at step 18690  Loss:  0.692865788936615\n",
      "Write summary at step 18700  Loss:  0.6179684400558472\n",
      "Write summary at step 18710  Loss:  0.7405192852020264\n",
      "Write summary at step 18720  Loss:  0.7403296232223511\n",
      "Write summary at step 18730  Loss:  0.61487877368927\n",
      "Write summary at step 18740  Loss:  0.6929532289505005\n",
      "Write summary at step 18750  Loss:  0.6986865401268005\n",
      "Write summary at step 18760  Loss:  0.568468451499939\n",
      "Write summary at step 18770  Loss:  0.729041576385498\n",
      "Write summary at step 18780  Loss:  0.5544770956039429\n",
      "Write summary at step 18790  Loss:  0.7241973876953125\n",
      "Write summary at step 18800  Loss:  0.699142575263977\n",
      "Write summary at step 18810  Loss:  0.6223912239074707\n",
      "Write summary at step 18820  Loss:  0.7757235765457153\n",
      "Write summary at step 18830  Loss:  0.7243821024894714\n",
      "Write summary at step 18840  Loss:  0.6516848802566528\n",
      "Write summary at step 18850  Loss:  0.6673386096954346\n",
      "Write summary at step 18860  Loss:  0.6714701652526855\n",
      "Write summary at step 18870  Loss:  0.6316925883293152\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6536796536796536 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.375 Acurracy Balanced 0.5508879781420766\n",
      "Loss normal: 0.6199697568303063 Loss Control: 0.5721283945880953 Loss Patient: 0.8023649659007788 Loss balanced:  0.687246680244437 Loss1+loss2: 0.687246680244437\n",
      "Write summary at step 18880  Loss:  0.6424442529678345\n",
      "Write summary at step 18890  Loss:  0.5904334187507629\n",
      "Write summary at step 18900  Loss:  0.7346187233924866\n",
      "Write summary at step 18910  Loss:  0.6052243709564209\n",
      "Write summary at step 18920  Loss:  0.587872326374054\n",
      "Write summary at step 18930  Loss:  0.694301962852478\n",
      "Write summary at step 18940  Loss:  0.6358857154846191\n",
      "Write summary at step 18950  Loss:  0.6300172209739685\n",
      "Write summary at step 18960  Loss:  0.8112021684646606\n",
      "Write summary at step 18970  Loss:  0.5865254402160645\n",
      "Write summary at step 18980  Loss:  0.6429667472839355\n",
      "Write summary at step 18990  Loss:  0.5459277033805847\n",
      "Write summary at step 19000  Loss:  0.6870392560958862\n",
      "Saved checkpoint to: result/42/panns/checkpoint_19000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7359307359307359 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.3125 Acurracy Balanced 0.5797472677595629\n",
      "Loss normal: 0.5663605906488576 Loss Control: 0.46074678386495416 Loss Patient: 0.9690132172157367 Loss balanced:  0.7148800005403455 Loss1+loss2: 0.7148800005403455\n",
      "Write summary at step 19010  Loss:  0.5362042784690857\n",
      "Write summary at step 19020  Loss:  0.6908739805221558\n",
      "Write summary at step 19030  Loss:  0.8389132022857666\n",
      "Write summary at step 19040  Loss:  0.6603906750679016\n",
      "Write summary at step 19050  Loss:  0.6513144969940186\n",
      "Write summary at step 19060  Loss:  0.696459174156189\n",
      "Write summary at step 19070  Loss:  0.6533283591270447\n",
      "Write summary at step 19080  Loss:  0.7696003913879395\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.25 Acurracy Balanced 0.58948087431694\n",
      "Loss normal: 0.5312889432494259 Loss Control: 0.3308182459711377 Loss Patient: 1.2955834946284692 Loss balanced:  0.8132008702998035 Loss1+loss2: 0.8132008702998035\n",
      "Write summary at step 19090  Loss:  0.5862003564834595\n",
      "Write summary at step 19100  Loss:  0.4784858226776123\n",
      "Write summary at step 19110  Loss:  0.6614817380905151\n",
      "Write summary at step 19120  Loss:  0.6786263585090637\n",
      "Write summary at step 19130  Loss:  0.7731902003288269\n",
      "Write summary at step 19140  Loss:  0.5815961360931396\n",
      "Write summary at step 19150  Loss:  0.6607042551040649\n",
      "Write summary at step 19160  Loss:  0.6694301962852478\n",
      "Write summary at step 19170  Loss:  0.6462121605873108\n",
      "Write summary at step 19180  Loss:  0.642337441444397\n",
      "Write summary at step 19190  Loss:  0.6467258334159851\n",
      "Write summary at step 19200  Loss:  0.6940826773643494\n",
      "Write summary at step 19210  Loss:  0.6527581214904785\n",
      "Write summary at step 19220  Loss:  0.5748169422149658\n",
      "Write summary at step 19230  Loss:  0.5606218576431274\n",
      "Write summary at step 19240  Loss:  0.6226004362106323\n",
      "Write summary at step 19250  Loss:  0.6773757934570312\n",
      "Write summary at step 19260  Loss:  0.5905853509902954\n",
      "Write summary at step 19270  Loss:  0.6845492124557495\n",
      "Write summary at step 19280  Loss:  0.6529613137245178\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.4588744588744589 Acurracy Control:  0.4371584699453552 Acurracy Patient:  0.5416666666666666 Acurracy Balanced 0.4894125683060109\n",
      "Loss normal: 0.6940696115617628 Loss Control: 0.6888895334441805 Loss Patient: 0.7138186631103357 Loss balanced:  0.7013540982772581 Loss1+loss2: 0.7013540982772581\n",
      "Write summary at step 19290  Loss:  0.6800572276115417\n",
      "Write summary at step 19300  Loss:  0.6677390933036804\n",
      "Write summary at step 19310  Loss:  0.68166184425354\n",
      "Write summary at step 19320  Loss:  0.5753188133239746\n",
      "Write summary at step 19330  Loss:  0.7498328685760498\n",
      "Write summary at step 19340  Loss:  0.694444477558136\n",
      "Write summary at step 19350  Loss:  0.7354558706283569\n",
      "Write summary at step 19360  Loss:  0.6465924978256226\n",
      "Write summary at step 19370  Loss:  0.5918152928352356\n",
      "Write summary at step 19380  Loss:  0.6572423577308655\n",
      "Write summary at step 19390  Loss:  0.5937755703926086\n",
      "Write summary at step 19400  Loss:  0.7291175723075867\n",
      "Write summary at step 19410  Loss:  0.7224472761154175\n",
      "Write summary at step 19420  Loss:  0.5836179256439209\n",
      "Write summary at step 19430  Loss:  0.6269299983978271\n",
      "Write summary at step 19440  Loss:  0.5969370007514954\n",
      "Write summary at step 19450  Loss:  0.5699917078018188\n",
      "Write summary at step 19460  Loss:  0.6786924600601196\n",
      "Write summary at step 19470  Loss:  0.7779110670089722\n",
      "Write summary at step 19480  Loss:  0.6045823097229004\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.585724043715847\n",
      "Loss normal: 0.5818707294020302 Loss Control: 0.5180900306975256 Loss Patient: 0.8250346562514702 Loss balanced:  0.671562343474498 Loss1+loss2: 0.671562343474498\n",
      "Write summary at step 19490  Loss:  0.6857086420059204\n",
      "Write summary at step 19500  Loss:  0.6823437809944153\n",
      "Saved checkpoint to: result/42/panns/checkpoint_19500.pt\n",
      "Validation:\n",
      "Acurracy:  0.658008658008658 Acurracy Control:  0.7213114754098361 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.5689890710382514\n",
      "Loss normal: 0.6129681226753053 Loss Control: 0.5722008231884795 Loss Patient: 0.7683934631446997 Loss balanced:  0.6702971431665896 Loss1+loss2: 0.6702971431665896\n",
      "Write summary at step 19510  Loss:  0.5262275338172913\n",
      "Write summary at step 19520  Loss:  0.6333580017089844\n",
      "Write summary at step 19530  Loss:  0.7072062492370605\n",
      "Write summary at step 19540  Loss:  0.6852113008499146\n",
      "Write summary at step 19550  Loss:  0.6912276744842529\n",
      "Write summary at step 19560  Loss:  0.6078023910522461\n",
      "Write summary at step 19570  Loss:  0.7011008262634277\n",
      "Write summary at step 19580  Loss:  0.7387744784355164\n",
      "Write summary at step 19590  Loss:  0.5957038998603821\n",
      "Write summary at step 19600  Loss:  0.6226543188095093\n",
      "Write summary at step 19610  Loss:  0.5986513495445251\n",
      "Write summary at step 19620  Loss:  0.6638108491897583\n",
      "Write summary at step 19630  Loss:  0.6300039291381836\n",
      "Write summary at step 19640  Loss:  0.5989913940429688\n",
      "Write summary at step 19650  Loss:  0.7135557532310486\n",
      "Write summary at step 19660  Loss:  0.6071957349777222\n",
      "Write summary at step 19670  Loss:  0.7492470741271973\n",
      "Write summary at step 19680  Loss:  0.7563443779945374\n",
      "Write summary at step 19690  Loss:  0.6516346335411072\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5930735930735931 Acurracy Control:  0.6284153005464481 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.5433743169398907\n",
      "Loss normal: 0.6422511478523155 Loss Control: 0.6048889876714821 Loss Patient: 0.7846944127231836 Loss balanced:  0.6947917001973329 Loss1+loss2: 0.6947917001973329\n",
      "Write summary at step 19700  Loss:  0.6092648506164551\n",
      "Write summary at step 19710  Loss:  0.6138339638710022\n",
      "Write summary at step 19720  Loss:  0.7207926511764526\n",
      "Write summary at step 19730  Loss:  0.6102944612503052\n",
      "Write summary at step 19740  Loss:  0.6255090236663818\n",
      "Write summary at step 19750  Loss:  0.7193106412887573\n",
      "Write summary at step 19760  Loss:  0.5752824544906616\n",
      "Write summary at step 19770  Loss:  0.6526691317558289\n",
      "Write summary at step 19780  Loss:  0.7191284894943237\n",
      "Write summary at step 19790  Loss:  0.6795490980148315\n",
      "Write summary at step 19800  Loss:  0.7201379537582397\n",
      "Write summary at step 19810  Loss:  0.7192732095718384\n",
      "Write summary at step 19820  Loss:  0.7206571102142334\n",
      "Write summary at step 19830  Loss:  0.725637674331665\n",
      "Write summary at step 19840  Loss:  0.6742227077484131\n",
      "Write summary at step 19850  Loss:  0.756919801235199\n",
      "Write summary at step 19860  Loss:  0.6114794015884399\n",
      "Write summary at step 19870  Loss:  0.7860045433044434\n",
      "Write summary at step 19880  Loss:  0.5641524195671082\n",
      "Write summary at step 19890  Loss:  0.5486941337585449\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8225108225108225 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5806010928961749\n",
      "Loss normal: 0.517439588968888 Loss Control: 0.3666731277124478 Loss Patient: 1.0922367225090663 Loss balanced:  0.729454925110757 Loss1+loss2: 0.729454925110757\n",
      "Write summary at step 19900  Loss:  0.5659036040306091\n",
      "Write summary at step 19910  Loss:  0.6075512170791626\n",
      "Write summary at step 19920  Loss:  0.5786615610122681\n",
      "Write summary at step 19930  Loss:  0.6024637222290039\n",
      "Write summary at step 19940  Loss:  0.5417642593383789\n",
      "Write summary at step 19950  Loss:  0.6161622405052185\n",
      "Write summary at step 19960  Loss:  0.7012467384338379\n",
      "Write summary at step 19970  Loss:  0.6180578470230103\n",
      "Write summary at step 19980  Loss:  0.7491946220397949\n",
      "Write summary at step 19990  Loss:  0.5905792713165283\n",
      "Write summary at step 20000  Loss:  0.6640903949737549\n",
      "Saved checkpoint to: result/42/panns/checkpoint_20000.pt\n",
      "Validation:\n",
      "Acurracy:  0.645021645021645 Acurracy Control:  0.7049180327868853 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.5607923497267759\n",
      "Loss normal: 0.6318214631183839 Loss Control: 0.5615963284435168 Loss Patient: 0.8995548139015833 Loss balanced:  0.7305755711725501 Loss1+loss2: 0.7305755711725501\n",
      "Write summary at step 20010  Loss:  0.8716378211975098\n",
      "Write summary at step 20020  Loss:  0.6917198300361633\n",
      "Write summary at step 20030  Loss:  0.6552414894104004\n",
      "Write summary at step 20040  Loss:  0.7155605554580688\n",
      "Write summary at step 20050  Loss:  0.6436434388160706\n",
      "Write summary at step 20060  Loss:  0.6505166292190552\n",
      "Write summary at step 20070  Loss:  0.5497741103172302\n",
      "Write summary at step 20080  Loss:  0.6214443445205688\n",
      "Write summary at step 20090  Loss:  0.6599733829498291\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5642076502732241\n",
      "Loss normal: 0.5446834499701793 Loss Control: 0.37967051280652236 Loss Patient: 1.17379525800546 Loss balanced:  0.7767328854059912 Loss1+loss2: 0.7767328854059912\n",
      "Write summary at step 20100  Loss:  0.6410495042800903\n",
      "Write summary at step 20110  Loss:  0.6249789595603943\n",
      "Write summary at step 20120  Loss:  0.48311105370521545\n",
      "Write summary at step 20130  Loss:  0.6158238053321838\n",
      "Write summary at step 20140  Loss:  0.6870074272155762\n",
      "Write summary at step 20150  Loss:  0.7151046991348267\n",
      "Write summary at step 20160  Loss:  0.6291764378547668\n",
      "Write summary at step 20170  Loss:  0.7719192504882812\n",
      "Write summary at step 20180  Loss:  0.491953045129776\n",
      "Write summary at step 20190  Loss:  0.6631713509559631\n",
      "Write summary at step 20200  Loss:  0.7793934345245361\n",
      "Write summary at step 20210  Loss:  0.6575556397438049\n",
      "Write summary at step 20220  Loss:  0.755218505859375\n",
      "Write summary at step 20230  Loss:  0.651098906993866\n",
      "Write summary at step 20240  Loss:  0.6596130132675171\n",
      "Write summary at step 20250  Loss:  0.6321211457252502\n",
      "Write summary at step 20260  Loss:  0.650121808052063\n",
      "Write summary at step 20270  Loss:  0.6467803716659546\n",
      "Write summary at step 20280  Loss:  0.7675645351409912\n",
      "Write summary at step 20290  Loss:  0.5882854461669922\n",
      "Write summary at step 20300  Loss:  0.6953064203262329\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7186147186147186 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5380806010928962\n",
      "Loss normal: 0.6169212635977444 Loss Control: 0.547728711464366 Loss Patient: 0.8807178841282924 Loss balanced:  0.7142232977963292 Loss1+loss2: 0.7142232977963292\n",
      "------------------------------\n",
      "SEED: 42 Best Loss: 0.6666430384633157\n",
      "______________________________\n",
      "The Max Time dim Lenght is: 1498 (+- 29.96 seconds)\n",
      "The Min Time dim Lenght is: 19 (+- 0.38 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.5351840853691101\n",
      "Write summary at step 20  Loss:  0.6969692707061768\n",
      "Write summary at step 30  Loss:  0.8234400749206543\n",
      "Write summary at step 40  Loss:  0.6736846566200256\n",
      "Write summary at step 50  Loss:  0.8015320301055908\n",
      "Write summary at step 60  Loss:  0.7054481506347656\n",
      "Write summary at step 70  Loss:  0.7342816591262817\n",
      "Write summary at step 80  Loss:  0.815342128276825\n",
      "Write summary at step 90  Loss:  0.6572010517120361\n",
      "Write summary at step 100  Loss:  0.6974201202392578\n",
      "Write summary at step 110  Loss:  0.6950249671936035\n",
      "Write summary at step 120  Loss:  0.699434220790863\n",
      "Write summary at step 130  Loss:  0.6588984727859497\n",
      "Write summary at step 140  Loss:  0.7164491415023804\n",
      "Write summary at step 150  Loss:  0.6743671894073486\n",
      "Write summary at step 160  Loss:  0.6914911866188049\n",
      "Write summary at step 170  Loss:  0.7286409139633179\n",
      "Write summary at step 180  Loss:  0.7199220657348633\n",
      "Write summary at step 190  Loss:  0.6791625022888184\n",
      "Write summary at step 200  Loss:  0.6291005611419678\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.0 Acurracy Balanced 0.4918032786885246\n",
      "Loss normal: 0.6330244564390802 Loss Control: 0.5886627719050548 Loss Patient: 0.8021533551315466 Loss balanced:  0.6954080635183006 Loss1+loss2: 0.6954080635183006\n",
      "\n",
      " > BEST MODEL (0.69541) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 210  Loss:  0.7485414743423462\n",
      "Write summary at step 220  Loss:  0.7343189716339111\n",
      "Write summary at step 230  Loss:  0.6735885143280029\n",
      "Write summary at step 240  Loss:  0.6578629016876221\n",
      "Write summary at step 250  Loss:  0.7291500568389893\n",
      "Write summary at step 260  Loss:  0.6441606283187866\n",
      "Write summary at step 270  Loss:  0.7685729265213013\n",
      "Write summary at step 280  Loss:  0.7146981358528137\n",
      "Write summary at step 290  Loss:  0.7220969200134277\n",
      "Write summary at step 300  Loss:  0.7801032066345215\n",
      "Write summary at step 310  Loss:  0.6420755386352539\n",
      "Write summary at step 320  Loss:  0.8574957847595215\n",
      "Write summary at step 330  Loss:  0.6339403986930847\n",
      "Write summary at step 340  Loss:  0.6992396712303162\n",
      "Write summary at step 350  Loss:  0.5358819365501404\n",
      "Write summary at step 360  Loss:  0.6626543998718262\n",
      "Write summary at step 370  Loss:  0.8211779594421387\n",
      "Write summary at step 380  Loss:  0.759497880935669\n",
      "Write summary at step 390  Loss:  0.7081921696662903\n",
      "Write summary at step 400  Loss:  0.6971585750579834\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.5607254359371219 Loss Control: 0.4231321823075821 Loss Patient: 1.0852997762461503 Loss balanced:  0.7542159792768661 Loss1+loss2: 0.7542159792768661\n",
      "Write summary at step 410  Loss:  0.8137326240539551\n",
      "Write summary at step 420  Loss:  0.5549818277359009\n",
      "Write summary at step 430  Loss:  0.7889313697814941\n",
      "Write summary at step 440  Loss:  0.8374487161636353\n",
      "Write summary at step 450  Loss:  1.0424553155899048\n",
      "Write summary at step 460  Loss:  0.6876298785209656\n",
      "Write summary at step 470  Loss:  0.781085729598999\n",
      "Write summary at step 480  Loss:  0.9176470041275024\n",
      "Write summary at step 490  Loss:  0.8313045501708984\n",
      "Write summary at step 500  Loss:  0.5789573788642883\n",
      "Saved checkpoint to: result/46/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2554112554112554 Acurracy Control:  0.1366120218579235 Acurracy Patient:  0.7083333333333334 Acurracy Balanced 0.42247267759562845\n",
      "Loss normal: 0.736027019622522 Loss Control: 0.7527923997634095 Loss Patient: 0.6721089780330658 Loss balanced:  0.7124506888982376 Loss1+loss2: 0.7124506888982376\n",
      "Write summary at step 510  Loss:  0.8070477247238159\n",
      "Write summary at step 520  Loss:  0.6655462980270386\n",
      "Write summary at step 530  Loss:  0.6430266499519348\n",
      "Write summary at step 540  Loss:  0.7323213815689087\n",
      "Write summary at step 550  Loss:  0.7620776891708374\n",
      "Write summary at step 560  Loss:  0.6538227200508118\n",
      "Write summary at step 570  Loss:  0.6965948939323425\n",
      "Write summary at step 580  Loss:  0.749241828918457\n",
      "Write summary at step 590  Loss:  0.6846626996994019\n",
      "Write summary at step 600  Loss:  0.6572971343994141\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6406926406926406 Acurracy Control:  0.6994535519125683 Acurracy Patient:  0.4166666666666667 Acurracy Balanced 0.5580601092896175\n",
      "Loss normal: 0.6702106504729299 Loss Control: 0.676019665973434 Loss Patient: 0.6480637819816669 Loss balanced:  0.6620417239775505 Loss1+loss2: 0.6620417239775505\n",
      "\n",
      " > BEST MODEL (0.66204) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 610  Loss:  0.7265655994415283\n",
      "Write summary at step 620  Loss:  0.5578173398971558\n",
      "Write summary at step 630  Loss:  0.6947895288467407\n",
      "Write summary at step 640  Loss:  0.7185745239257812\n",
      "Write summary at step 650  Loss:  0.7272366285324097\n",
      "Write summary at step 660  Loss:  0.725283145904541\n",
      "Write summary at step 670  Loss:  0.8061215877532959\n",
      "Write summary at step 680  Loss:  0.7344983816146851\n",
      "Write summary at step 690  Loss:  0.684036374092102\n",
      "Write summary at step 700  Loss:  0.7834146618843079\n",
      "Write summary at step 710  Loss:  0.6403330564498901\n",
      "Write summary at step 720  Loss:  0.687165379524231\n",
      "Write summary at step 730  Loss:  0.6906977891921997\n",
      "Write summary at step 740  Loss:  0.7431043386459351\n",
      "Write summary at step 750  Loss:  0.6565101146697998\n",
      "Write summary at step 760  Loss:  0.7156455516815186\n",
      "Write summary at step 770  Loss:  0.6896860599517822\n",
      "Write summary at step 780  Loss:  0.7028765678405762\n",
      "Write summary at step 790  Loss:  0.7498167753219604\n",
      "Write summary at step 800  Loss:  0.6953295469284058\n",
      "Write summary at step 810  Loss:  0.7003011703491211\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2077922077922078 Acurracy Control:  0.0 Acurracy Patient:  1.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.7461636025152165 Loss Control: 0.7935847623752115 Loss Patient: 0.5653704105255505 Loss balanced:  0.679477586450381 Loss1+loss2: 0.679477586450381\n",
      "Write summary at step 820  Loss:  0.6655334234237671\n",
      "Write summary at step 830  Loss:  0.7215046286582947\n",
      "Write summary at step 840  Loss:  0.8799591064453125\n",
      "Write summary at step 850  Loss:  0.6459904313087463\n",
      "Write summary at step 860  Loss:  0.6951636075973511\n",
      "Write summary at step 870  Loss:  0.7013428211212158\n",
      "Write summary at step 880  Loss:  0.6530079245567322\n",
      "Write summary at step 890  Loss:  0.6150486469268799\n",
      "Write summary at step 900  Loss:  0.6416711807250977\n",
      "Write summary at step 910  Loss:  0.7561495304107666\n",
      "Write summary at step 920  Loss:  0.6504327058792114\n",
      "Write summary at step 930  Loss:  0.712731122970581\n",
      "Write summary at step 940  Loss:  0.7581822276115417\n",
      "Write summary at step 950  Loss:  0.7073232531547546\n",
      "Write summary at step 960  Loss:  0.7215102314949036\n",
      "Write summary at step 970  Loss:  0.6699339151382446\n",
      "Write summary at step 980  Loss:  0.6510909199714661\n",
      "Write summary at step 990  Loss:  0.6956320405006409\n",
      "Write summary at step 1000  Loss:  0.7024585604667664\n",
      "Saved checkpoint to: result/46/panns/checkpoint_1000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.45021645021645024 Acurracy Control:  0.46994535519125685 Acurracy Patient:  0.375 Acurracy Balanced 0.42247267759562845\n",
      "Loss normal: 0.693815917421729 Loss Control: 0.6846002552027259 Loss Patient: 0.728950614730517 Loss balanced:  0.7067754349666215 Loss1+loss2: 0.7067754349666215\n",
      "Write summary at step 1010  Loss:  0.6973109245300293\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.41125541125541126 Acurracy Control:  0.3989071038251366 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.42862021857923494\n",
      "Loss normal: 0.6965714969160237 Loss Control: 0.6965047730122759 Loss Patient: 0.6968259041508039 Loss balanced:  0.6966653385815399 Loss1+loss2: 0.6966653385815399\n",
      "Write summary at step 1020  Loss:  0.7398272752761841\n",
      "Write summary at step 1030  Loss:  0.6839483976364136\n",
      "Write summary at step 1040  Loss:  0.7547996044158936\n",
      "Write summary at step 1050  Loss:  0.7070333361625671\n",
      "Write summary at step 1060  Loss:  0.746857762336731\n",
      "Write summary at step 1070  Loss:  0.6594241857528687\n",
      "Write summary at step 1080  Loss:  0.6788398027420044\n",
      "Write summary at step 1090  Loss:  0.7462735772132874\n",
      "Write summary at step 1100  Loss:  0.672134280204773\n",
      "Write summary at step 1110  Loss:  0.7058576941490173\n",
      "Write summary at step 1120  Loss:  0.733670711517334\n",
      "Write summary at step 1130  Loss:  0.7090896368026733\n",
      "Write summary at step 1140  Loss:  0.7073525190353394\n",
      "Write summary at step 1150  Loss:  0.659697949886322\n",
      "Write summary at step 1160  Loss:  0.6770969033241272\n",
      "Write summary at step 1170  Loss:  0.7185925841331482\n",
      "Write summary at step 1180  Loss:  0.7036153078079224\n",
      "Write summary at step 1190  Loss:  0.6739943027496338\n",
      "Write summary at step 1200  Loss:  0.6764239072799683\n",
      "Write summary at step 1210  Loss:  0.6793500185012817\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4675324675324675 Acurracy Control:  0.5027322404371585 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.4180327868852459\n",
      "Loss normal: 0.6911424070725709 Loss Control: 0.6865305128644724 Loss Patient: 0.7087252500156561 Loss balanced:  0.6976278814400643 Loss1+loss2: 0.6976278814400643\n",
      "Write summary at step 1220  Loss:  0.6668275594711304\n",
      "Write summary at step 1230  Loss:  0.6859508752822876\n",
      "Write summary at step 1240  Loss:  0.7467904090881348\n",
      "Write summary at step 1250  Loss:  0.6942468881607056\n",
      "Write summary at step 1260  Loss:  0.7491174936294556\n",
      "Write summary at step 1270  Loss:  0.7620707750320435\n",
      "Write summary at step 1280  Loss:  0.6298321485519409\n",
      "Write summary at step 1290  Loss:  0.7447855472564697\n",
      "Write summary at step 1300  Loss:  0.710753321647644\n",
      "Write summary at step 1310  Loss:  0.6971994638442993\n",
      "Write summary at step 1320  Loss:  0.6926660537719727\n",
      "Write summary at step 1330  Loss:  0.6849647760391235\n",
      "Write summary at step 1340  Loss:  0.6600682139396667\n",
      "Write summary at step 1350  Loss:  0.6869019269943237\n",
      "Write summary at step 1360  Loss:  0.6613849401473999\n",
      "Write summary at step 1370  Loss:  0.7220863103866577\n",
      "Write summary at step 1380  Loss:  0.6765668392181396\n",
      "Write summary at step 1390  Loss:  0.7035528421401978\n",
      "Write summary at step 1400  Loss:  0.7176859378814697\n",
      "Write summary at step 1410  Loss:  0.7138310074806213\n",
      "Write summary at step 1420  Loss:  0.7131683826446533\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7186147186147186 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.125 Acurracy Balanced 0.4996584699453552\n",
      "Loss normal: 0.6658198209035964 Loss Control: 0.647064014210727 Loss Patient: 0.7373263525466124 Loss balanced:  0.6921951833786697 Loss1+loss2: 0.6921951833786697\n",
      "Write summary at step 1430  Loss:  0.7371817827224731\n",
      "Write summary at step 1440  Loss:  0.7212742567062378\n",
      "Write summary at step 1450  Loss:  0.6943591237068176\n",
      "Write summary at step 1460  Loss:  0.6815550327301025\n",
      "Write summary at step 1470  Loss:  0.6694479584693909\n",
      "Write summary at step 1480  Loss:  0.7652409076690674\n",
      "Write summary at step 1490  Loss:  0.750070333480835\n",
      "Write summary at step 1500  Loss:  0.7289988398551941\n",
      "Saved checkpoint to: result/46/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6623376623376623 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.375 Acurracy Balanced 0.5563524590163935\n",
      "Loss normal: 0.6899775473070351 Loss Control: 0.6901948706048434 Loss Patient: 0.6891489898165067 Loss balanced:  0.6896719302106751 Loss1+loss2: 0.6896719302106751\n",
      "Write summary at step 1510  Loss:  0.7297285199165344\n",
      "Write summary at step 1520  Loss:  0.7227098345756531\n",
      "Write summary at step 1530  Loss:  0.6399953365325928\n",
      "Write summary at step 1540  Loss:  0.6585974097251892\n",
      "Write summary at step 1550  Loss:  0.7275316715240479\n",
      "Write summary at step 1560  Loss:  0.7104815244674683\n",
      "Write summary at step 1570  Loss:  0.7001567482948303\n",
      "Write summary at step 1580  Loss:  0.7091261148452759\n",
      "Write summary at step 1590  Loss:  0.7351527214050293\n",
      "Write summary at step 1600  Loss:  0.736170768737793\n",
      "Write summary at step 1610  Loss:  0.7218015193939209\n",
      "Write summary at step 1620  Loss:  0.7364451885223389\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6652241565964438 Loss Control: 0.6439217970670899 Loss Patient: 0.7464394047856331 Loss balanced:  0.6951806009263615 Loss1+loss2: 0.6951806009263615\n",
      "Write summary at step 1630  Loss:  0.6814939379692078\n",
      "Write summary at step 1640  Loss:  0.7037469148635864\n",
      "Write summary at step 1650  Loss:  0.6130834817886353\n",
      "Write summary at step 1660  Loss:  0.6069857478141785\n",
      "Write summary at step 1670  Loss:  0.6632941365242004\n",
      "Write summary at step 1680  Loss:  0.7228237390518188\n",
      "Write summary at step 1690  Loss:  0.7052924633026123\n",
      "Write summary at step 1700  Loss:  0.6491045355796814\n",
      "Write summary at step 1710  Loss:  0.6624274253845215\n",
      "Write summary at step 1720  Loss:  0.6788042187690735\n",
      "Write summary at step 1730  Loss:  0.6792322397232056\n",
      "Write summary at step 1740  Loss:  0.723552942276001\n",
      "Write summary at step 1750  Loss:  0.69556725025177\n",
      "Write summary at step 1760  Loss:  0.7078567147254944\n",
      "Write summary at step 1770  Loss:  0.6383891105651855\n",
      "Write summary at step 1780  Loss:  0.6891220211982727\n",
      "Write summary at step 1790  Loss:  0.7264634370803833\n",
      "Write summary at step 1800  Loss:  0.6403746008872986\n",
      "Write summary at step 1810  Loss:  0.7316638231277466\n",
      "Write summary at step 1820  Loss:  0.6945269107818604\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.01639344262295082 Acurracy Patient:  0.9791666666666666 Acurracy Balanced 0.49778005464480873\n",
      "Loss normal: 0.7120816467644332 Loss Control: 0.7241049903989489 Loss Patient: 0.6662426503996054 Loss balanced:  0.6951738203992772 Loss1+loss2: 0.6951738203992772\n",
      "Write summary at step 1830  Loss:  0.7283715009689331\n",
      "Write summary at step 1840  Loss:  0.6824898719787598\n",
      "Write summary at step 1850  Loss:  0.6432690024375916\n",
      "Write summary at step 1860  Loss:  0.7246177196502686\n",
      "Write summary at step 1870  Loss:  0.7290486097335815\n",
      "Write summary at step 1880  Loss:  0.6874747276306152\n",
      "Write summary at step 1890  Loss:  0.7480373382568359\n",
      "Write summary at step 1900  Loss:  0.7385970950126648\n",
      "Write summary at step 1910  Loss:  0.7064238786697388\n",
      "Write summary at step 1920  Loss:  0.7381831407546997\n",
      "Write summary at step 1930  Loss:  0.7136131525039673\n",
      "Write summary at step 1940  Loss:  0.6613817811012268\n",
      "Write summary at step 1950  Loss:  0.7125810384750366\n",
      "Write summary at step 1960  Loss:  0.6933472752571106\n",
      "Write summary at step 1970  Loss:  0.6851227879524231\n",
      "Write summary at step 1980  Loss:  0.6761423349380493\n",
      "Write summary at step 1990  Loss:  0.6359747648239136\n",
      "Write summary at step 2000  Loss:  0.7015032768249512\n",
      "Saved checkpoint to: result/46/panns/checkpoint_2000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.020833333333333332 Acurracy Balanced 0.5049521857923497\n",
      "Loss normal: 0.6814849546977452 Loss Control: 0.6727107411525288 Loss Patient: 0.7149366699159145 Loss balanced:  0.6938237055342217 Loss1+loss2: 0.6938237055342217\n",
      "Write summary at step 2010  Loss:  0.7198487520217896\n",
      "Write summary at step 2020  Loss:  0.7240376472473145\n",
      "Write summary at step 2030  Loss:  0.6770435571670532\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2510822510822511 Acurracy Control:  0.10382513661202186 Acurracy Patient:  0.8125 Acurracy Balanced 0.45816256830601093\n",
      "Loss normal: 0.6932800045777193 Loss Control: 0.6928258974695466 Loss Patient: 0.6950113077958425 Loss balanced:  0.6939186026326946 Loss1+loss2: 0.6939186026326946\n",
      "Write summary at step 2040  Loss:  0.7514965534210205\n",
      "Write summary at step 2050  Loss:  0.7507067918777466\n",
      "Write summary at step 2060  Loss:  0.7036547660827637\n",
      "Write summary at step 2070  Loss:  0.675630509853363\n",
      "Write summary at step 2080  Loss:  0.6930620670318604\n",
      "Write summary at step 2090  Loss:  0.7310667037963867\n",
      "Write summary at step 2100  Loss:  0.7069233655929565\n",
      "Write summary at step 2110  Loss:  0.693317174911499\n",
      "Write summary at step 2120  Loss:  0.7046512961387634\n",
      "Write summary at step 2130  Loss:  0.8279016017913818\n",
      "Write summary at step 2140  Loss:  0.6601063013076782\n",
      "Write summary at step 2150  Loss:  0.7263758182525635\n",
      "Write summary at step 2160  Loss:  0.6931583285331726\n",
      "Write summary at step 2170  Loss:  0.6251724362373352\n",
      "Write summary at step 2180  Loss:  0.7092220783233643\n",
      "Write summary at step 2190  Loss:  0.6255621910095215\n",
      "Write summary at step 2200  Loss:  0.7119946479797363\n",
      "Write summary at step 2210  Loss:  0.7204223871231079\n",
      "Write summary at step 2220  Loss:  0.6872445344924927\n",
      "Write summary at step 2230  Loss:  0.7116926908493042\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.6805047379943715 Loss Control: 0.6708907025759338 Loss Patient: 0.7171581710378329 Loss balanced:  0.6940244368068833 Loss1+loss2: 0.6940244368068833\n",
      "Write summary at step 2240  Loss:  0.7156731486320496\n",
      "Write summary at step 2250  Loss:  0.7109552621841431\n",
      "Write summary at step 2260  Loss:  0.800747275352478\n",
      "Write summary at step 2270  Loss:  0.664644718170166\n",
      "Write summary at step 2280  Loss:  0.7074986100196838\n",
      "Write summary at step 2290  Loss:  0.6587914824485779\n",
      "Write summary at step 2300  Loss:  0.6390832662582397\n",
      "Write summary at step 2310  Loss:  0.6570194959640503\n",
      "Write summary at step 2320  Loss:  0.7235373854637146\n",
      "Write summary at step 2330  Loss:  0.7187035083770752\n",
      "Write summary at step 2340  Loss:  0.6903269290924072\n",
      "Write summary at step 2350  Loss:  0.7732036709785461\n",
      "Write summary at step 2360  Loss:  0.6721698045730591\n",
      "Write summary at step 2370  Loss:  0.7233916521072388\n",
      "Write summary at step 2380  Loss:  0.723717451095581\n",
      "Write summary at step 2390  Loss:  0.7165005207061768\n",
      "Write summary at step 2400  Loss:  0.7338517904281616\n",
      "Write summary at step 2410  Loss:  0.6968013048171997\n",
      "Write summary at step 2420  Loss:  0.6922930479049683\n",
      "Write summary at step 2430  Loss:  0.7117363214492798\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.21645021645021645 Acurracy Control:  0.0273224043715847 Acurracy Patient:  0.9375 Acurracy Balanced 0.48241120218579236\n",
      "Loss normal: 0.7446552143468486 Loss Control: 0.7747199177090588 Loss Patient: 0.6300334880749384 Loss balanced:  0.7023767028919986 Loss1+loss2: 0.7023767028919986\n",
      "Write summary at step 2440  Loss:  0.6970513463020325\n",
      "Write summary at step 2450  Loss:  0.733454704284668\n",
      "Write summary at step 2460  Loss:  0.7206322550773621\n",
      "Write summary at step 2470  Loss:  0.6953279972076416\n",
      "Write summary at step 2480  Loss:  0.725809633731842\n",
      "Write summary at step 2490  Loss:  0.699468731880188\n",
      "Write summary at step 2500  Loss:  0.6636972427368164\n",
      "Saved checkpoint to: result/46/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.2510822510822511 Acurracy Control:  0.09289617486338798 Acurracy Patient:  0.8541666666666666 Acurracy Balanced 0.4735314207650273\n",
      "Loss normal: 0.7296319038836987 Loss Control: 0.7490136493099192 Loss Patient: 0.6557390814026197 Loss balanced:  0.7023763653562695 Loss1+loss2: 0.7023763653562695\n",
      "Write summary at step 2510  Loss:  0.6681569814682007\n",
      "Write summary at step 2520  Loss:  0.6743314862251282\n",
      "Write summary at step 2530  Loss:  0.700934648513794\n",
      "Write summary at step 2540  Loss:  0.6106009483337402\n",
      "Write summary at step 2550  Loss:  0.7000874876976013\n",
      "Write summary at step 2560  Loss:  0.7193218469619751\n",
      "Write summary at step 2570  Loss:  0.6595884561538696\n",
      "Write summary at step 2580  Loss:  0.6189926862716675\n",
      "Write summary at step 2590  Loss:  0.7042058706283569\n",
      "Write summary at step 2600  Loss:  0.5496145486831665\n",
      "Write summary at step 2610  Loss:  0.7909700870513916\n",
      "Write summary at step 2620  Loss:  0.7168383002281189\n",
      "Write summary at step 2630  Loss:  0.6963293552398682\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5497835497835498 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.1875 Acurracy Balanced 0.4161543715846995\n",
      "Loss normal: 0.6861470044949354 Loss Control: 0.6768306018224831 Loss Patient: 0.7216657660901546 Loss balanced:  0.6992481839563189 Loss1+loss2: 0.6992481839563189\n",
      "Write summary at step 2640  Loss:  0.7037973403930664\n",
      "Write summary at step 2650  Loss:  0.6765036582946777\n",
      "Write summary at step 2660  Loss:  0.6825000047683716\n",
      "Write summary at step 2670  Loss:  0.7026656270027161\n",
      "Write summary at step 2680  Loss:  0.7185345888137817\n",
      "Write summary at step 2690  Loss:  0.693712592124939\n",
      "Write summary at step 2700  Loss:  0.7176171541213989\n",
      "Write summary at step 2710  Loss:  0.6487030982971191\n",
      "Write summary at step 2720  Loss:  0.6815487146377563\n",
      "Write summary at step 2730  Loss:  0.6409062147140503\n",
      "Write summary at step 2740  Loss:  0.7094181776046753\n",
      "Write summary at step 2750  Loss:  0.7244797945022583\n",
      "Write summary at step 2760  Loss:  0.6803228259086609\n",
      "Write summary at step 2770  Loss:  0.6880831122398376\n",
      "Write summary at step 2780  Loss:  0.7235394716262817\n",
      "Write summary at step 2790  Loss:  0.6803590059280396\n",
      "Write summary at step 2800  Loss:  0.6988304853439331\n",
      "Write summary at step 2810  Loss:  0.6749682426452637\n",
      "Write summary at step 2820  Loss:  0.6348807215690613\n",
      "Write summary at step 2830  Loss:  0.637272298336029\n",
      "Write summary at step 2840  Loss:  0.6253136396408081\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.39826839826839827 Acurracy Control:  0.36065573770491804 Acurracy Patient:  0.5416666666666666 Acurracy Balanced 0.45116120218579236\n",
      "Loss normal: 0.7113027474580905 Loss Control: 0.718243333811317 Loss Patient: 0.6848417297005653 Loss balanced:  0.7015425317559412 Loss1+loss2: 0.7015425317559412\n",
      "Write summary at step 2850  Loss:  0.6691521406173706\n",
      "Write summary at step 2860  Loss:  0.7176991701126099\n",
      "Write summary at step 2870  Loss:  0.7006365060806274\n",
      "Write summary at step 2880  Loss:  0.6342051029205322\n",
      "Write summary at step 2890  Loss:  0.6002863645553589\n",
      "Write summary at step 2900  Loss:  0.7257251143455505\n",
      "Write summary at step 2910  Loss:  0.7047296762466431\n",
      "Write summary at step 2920  Loss:  0.675297200679779\n",
      "Write summary at step 2930  Loss:  0.689408540725708\n",
      "Write summary at step 2940  Loss:  0.7178012132644653\n",
      "Write summary at step 2950  Loss:  0.6827658414840698\n",
      "Write summary at step 2960  Loss:  0.5930323600769043\n",
      "Write summary at step 2970  Loss:  0.7776903510093689\n",
      "Write summary at step 2980  Loss:  0.7920147776603699\n",
      "Write summary at step 2990  Loss:  0.6346719264984131\n",
      "Write summary at step 3000  Loss:  0.7655286192893982\n",
      "Saved checkpoint to: result/46/panns/checkpoint_3000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.3939393939393939 Acurracy Control:  0.4098360655737705 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.3715846994535519\n",
      "Loss normal: 0.704839898136271 Loss Control: 0.6947311934877615 Loss Patient: 0.7433793172240257 Loss balanced:  0.7190552553558935 Loss1+loss2: 0.7190552553558935\n",
      "Write summary at step 3010  Loss:  0.7188097238540649\n",
      "Write summary at step 3020  Loss:  0.7246408462524414\n",
      "Write summary at step 3030  Loss:  0.7393966913223267\n",
      "Write summary at step 3040  Loss:  0.7111067771911621\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.29004329004329005 Acurracy Control:  0.21311475409836064 Acurracy Patient:  0.5833333333333334 Acurracy Balanced 0.398224043715847\n",
      "Loss normal: 0.7270019787214536 Loss Control: 0.738536089495883 Loss Patient: 0.6830281155804793 Loss balanced:  0.7107821025381811 Loss1+loss2: 0.7107821025381811\n",
      "Write summary at step 3050  Loss:  0.6279006004333496\n",
      "Write summary at step 3060  Loss:  0.7718245983123779\n",
      "Write summary at step 3070  Loss:  0.6580953001976013\n",
      "Write summary at step 3080  Loss:  0.7276819348335266\n",
      "Write summary at step 3090  Loss:  0.7185037732124329\n",
      "Write summary at step 3100  Loss:  0.7360577583312988\n",
      "Write summary at step 3110  Loss:  0.6555144786834717\n",
      "Write summary at step 3120  Loss:  0.718737006187439\n",
      "Write summary at step 3130  Loss:  0.7169333100318909\n",
      "Write summary at step 3140  Loss:  0.6960241794586182\n",
      "Write summary at step 3150  Loss:  0.7175776958465576\n",
      "Write summary at step 3160  Loss:  0.7652982473373413\n",
      "Write summary at step 3170  Loss:  0.6777595281600952\n",
      "Write summary at step 3180  Loss:  0.6761014461517334\n",
      "Write summary at step 3190  Loss:  0.6989326477050781\n",
      "Write summary at step 3200  Loss:  0.6637790203094482\n",
      "Write summary at step 3210  Loss:  0.6577353477478027\n",
      "Write summary at step 3220  Loss:  0.6996471881866455\n",
      "Write summary at step 3230  Loss:  0.7187561988830566\n",
      "Write summary at step 3240  Loss:  0.6597242951393127\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4458874458874459 Acurracy Control:  0.48633879781420764 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.38900273224043713\n",
      "Loss normal: 0.6951651952483437 Loss Control: 0.6825362590492748 Loss Patient: 0.7433129735291004 Loss balanced:  0.7129246162891876 Loss1+loss2: 0.7129246162891876\n",
      "Write summary at step 3250  Loss:  0.6918946504592896\n",
      "Write summary at step 3260  Loss:  0.677069902420044\n",
      "Write summary at step 3270  Loss:  0.6315679550170898\n",
      "Write summary at step 3280  Loss:  0.7002084851264954\n",
      "Write summary at step 3290  Loss:  0.6507930159568787\n",
      "Write summary at step 3300  Loss:  0.7329705953598022\n",
      "Write summary at step 3310  Loss:  0.6669919490814209\n",
      "Write summary at step 3320  Loss:  0.7035114765167236\n",
      "Write summary at step 3330  Loss:  0.7512348294258118\n",
      "Write summary at step 3340  Loss:  0.6179925799369812\n",
      "Write summary at step 3350  Loss:  0.6442234516143799\n",
      "Write summary at step 3360  Loss:  0.6598571538925171\n",
      "Write summary at step 3370  Loss:  0.6492682099342346\n",
      "Write summary at step 3380  Loss:  0.7223501205444336\n",
      "Write summary at step 3390  Loss:  0.7567213773727417\n",
      "Write summary at step 3400  Loss:  0.732465386390686\n",
      "Write summary at step 3410  Loss:  0.6872075796127319\n",
      "Write summary at step 3420  Loss:  0.6460387110710144\n",
      "Write summary at step 3430  Loss:  0.6955686807632446\n",
      "Write summary at step 3440  Loss:  0.7370604872703552\n",
      "Write summary at step 3450  Loss:  0.7097486257553101\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.125 Acurracy Balanced 0.4805327868852459\n",
      "Loss normal: 0.6498991741246475 Loss Control: 0.6061345045683814 Loss Patient: 0.8167519631485144 Loss balanced:  0.7114432338584479 Loss1+loss2: 0.7114432338584479\n",
      "Write summary at step 3460  Loss:  0.7297846674919128\n",
      "Write summary at step 3470  Loss:  0.6957196593284607\n",
      "Write summary at step 3480  Loss:  0.5903550386428833\n",
      "Write summary at step 3490  Loss:  0.6965236663818359\n",
      "Write summary at step 3500  Loss:  0.724789023399353\n",
      "Saved checkpoint to: result/46/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.341991341991342 Acurracy Control:  0.24043715846994534 Acurracy Patient:  0.7291666666666666 Acurracy Balanced 0.48480191256830596\n",
      "Loss normal: 0.7464726087334869 Loss Control: 0.7749214800980573 Loss Patient: 0.6380113077660402 Loss balanced:  0.7064663939320488 Loss1+loss2: 0.7064663939320488\n",
      "Write summary at step 3510  Loss:  0.7036556005477905\n",
      "Write summary at step 3520  Loss:  0.7154536247253418\n",
      "Write summary at step 3530  Loss:  0.7160952091217041\n",
      "Write summary at step 3540  Loss:  0.7046785354614258\n",
      "Write summary at step 3550  Loss:  0.7011927366256714\n",
      "Write summary at step 3560  Loss:  0.7813693284988403\n",
      "Write summary at step 3570  Loss:  0.6410819888114929\n",
      "Write summary at step 3580  Loss:  0.6962346434593201\n",
      "Write summary at step 3590  Loss:  0.6449688673019409\n",
      "Write summary at step 3600  Loss:  0.861806333065033\n",
      "Write summary at step 3610  Loss:  0.7129523754119873\n",
      "Write summary at step 3620  Loss:  0.6350895166397095\n",
      "Write summary at step 3630  Loss:  0.72064608335495\n",
      "Write summary at step 3640  Loss:  0.660545825958252\n",
      "Write summary at step 3650  Loss:  0.766396701335907\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5670995670995671 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.4347677595628415\n",
      "Loss normal: 0.6770648752456103 Loss Control: 0.6514307752333052 Loss Patient: 0.774794856707255 Loss balanced:  0.7131128159702801 Loss1+loss2: 0.7131128159702801\n",
      "Write summary at step 3660  Loss:  0.6788641214370728\n",
      "Write summary at step 3670  Loss:  0.7326240539550781\n",
      "Write summary at step 3680  Loss:  0.6392325758934021\n",
      "Write summary at step 3690  Loss:  0.6531599760055542\n",
      "Write summary at step 3700  Loss:  0.6613067388534546\n",
      "Write summary at step 3710  Loss:  0.6630752086639404\n",
      "Write summary at step 3720  Loss:  0.7487078905105591\n",
      "Write summary at step 3730  Loss:  0.6992151737213135\n",
      "Write summary at step 3740  Loss:  0.7253726124763489\n",
      "Write summary at step 3750  Loss:  0.7412995100021362\n",
      "Write summary at step 3760  Loss:  0.673703670501709\n",
      "Write summary at step 3770  Loss:  0.7351762652397156\n",
      "Write summary at step 3780  Loss:  0.6756542921066284\n",
      "Write summary at step 3790  Loss:  0.7229419350624084\n",
      "Write summary at step 3800  Loss:  0.6819652915000916\n",
      "Write summary at step 3810  Loss:  0.7133699655532837\n",
      "Write summary at step 3820  Loss:  0.8235791921615601\n",
      "Write summary at step 3830  Loss:  0.687118411064148\n",
      "Write summary at step 3840  Loss:  0.6792880296707153\n",
      "Write summary at step 3850  Loss:  0.753607988357544\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.3722943722943723 Acurracy Control:  0.3825136612021858 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.3579234972677595\n",
      "Loss normal: 0.7023624220451752 Loss Control: 0.6831218118224639 Loss Patient: 0.7757172547280788 Loss balanced:  0.7294195332752713 Loss1+loss2: 0.7294195332752713\n",
      "Write summary at step 3860  Loss:  0.7440661191940308\n",
      "Write summary at step 3870  Loss:  0.7242467999458313\n",
      "Write summary at step 3880  Loss:  0.6997452974319458\n",
      "Write summary at step 3890  Loss:  0.7791692018508911\n",
      "Write summary at step 3900  Loss:  0.6905034780502319\n",
      "Write summary at step 3910  Loss:  0.7368550896644592\n",
      "Write summary at step 3920  Loss:  0.6823351383209229\n",
      "Write summary at step 3930  Loss:  0.6791701316833496\n",
      "Write summary at step 3940  Loss:  0.6592937707901001\n",
      "Write summary at step 3950  Loss:  0.658423900604248\n",
      "Write summary at step 3960  Loss:  0.6727352738380432\n",
      "Write summary at step 3970  Loss:  0.6510385274887085\n",
      "Write summary at step 3980  Loss:  0.6773859858512878\n",
      "Write summary at step 3990  Loss:  0.6017017364501953\n",
      "Write summary at step 4000  Loss:  0.7105377316474915\n",
      "Saved checkpoint to: result/46/panns/checkpoint_4000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.35064935064935066 Acurracy Control:  0.2896174863387978 Acurracy Patient:  0.5833333333333334 Acurracy Balanced 0.4364754098360656\n",
      "Loss normal: 0.7414416647576666 Loss Control: 0.7595699992987628 Loss Patient: 0.6723274203638235 Loss balanced:  0.7159487098312931 Loss1+loss2: 0.7159487098312931\n",
      "Write summary at step 4010  Loss:  0.6163887977600098\n",
      "Write summary at step 4020  Loss:  0.678708016872406\n",
      "Write summary at step 4030  Loss:  0.6834452152252197\n",
      "Write summary at step 4040  Loss:  0.7201297283172607\n",
      "Write summary at step 4050  Loss:  0.6560728549957275\n",
      "Write summary at step 4060  Loss:  0.6601741313934326\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6363636363636364 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.45543032786885246\n",
      "Loss normal: 0.6588630676269531 Loss Control: 0.6268569797766014 Loss Patient: 0.7808862713476022 Loss balanced:  0.7038716255621018 Loss1+loss2: 0.7038716255621018\n",
      "Write summary at step 4070  Loss:  0.651964008808136\n",
      "Write summary at step 4080  Loss:  0.6794881224632263\n",
      "Write summary at step 4090  Loss:  0.6174629926681519\n",
      "Write summary at step 4100  Loss:  0.6969711184501648\n",
      "Write summary at step 4110  Loss:  0.6492668390274048\n",
      "Write summary at step 4120  Loss:  0.735642671585083\n",
      "Write summary at step 4130  Loss:  0.6802995204925537\n",
      "Write summary at step 4140  Loss:  0.732934832572937\n",
      "Write summary at step 4150  Loss:  0.8399258852005005\n",
      "Write summary at step 4160  Loss:  0.6720939874649048\n",
      "Write summary at step 4170  Loss:  0.7013635635375977\n",
      "Write summary at step 4180  Loss:  0.6744276285171509\n",
      "Write summary at step 4190  Loss:  0.7625054121017456\n",
      "Write summary at step 4200  Loss:  0.7794538736343384\n",
      "Write summary at step 4210  Loss:  0.6419446468353271\n",
      "Write summary at step 4220  Loss:  0.6983886957168579\n",
      "Write summary at step 4230  Loss:  0.7003918886184692\n",
      "Write summary at step 4240  Loss:  0.667805016040802\n",
      "Write summary at step 4250  Loss:  0.6189916729927063\n",
      "Write summary at step 4260  Loss:  0.682343602180481\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.43722943722943725 Acurracy Control:  0.366120218579235 Acurracy Patient:  0.7083333333333334 Acurracy Balanced 0.5372267759562842\n",
      "Loss normal: 0.6964487804994954 Loss Control: 0.695968177474913 Loss Patient: 0.6982810807724794 Loss balanced:  0.6971246291236962 Loss1+loss2: 0.6971246291236962\n",
      "Write summary at step 4270  Loss:  0.6653481721878052\n",
      "Write summary at step 4280  Loss:  0.7818245887756348\n",
      "Write summary at step 4290  Loss:  0.6944770812988281\n",
      "Write summary at step 4300  Loss:  0.6652148962020874\n",
      "Write summary at step 4310  Loss:  0.6875099539756775\n",
      "Write summary at step 4320  Loss:  0.6079877614974976\n",
      "Write summary at step 4330  Loss:  0.689670741558075\n",
      "Write summary at step 4340  Loss:  0.8281689286231995\n",
      "Write summary at step 4350  Loss:  0.7964352369308472\n",
      "Write summary at step 4360  Loss:  0.7710247039794922\n",
      "Write summary at step 4370  Loss:  0.6473590135574341\n",
      "Write summary at step 4380  Loss:  0.7056030631065369\n",
      "Write summary at step 4390  Loss:  0.6432254910469055\n",
      "Write summary at step 4400  Loss:  0.7919832468032837\n",
      "Write summary at step 4410  Loss:  0.6183478832244873\n",
      "Write summary at step 4420  Loss:  0.7300863265991211\n",
      "Write summary at step 4430  Loss:  0.5878311395645142\n",
      "Write summary at step 4440  Loss:  0.8211971521377563\n",
      "Write summary at step 4450  Loss:  0.6564188003540039\n",
      "Write summary at step 4460  Loss:  0.7517144680023193\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4935064935064935 Acurracy Control:  0.5300546448087432 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.4421106557377049\n",
      "Loss normal: 0.6802663877928928 Loss Control: 0.6584862688851487 Loss Patient: 0.7633030166228613 Loss balanced:  0.710894642754005 Loss1+loss2: 0.710894642754005\n",
      "Write summary at step 4470  Loss:  0.776559591293335\n",
      "Write summary at step 4480  Loss:  0.6863412261009216\n",
      "Write summary at step 4490  Loss:  0.6440125107765198\n",
      "Write summary at step 4500  Loss:  0.6421381235122681\n",
      "Saved checkpoint to: result/46/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7445887445887446 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5237363387978142\n",
      "Loss normal: 0.656755277346739 Loss Control: 0.623202539206854 Loss Patient: 0.7846750964721044 Loss balanced:  0.7039388178394792 Loss1+loss2: 0.7039388178394792\n",
      "Write summary at step 4510  Loss:  0.7189640998840332\n",
      "Write summary at step 4520  Loss:  0.7237701416015625\n",
      "Write summary at step 4530  Loss:  0.7214818000793457\n",
      "Write summary at step 4540  Loss:  0.7244837880134583\n",
      "Write summary at step 4550  Loss:  0.7287918329238892\n",
      "Write summary at step 4560  Loss:  0.6655223369598389\n",
      "Write summary at step 4570  Loss:  0.7101722359657288\n",
      "Write summary at step 4580  Loss:  0.7168766260147095\n",
      "Write summary at step 4590  Loss:  0.6454648971557617\n",
      "Write summary at step 4600  Loss:  0.7155959010124207\n",
      "Write summary at step 4610  Loss:  0.617279052734375\n",
      "Write summary at step 4620  Loss:  0.6812244653701782\n",
      "Write summary at step 4630  Loss:  0.7179956436157227\n",
      "Write summary at step 4640  Loss:  0.7742995023727417\n",
      "Write summary at step 4650  Loss:  0.7411639094352722\n",
      "Write summary at step 4660  Loss:  0.7375307083129883\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5844155844155844 Acurracy Control:  0.6557377049180327 Acurracy Patient:  0.3125 Acurracy Balanced 0.48411885245901637\n",
      "Loss normal: 0.6677163431654761 Loss Control: 0.6345789380412284 Loss Patient: 0.7940526232123375 Loss balanced:  0.714315780626783 Loss1+loss2: 0.714315780626783\n",
      "Write summary at step 4670  Loss:  0.5832538604736328\n",
      "Write summary at step 4680  Loss:  0.7376863956451416\n",
      "Write summary at step 4690  Loss:  0.6981706023216248\n",
      "Write summary at step 4700  Loss:  0.699203610420227\n",
      "Write summary at step 4710  Loss:  0.6671159267425537\n",
      "Write summary at step 4720  Loss:  0.6755971908569336\n",
      "Write summary at step 4730  Loss:  0.8304260969161987\n",
      "Write summary at step 4740  Loss:  0.6834949254989624\n",
      "Write summary at step 4750  Loss:  0.6518856883049011\n",
      "Write summary at step 4760  Loss:  0.604622483253479\n",
      "Write summary at step 4770  Loss:  0.646454930305481\n",
      "Write summary at step 4780  Loss:  0.6866593360900879\n",
      "Write summary at step 4790  Loss:  0.6926493644714355\n",
      "Write summary at step 4800  Loss:  0.6728740930557251\n",
      "Write summary at step 4810  Loss:  0.6739722490310669\n",
      "Write summary at step 4820  Loss:  0.6666183471679688\n",
      "Write summary at step 4830  Loss:  0.7022159099578857\n",
      "Write summary at step 4840  Loss:  0.697034478187561\n",
      "Write summary at step 4850  Loss:  0.693463146686554\n",
      "Write summary at step 4860  Loss:  0.7157873511314392\n",
      "Write summary at step 4870  Loss:  0.6426011919975281\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.49783549783549785 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.43715846994535523\n",
      "Loss normal: 0.6768614980049463 Loss Control: 0.6493175840768658 Loss Patient: 0.7818726524710655 Loss balanced:  0.7155951182739657 Loss1+loss2: 0.7155951182739657\n",
      "Write summary at step 4880  Loss:  0.6382963061332703\n",
      "Write summary at step 4890  Loss:  0.6641790866851807\n",
      "Write summary at step 4900  Loss:  0.7782793641090393\n",
      "Write summary at step 4910  Loss:  0.720928966999054\n",
      "Write summary at step 4920  Loss:  0.6454010009765625\n",
      "Write summary at step 4930  Loss:  0.7117936611175537\n",
      "Write summary at step 4940  Loss:  0.6963968276977539\n",
      "Write summary at step 4950  Loss:  0.7810488343238831\n",
      "Write summary at step 4960  Loss:  0.6434520483016968\n",
      "Write summary at step 4970  Loss:  0.6917493343353271\n",
      "Write summary at step 4980  Loss:  0.6598482131958008\n",
      "Write summary at step 4990  Loss:  0.71385258436203\n",
      "Write summary at step 5000  Loss:  0.6274486780166626\n",
      "Saved checkpoint to: result/46/panns/checkpoint_5000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.5064935064935064 Acurracy Control:  0.5191256830601093 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.48872950819672134\n",
      "Loss normal: 0.663500223840986 Loss Control: 0.6312348810050006 Loss Patient: 0.7865118446449438 Loss balanced:  0.7088733628249722 Loss1+loss2: 0.7088733628249722\n",
      "Write summary at step 5010  Loss:  0.6984525918960571\n",
      "Write summary at step 5020  Loss:  0.6533979177474976\n",
      "Write summary at step 5030  Loss:  0.7381003499031067\n",
      "Write summary at step 5040  Loss:  0.6931192874908447\n",
      "Write summary at step 5050  Loss:  0.6952388882637024\n",
      "Write summary at step 5060  Loss:  0.8005770444869995\n",
      "Write summary at step 5070  Loss:  0.7065654993057251\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7316017316017316 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5155396174863388\n",
      "Loss normal: 0.6885052230451014 Loss Control: 0.6823501153721836 Loss Patient: 0.7119715462128321 Loss balanced:  0.6971608307925079 Loss1+loss2: 0.6971608307925079\n",
      "Write summary at step 5080  Loss:  0.7367540597915649\n",
      "Write summary at step 5090  Loss:  0.6514711976051331\n",
      "Write summary at step 5100  Loss:  0.746173620223999\n",
      "Write summary at step 5110  Loss:  0.7124374508857727\n",
      "Write summary at step 5120  Loss:  0.7240039110183716\n",
      "Write summary at step 5130  Loss:  0.702311098575592\n",
      "Write summary at step 5140  Loss:  0.704041600227356\n",
      "Write summary at step 5150  Loss:  0.6821707487106323\n",
      "Write summary at step 5160  Loss:  0.656980037689209\n",
      "Write summary at step 5170  Loss:  0.665471613407135\n",
      "Write summary at step 5180  Loss:  0.726409375667572\n",
      "Write summary at step 5190  Loss:  0.7083442807197571\n",
      "Write summary at step 5200  Loss:  0.6897766590118408\n",
      "Write summary at step 5210  Loss:  0.6840511560440063\n",
      "Write summary at step 5220  Loss:  0.6688451170921326\n",
      "Write summary at step 5230  Loss:  0.659138023853302\n",
      "Write summary at step 5240  Loss:  0.7114217281341553\n",
      "Write summary at step 5250  Loss:  0.7162092924118042\n",
      "Write summary at step 5260  Loss:  0.6686674356460571\n",
      "Write summary at step 5270  Loss:  0.6650354862213135\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  1.0 Acurracy Patient:  0.0 Acurracy Balanced 0.5\n",
      "Loss normal: 0.5934494537708563 Loss Control: 0.520139778246645 Loss Patient: 0.8729426277180513 Loss balanced:  0.6965412029823481 Loss1+loss2: 0.6965412029823481\n",
      "Write summary at step 5280  Loss:  0.7285523414611816\n",
      "Write summary at step 5290  Loss:  0.6790376901626587\n",
      "Write summary at step 5300  Loss:  0.7112456560134888\n",
      "Write summary at step 5310  Loss:  0.6574738025665283\n",
      "Write summary at step 5320  Loss:  0.6773421168327332\n",
      "Write summary at step 5330  Loss:  0.6891077756881714\n",
      "Write summary at step 5340  Loss:  0.7253247499465942\n",
      "Write summary at step 5350  Loss:  0.730842113494873\n",
      "Write summary at step 5360  Loss:  0.6441432237625122\n",
      "Write summary at step 5370  Loss:  0.7336241602897644\n",
      "Write summary at step 5380  Loss:  0.700168251991272\n",
      "Write summary at step 5390  Loss:  0.7887486219406128\n",
      "Write summary at step 5400  Loss:  0.678851842880249\n",
      "Write summary at step 5410  Loss:  0.6639799475669861\n",
      "Write summary at step 5420  Loss:  0.6364135146141052\n",
      "Write summary at step 5430  Loss:  0.7018418312072754\n",
      "Write summary at step 5440  Loss:  0.6803383827209473\n",
      "Write summary at step 5450  Loss:  0.7137702107429504\n",
      "Write summary at step 5460  Loss:  0.6492576599121094\n",
      "Write summary at step 5470  Loss:  0.6474553346633911\n",
      "Write summary at step 5480  Loss:  0.6691697239875793\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5899931693989071\n",
      "Loss normal: 0.6006544193664154 Loss Control: 0.5333354186490585 Loss Patient: 0.8573080835243067 Loss balanced:  0.6953217510866826 Loss1+loss2: 0.6953217510866826\n",
      "Write summary at step 5490  Loss:  0.6596978902816772\n",
      "Write summary at step 5500  Loss:  0.708833634853363\n",
      "Saved checkpoint to: result/46/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6233766233766234 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.49334016393442626\n",
      "Loss normal: 0.6506749572175922 Loss Control: 0.6032378347845025 Loss Patient: 0.8315289989113808 Loss balanced:  0.7173834168479416 Loss1+loss2: 0.7173834168479416\n",
      "Write summary at step 5510  Loss:  0.6362566947937012\n",
      "Write summary at step 5520  Loss:  0.6641088128089905\n",
      "Write summary at step 5530  Loss:  0.6573805809020996\n",
      "Write summary at step 5540  Loss:  0.6992406845092773\n",
      "Write summary at step 5550  Loss:  0.6167923212051392\n",
      "Write summary at step 5560  Loss:  0.7030239105224609\n",
      "Write summary at step 5570  Loss:  0.6711277961730957\n",
      "Write summary at step 5580  Loss:  0.6756374835968018\n",
      "Write summary at step 5590  Loss:  0.6883552670478821\n",
      "Write summary at step 5600  Loss:  0.6562936902046204\n",
      "Write summary at step 5610  Loss:  0.5873240828514099\n",
      "Write summary at step 5620  Loss:  0.6922086477279663\n",
      "Write summary at step 5630  Loss:  0.6917410492897034\n",
      "Write summary at step 5640  Loss:  0.6509741544723511\n",
      "Write summary at step 5650  Loss:  0.9086743593215942\n",
      "Write summary at step 5660  Loss:  0.6418039202690125\n",
      "Write summary at step 5670  Loss:  0.6736968159675598\n",
      "Write summary at step 5680  Loss:  0.6639804840087891\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.45021645021645024 Acurracy Control:  0.46994535519125685 Acurracy Patient:  0.375 Acurracy Balanced 0.42247267759562845\n",
      "Loss normal: 0.7206411614562526 Loss Control: 0.7216637518887963 Loss Patient: 0.7167425105969111 Loss balanced:  0.7192031312428537 Loss1+loss2: 0.7192031312428537\n",
      "Write summary at step 5690  Loss:  0.6390183568000793\n",
      "Write summary at step 5700  Loss:  0.6264803409576416\n",
      "Write summary at step 5710  Loss:  0.5727218389511108\n",
      "Write summary at step 5720  Loss:  0.7049332857131958\n",
      "Write summary at step 5730  Loss:  0.6801719665527344\n",
      "Write summary at step 5740  Loss:  0.7144893407821655\n",
      "Write summary at step 5750  Loss:  0.706372082233429\n",
      "Write summary at step 5760  Loss:  0.7217667102813721\n",
      "Write summary at step 5770  Loss:  0.6730968952178955\n",
      "Write summary at step 5780  Loss:  0.6408692002296448\n",
      "Write summary at step 5790  Loss:  0.6143473386764526\n",
      "Write summary at step 5800  Loss:  0.6442139744758606\n",
      "Write summary at step 5810  Loss:  0.6016261577606201\n",
      "Write summary at step 5820  Loss:  0.7291886806488037\n",
      "Write summary at step 5830  Loss:  0.6296953558921814\n",
      "Write summary at step 5840  Loss:  0.6972026824951172\n",
      "Write summary at step 5850  Loss:  0.6053321957588196\n",
      "Write summary at step 5860  Loss:  0.7402092218399048\n",
      "Write summary at step 5870  Loss:  0.687025785446167\n",
      "Write summary at step 5880  Loss:  0.5930033922195435\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6277056277056277 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.25 Acurracy Balanced 0.4883879781420765\n",
      "Loss normal: 0.6630783646137683 Loss Control: 0.6312678925326614 Loss Patient: 0.7843557856976986 Loss balanced:  0.70781183911518 Loss1+loss2: 0.70781183911518\n",
      "Write summary at step 5890  Loss:  0.6470537185668945\n",
      "Write summary at step 5900  Loss:  0.6376429796218872\n",
      "Write summary at step 5910  Loss:  0.7218109965324402\n",
      "Write summary at step 5920  Loss:  0.6527707576751709\n",
      "Write summary at step 5930  Loss:  0.5584567785263062\n",
      "Write summary at step 5940  Loss:  0.6603124141693115\n",
      "Write summary at step 5950  Loss:  0.645058810710907\n",
      "Write summary at step 5960  Loss:  0.6352680921554565\n",
      "Write summary at step 5970  Loss:  0.7188253998756409\n",
      "Write summary at step 5980  Loss:  0.7218592166900635\n",
      "Write summary at step 5990  Loss:  0.6140845417976379\n",
      "Write summary at step 6000  Loss:  0.741986095905304\n",
      "Saved checkpoint to: result/46/panns/checkpoint_6000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7272727272727273 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.25 Acurracy Balanced 0.5512295081967213\n",
      "Loss normal: 0.6040933710156065 Loss Control: 0.5013605740552391 Loss Patient: 0.9957621594270071 Loss balanced:  0.7485613667411231 Loss1+loss2: 0.7485613667411231\n",
      "Write summary at step 6010  Loss:  0.6685221195220947\n",
      "Write summary at step 6020  Loss:  0.5877809524536133\n",
      "Write summary at step 6030  Loss:  0.6929308176040649\n",
      "Write summary at step 6040  Loss:  0.7116613984107971\n",
      "Write summary at step 6050  Loss:  0.6870807409286499\n",
      "Write summary at step 6060  Loss:  0.7090908288955688\n",
      "Write summary at step 6070  Loss:  0.7051368951797485\n",
      "Write summary at step 6080  Loss:  0.756938099861145\n",
      "Write summary at step 6090  Loss:  0.6708917021751404\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.1875 Acurracy Balanced 0.5035860655737705\n",
      "Loss normal: 0.6396431904850584 Loss Control: 0.5764714606472703 Loss Patient: 0.8804854253927866 Loss balanced:  0.7284784430200284 Loss1+loss2: 0.7284784430200284\n",
      "Write summary at step 6100  Loss:  0.5981924533843994\n",
      "Write summary at step 6110  Loss:  0.6563323736190796\n",
      "Write summary at step 6120  Loss:  0.74534010887146\n",
      "Write summary at step 6130  Loss:  0.6692257523536682\n",
      "Write summary at step 6140  Loss:  0.6711993217468262\n",
      "Write summary at step 6150  Loss:  0.6596248149871826\n",
      "Write summary at step 6160  Loss:  0.7263871431350708\n",
      "Write summary at step 6170  Loss:  0.7196496725082397\n",
      "Write summary at step 6180  Loss:  0.7007865905761719\n",
      "Write summary at step 6190  Loss:  0.697205662727356\n",
      "Write summary at step 6200  Loss:  0.7539752721786499\n",
      "Write summary at step 6210  Loss:  0.7371633052825928\n",
      "Write summary at step 6220  Loss:  0.8196166157722473\n",
      "Write summary at step 6230  Loss:  0.6594403982162476\n",
      "Write summary at step 6240  Loss:  0.7141060829162598\n",
      "Write summary at step 6250  Loss:  0.7445825934410095\n",
      "Write summary at step 6260  Loss:  0.7079339027404785\n",
      "Write summary at step 6270  Loss:  0.6553188562393188\n",
      "Write summary at step 6280  Loss:  0.6441265344619751\n",
      "Write summary at step 6290  Loss:  0.6412216424942017\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5522540983606558\n",
      "Loss normal: 0.619427566920524 Loss Control: 0.5570769980956948 Loss Patient: 0.8571390826255083 Loss balanced:  0.7071080403606016 Loss1+loss2: 0.7071080403606016\n",
      "Write summary at step 6300  Loss:  0.6745720505714417\n",
      "Write summary at step 6310  Loss:  0.6866790056228638\n",
      "Write summary at step 6320  Loss:  0.6220654249191284\n",
      "Write summary at step 6330  Loss:  0.6751297116279602\n",
      "Write summary at step 6340  Loss:  0.6944409608840942\n",
      "Write summary at step 6350  Loss:  0.6373686790466309\n",
      "Write summary at step 6360  Loss:  0.868796706199646\n",
      "Write summary at step 6370  Loss:  0.635636568069458\n",
      "Write summary at step 6380  Loss:  0.6590800285339355\n",
      "Write summary at step 6390  Loss:  0.7211805582046509\n",
      "Write summary at step 6400  Loss:  0.6328796148300171\n",
      "Write summary at step 6410  Loss:  0.6744964122772217\n",
      "Write summary at step 6420  Loss:  0.7710322141647339\n",
      "Write summary at step 6430  Loss:  0.6648105978965759\n",
      "Write summary at step 6440  Loss:  0.6621826887130737\n",
      "Write summary at step 6450  Loss:  0.559047520160675\n",
      "Write summary at step 6460  Loss:  0.711471676826477\n",
      "Write summary at step 6470  Loss:  0.6443676352500916\n",
      "Write summary at step 6480  Loss:  0.7679843902587891\n",
      "Write summary at step 6490  Loss:  0.7613340616226196\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6666666666666666 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.1875 Acurracy Balanced 0.48992486338797814\n",
      "Loss normal: 0.6338811705122779 Loss Control: 0.5679271208132551 Loss Patient: 0.885330967605114 Loss balanced:  0.7266290442091845 Loss1+loss2: 0.7266290442091845\n",
      "Write summary at step 6500  Loss:  0.6636519432067871\n",
      "Saved checkpoint to: result/46/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5140027322404371\n",
      "Loss normal: 0.6312005488903492 Loss Control: 0.5630771123646386 Loss Patient: 0.8909211295346419 Loss balanced:  0.7269991209496403 Loss1+loss2: 0.7269991209496403\n",
      "Write summary at step 6510  Loss:  0.721131443977356\n",
      "Write summary at step 6520  Loss:  0.6697337627410889\n",
      "Write summary at step 6530  Loss:  0.6443767547607422\n",
      "Write summary at step 6540  Loss:  0.7861351370811462\n",
      "Write summary at step 6550  Loss:  0.7034018635749817\n",
      "Write summary at step 6560  Loss:  0.671656608581543\n",
      "Write summary at step 6570  Loss:  0.6969985961914062\n",
      "Write summary at step 6580  Loss:  0.7428000569343567\n",
      "Write summary at step 6590  Loss:  0.7019808292388916\n",
      "Write summary at step 6600  Loss:  0.5843812227249146\n",
      "Write summary at step 6610  Loss:  0.7098216414451599\n",
      "Write summary at step 6620  Loss:  0.677682638168335\n",
      "Write summary at step 6630  Loss:  0.6661946773529053\n",
      "Write summary at step 6640  Loss:  0.6325292587280273\n",
      "Write summary at step 6650  Loss:  0.7212991118431091\n",
      "Write summary at step 6660  Loss:  0.7348333597183228\n",
      "Write summary at step 6670  Loss:  0.7923488616943359\n",
      "Write summary at step 6680  Loss:  0.623001217842102\n",
      "Write summary at step 6690  Loss:  0.7968810796737671\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.45021645021645024 Acurracy Control:  0.43169398907103823 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.4762636612021858\n",
      "Loss normal: 0.7352962173940816 Loss Control: 0.7473980598762388 Loss Patient: 0.6891578808426857 Loss balanced:  0.7182779703594622 Loss1+loss2: 0.7182779703594622\n",
      "Write summary at step 6700  Loss:  0.6441507339477539\n",
      "Write summary at step 6710  Loss:  0.6612719297409058\n",
      "Write summary at step 6720  Loss:  0.6585066318511963\n",
      "Write summary at step 6730  Loss:  0.7042794227600098\n",
      "Write summary at step 6740  Loss:  0.691704511642456\n",
      "Write summary at step 6750  Loss:  0.7314282059669495\n",
      "Write summary at step 6760  Loss:  0.6606448888778687\n",
      "Write summary at step 6770  Loss:  0.6398999691009521\n",
      "Write summary at step 6780  Loss:  0.6086640357971191\n",
      "Write summary at step 6790  Loss:  0.6189707517623901\n",
      "Write summary at step 6800  Loss:  0.7527316808700562\n",
      "Write summary at step 6810  Loss:  0.7052186727523804\n",
      "Write summary at step 6820  Loss:  0.6548720598220825\n",
      "Write summary at step 6830  Loss:  0.6992479562759399\n",
      "Write summary at step 6840  Loss:  0.6978716850280762\n",
      "Write summary at step 6850  Loss:  0.6503657102584839\n",
      "Write summary at step 6860  Loss:  0.6059592962265015\n",
      "Write summary at step 6870  Loss:  0.6888689994812012\n",
      "Write summary at step 6880  Loss:  0.7235656976699829\n",
      "Write summary at step 6890  Loss:  0.6009037494659424\n",
      "Write summary at step 6900  Loss:  0.7329404950141907\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5151515151515151 Acurracy Control:  0.5792349726775956 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.42503415300546443\n",
      "Loss normal: 0.6800419339885959 Loss Control: 0.6562628908886936 Loss Patient: 0.7706995817522208 Loss balanced:  0.7134812363204572 Loss1+loss2: 0.7134812363204572\n",
      "Write summary at step 6910  Loss:  0.6591176986694336\n",
      "Write summary at step 6920  Loss:  0.7407689094543457\n",
      "Write summary at step 6930  Loss:  0.6073310375213623\n",
      "Write summary at step 6940  Loss:  0.6796406507492065\n",
      "Write summary at step 6950  Loss:  0.6392966508865356\n",
      "Write summary at step 6960  Loss:  0.703685462474823\n",
      "Write summary at step 6970  Loss:  0.655361533164978\n",
      "Write summary at step 6980  Loss:  0.7252455949783325\n",
      "Write summary at step 6990  Loss:  0.6933765411376953\n",
      "Write summary at step 7000  Loss:  0.6108536720275879\n",
      "Saved checkpoint to: result/46/panns/checkpoint_7000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5286885245901639\n",
      "Loss normal: 0.6041729586981076 Loss Control: 0.5132310966976353 Loss Patient: 0.9508888212343057 Loss balanced:  0.7320599589659705 Loss1+loss2: 0.7320599589659705\n",
      "Write summary at step 7010  Loss:  0.7088733911514282\n",
      "Write summary at step 7020  Loss:  0.6547412872314453\n",
      "Write summary at step 7030  Loss:  0.6494096517562866\n",
      "Write summary at step 7040  Loss:  0.7178207635879517\n",
      "Write summary at step 7050  Loss:  0.5727793574333191\n",
      "Write summary at step 7060  Loss:  0.6812609434127808\n",
      "Write summary at step 7070  Loss:  0.757216215133667\n",
      "Write summary at step 7080  Loss:  0.6169043183326721\n",
      "Write summary at step 7090  Loss:  0.6334402561187744\n",
      "Write summary at step 7100  Loss:  0.6003040671348572\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.683982683982684 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5162226775956285\n",
      "Loss normal: 0.618073012147631 Loss Control: 0.5428301112247946 Loss Patient: 0.9049365452180306 Loss balanced:  0.7238833282214125 Loss1+loss2: 0.7238833282214125\n",
      "Write summary at step 7110  Loss:  0.7012687921524048\n",
      "Write summary at step 7120  Loss:  0.5320051312446594\n",
      "Write summary at step 7130  Loss:  0.6837177276611328\n",
      "Write summary at step 7140  Loss:  0.6123085021972656\n",
      "Write summary at step 7150  Loss:  0.7213863134384155\n",
      "Write summary at step 7160  Loss:  0.5956381559371948\n",
      "Write summary at step 7170  Loss:  0.6216116547584534\n",
      "Write summary at step 7180  Loss:  0.7086553573608398\n",
      "Write summary at step 7190  Loss:  0.6910825967788696\n",
      "Write summary at step 7200  Loss:  0.7131516933441162\n",
      "Write summary at step 7210  Loss:  0.7080984711647034\n",
      "Write summary at step 7220  Loss:  0.7559955716133118\n",
      "Write summary at step 7230  Loss:  0.6504863500595093\n",
      "Write summary at step 7240  Loss:  0.7354615330696106\n",
      "Write summary at step 7250  Loss:  0.6491100788116455\n",
      "Write summary at step 7260  Loss:  0.5827096700668335\n",
      "Write summary at step 7270  Loss:  0.5230075716972351\n",
      "Write summary at step 7280  Loss:  0.6634400486946106\n",
      "Write summary at step 7290  Loss:  0.5607929229736328\n",
      "Write summary at step 7300  Loss:  0.6623448133468628\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4069264069264069 Acurracy Control:  0.3770491803278688 Acurracy Patient:  0.5208333333333334 Acurracy Balanced 0.4489412568306011\n",
      "Loss normal: 0.75526694508342 Loss Control: 0.7729523064660244 Loss Patient: 0.6878415451695522 Loss balanced:  0.7303969258177883 Loss1+loss2: 0.7303969258177883\n",
      "Write summary at step 7310  Loss:  0.631881594657898\n",
      "Write summary at step 7320  Loss:  0.7387892007827759\n",
      "Write summary at step 7330  Loss:  0.6198019981384277\n",
      "Write summary at step 7340  Loss:  0.8040028810501099\n",
      "Write summary at step 7350  Loss:  0.6692272424697876\n",
      "Write summary at step 7360  Loss:  0.7972357273101807\n",
      "Write summary at step 7370  Loss:  0.7261388897895813\n",
      "Write summary at step 7380  Loss:  0.5585623383522034\n",
      "Write summary at step 7390  Loss:  0.6369386911392212\n",
      "Write summary at step 7400  Loss:  0.667870283126831\n",
      "Write summary at step 7410  Loss:  0.6008768677711487\n",
      "Write summary at step 7420  Loss:  0.6384410858154297\n",
      "Write summary at step 7430  Loss:  0.8333138227462769\n",
      "Write summary at step 7440  Loss:  0.6925990581512451\n",
      "Write summary at step 7450  Loss:  0.6188225746154785\n",
      "Write summary at step 7460  Loss:  0.6584673523902893\n",
      "Write summary at step 7470  Loss:  0.8069124221801758\n",
      "Write summary at step 7480  Loss:  0.7204003930091858\n",
      "Write summary at step 7490  Loss:  0.7478214502334595\n",
      "Write summary at step 7500  Loss:  0.6867343187332153\n",
      "Saved checkpoint to: result/46/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5604508196721312\n",
      "Loss normal: 0.6063104444768006 Loss Control: 0.5403699646882021 Loss Patient: 0.8577085509896278 Loss balanced:  0.699039257838915 Loss1+loss2: 0.699039257838915\n",
      "Write summary at step 7510  Loss:  0.6716889142990112\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7056277056277056 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.25 Acurracy Balanced 0.537568306010929\n",
      "Loss normal: 0.640186142869842 Loss Control: 0.6071354525336803 Loss Patient: 0.7661918830126524 Loss balanced:  0.6866636677731663 Loss1+loss2: 0.6866636677731663\n",
      "Write summary at step 7520  Loss:  0.6222886443138123\n",
      "Write summary at step 7530  Loss:  0.6428705453872681\n",
      "Write summary at step 7540  Loss:  0.6035210490226746\n",
      "Write summary at step 7550  Loss:  0.7496366500854492\n",
      "Write summary at step 7560  Loss:  0.7941415309906006\n",
      "Write summary at step 7570  Loss:  0.6684489250183105\n",
      "Write summary at step 7580  Loss:  0.699392557144165\n",
      "Write summary at step 7590  Loss:  0.7905674576759338\n",
      "Write summary at step 7600  Loss:  0.656059741973877\n",
      "Write summary at step 7610  Loss:  0.634934663772583\n",
      "Write summary at step 7620  Loss:  0.6708128452301025\n",
      "Write summary at step 7630  Loss:  0.746421217918396\n",
      "Write summary at step 7640  Loss:  0.6132321357727051\n",
      "Write summary at step 7650  Loss:  0.7119951248168945\n",
      "Write summary at step 7660  Loss:  0.5591094493865967\n",
      "Write summary at step 7670  Loss:  0.71610027551651\n",
      "Write summary at step 7680  Loss:  0.6705285310745239\n",
      "Write summary at step 7690  Loss:  0.6706564426422119\n",
      "Write summary at step 7700  Loss:  0.6983385682106018\n",
      "Write summary at step 7710  Loss:  0.6526312828063965\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.658008658008658 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.3125 Acurracy Balanced 0.5305669398907105\n",
      "Loss normal: 0.6581379417733196 Loss Control: 0.6380071184022831 Loss Patient: 0.7348866996665796 Loss balanced:  0.6864469090344314 Loss1+loss2: 0.6864469090344314\n",
      "Write summary at step 7720  Loss:  0.6581846475601196\n",
      "Write summary at step 7730  Loss:  0.6033759117126465\n",
      "Write summary at step 7740  Loss:  0.6986486315727234\n",
      "Write summary at step 7750  Loss:  0.7721142768859863\n",
      "Write summary at step 7760  Loss:  0.6646853685379028\n",
      "Write summary at step 7770  Loss:  0.6214073896408081\n",
      "Write summary at step 7780  Loss:  0.7195255160331726\n",
      "Write summary at step 7790  Loss:  0.7738280892372131\n",
      "Write summary at step 7800  Loss:  0.6055310964584351\n",
      "Write summary at step 7810  Loss:  0.6567521691322327\n",
      "Write summary at step 7820  Loss:  0.7229296565055847\n",
      "Write summary at step 7830  Loss:  0.7246801853179932\n",
      "Write summary at step 7840  Loss:  0.7164888978004456\n",
      "Write summary at step 7850  Loss:  0.6070622205734253\n",
      "Write summary at step 7860  Loss:  0.6552963256835938\n",
      "Write summary at step 7870  Loss:  0.703835129737854\n",
      "Write summary at step 7880  Loss:  0.660847008228302\n",
      "Write summary at step 7890  Loss:  0.7114213705062866\n",
      "Write summary at step 7900  Loss:  0.7215093970298767\n",
      "Write summary at step 7910  Loss:  0.6936704516410828\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.6157786885245902\n",
      "Loss normal: 0.6253873651677911 Loss Control: 0.5852099376949457 Loss Patient: 0.7785638061662515 Loss balanced:  0.6818868719305986 Loss1+loss2: 0.6818868719305986\n",
      "Write summary at step 7920  Loss:  0.6959118843078613\n",
      "Write summary at step 7930  Loss:  0.7376993298530579\n",
      "Write summary at step 7940  Loss:  0.8213542699813843\n",
      "Write summary at step 7950  Loss:  0.6425992250442505\n",
      "Write summary at step 7960  Loss:  0.6633154153823853\n",
      "Write summary at step 7970  Loss:  0.6599860191345215\n",
      "Write summary at step 7980  Loss:  0.7893297672271729\n",
      "Write summary at step 7990  Loss:  0.7558786869049072\n",
      "Write summary at step 8000  Loss:  0.6552742123603821\n",
      "Saved checkpoint to: result/46/panns/checkpoint_8000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.5194805194805194 Acurracy Control:  0.5573770491803278 Acurracy Patient:  0.375 Acurracy Balanced 0.4661885245901639\n",
      "Loss normal: 0.7016495285612164 Loss Control: 0.6975755548216606 Loss Patient: 0.7171815298497677 Loss balanced:  0.7073785423357142 Loss1+loss2: 0.7073785423357142\n",
      "Write summary at step 8010  Loss:  0.723862886428833\n",
      "Write summary at step 8020  Loss:  0.6096335053443909\n",
      "Write summary at step 8030  Loss:  0.7116316556930542\n",
      "Write summary at step 8040  Loss:  0.6706055998802185\n",
      "Write summary at step 8050  Loss:  0.7323839664459229\n",
      "Write summary at step 8060  Loss:  0.7577163577079773\n",
      "Write summary at step 8070  Loss:  0.6449957489967346\n",
      "Write summary at step 8080  Loss:  0.7287071347236633\n",
      "Write summary at step 8090  Loss:  0.7586201429367065\n",
      "Write summary at step 8100  Loss:  0.6292421817779541\n",
      "Write summary at step 8110  Loss:  0.7435853481292725\n",
      "Write summary at step 8120  Loss:  0.7130616903305054\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5541125541125541 Acurracy Control:  0.6120218579234973 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.47267759562841527\n",
      "Loss normal: 0.7011826474429209 Loss Control: 0.6838706559170791 Loss Patient: 0.7671846145143112 Loss balanced:  0.7255276352156952 Loss1+loss2: 0.7255276352156952\n",
      "Write summary at step 8130  Loss:  0.6668912172317505\n",
      "Write summary at step 8140  Loss:  0.8917664289474487\n",
      "Write summary at step 8150  Loss:  0.6244455575942993\n",
      "Write summary at step 8160  Loss:  0.6856639385223389\n",
      "Write summary at step 8170  Loss:  0.5570399761199951\n",
      "Write summary at step 8180  Loss:  0.636276364326477\n",
      "Write summary at step 8190  Loss:  0.6775524616241455\n",
      "Write summary at step 8200  Loss:  0.8080162405967712\n",
      "Write summary at step 8210  Loss:  0.6666563749313354\n",
      "Write summary at step 8220  Loss:  0.634276270866394\n",
      "Write summary at step 8230  Loss:  0.7353777289390564\n",
      "Write summary at step 8240  Loss:  0.6230683326721191\n",
      "Write summary at step 8250  Loss:  0.6462053060531616\n",
      "Write summary at step 8260  Loss:  0.621679425239563\n",
      "Write summary at step 8270  Loss:  0.7290092706680298\n",
      "Write summary at step 8280  Loss:  0.73525071144104\n",
      "Write summary at step 8290  Loss:  0.6324975490570068\n",
      "Write summary at step 8300  Loss:  0.6699679493904114\n",
      "Write summary at step 8310  Loss:  0.735943078994751\n",
      "Write summary at step 8320  Loss:  0.6637178659439087\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8181818181818182 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.5778688524590164\n",
      "Loss normal: 0.5551871038102484 Loss Control: 0.41579460739438 Loss Patient: 1.086621039857467 Loss balanced:  0.7512078236259234 Loss1+loss2: 0.7512078236259234\n",
      "Write summary at step 8330  Loss:  0.6651252508163452\n",
      "Write summary at step 8340  Loss:  0.7171601057052612\n",
      "Write summary at step 8350  Loss:  0.6117092370986938\n",
      "Write summary at step 8360  Loss:  0.7155759930610657\n",
      "Write summary at step 8370  Loss:  0.5945693254470825\n",
      "Write summary at step 8380  Loss:  0.7426058650016785\n",
      "Write summary at step 8390  Loss:  0.6706041693687439\n",
      "Write summary at step 8400  Loss:  0.5890341401100159\n",
      "Write summary at step 8410  Loss:  0.6670808792114258\n",
      "Write summary at step 8420  Loss:  0.5605354905128479\n",
      "Write summary at step 8430  Loss:  0.6520780324935913\n",
      "Write summary at step 8440  Loss:  0.7416038513183594\n",
      "Write summary at step 8450  Loss:  0.6595302820205688\n",
      "Write summary at step 8460  Loss:  0.6953868865966797\n",
      "Write summary at step 8470  Loss:  0.6915090084075928\n",
      "Write summary at step 8480  Loss:  0.7702435255050659\n",
      "Write summary at step 8490  Loss:  0.6319719552993774\n",
      "Write summary at step 8500  Loss:  0.7210597395896912\n",
      "Saved checkpoint to: result/46/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7272727272727273 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.25 Acurracy Balanced 0.5512295081967213\n",
      "Loss normal: 0.617265510352659 Loss Control: 0.5682574816740276 Loss Patient: 0.8041086041678985 Loss balanced:  0.686183042920963 Loss1+loss2: 0.686183042920963\n",
      "Write summary at step 8510  Loss:  0.623816967010498\n",
      "Write summary at step 8520  Loss:  0.6750856637954712\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8138528138528138 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5981898907103825\n",
      "Loss normal: 0.5872341528599396 Loss Control: 0.5248731361712263 Loss Patient: 0.8249855302274227 Loss balanced:  0.6749293331993245 Loss1+loss2: 0.6749293331993245\n",
      "Write summary at step 8530  Loss:  0.6736633777618408\n",
      "Write summary at step 8540  Loss:  0.6719911694526672\n",
      "Write summary at step 8550  Loss:  0.5369275808334351\n",
      "Write summary at step 8560  Loss:  0.6509411931037903\n",
      "Write summary at step 8570  Loss:  0.5669103264808655\n",
      "Write summary at step 8580  Loss:  0.7074263691902161\n",
      "Write summary at step 8590  Loss:  0.8591736555099487\n",
      "Write summary at step 8600  Loss:  0.6250419020652771\n",
      "Write summary at step 8610  Loss:  0.6414552927017212\n",
      "Write summary at step 8620  Loss:  0.7585538029670715\n",
      "Write summary at step 8630  Loss:  0.7413576245307922\n",
      "Write summary at step 8640  Loss:  0.598265528678894\n",
      "Write summary at step 8650  Loss:  0.6448949575424194\n",
      "Write summary at step 8660  Loss:  0.7851602435112\n",
      "Write summary at step 8670  Loss:  0.8036131858825684\n",
      "Write summary at step 8680  Loss:  0.611309289932251\n",
      "Write summary at step 8690  Loss:  0.7019839286804199\n",
      "Write summary at step 8700  Loss:  0.6867120265960693\n",
      "Write summary at step 8710  Loss:  0.635857880115509\n",
      "Write summary at step 8720  Loss:  0.7367912530899048\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.1875 Acurracy Balanced 0.5800887978142076\n",
      "Loss normal: 0.5737904018653935 Loss Control: 0.49284550824451967 Loss Patient: 0.8823928025861582 Loss balanced:  0.6876191554153389 Loss1+loss2: 0.6876191554153389\n",
      "Write summary at step 8730  Loss:  0.677551805973053\n",
      "Write summary at step 8740  Loss:  0.6326090097427368\n",
      "Write summary at step 8750  Loss:  0.7758312225341797\n",
      "Write summary at step 8760  Loss:  0.7106730937957764\n",
      "Write summary at step 8770  Loss:  0.6059503555297852\n",
      "Write summary at step 8780  Loss:  0.5684069395065308\n",
      "Write summary at step 8790  Loss:  0.6385405659675598\n",
      "Write summary at step 8800  Loss:  0.7111519575119019\n",
      "Write summary at step 8810  Loss:  0.7081993818283081\n",
      "Write summary at step 8820  Loss:  0.7150181531906128\n",
      "Write summary at step 8830  Loss:  0.8731905221939087\n",
      "Write summary at step 8840  Loss:  0.703460693359375\n",
      "Write summary at step 8850  Loss:  0.8595527410507202\n",
      "Write summary at step 8860  Loss:  0.686184287071228\n",
      "Write summary at step 8870  Loss:  0.6977138519287109\n",
      "Write summary at step 8880  Loss:  0.8022485971450806\n",
      "Write summary at step 8890  Loss:  0.7359004616737366\n",
      "Write summary at step 8900  Loss:  0.5389089584350586\n",
      "Write summary at step 8910  Loss:  0.6165817975997925\n",
      "Write summary at step 8920  Loss:  0.5979390144348145\n",
      "Write summary at step 8930  Loss:  0.636864185333252\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5686475409836066\n",
      "Loss normal: 0.5874453816579018 Loss Control: 0.4993245676566994 Loss Patient: 0.9234059862792492 Loss balanced:  0.7113652769679744 Loss1+loss2: 0.7113652769679744\n",
      "Write summary at step 8940  Loss:  0.6759721040725708\n",
      "Write summary at step 8950  Loss:  0.7581452131271362\n",
      "Write summary at step 8960  Loss:  0.5883532762527466\n",
      "Write summary at step 8970  Loss:  0.5836215019226074\n",
      "Write summary at step 8980  Loss:  0.7575764656066895\n",
      "Write summary at step 8990  Loss:  0.663009524345398\n",
      "Write summary at step 9000  Loss:  0.7613240480422974\n",
      "Saved checkpoint to: result/46/panns/checkpoint_9000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.645021645021645 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.3125 Acurracy Balanced 0.5223702185792349\n",
      "Loss normal: 0.6546644307834245 Loss Control: 0.6187630494435629 Loss Patient: 0.7915384508669376 Loss balanced:  0.7051507501552503 Loss1+loss2: 0.7051507501552503\n",
      "Write summary at step 9010  Loss:  0.6631613969802856\n",
      "Write summary at step 9020  Loss:  0.6531485319137573\n",
      "Write summary at step 9030  Loss:  0.6325774192810059\n",
      "Write summary at step 9040  Loss:  0.6207549571990967\n",
      "Write summary at step 9050  Loss:  0.5960516333580017\n",
      "Write summary at step 9060  Loss:  0.7264283299446106\n",
      "Write summary at step 9070  Loss:  0.6535489559173584\n",
      "Write summary at step 9080  Loss:  0.7804011702537537\n",
      "Write summary at step 9090  Loss:  0.7261124849319458\n",
      "Write summary at step 9100  Loss:  0.6865192651748657\n",
      "Write summary at step 9110  Loss:  0.7945016622543335\n",
      "Write summary at step 9120  Loss:  0.6377055644989014\n",
      "Write summary at step 9130  Loss:  0.6963704228401184\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5714285714285714 Acurracy Control:  0.6065573770491803 Acurracy Patient:  0.4375 Acurracy Balanced 0.5220286885245902\n",
      "Loss normal: 0.6859676427655406 Loss Control: 0.671202299047689 Loss Patient: 0.7422605417668819 Loss balanced:  0.7067314204072854 Loss1+loss2: 0.7067314204072854\n",
      "Write summary at step 9140  Loss:  0.8007822632789612\n",
      "Write summary at step 9150  Loss:  0.7567176222801208\n",
      "Write summary at step 9160  Loss:  0.5814881324768066\n",
      "Write summary at step 9170  Loss:  0.5842278599739075\n",
      "Write summary at step 9180  Loss:  0.5938330292701721\n",
      "Write summary at step 9190  Loss:  0.6763389706611633\n",
      "Write summary at step 9200  Loss:  0.617746114730835\n",
      "Write summary at step 9210  Loss:  0.6031827926635742\n",
      "Write summary at step 9220  Loss:  0.6619015336036682\n",
      "Write summary at step 9230  Loss:  0.6860042810440063\n",
      "Write summary at step 9240  Loss:  0.6643081307411194\n",
      "Write summary at step 9250  Loss:  0.7010967135429382\n",
      "Write summary at step 9260  Loss:  0.8241993188858032\n",
      "Write summary at step 9270  Loss:  0.6185600757598877\n",
      "Write summary at step 9280  Loss:  0.6507058143615723\n",
      "Write summary at step 9290  Loss:  0.636189341545105\n",
      "Write summary at step 9300  Loss:  0.601030170917511\n",
      "Write summary at step 9310  Loss:  0.6782614588737488\n",
      "Write summary at step 9320  Loss:  0.5807327032089233\n",
      "Write summary at step 9330  Loss:  0.5945668816566467\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.42424242424242425 Acurracy Control:  0.40437158469945356 Acurracy Patient:  0.5 Acurracy Balanced 0.4521857923497268\n",
      "Loss normal: 0.7863704554446331 Loss Control: 0.8027755035077287 Loss Patient: 0.7238261854896942 Loss balanced:  0.7633008444987115 Loss1+loss2: 0.7633008444987115\n",
      "Write summary at step 9340  Loss:  0.5884233713150024\n",
      "Write summary at step 9350  Loss:  0.7245639562606812\n",
      "Write summary at step 9360  Loss:  0.6374872922897339\n",
      "Write summary at step 9370  Loss:  0.576134443283081\n",
      "Write summary at step 9380  Loss:  0.7257940769195557\n",
      "Write summary at step 9390  Loss:  0.6631650924682617\n",
      "Write summary at step 9400  Loss:  0.735058069229126\n",
      "Write summary at step 9410  Loss:  0.7783792614936829\n",
      "Write summary at step 9420  Loss:  0.6127910017967224\n",
      "Write summary at step 9430  Loss:  0.6575168371200562\n",
      "Write summary at step 9440  Loss:  0.6101025342941284\n",
      "Write summary at step 9450  Loss:  0.5219696164131165\n",
      "Write summary at step 9460  Loss:  0.8168280124664307\n",
      "Write summary at step 9470  Loss:  0.729859471321106\n",
      "Write summary at step 9480  Loss:  0.6698449850082397\n",
      "Write summary at step 9490  Loss:  0.667648196220398\n",
      "Write summary at step 9500  Loss:  0.6039791107177734\n",
      "Saved checkpoint to: result/46/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.46320346320346323 Acurracy Control:  0.46994535519125685 Acurracy Patient:  0.4375 Acurracy Balanced 0.45372267759562845\n",
      "Loss normal: 0.7235540352858506 Loss Control: 0.7241028801339572 Loss Patient: 0.7214615736156702 Loss balanced:  0.7227822268748136 Loss1+loss2: 0.7227822268748136\n",
      "Write summary at step 9510  Loss:  0.7208818793296814\n",
      "Write summary at step 9520  Loss:  0.5866610407829285\n",
      "Write summary at step 9530  Loss:  0.6500633358955383\n",
      "Write summary at step 9540  Loss:  0.7332612872123718\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.1875 Acurracy Balanced 0.5035860655737705\n",
      "Loss normal: 0.6313941437444646 Loss Control: 0.5302275073984282 Loss Patient: 1.017091987033685 Loss balanced:  0.7736597472160566 Loss1+loss2: 0.7736597472160566\n",
      "Write summary at step 9550  Loss:  0.7024847865104675\n",
      "Write summary at step 9560  Loss:  0.908123254776001\n",
      "Write summary at step 9570  Loss:  0.6162753701210022\n",
      "Write summary at step 9580  Loss:  0.7838225960731506\n",
      "Write summary at step 9590  Loss:  0.7335527539253235\n",
      "Write summary at step 9600  Loss:  0.7191673517227173\n",
      "Write summary at step 9610  Loss:  0.6298640966415405\n",
      "Write summary at step 9620  Loss:  0.6842570304870605\n",
      "Write summary at step 9630  Loss:  0.7286049127578735\n",
      "Write summary at step 9640  Loss:  0.5799663066864014\n",
      "Write summary at step 9650  Loss:  0.8026342391967773\n",
      "Write summary at step 9660  Loss:  0.6709464192390442\n",
      "Write summary at step 9670  Loss:  0.6855089068412781\n",
      "Write summary at step 9680  Loss:  0.6167022585868835\n",
      "Write summary at step 9690  Loss:  0.7152633666992188\n",
      "Write summary at step 9700  Loss:  0.6551614999771118\n",
      "Write summary at step 9710  Loss:  0.7942320704460144\n",
      "Write summary at step 9720  Loss:  0.6764650344848633\n",
      "Write summary at step 9730  Loss:  0.6360149383544922\n",
      "Write summary at step 9740  Loss:  0.5872731804847717\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5887445887445888 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5022199453551912\n",
      "Loss normal: 0.6756170732634408 Loss Control: 0.6461160557517589 Loss Patient: 0.7880897087355455 Loss balanced:  0.7171028822436523 Loss1+loss2: 0.7171028822436523\n",
      "Write summary at step 9750  Loss:  0.5216851234436035\n",
      "Write summary at step 9760  Loss:  0.7355445027351379\n",
      "Write summary at step 9770  Loss:  0.7269188165664673\n",
      "Write summary at step 9780  Loss:  0.698685884475708\n",
      "Write summary at step 9790  Loss:  0.7601311206817627\n",
      "Write summary at step 9800  Loss:  0.7547732591629028\n",
      "Write summary at step 9810  Loss:  0.663051426410675\n",
      "Write summary at step 9820  Loss:  0.6605738997459412\n",
      "Write summary at step 9830  Loss:  0.6370687484741211\n",
      "Write summary at step 9840  Loss:  0.8500310182571411\n",
      "Write summary at step 9850  Loss:  0.6735966205596924\n",
      "Write summary at step 9860  Loss:  0.8223080635070801\n",
      "Write summary at step 9870  Loss:  0.606624960899353\n",
      "Write summary at step 9880  Loss:  0.6945598125457764\n",
      "Write summary at step 9890  Loss:  0.6094847321510315\n",
      "Write summary at step 9900  Loss:  0.6576128005981445\n",
      "Write summary at step 9910  Loss:  0.6943365335464478\n",
      "Write summary at step 9920  Loss:  0.6372300386428833\n",
      "Write summary at step 9930  Loss:  0.666975736618042\n",
      "Write summary at step 9940  Loss:  0.7339199781417847\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5887445887445888 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.375 Acurracy Balanced 0.5099043715846995\n",
      "Loss normal: 0.6751867986860729 Loss Control: 0.659294516011014 Loss Patient: 0.7357761450111866 Loss balanced:  0.6975353305111003 Loss1+loss2: 0.6975353305111003\n",
      "Write summary at step 9950  Loss:  0.6820560693740845\n",
      "Write summary at step 9960  Loss:  0.6800713539123535\n",
      "Write summary at step 9970  Loss:  0.7187118530273438\n",
      "Write summary at step 9980  Loss:  0.5595316886901855\n",
      "Write summary at step 9990  Loss:  0.6760680675506592\n",
      "Write summary at step 10000  Loss:  0.8135157823562622\n",
      "Saved checkpoint to: result/46/panns/checkpoint_10000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.3125 Acurracy Balanced 0.5141734972677596\n",
      "Loss normal: 0.6560527210111742 Loss Control: 0.6245966485289277 Loss Patient: 0.7759790476411581 Loss balanced:  0.700287848085043 Loss1+loss2: 0.700287848085043\n",
      "Write summary at step 10010  Loss:  0.5587648153305054\n",
      "Write summary at step 10020  Loss:  0.6275785565376282\n",
      "Write summary at step 10030  Loss:  0.7147622108459473\n",
      "Write summary at step 10040  Loss:  0.6796695590019226\n",
      "Write summary at step 10050  Loss:  0.6534676551818848\n",
      "Write summary at step 10060  Loss:  0.7135376334190369\n",
      "Write summary at step 10070  Loss:  0.5907058119773865\n",
      "Write summary at step 10080  Loss:  0.6485946178436279\n",
      "Write summary at step 10090  Loss:  0.7685292959213257\n",
      "Write summary at step 10100  Loss:  0.6581310033798218\n",
      "Write summary at step 10110  Loss:  0.6875225305557251\n",
      "Write summary at step 10120  Loss:  0.7622369527816772\n",
      "Write summary at step 10130  Loss:  0.57435142993927\n",
      "Write summary at step 10140  Loss:  0.49594151973724365\n",
      "Write summary at step 10150  Loss:  0.6697113513946533\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5151515151515151 Acurracy Control:  0.5519125683060109 Acurracy Patient:  0.375 Acurracy Balanced 0.46345628415300544\n",
      "Loss normal: 0.70162957493877 Loss Control: 0.6888845217683928 Loss Patient: 0.7502200429638227 Loss balanced:  0.7195522823661078 Loss1+loss2: 0.7195522823661078\n",
      "Write summary at step 10160  Loss:  0.6808950901031494\n",
      "Write summary at step 10170  Loss:  0.6518265604972839\n",
      "Write summary at step 10180  Loss:  0.5803278088569641\n",
      "Write summary at step 10190  Loss:  0.612144947052002\n",
      "Write summary at step 10200  Loss:  0.6129432916641235\n",
      "Write summary at step 10210  Loss:  0.5783805847167969\n",
      "Write summary at step 10220  Loss:  0.6261069178581238\n",
      "Write summary at step 10230  Loss:  0.558758020401001\n",
      "Write summary at step 10240  Loss:  0.6053323745727539\n",
      "Write summary at step 10250  Loss:  0.6854710578918457\n",
      "Write summary at step 10260  Loss:  0.7310816645622253\n",
      "Write summary at step 10270  Loss:  0.7127264142036438\n",
      "Write summary at step 10280  Loss:  0.6723219752311707\n",
      "Write summary at step 10290  Loss:  0.7141368985176086\n",
      "Write summary at step 10300  Loss:  0.5848571062088013\n",
      "Write summary at step 10310  Loss:  0.6929084062576294\n",
      "Write summary at step 10320  Loss:  0.6948973536491394\n",
      "Write summary at step 10330  Loss:  0.7209667563438416\n",
      "Write summary at step 10340  Loss:  0.6971980929374695\n",
      "Write summary at step 10350  Loss:  0.6275643706321716\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5541125541125541 Acurracy Control:  0.5792349726775956 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.5187841530054644\n",
      "Loss normal: 0.6952649762620141 Loss Control: 0.70263848669542 Loss Patient: 0.6671535025040308 Loss balanced:  0.6848959945997254 Loss1+loss2: 0.6848959945997254\n",
      "Write summary at step 10360  Loss:  0.5957348346710205\n",
      "Write summary at step 10370  Loss:  0.6932348012924194\n",
      "Write summary at step 10380  Loss:  0.6147311925888062\n",
      "Write summary at step 10390  Loss:  0.6492332220077515\n",
      "Write summary at step 10400  Loss:  0.6856645941734314\n",
      "Write summary at step 10410  Loss:  0.7355862855911255\n",
      "Write summary at step 10420  Loss:  0.6569991111755371\n",
      "Write summary at step 10430  Loss:  0.6334463357925415\n",
      "Write summary at step 10440  Loss:  0.5986284613609314\n",
      "Write summary at step 10450  Loss:  0.8978438973426819\n",
      "Write summary at step 10460  Loss:  0.7435328960418701\n",
      "Write summary at step 10470  Loss:  0.5896024703979492\n",
      "Write summary at step 10480  Loss:  0.6215070486068726\n",
      "Write summary at step 10490  Loss:  0.5537394285202026\n",
      "Write summary at step 10500  Loss:  0.6437909007072449\n",
      "Saved checkpoint to: result/46/panns/checkpoint_10500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7619047619047619 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5654030054644809\n",
      "Loss normal: 0.6043391330933674 Loss Control: 0.5364169501216034 Loss Patient: 0.8632924277335405 Loss balanced:  0.699854688927572 Loss1+loss2: 0.699854688927572\n",
      "Write summary at step 10510  Loss:  0.720203161239624\n",
      "Write summary at step 10520  Loss:  0.4862108826637268\n",
      "Write summary at step 10530  Loss:  0.6682668924331665\n",
      "Write summary at step 10540  Loss:  0.6059583425521851\n",
      "Write summary at step 10550  Loss:  0.689238429069519\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5713797814207651\n",
      "Loss normal: 0.5995852771775547 Loss Control: 0.5353132310460825 Loss Patient: 0.844622399037083 Loss balanced:  0.6899678150415828 Loss1+loss2: 0.6899678150415828\n",
      "Write summary at step 10560  Loss:  0.6460814476013184\n",
      "Write summary at step 10570  Loss:  0.654149055480957\n",
      "Write summary at step 10580  Loss:  0.7686852812767029\n",
      "Write summary at step 10590  Loss:  0.6154196262359619\n",
      "Write summary at step 10600  Loss:  0.6509150266647339\n",
      "Write summary at step 10610  Loss:  0.6578667163848877\n",
      "Write summary at step 10620  Loss:  0.6995181441307068\n",
      "Write summary at step 10630  Loss:  0.6822935342788696\n",
      "Write summary at step 10640  Loss:  0.7295717597007751\n",
      "Write summary at step 10650  Loss:  0.6769381761550903\n",
      "Write summary at step 10660  Loss:  0.619123101234436\n",
      "Write summary at step 10670  Loss:  0.6510982513427734\n",
      "Write summary at step 10680  Loss:  0.7653334140777588\n",
      "Write summary at step 10690  Loss:  0.6084754467010498\n",
      "Write summary at step 10700  Loss:  0.6857733130455017\n",
      "Write summary at step 10710  Loss:  0.7831012010574341\n",
      "Write summary at step 10720  Loss:  0.6862043738365173\n",
      "Write summary at step 10730  Loss:  0.7108815908432007\n",
      "Write summary at step 10740  Loss:  0.6702573895454407\n",
      "Write summary at step 10750  Loss:  0.657199501991272\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5944330601092896\n",
      "Loss normal: 0.6307955735173576 Loss Control: 0.5948541734387965 Loss Patient: 0.7678221662839254 Loss balanced:  0.681338169861361 Loss1+loss2: 0.681338169861361\n",
      "Write summary at step 10760  Loss:  0.7275853157043457\n",
      "Write summary at step 10770  Loss:  0.5972195863723755\n",
      "Write summary at step 10780  Loss:  0.6610846519470215\n",
      "Write summary at step 10790  Loss:  0.6841398477554321\n",
      "Write summary at step 10800  Loss:  0.5622216463088989\n",
      "Write summary at step 10810  Loss:  0.7034237384796143\n",
      "Write summary at step 10820  Loss:  0.7908240556716919\n",
      "Write summary at step 10830  Loss:  0.663362443447113\n",
      "Write summary at step 10840  Loss:  0.6833624243736267\n",
      "Write summary at step 10850  Loss:  0.7247701287269592\n",
      "Write summary at step 10860  Loss:  0.47852110862731934\n",
      "Write summary at step 10870  Loss:  0.6827988028526306\n",
      "Write summary at step 10880  Loss:  0.7103462219238281\n",
      "Write summary at step 10890  Loss:  0.6386085748672485\n",
      "Write summary at step 10900  Loss:  0.6885645389556885\n",
      "Write summary at step 10910  Loss:  0.5770101547241211\n",
      "Write summary at step 10920  Loss:  0.6218057870864868\n",
      "Write summary at step 10930  Loss:  0.7742639183998108\n",
      "Write summary at step 10940  Loss:  0.5783118009567261\n",
      "Write summary at step 10950  Loss:  0.7553073167800903\n",
      "Write summary at step 10960  Loss:  0.6379865407943726\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6753246753246753 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.5722336065573771\n",
      "Loss normal: 0.6444363914010844 Loss Control: 0.6202439662537288 Loss Patient: 0.7366700091709694 Loss balanced:  0.6784569877123491 Loss1+loss2: 0.6784569877123491\n",
      "Write summary at step 10970  Loss:  0.6654359102249146\n",
      "Write summary at step 10980  Loss:  0.6384110450744629\n",
      "Write summary at step 10990  Loss:  0.6832075715065002\n",
      "Write summary at step 11000  Loss:  0.9770488739013672\n",
      "Saved checkpoint to: result/46/panns/checkpoint_11000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5216871584699454\n",
      "Loss normal: 0.6270198481423515 Loss Control: 0.5713424917127266 Loss Patient: 0.8392897869149843 Loss balanced:  0.7053161393138554 Loss1+loss2: 0.7053161393138554\n",
      "Write summary at step 11010  Loss:  0.8358668088912964\n",
      "Write summary at step 11020  Loss:  0.5252383947372437\n",
      "Write summary at step 11030  Loss:  0.5815469026565552\n",
      "Write summary at step 11040  Loss:  0.5957898497581482\n",
      "Write summary at step 11050  Loss:  0.7636792659759521\n",
      "Write summary at step 11060  Loss:  0.599297285079956\n",
      "Write summary at step 11070  Loss:  0.6448635458946228\n",
      "Write summary at step 11080  Loss:  0.7824527025222778\n",
      "Write summary at step 11090  Loss:  0.773625373840332\n",
      "Write summary at step 11100  Loss:  0.5802993178367615\n",
      "Write summary at step 11110  Loss:  0.5893025994300842\n",
      "Write summary at step 11120  Loss:  0.6088943481445312\n",
      "Write summary at step 11130  Loss:  0.5955560207366943\n",
      "Write summary at step 11140  Loss:  0.820297360420227\n",
      "Write summary at step 11150  Loss:  0.682939887046814\n",
      "Write summary at step 11160  Loss:  0.6118917465209961\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5650614754098361\n",
      "Loss normal: 0.640707746986703 Loss Control: 0.6169597441381444 Loss Patient: 0.7312470295776924 Loss balanced:  0.6741033868579184 Loss1+loss2: 0.6741033868579184\n",
      "Write summary at step 11170  Loss:  0.6392862796783447\n",
      "Write summary at step 11180  Loss:  0.731439471244812\n",
      "Write summary at step 11190  Loss:  0.6620912551879883\n",
      "Write summary at step 11200  Loss:  0.602717399597168\n",
      "Write summary at step 11210  Loss:  0.6005355715751648\n",
      "Write summary at step 11220  Loss:  0.7324798107147217\n",
      "Write summary at step 11230  Loss:  0.6443918943405151\n",
      "Write summary at step 11240  Loss:  0.5995993614196777\n",
      "Write summary at step 11250  Loss:  0.6028790473937988\n",
      "Write summary at step 11260  Loss:  0.5665047764778137\n",
      "Write summary at step 11270  Loss:  0.7197127342224121\n",
      "Write summary at step 11280  Loss:  0.5573263168334961\n",
      "Write summary at step 11290  Loss:  0.6340017318725586\n",
      "Write summary at step 11300  Loss:  0.7459033727645874\n",
      "Write summary at step 11310  Loss:  0.6446263194084167\n",
      "Write summary at step 11320  Loss:  0.5533208847045898\n",
      "Write summary at step 11330  Loss:  0.6725709438323975\n",
      "Write summary at step 11340  Loss:  0.7074058055877686\n",
      "Write summary at step 11350  Loss:  0.5767369270324707\n",
      "Write summary at step 11360  Loss:  0.649306058883667\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5790642076502732\n",
      "Loss normal: 0.5980198535568271 Loss Control: 0.5297198422619553 Loss Patient: 0.8584136615196863 Loss balanced:  0.6940667518908208 Loss1+loss2: 0.6940667518908208\n",
      "Write summary at step 11370  Loss:  0.5212742686271667\n",
      "Write summary at step 11380  Loss:  0.6738805174827576\n",
      "Write summary at step 11390  Loss:  0.6546679735183716\n",
      "Write summary at step 11400  Loss:  0.6861165761947632\n",
      "Write summary at step 11410  Loss:  0.6503554582595825\n",
      "Write summary at step 11420  Loss:  0.6072076559066772\n",
      "Write summary at step 11430  Loss:  0.6468298435211182\n",
      "Write summary at step 11440  Loss:  0.780677080154419\n",
      "Write summary at step 11450  Loss:  0.6691097617149353\n",
      "Write summary at step 11460  Loss:  0.6679652333259583\n",
      "Write summary at step 11470  Loss:  0.7809813618659973\n",
      "Write summary at step 11480  Loss:  0.6613574624061584\n",
      "Write summary at step 11490  Loss:  0.6282590627670288\n",
      "Write summary at step 11500  Loss:  0.5696691870689392\n",
      "Saved checkpoint to: result/46/panns/checkpoint_11500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.08333333333333333 Acurracy Balanced 0.5307377049180327\n",
      "Loss normal: 0.5594291867631854 Loss Control: 0.41983883693569995 Loss Patient: 1.0916174141069253 Loss balanced:  0.7557281255213126 Loss1+loss2: 0.7557281255213126\n",
      "Write summary at step 11510  Loss:  0.5690550804138184\n",
      "Write summary at step 11520  Loss:  0.6939695477485657\n",
      "Write summary at step 11530  Loss:  0.6987248659133911\n",
      "Write summary at step 11540  Loss:  0.6844769716262817\n",
      "Write summary at step 11550  Loss:  0.612881064414978\n",
      "Write summary at step 11560  Loss:  0.6825365424156189\n",
      "Write summary at step 11570  Loss:  0.6367686986923218\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7142857142857143 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5584016393442623\n",
      "Loss normal: 0.6434946870390987 Loss Control: 0.6160643628386201 Loss Patient: 0.7480727856357893 Loss balanced:  0.6820685742372047 Loss1+loss2: 0.6820685742372047\n",
      "Write summary at step 11580  Loss:  0.6389444470405579\n",
      "Write summary at step 11590  Loss:  0.7095538973808289\n",
      "Write summary at step 11600  Loss:  0.6152783036231995\n",
      "Write summary at step 11610  Loss:  0.6942569017410278\n",
      "Write summary at step 11620  Loss:  0.6089564561843872\n",
      "Write summary at step 11630  Loss:  0.5984956622123718\n",
      "Write summary at step 11640  Loss:  0.811396598815918\n",
      "Write summary at step 11650  Loss:  0.5358656644821167\n",
      "Write summary at step 11660  Loss:  0.6692781448364258\n",
      "Write summary at step 11670  Loss:  0.7925553321838379\n",
      "Write summary at step 11680  Loss:  0.5342329144477844\n",
      "Write summary at step 11690  Loss:  0.6632798910140991\n",
      "Write summary at step 11700  Loss:  0.8415173888206482\n",
      "Write summary at step 11710  Loss:  0.7359961867332458\n",
      "Write summary at step 11720  Loss:  0.6798360347747803\n",
      "Write summary at step 11730  Loss:  0.7273836135864258\n",
      "Write summary at step 11740  Loss:  0.6312305927276611\n",
      "Write summary at step 11750  Loss:  0.6239116191864014\n",
      "Write summary at step 11760  Loss:  0.6404256820678711\n",
      "Write summary at step 11770  Loss:  0.7087215781211853\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.1875 Acurracy Balanced 0.552766393442623\n",
      "Loss normal: 0.6096948509092455 Loss Control: 0.5406008020776217 Loss Patient: 0.8731159729262193 Loss balanced:  0.7068583875019205 Loss1+loss2: 0.7068583875019205\n",
      "Write summary at step 11780  Loss:  0.6835277080535889\n",
      "Write summary at step 11790  Loss:  0.7718949913978577\n",
      "Write summary at step 11800  Loss:  0.6734231114387512\n",
      "Write summary at step 11810  Loss:  0.6351333856582642\n",
      "Write summary at step 11820  Loss:  0.679166316986084\n",
      "Write summary at step 11830  Loss:  0.6015214323997498\n",
      "Write summary at step 11840  Loss:  0.7362614274024963\n",
      "Write summary at step 11850  Loss:  0.6040034294128418\n",
      "Write summary at step 11860  Loss:  0.6121898293495178\n",
      "Write summary at step 11870  Loss:  0.6551745533943176\n",
      "Write summary at step 11880  Loss:  0.622967004776001\n",
      "Write summary at step 11890  Loss:  0.6322903037071228\n",
      "Write summary at step 11900  Loss:  0.7043070793151855\n",
      "Write summary at step 11910  Loss:  0.6272210478782654\n",
      "Write summary at step 11920  Loss:  0.6184442043304443\n",
      "Write summary at step 11930  Loss:  0.6109417676925659\n",
      "Write summary at step 11940  Loss:  0.6173731088638306\n",
      "Write summary at step 11950  Loss:  0.5831187963485718\n",
      "Write summary at step 11960  Loss:  0.7481498718261719\n",
      "Write summary at step 11970  Loss:  0.7319716215133667\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5899931693989071\n",
      "Loss normal: 0.5958007470869915 Loss Control: 0.534029494869253 Loss Patient: 0.8313036859035492 Loss balanced:  0.6826665903864011 Loss1+loss2: 0.6826665903864011\n",
      "Write summary at step 11980  Loss:  0.6698441505432129\n",
      "Write summary at step 11990  Loss:  0.5644115209579468\n",
      "Write summary at step 12000  Loss:  0.7233414649963379\n",
      "Saved checkpoint to: result/46/panns/checkpoint_12000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5747950819672131\n",
      "Loss normal: 0.6074539786809451 Loss Control: 0.5570252993719174 Loss Patient: 0.7997132881234089 Loss balanced:  0.6783692937476631 Loss1+loss2: 0.6783692937476631\n",
      "Write summary at step 12010  Loss:  0.7115101218223572\n",
      "Write summary at step 12020  Loss:  0.6070898175239563\n",
      "Write summary at step 12030  Loss:  0.6615145802497864\n",
      "Write summary at step 12040  Loss:  0.701593279838562\n",
      "Write summary at step 12050  Loss:  0.6350946426391602\n",
      "Write summary at step 12060  Loss:  0.625520646572113\n",
      "Write summary at step 12070  Loss:  0.5551261305809021\n",
      "Write summary at step 12080  Loss:  0.6233627796173096\n",
      "Write summary at step 12090  Loss:  0.694722056388855\n",
      "Write summary at step 12100  Loss:  0.6391977071762085\n",
      "Write summary at step 12110  Loss:  0.7025694251060486\n",
      "Write summary at step 12120  Loss:  0.6092091202735901\n",
      "Write summary at step 12130  Loss:  0.8033449053764343\n",
      "Write summary at step 12140  Loss:  0.8618990182876587\n",
      "Write summary at step 12150  Loss:  0.6228376626968384\n",
      "Write summary at step 12160  Loss:  0.6605352163314819\n",
      "Write summary at step 12170  Loss:  0.6194717884063721\n",
      "Write summary at step 12180  Loss:  0.6326650381088257\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6883116883116883 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5573770491803278\n",
      "Loss normal: 0.6392105864239978 Loss Control: 0.6102896036346102 Loss Patient: 0.7494718624899784 Loss balanced:  0.6798807330622942 Loss1+loss2: 0.6798807330622942\n",
      "Write summary at step 12190  Loss:  0.6776736974716187\n",
      "Write summary at step 12200  Loss:  0.44550585746765137\n",
      "Write summary at step 12210  Loss:  0.7379448413848877\n",
      "Write summary at step 12220  Loss:  0.6991366744041443\n",
      "Write summary at step 12230  Loss:  0.7394249439239502\n",
      "Write summary at step 12240  Loss:  0.7089823484420776\n",
      "Write summary at step 12250  Loss:  0.5879421234130859\n",
      "Write summary at step 12260  Loss:  0.5981647968292236\n",
      "Write summary at step 12270  Loss:  0.705125093460083\n",
      "Write summary at step 12280  Loss:  0.6589102745056152\n",
      "Write summary at step 12290  Loss:  0.7249277830123901\n",
      "Write summary at step 12300  Loss:  0.6406289339065552\n",
      "Write summary at step 12310  Loss:  0.6753905415534973\n",
      "Write summary at step 12320  Loss:  0.6785562038421631\n",
      "Write summary at step 12330  Loss:  0.7318066358566284\n",
      "Write summary at step 12340  Loss:  0.6179877519607544\n",
      "Write summary at step 12350  Loss:  0.5932555794715881\n",
      "Write summary at step 12360  Loss:  0.6038881540298462\n",
      "Write summary at step 12370  Loss:  0.8692148327827454\n",
      "Write summary at step 12380  Loss:  0.5498076677322388\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5604508196721312\n",
      "Loss normal: 0.6068006253345705 Loss Control: 0.5404630189384919 Loss Patient: 0.8597128167748451 Loss balanced:  0.7000879178566686 Loss1+loss2: 0.7000879178566686\n",
      "Write summary at step 12390  Loss:  0.771470308303833\n",
      "Write summary at step 12400  Loss:  0.6072466373443604\n",
      "Write summary at step 12410  Loss:  0.849626362323761\n",
      "Write summary at step 12420  Loss:  0.7371318340301514\n",
      "Write summary at step 12430  Loss:  0.6942417621612549\n",
      "Write summary at step 12440  Loss:  0.5388742685317993\n",
      "Write summary at step 12450  Loss:  0.6202793121337891\n",
      "Write summary at step 12460  Loss:  0.68964684009552\n",
      "Write summary at step 12470  Loss:  0.7299541234970093\n",
      "Write summary at step 12480  Loss:  0.6695698499679565\n",
      "Write summary at step 12490  Loss:  0.6556417942047119\n",
      "Write summary at step 12500  Loss:  0.6097450256347656\n",
      "Saved checkpoint to: result/46/panns/checkpoint_12500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.14583333333333334 Acurracy Balanced 0.5565232240437158\n",
      "Loss normal: 0.5607662440894486 Loss Control: 0.4570661493337871 Loss Patient: 0.9561228938400745 Loss balanced:  0.7065945215869308 Loss1+loss2: 0.7065945215869308\n",
      "Write summary at step 12510  Loss:  0.7380771636962891\n",
      "Write summary at step 12520  Loss:  0.6087024211883545\n",
      "Write summary at step 12530  Loss:  0.7451225519180298\n",
      "Write summary at step 12540  Loss:  0.7244970798492432\n",
      "Write summary at step 12550  Loss:  0.662995457649231\n",
      "Write summary at step 12560  Loss:  0.7563166618347168\n",
      "Write summary at step 12570  Loss:  0.7124931812286377\n",
      "Write summary at step 12580  Loss:  0.7063354849815369\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6277056277056277 Acurracy Control:  0.6721311475409836 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.5652322404371585\n",
      "Loss normal: 0.6772911236399696 Loss Control: 0.6777981679296233 Loss Patient: 0.6753579645107189 Loss balanced:  0.6765780662201711 Loss1+loss2: 0.6765780662201711\n",
      "Write summary at step 12590  Loss:  0.9539749026298523\n",
      "Write summary at step 12600  Loss:  0.9322158098220825\n",
      "Write summary at step 12610  Loss:  0.6954426765441895\n",
      "Write summary at step 12620  Loss:  0.7718578577041626\n",
      "Write summary at step 12630  Loss:  0.7308980226516724\n",
      "Write summary at step 12640  Loss:  0.5806789398193359\n",
      "Write summary at step 12650  Loss:  0.5843384265899658\n",
      "Write summary at step 12660  Loss:  0.6062325835227966\n",
      "Write summary at step 12670  Loss:  0.5871182680130005\n",
      "Write summary at step 12680  Loss:  0.7458993196487427\n",
      "Write summary at step 12690  Loss:  0.6889953017234802\n",
      "Write summary at step 12700  Loss:  0.5237461924552917\n",
      "Write summary at step 12710  Loss:  0.7582299709320068\n",
      "Write summary at step 12720  Loss:  0.7241905927658081\n",
      "Write summary at step 12730  Loss:  0.7024446725845337\n",
      "Write summary at step 12740  Loss:  0.766082227230072\n",
      "Write summary at step 12750  Loss:  0.6737823486328125\n",
      "Write summary at step 12760  Loss:  0.7094643115997314\n",
      "Write summary at step 12770  Loss:  0.7201563119888306\n",
      "Write summary at step 12780  Loss:  0.6741914749145508\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7272727272727273 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5589139344262295\n",
      "Loss normal: 0.6319460234084686 Loss Control: 0.5868184273360205 Loss Patient: 0.8039950020611286 Loss balanced:  0.6954067146985745 Loss1+loss2: 0.6954067146985745\n",
      "Write summary at step 12790  Loss:  0.6834157705307007\n",
      "Write summary at step 12800  Loss:  0.7293370366096497\n",
      "Write summary at step 12810  Loss:  0.7025609612464905\n",
      "Write summary at step 12820  Loss:  0.6564889550209045\n",
      "Write summary at step 12830  Loss:  0.7403051853179932\n",
      "Write summary at step 12840  Loss:  0.817068338394165\n",
      "Write summary at step 12850  Loss:  0.6094908714294434\n",
      "Write summary at step 12860  Loss:  0.6171650290489197\n",
      "Write summary at step 12870  Loss:  0.6205915212631226\n",
      "Write summary at step 12880  Loss:  0.7078951597213745\n",
      "Write summary at step 12890  Loss:  0.7713298797607422\n",
      "Write summary at step 12900  Loss:  0.7006087303161621\n",
      "Write summary at step 12910  Loss:  0.5635175108909607\n",
      "Write summary at step 12920  Loss:  0.6190251111984253\n",
      "Write summary at step 12930  Loss:  0.5451172590255737\n",
      "Write summary at step 12940  Loss:  0.582664966583252\n",
      "Write summary at step 12950  Loss:  0.8152579069137573\n",
      "Write summary at step 12960  Loss:  0.5810112953186035\n",
      "Write summary at step 12970  Loss:  0.6432802677154541\n",
      "Write summary at step 12980  Loss:  0.5420185327529907\n",
      "Write summary at step 12990  Loss:  0.7024646401405334\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5795765027322404\n",
      "Loss normal: 0.5791677063677734 Loss Control: 0.48298235376024506 Loss Patient: 0.9458743513872226 Loss balanced:  0.7144283525737338 Loss1+loss2: 0.7144283525737338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 13000  Loss:  0.680109977722168\n",
      "Saved checkpoint to: result/46/panns/checkpoint_13000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.6021174863387978\n",
      "Loss normal: 0.6003636382358931 Loss Control: 0.540149030463943 Loss Patient: 0.8299318415423235 Loss balanced:  0.6850404360031332 Loss1+loss2: 0.6850404360031332\n",
      "Write summary at step 13010  Loss:  0.6182163953781128\n",
      "Write summary at step 13020  Loss:  0.5798301696777344\n",
      "Write summary at step 13030  Loss:  0.5679211616516113\n",
      "Write summary at step 13040  Loss:  0.5873380899429321\n",
      "Write summary at step 13050  Loss:  0.6946313381195068\n",
      "Write summary at step 13060  Loss:  0.5209035873413086\n",
      "Write summary at step 13070  Loss:  0.7781636118888855\n",
      "Write summary at step 13080  Loss:  0.6660058498382568\n",
      "Write summary at step 13090  Loss:  0.6439926624298096\n",
      "Write summary at step 13100  Loss:  0.7407720685005188\n",
      "Write summary at step 13110  Loss:  0.7056159973144531\n",
      "Write summary at step 13120  Loss:  0.615882158279419\n",
      "Write summary at step 13130  Loss:  0.7660131454467773\n",
      "Write summary at step 13140  Loss:  0.7187818288803101\n",
      "Write summary at step 13150  Loss:  0.6041030287742615\n",
      "Write summary at step 13160  Loss:  0.551774263381958\n",
      "Write summary at step 13170  Loss:  0.7828724384307861\n",
      "Write summary at step 13180  Loss:  0.676688015460968\n",
      "Write summary at step 13190  Loss:  0.6703026294708252\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7445887445887446 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5467896174863388\n",
      "Loss normal: 0.6061074927255705 Loss Control: 0.5224240239852113 Loss Patient: 0.9251507340619961 Loss balanced:  0.7237873790236037 Loss1+loss2: 0.7237873790236037\n",
      "Write summary at step 13200  Loss:  0.6109926700592041\n",
      "Write summary at step 13210  Loss:  0.645724892616272\n",
      "Write summary at step 13220  Loss:  0.7032713890075684\n",
      "Write summary at step 13230  Loss:  0.6869695782661438\n",
      "Write summary at step 13240  Loss:  0.6780554056167603\n",
      "Write summary at step 13250  Loss:  0.5396856069564819\n",
      "Write summary at step 13260  Loss:  0.7147212624549866\n",
      "Write summary at step 13270  Loss:  0.6655571460723877\n",
      "Write summary at step 13280  Loss:  0.5841938257217407\n",
      "Write summary at step 13290  Loss:  0.648661196231842\n",
      "Write summary at step 13300  Loss:  0.8280739784240723\n",
      "Write summary at step 13310  Loss:  0.6448748707771301\n",
      "Write summary at step 13320  Loss:  0.6242078542709351\n",
      "Write summary at step 13330  Loss:  0.6212334036827087\n",
      "Write summary at step 13340  Loss:  0.7280879616737366\n",
      "Write summary at step 13350  Loss:  0.6937484741210938\n",
      "Write summary at step 13360  Loss:  0.6823767423629761\n",
      "Write summary at step 13370  Loss:  0.6461510062217712\n",
      "Write summary at step 13380  Loss:  0.5572049617767334\n",
      "Write summary at step 13390  Loss:  0.5670928955078125\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7965367965367965 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.125 Acurracy Balanced 0.5488387978142076\n",
      "Loss normal: 0.570631938708293 Loss Control: 0.45764494349396295 Loss Patient: 1.0013948418200016 Loss balanced:  0.7295198926569822 Loss1+loss2: 0.7295198926569822\n",
      "Write summary at step 13400  Loss:  0.6740502715110779\n",
      "Write summary at step 13410  Loss:  0.662298321723938\n",
      "Write summary at step 13420  Loss:  0.6287551522254944\n",
      "Write summary at step 13430  Loss:  0.6858679056167603\n",
      "Write summary at step 13440  Loss:  0.5930384993553162\n",
      "Write summary at step 13450  Loss:  0.6470336318016052\n",
      "Write summary at step 13460  Loss:  0.5848942399024963\n",
      "Write summary at step 13470  Loss:  0.7155240178108215\n",
      "Write summary at step 13480  Loss:  0.6168033480644226\n",
      "Write summary at step 13490  Loss:  0.6372764110565186\n",
      "Write summary at step 13500  Loss:  0.6115553975105286\n",
      "Saved checkpoint to: result/46/panns/checkpoint_13500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.585724043715847\n",
      "Loss normal: 0.6152377471779332 Loss Control: 0.5773578462053518 Loss Patient: 0.7596548659106096 Loss balanced:  0.6685063560579807 Loss1+loss2: 0.6685063560579807\n",
      "Write summary at step 13510  Loss:  0.7023710608482361\n",
      "Write summary at step 13520  Loss:  0.6828548908233643\n",
      "Write summary at step 13530  Loss:  0.648589015007019\n",
      "Write summary at step 13540  Loss:  0.5767601728439331\n",
      "Write summary at step 13550  Loss:  0.9456966519355774\n",
      "Write summary at step 13560  Loss:  0.7522504925727844\n",
      "Write summary at step 13570  Loss:  0.5648181438446045\n",
      "Write summary at step 13580  Loss:  0.5563742518424988\n",
      "Write summary at step 13590  Loss:  0.6222571134567261\n",
      "Write summary at step 13600  Loss:  0.7349586486816406\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7792207792207793 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.1875 Acurracy Balanced 0.5609631147540983\n",
      "Loss normal: 0.5589151468885926 Loss Control: 0.44526499395813446 Loss Patient: 0.992206352452437 Loss balanced:  0.7187356732052858 Loss1+loss2: 0.7187356732052858\n",
      "Write summary at step 13610  Loss:  0.6772450804710388\n",
      "Write summary at step 13620  Loss:  0.7807208299636841\n",
      "Write summary at step 13630  Loss:  0.6766808032989502\n",
      "Write summary at step 13640  Loss:  0.6877628564834595\n",
      "Write summary at step 13650  Loss:  0.6673485636711121\n",
      "Write summary at step 13660  Loss:  0.5591487884521484\n",
      "Write summary at step 13670  Loss:  0.6435314416885376\n",
      "Write summary at step 13680  Loss:  0.6860352754592896\n",
      "Write summary at step 13690  Loss:  0.6356802582740784\n",
      "Write summary at step 13700  Loss:  0.6481276750564575\n",
      "Write summary at step 13710  Loss:  0.8751159310340881\n",
      "Write summary at step 13720  Loss:  0.6120572090148926\n",
      "Write summary at step 13730  Loss:  0.5253905057907104\n",
      "Write summary at step 13740  Loss:  0.7310503125190735\n",
      "Write summary at step 13750  Loss:  0.6532999277114868\n",
      "Write summary at step 13760  Loss:  0.589502215385437\n",
      "Write summary at step 13770  Loss:  0.632550835609436\n",
      "Write summary at step 13780  Loss:  0.8215759992599487\n",
      "Write summary at step 13790  Loss:  0.6588789820671082\n",
      "Write summary at step 13800  Loss:  0.6573803424835205\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6320346320346321 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5218579234972678\n",
      "Loss normal: 0.6459680914362788 Loss Control: 0.6206250594613331 Loss Patient: 0.7425884138792753 Loss balanced:  0.6816067366703042 Loss1+loss2: 0.6816067366703042\n",
      "Write summary at step 13810  Loss:  0.5789593458175659\n",
      "Write summary at step 13820  Loss:  0.5060714483261108\n",
      "Write summary at step 13830  Loss:  0.6799328923225403\n",
      "Write summary at step 13840  Loss:  0.5692473649978638\n",
      "Write summary at step 13850  Loss:  0.5537676811218262\n",
      "Write summary at step 13860  Loss:  0.7069741487503052\n",
      "Write summary at step 13870  Loss:  0.5947270393371582\n",
      "Write summary at step 13880  Loss:  0.6022520661354065\n",
      "Write summary at step 13890  Loss:  0.6952448487281799\n",
      "Write summary at step 13900  Loss:  0.6627769470214844\n",
      "Write summary at step 13910  Loss:  0.6459239721298218\n",
      "Write summary at step 13920  Loss:  0.7120335102081299\n",
      "Write summary at step 13930  Loss:  0.6741042137145996\n",
      "Write summary at step 13940  Loss:  0.707300066947937\n",
      "Write summary at step 13950  Loss:  0.6278133392333984\n",
      "Write summary at step 13960  Loss:  0.664358377456665\n",
      "Write summary at step 13970  Loss:  0.7399505376815796\n",
      "Write summary at step 13980  Loss:  0.5243006944656372\n",
      "Write summary at step 13990  Loss:  0.6066062450408936\n",
      "Write summary at step 14000  Loss:  0.5683002471923828\n",
      "Saved checkpoint to: result/46/panns/checkpoint_14000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7229437229437229 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5638661202185793\n",
      "Loss normal: 0.6157106643631345 Loss Control: 0.5676397642151254 Loss Patient: 0.7989809898038706 Loss balanced:  0.6833103770094979 Loss1+loss2: 0.6833103770094979\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.576844262295082\n",
      "Loss normal: 0.5714733123263239 Loss Control: 0.4730730288015689 Loss Patient: 0.9466243833303452 Loss balanced:  0.7098487060659571 Loss1+loss2: 0.7098487060659571\n",
      "Write summary at step 14010  Loss:  0.6741651296615601\n",
      "Write summary at step 14020  Loss:  0.6350682973861694\n",
      "Write summary at step 14030  Loss:  0.5617862343788147\n",
      "Write summary at step 14040  Loss:  0.612949788570404\n",
      "Write summary at step 14050  Loss:  0.5660032629966736\n",
      "Write summary at step 14060  Loss:  0.6128218770027161\n",
      "Write summary at step 14070  Loss:  0.7048850059509277\n",
      "Write summary at step 14080  Loss:  0.6571764349937439\n",
      "Write summary at step 14090  Loss:  0.5306047201156616\n",
      "Write summary at step 14100  Loss:  0.4983810782432556\n",
      "Write summary at step 14110  Loss:  0.5659981966018677\n",
      "Write summary at step 14120  Loss:  0.6221041679382324\n",
      "Write summary at step 14130  Loss:  0.6414370536804199\n",
      "Write summary at step 14140  Loss:  0.7691282033920288\n",
      "Write summary at step 14150  Loss:  0.6312561631202698\n",
      "Write summary at step 14160  Loss:  0.6917360424995422\n",
      "Write summary at step 14170  Loss:  0.7406459450721741\n",
      "Write summary at step 14180  Loss:  0.7808085680007935\n",
      "Write summary at step 14190  Loss:  0.6702553629875183\n",
      "Write summary at step 14200  Loss:  0.5421326756477356\n",
      "Write summary at step 14210  Loss:  0.694170355796814\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6926406926406926 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.5831625683060109\n",
      "Loss normal: 0.6321600647199721 Loss Control: 0.6156596430663854 Loss Patient: 0.695067884400487 Loss balanced:  0.6553637637334362 Loss1+loss2: 0.6553637637334362\n",
      "\n",
      " > BEST MODEL (0.65536) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 14220  Loss:  0.7107315063476562\n",
      "Write summary at step 14230  Loss:  0.6303322911262512\n",
      "Write summary at step 14240  Loss:  0.6917021870613098\n",
      "Write summary at step 14250  Loss:  0.6040533185005188\n",
      "Write summary at step 14260  Loss:  0.6341226100921631\n",
      "Write summary at step 14270  Loss:  0.6275590658187866\n",
      "Write summary at step 14280  Loss:  0.5750041007995605\n",
      "Write summary at step 14290  Loss:  0.7511394023895264\n",
      "Write summary at step 14300  Loss:  0.5826706886291504\n",
      "Write summary at step 14310  Loss:  0.641979455947876\n",
      "Write summary at step 14320  Loss:  0.6918061971664429\n",
      "Write summary at step 14330  Loss:  0.719032883644104\n",
      "Write summary at step 14340  Loss:  0.6659277677536011\n",
      "Write summary at step 14350  Loss:  0.64857417345047\n",
      "Write summary at step 14360  Loss:  0.5032641291618347\n",
      "Write summary at step 14370  Loss:  0.6647965908050537\n",
      "Write summary at step 14380  Loss:  0.5353442430496216\n",
      "Write summary at step 14390  Loss:  0.6492772102355957\n",
      "Write summary at step 14400  Loss:  0.7535538673400879\n",
      "Write summary at step 14410  Loss:  0.8594714403152466\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5324675324675324 Acurracy Control:  0.5519125683060109 Acurracy Patient:  0.4583333333333333 Acurracy Balanced 0.5051229508196721\n",
      "Loss normal: 0.66855027562096 Loss Control: 0.6581983279660751 Loss Patient: 0.7080170599122843 Loss balanced:  0.6831076939391797 Loss1+loss2: 0.6831076939391797\n",
      "Write summary at step 14420  Loss:  0.7417404651641846\n",
      "Write summary at step 14430  Loss:  0.5861004590988159\n",
      "Write summary at step 14440  Loss:  0.5260802507400513\n",
      "Write summary at step 14450  Loss:  0.5653328895568848\n",
      "Write summary at step 14460  Loss:  0.654927670955658\n",
      "Write summary at step 14470  Loss:  0.6690716743469238\n",
      "Write summary at step 14480  Loss:  0.6222949028015137\n",
      "Write summary at step 14490  Loss:  0.6496309638023376\n",
      "Write summary at step 14500  Loss:  0.624462366104126\n",
      "Saved checkpoint to: result/46/panns/checkpoint_14500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5790642076502732\n",
      "Loss normal: 0.5857769506318229 Loss Control: 0.5272276782598652 Loss Patient: 0.8089960304399332 Loss balanced:  0.6681118543498992 Loss1+loss2: 0.6681118543498992\n",
      "Write summary at step 14510  Loss:  0.6532903909683228\n",
      "Write summary at step 14520  Loss:  0.6531765460968018\n",
      "Write summary at step 14530  Loss:  0.708746075630188\n",
      "Write summary at step 14540  Loss:  0.640262246131897\n",
      "Write summary at step 14550  Loss:  0.738305926322937\n",
      "Write summary at step 14560  Loss:  0.711898684501648\n",
      "Write summary at step 14570  Loss:  0.6976991891860962\n",
      "Write summary at step 14580  Loss:  0.683198869228363\n",
      "Write summary at step 14590  Loss:  0.6072474718093872\n",
      "Write summary at step 14600  Loss:  0.6258195638656616\n",
      "Write summary at step 14610  Loss:  0.6480610370635986\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.70995670995671 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5556693989071039\n",
      "Loss normal: 0.6163592772050337 Loss Control: 0.5740643342336019 Loss Patient: 0.7776087410748005 Loss balanced:  0.6758365376542013 Loss1+loss2: 0.6758365376542013\n",
      "Write summary at step 14620  Loss:  0.6095143556594849\n",
      "Write summary at step 14630  Loss:  0.6227044463157654\n",
      "Write summary at step 14640  Loss:  0.6142020225524902\n",
      "Write summary at step 14650  Loss:  0.5387685298919678\n",
      "Write summary at step 14660  Loss:  0.6646210551261902\n",
      "Write summary at step 14670  Loss:  0.5634539127349854\n",
      "Write summary at step 14680  Loss:  0.5014799237251282\n",
      "Write summary at step 14690  Loss:  0.6748731136322021\n",
      "Write summary at step 14700  Loss:  0.7521030902862549\n",
      "Write summary at step 14710  Loss:  0.6903395652770996\n",
      "Write summary at step 14720  Loss:  0.7205967903137207\n",
      "Write summary at step 14730  Loss:  0.6044954061508179\n",
      "Write summary at step 14740  Loss:  0.7163394689559937\n",
      "Write summary at step 14750  Loss:  0.6302236914634705\n",
      "Write summary at step 14760  Loss:  0.5898364186286926\n",
      "Write summary at step 14770  Loss:  0.6468801498413086\n",
      "Write summary at step 14780  Loss:  0.5674247741699219\n",
      "Write summary at step 14790  Loss:  0.7733995914459229\n",
      "Write summary at step 14800  Loss:  0.6723436117172241\n",
      "Write summary at step 14810  Loss:  0.725255012512207\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.3125 Acurracy Balanced 0.5934084699453552\n",
      "Loss normal: 0.5829321938159662 Loss Control: 0.5206887373507348 Loss Patient: 0.8202353976666927 Loss balanced:  0.6704620675087138 Loss1+loss2: 0.6704620675087138\n",
      "Write summary at step 14820  Loss:  0.6345959901809692\n",
      "Write summary at step 14830  Loss:  0.521719217300415\n",
      "Write summary at step 14840  Loss:  0.8403029441833496\n",
      "Write summary at step 14850  Loss:  0.5355889201164246\n",
      "Write summary at step 14860  Loss:  0.624286413192749\n",
      "Write summary at step 14870  Loss:  0.5330772399902344\n",
      "Write summary at step 14880  Loss:  0.5953797698020935\n",
      "Write summary at step 14890  Loss:  0.6632832288742065\n",
      "Write summary at step 14900  Loss:  0.6569872498512268\n",
      "Write summary at step 14910  Loss:  0.7541928887367249\n",
      "Write summary at step 14920  Loss:  0.6847180128097534\n",
      "Write summary at step 14930  Loss:  0.5833660364151001\n",
      "Write summary at step 14940  Loss:  0.7445775270462036\n",
      "Write summary at step 14950  Loss:  0.5331305265426636\n",
      "Write summary at step 14960  Loss:  0.6469006538391113\n",
      "Write summary at step 14970  Loss:  0.5946125984191895\n",
      "Write summary at step 14980  Loss:  0.6543565988540649\n",
      "Write summary at step 14990  Loss:  0.822507381439209\n",
      "Write summary at step 15000  Loss:  0.7038394808769226\n",
      "Saved checkpoint to: result/46/panns/checkpoint_15000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7142857142857143 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5584016393442623\n",
      "Loss normal: 0.6001635242850234 Loss Control: 0.5535925040479566 Loss Patient: 0.7777154818177223 Loss balanced:  0.6656539929328394 Loss1+loss2: 0.6656539929328394\n",
      "Write summary at step 15010  Loss:  0.5900084972381592\n",
      "Write summary at step 15020  Loss:  0.6996338367462158\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5790642076502732\n",
      "Loss normal: 0.5780406122083788 Loss Control: 0.4984645635052457 Loss Patient: 0.8814243140319983 Loss balanced:  0.689944438768622 Loss1+loss2: 0.689944438768622\n",
      "Write summary at step 15030  Loss:  0.5623742938041687\n",
      "Write summary at step 15040  Loss:  0.5917966365814209\n",
      "Write summary at step 15050  Loss:  0.6111668348312378\n",
      "Write summary at step 15060  Loss:  0.6508803367614746\n",
      "Write summary at step 15070  Loss:  0.6258805990219116\n",
      "Write summary at step 15080  Loss:  0.7173625826835632\n",
      "Write summary at step 15090  Loss:  0.7559671998023987\n",
      "Write summary at step 15100  Loss:  0.49928832054138184\n",
      "Write summary at step 15110  Loss:  0.6305904388427734\n",
      "Write summary at step 15120  Loss:  0.5934334397315979\n",
      "Write summary at step 15130  Loss:  0.5026232004165649\n",
      "Write summary at step 15140  Loss:  0.4735272526741028\n",
      "Write summary at step 15150  Loss:  0.5190597176551819\n",
      "Write summary at step 15160  Loss:  0.6129157543182373\n",
      "Write summary at step 15170  Loss:  0.645557165145874\n",
      "Write summary at step 15180  Loss:  0.5165709257125854\n",
      "Write summary at step 15190  Loss:  0.5779532194137573\n",
      "Write summary at step 15200  Loss:  0.8247998356819153\n",
      "Write summary at step 15210  Loss:  0.6847632527351379\n",
      "Write summary at step 15220  Loss:  0.5895776748657227\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.125 Acurracy Balanced 0.5433743169398907\n",
      "Loss normal: 0.5307108531524609 Loss Control: 0.40693831850922174 Loss Patient: 1.0025936476886272 Loss balanced:  0.7047659830989245 Loss1+loss2: 0.7047659830989245\n",
      "Write summary at step 15230  Loss:  0.6609719395637512\n",
      "Write summary at step 15240  Loss:  0.7782351970672607\n",
      "Write summary at step 15250  Loss:  0.7441069483757019\n",
      "Write summary at step 15260  Loss:  0.8467966318130493\n",
      "Write summary at step 15270  Loss:  0.6642175316810608\n",
      "Write summary at step 15280  Loss:  0.48499149084091187\n",
      "Write summary at step 15290  Loss:  0.771222710609436\n",
      "Write summary at step 15300  Loss:  0.7138879299163818\n",
      "Write summary at step 15310  Loss:  0.5783340930938721\n",
      "Write summary at step 15320  Loss:  0.5611768960952759\n",
      "Write summary at step 15330  Loss:  0.7047149538993835\n",
      "Write summary at step 15340  Loss:  0.6752986907958984\n",
      "Write summary at step 15350  Loss:  0.6889556646347046\n",
      "Write summary at step 15360  Loss:  0.6244240999221802\n",
      "Write summary at step 15370  Loss:  0.6171937584877014\n",
      "Write summary at step 15380  Loss:  0.6809650659561157\n",
      "Write summary at step 15390  Loss:  0.4183761477470398\n",
      "Write summary at step 15400  Loss:  0.7150330543518066\n",
      "Write summary at step 15410  Loss:  0.5358153581619263\n",
      "Write summary at step 15420  Loss:  0.7493808269500732\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.125 Acurracy Balanced 0.557035519125683\n",
      "Loss normal: 0.490446218422481 Loss Control: 0.32986907131684934 Loss Patient: 1.102646578103304 Loss balanced:  0.7162578247100766 Loss1+loss2: 0.7162578247100766\n",
      "Write summary at step 15430  Loss:  0.8034819960594177\n",
      "Write summary at step 15440  Loss:  0.6402314901351929\n",
      "Write summary at step 15450  Loss:  0.5385858416557312\n",
      "Write summary at step 15460  Loss:  0.6612496972084045\n",
      "Write summary at step 15470  Loss:  0.6761900186538696\n",
      "Write summary at step 15480  Loss:  0.6527003049850464\n",
      "Write summary at step 15490  Loss:  0.5637201070785522\n",
      "Write summary at step 15500  Loss:  0.5352007746696472\n",
      "Saved checkpoint to: result/46/panns/checkpoint_15500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.25 Acurracy Balanced 0.58948087431694\n",
      "Loss normal: 0.5517537765430681 Loss Control: 0.4633965578561272 Loss Patient: 0.8886156926552454 Loss balanced:  0.6760061252556864 Loss1+loss2: 0.6760061252556864\n",
      "Write summary at step 15510  Loss:  0.7536047101020813\n",
      "Write summary at step 15520  Loss:  0.7691031098365784\n",
      "Write summary at step 15530  Loss:  0.669157087802887\n",
      "Write summary at step 15540  Loss:  0.6002936363220215\n",
      "Write summary at step 15550  Loss:  0.7934372425079346\n",
      "Write summary at step 15560  Loss:  0.6276875734329224\n",
      "Write summary at step 15570  Loss:  0.6430916786193848\n",
      "Write summary at step 15580  Loss:  0.572421669960022\n",
      "Write summary at step 15590  Loss:  0.6626631617546082\n",
      "Write summary at step 15600  Loss:  0.6042212843894958\n",
      "Write summary at step 15610  Loss:  0.7575469613075256\n",
      "Write summary at step 15620  Loss:  0.6505175232887268\n",
      "Write summary at step 15630  Loss:  0.5883887410163879\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5741120218579235\n",
      "Loss normal: 0.5559717427084456 Loss Control: 0.47908539524495275 Loss Patient: 0.8491009399294853 Loss balanced:  0.664093167587219 Loss1+loss2: 0.664093167587219\n",
      "Write summary at step 15640  Loss:  0.6221905946731567\n",
      "Write summary at step 15650  Loss:  0.8221532106399536\n",
      "Write summary at step 15660  Loss:  0.6269429922103882\n",
      "Write summary at step 15670  Loss:  0.6971502304077148\n",
      "Write summary at step 15680  Loss:  0.5614839792251587\n",
      "Write summary at step 15690  Loss:  0.555309534072876\n",
      "Write summary at step 15700  Loss:  0.6760190725326538\n",
      "Write summary at step 15710  Loss:  0.7534410357475281\n",
      "Write summary at step 15720  Loss:  0.5688908696174622\n",
      "Write summary at step 15730  Loss:  0.6325626969337463\n",
      "Write summary at step 15740  Loss:  0.6271438598632812\n",
      "Write summary at step 15750  Loss:  0.7908190488815308\n",
      "Write summary at step 15760  Loss:  0.580707311630249\n",
      "Write summary at step 15770  Loss:  0.6387959718704224\n",
      "Write summary at step 15780  Loss:  0.5814658403396606\n",
      "Write summary at step 15790  Loss:  0.5583279728889465\n",
      "Write summary at step 15800  Loss:  0.6367810964584351\n",
      "Write summary at step 15810  Loss:  0.5017191767692566\n",
      "Write summary at step 15820  Loss:  0.585371732711792\n",
      "Write summary at step 15830  Loss:  0.5473203063011169\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7402597402597403 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5517418032786885\n",
      "Loss normal: 0.5613431898288397 Loss Control: 0.45051740932334317 Loss Patient: 0.983866486698389 Loss balanced:  0.7171919480108662 Loss1+loss2: 0.7171919480108662\n",
      "Write summary at step 15840  Loss:  0.546377420425415\n",
      "Write summary at step 15850  Loss:  0.6895561218261719\n",
      "Write summary at step 15860  Loss:  0.6719255447387695\n",
      "Write summary at step 15870  Loss:  0.6856513619422913\n",
      "Write summary at step 15880  Loss:  0.7116900682449341\n",
      "Write summary at step 15890  Loss:  0.6319712996482849\n",
      "Write summary at step 15900  Loss:  0.6527049541473389\n",
      "Write summary at step 15910  Loss:  0.644565999507904\n",
      "Write summary at step 15920  Loss:  0.5888597369194031\n",
      "Write summary at step 15930  Loss:  0.6916095018386841\n",
      "Write summary at step 15940  Loss:  0.7382934093475342\n",
      "Write summary at step 15950  Loss:  0.6596246957778931\n",
      "Write summary at step 15960  Loss:  0.6247835159301758\n",
      "Write summary at step 15970  Loss:  0.6324564814567566\n",
      "Write summary at step 15980  Loss:  0.879989504814148\n",
      "Write summary at step 15990  Loss:  0.5988037586212158\n",
      "Write summary at step 16000  Loss:  0.6056643724441528\n",
      "Saved checkpoint to: result/46/panns/checkpoint_16000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7619047619047619 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5884562841530054\n",
      "Loss normal: 0.5495839463425921 Loss Control: 0.4453840338792957 Loss Patient: 0.9468460865318775 Loss balanced:  0.6961150602055866 Loss1+loss2: 0.6961150602055866\n",
      "Write summary at step 16010  Loss:  0.7291778326034546\n",
      "Write summary at step 16020  Loss:  0.8773703575134277\n",
      "Write summary at step 16030  Loss:  0.5558179616928101\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5817964480874317\n",
      "Loss normal: 0.542887128147728 Loss Control: 0.4219067485931793 Loss Patient: 1.0041248289247353 Loss balanced:  0.7130157887589573 Loss1+loss2: 0.7130157887589573\n",
      "Write summary at step 16040  Loss:  0.6580767035484314\n",
      "Write summary at step 16050  Loss:  0.7282081842422485\n",
      "Write summary at step 16060  Loss:  0.5968896150588989\n",
      "Write summary at step 16070  Loss:  0.5770879983901978\n",
      "Write summary at step 16080  Loss:  0.5846777558326721\n",
      "Write summary at step 16090  Loss:  0.7196227312088013\n",
      "Write summary at step 16100  Loss:  0.5417258143424988\n",
      "Write summary at step 16110  Loss:  0.5905300378799438\n",
      "Write summary at step 16120  Loss:  0.6130654215812683\n",
      "Write summary at step 16130  Loss:  0.462302029132843\n",
      "Write summary at step 16140  Loss:  0.7794541120529175\n",
      "Write summary at step 16150  Loss:  0.6475145220756531\n",
      "Write summary at step 16160  Loss:  0.6440157890319824\n",
      "Write summary at step 16170  Loss:  0.7618170976638794\n",
      "Write summary at step 16180  Loss:  0.6488543748855591\n",
      "Write summary at step 16190  Loss:  0.5986274480819702\n",
      "Write summary at step 16200  Loss:  0.6522476673126221\n",
      "Write summary at step 16210  Loss:  0.697880744934082\n",
      "Write summary at step 16220  Loss:  0.6520884037017822\n",
      "Write summary at step 16230  Loss:  0.6628357768058777\n",
      "Write summary at step 16240  Loss:  0.6250923275947571\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.58025956284153\n",
      "Loss normal: 0.5685287326961369 Loss Control: 0.48517714302396514 Loss Patient: 0.8863066943983237 Loss balanced:  0.6857419187111444 Loss1+loss2: 0.6857419187111444\n",
      "Write summary at step 16250  Loss:  0.6971176862716675\n",
      "Write summary at step 16260  Loss:  0.6795053482055664\n",
      "Write summary at step 16270  Loss:  0.6223440170288086\n",
      "Write summary at step 16280  Loss:  0.517024040222168\n",
      "Write summary at step 16290  Loss:  0.5697752833366394\n",
      "Write summary at step 16300  Loss:  0.7121000289916992\n",
      "Write summary at step 16310  Loss:  0.5561557412147522\n",
      "Write summary at step 16320  Loss:  0.8281227350234985\n",
      "Write summary at step 16330  Loss:  0.536769449710846\n",
      "Write summary at step 16340  Loss:  0.5650911331176758\n",
      "Write summary at step 16350  Loss:  0.7765834331512451\n",
      "Write summary at step 16360  Loss:  0.6096388101577759\n",
      "Write summary at step 16370  Loss:  0.6695672869682312\n",
      "Write summary at step 16380  Loss:  0.55097496509552\n",
      "Write summary at step 16390  Loss:  0.6785211563110352\n",
      "Write summary at step 16400  Loss:  0.5844285488128662\n",
      "Write summary at step 16410  Loss:  0.5133990049362183\n",
      "Write summary at step 16420  Loss:  0.5042292475700378\n",
      "Write summary at step 16430  Loss:  0.5099329352378845\n",
      "Write summary at step 16440  Loss:  0.7692230939865112\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8008658008658008 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.125 Acurracy Balanced 0.5515710382513661\n",
      "Loss normal: 0.5189913752533141 Loss Control: 0.34449758018300836 Loss Patient: 1.1842490049699943 Loss balanced:  0.7643732925765013 Loss1+loss2: 0.7643732925765013\n",
      "Write summary at step 16450  Loss:  0.7540251016616821\n",
      "Write summary at step 16460  Loss:  0.6500996351242065\n",
      "Write summary at step 16470  Loss:  0.654775857925415\n",
      "Write summary at step 16480  Loss:  0.49609577655792236\n",
      "Write summary at step 16490  Loss:  0.6217573881149292\n",
      "Write summary at step 16500  Loss:  0.6291047930717468\n",
      "Saved checkpoint to: result/46/panns/checkpoint_16500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7489177489177489 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5725751366120219\n",
      "Loss normal: 0.6028973344084504 Loss Control: 0.553994015917752 Loss Patient: 0.7893412547806898 Loss balanced:  0.6716676353492209 Loss1+loss2: 0.6716676353492209\n",
      "Write summary at step 16510  Loss:  0.642577588558197\n",
      "Write summary at step 16520  Loss:  0.5088970065116882\n",
      "Write summary at step 16530  Loss:  0.7055966854095459\n",
      "Write summary at step 16540  Loss:  0.5782566666603088\n",
      "Write summary at step 16550  Loss:  0.6747733950614929\n",
      "Write summary at step 16560  Loss:  0.5525031685829163\n",
      "Write summary at step 16570  Loss:  0.706048309803009\n",
      "Write summary at step 16580  Loss:  0.5648174285888672\n",
      "Write summary at step 16590  Loss:  0.5920428037643433\n",
      "Write summary at step 16600  Loss:  0.7099778652191162\n",
      "Write summary at step 16610  Loss:  0.5481471419334412\n",
      "Write summary at step 16620  Loss:  0.5672464966773987\n",
      "Write summary at step 16630  Loss:  0.6384236216545105\n",
      "Write summary at step 16640  Loss:  0.6264506578445435\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6103896103896104 Acurracy Control:  0.6830601092896175 Acurracy Patient:  0.3333333333333333 Acurracy Balanced 0.5081967213114754\n",
      "Loss normal: 0.6396567698939022 Loss Control: 0.5918398895224587 Loss Patient: 0.8219585940241814 Loss balanced:  0.70689924177332 Loss1+loss2: 0.70689924177332\n",
      "Write summary at step 16650  Loss:  0.5919620394706726\n",
      "Write summary at step 16660  Loss:  0.679895281791687\n",
      "Write summary at step 16670  Loss:  0.6338191032409668\n",
      "Write summary at step 16680  Loss:  0.8186085224151611\n",
      "Write summary at step 16690  Loss:  0.632712721824646\n",
      "Write summary at step 16700  Loss:  0.657563328742981\n",
      "Write summary at step 16710  Loss:  0.6159935593605042\n",
      "Write summary at step 16720  Loss:  0.6768641471862793\n",
      "Write summary at step 16730  Loss:  0.5612350702285767\n",
      "Write summary at step 16740  Loss:  0.5010919570922852\n",
      "Write summary at step 16750  Loss:  0.732540488243103\n",
      "Write summary at step 16760  Loss:  0.6483749151229858\n",
      "Write summary at step 16770  Loss:  0.7234594821929932\n",
      "Write summary at step 16780  Loss:  0.7354910969734192\n",
      "Write summary at step 16790  Loss:  0.5393648743629456\n",
      "Write summary at step 16800  Loss:  0.7574580907821655\n",
      "Write summary at step 16810  Loss:  0.6091494560241699\n",
      "Write summary at step 16820  Loss:  0.7612576484680176\n",
      "Write summary at step 16830  Loss:  0.6442362070083618\n",
      "Write summary at step 16840  Loss:  0.6307666301727295\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5522540983606558\n",
      "Loss normal: 0.569132736621997 Loss Control: 0.47684613847341695 Loss Patient: 0.9209753883381685 Loss balanced:  0.6989107634057927 Loss1+loss2: 0.6989107634057927\n",
      "Write summary at step 16850  Loss:  0.7070239186286926\n",
      "Write summary at step 16860  Loss:  0.675037682056427\n",
      "Write summary at step 16870  Loss:  0.6123533248901367\n",
      "Write summary at step 16880  Loss:  0.49668529629707336\n",
      "Write summary at step 16890  Loss:  0.5981138944625854\n",
      "Write summary at step 16900  Loss:  0.6196037530899048\n",
      "Write summary at step 16910  Loss:  0.5562002658843994\n",
      "Write summary at step 16920  Loss:  0.4615415930747986\n",
      "Write summary at step 16930  Loss:  0.5958448648452759\n",
      "Write summary at step 16940  Loss:  0.8323736190795898\n",
      "Write summary at step 16950  Loss:  0.7491013407707214\n",
      "Write summary at step 16960  Loss:  0.4975922703742981\n",
      "Write summary at step 16970  Loss:  0.614592432975769\n",
      "Write summary at step 16980  Loss:  0.6753297448158264\n",
      "Write summary at step 16990  Loss:  0.6826925277709961\n",
      "Write summary at step 17000  Loss:  0.7081525921821594\n",
      "Saved checkpoint to: result/46/panns/checkpoint_17000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.6060450819672131\n",
      "Loss normal: 0.581227116254501 Loss Control: 0.5227285102416909 Loss Patient: 0.8042530740300814 Loss balanced:  0.6634907921358861 Loss1+loss2: 0.6634907921358861\n",
      "Write summary at step 17010  Loss:  0.549256443977356\n",
      "Write summary at step 17020  Loss:  0.5568379163742065\n",
      "Write summary at step 17030  Loss:  0.7452316880226135\n",
      "Write summary at step 17040  Loss:  0.7297970056533813\n",
      "Write summary at step 17050  Loss:  0.8035024404525757\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7272727272727273 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.5665983606557378\n",
      "Loss normal: 0.5890729792448349 Loss Control: 0.5244850140126025 Loss Patient: 0.8353146289785703 Loss balanced:  0.6798998214955865 Loss1+loss2: 0.6798998214955865\n",
      "Write summary at step 17060  Loss:  0.6323596239089966\n",
      "Write summary at step 17070  Loss:  0.6212860345840454\n",
      "Write summary at step 17080  Loss:  0.5478320121765137\n",
      "Write summary at step 17090  Loss:  0.6597158312797546\n",
      "Write summary at step 17100  Loss:  0.5995832085609436\n",
      "Write summary at step 17110  Loss:  0.6191763877868652\n",
      "Write summary at step 17120  Loss:  0.6119866967201233\n",
      "Write summary at step 17130  Loss:  0.7179720401763916\n",
      "Write summary at step 17140  Loss:  0.5563841462135315\n",
      "Write summary at step 17150  Loss:  0.7037950158119202\n",
      "Write summary at step 17160  Loss:  0.5955677032470703\n",
      "Write summary at step 17170  Loss:  0.6527924537658691\n",
      "Write summary at step 17180  Loss:  0.5884262323379517\n",
      "Write summary at step 17190  Loss:  0.42276936769485474\n",
      "Write summary at step 17200  Loss:  0.6807417869567871\n",
      "Write summary at step 17210  Loss:  0.5492058992385864\n",
      "Write summary at step 17220  Loss:  0.8462684154510498\n",
      "Write summary at step 17230  Loss:  0.6451261043548584\n",
      "Write summary at step 17240  Loss:  0.686926543712616\n",
      "Write summary at step 17250  Loss:  0.581376314163208\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7532467532467533 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5753073770491803\n",
      "Loss normal: 0.5415058822342844 Loss Control: 0.43107627584634584 Loss Patient: 0.9625187062968811 Loss balanced:  0.6967974910716135 Loss1+loss2: 0.6967974910716135\n",
      "Write summary at step 17260  Loss:  0.5227025151252747\n",
      "Write summary at step 17270  Loss:  0.5278470516204834\n",
      "Write summary at step 17280  Loss:  0.6324464678764343\n",
      "Write summary at step 17290  Loss:  0.5940602421760559\n",
      "Write summary at step 17300  Loss:  0.6992534399032593\n",
      "Write summary at step 17310  Loss:  0.6179720759391785\n",
      "Write summary at step 17320  Loss:  0.4983597695827484\n",
      "Write summary at step 17330  Loss:  1.0004193782806396\n",
      "Write summary at step 17340  Loss:  0.5969237089157104\n",
      "Write summary at step 17350  Loss:  0.7085980176925659\n",
      "Write summary at step 17360  Loss:  0.5667142868041992\n",
      "Write summary at step 17370  Loss:  0.48187994956970215\n",
      "Write summary at step 17380  Loss:  0.7142081260681152\n",
      "Write summary at step 17390  Loss:  0.4406979978084564\n",
      "Write summary at step 17400  Loss:  0.6738556027412415\n",
      "Write summary at step 17410  Loss:  0.6290730237960815\n",
      "Write summary at step 17420  Loss:  0.5733667612075806\n",
      "Write summary at step 17430  Loss:  0.767047643661499\n",
      "Write summary at step 17440  Loss:  0.6502743363380432\n",
      "Write summary at step 17450  Loss:  0.5658975839614868\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6060606060606061 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.5285177595628415\n",
      "Loss normal: 0.6220781797970528 Loss Control: 0.5840477871764553 Loss Patient: 0.7670690168937048 Loss balanced:  0.67555840203508 Loss1+loss2: 0.67555840203508\n",
      "Write summary at step 17460  Loss:  0.6130889654159546\n",
      "Write summary at step 17470  Loss:  0.7548925280570984\n",
      "Write summary at step 17480  Loss:  0.6899158954620361\n",
      "Write summary at step 17490  Loss:  0.725909411907196\n",
      "Write summary at step 17500  Loss:  0.42468610405921936\n",
      "Saved checkpoint to: result/46/panns/checkpoint_17500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6103896103896104 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5158811475409836\n",
      "Loss normal: 0.6231631292151166 Loss Control: 0.574717828973395 Loss Patient: 0.8078608456999063 Loss balanced:  0.6912893373366507 Loss1+loss2: 0.6912893373366507\n",
      "Write summary at step 17510  Loss:  0.5063474178314209\n",
      "Write summary at step 17520  Loss:  0.7466446757316589\n",
      "Write summary at step 17530  Loss:  0.548399031162262\n",
      "Write summary at step 17540  Loss:  0.5265964269638062\n",
      "Write summary at step 17550  Loss:  0.48063230514526367\n",
      "Write summary at step 17560  Loss:  0.5278598070144653\n",
      "Write summary at step 17570  Loss:  0.7053778171539307\n",
      "Write summary at step 17580  Loss:  0.7781038284301758\n",
      "Write summary at step 17590  Loss:  0.5503952503204346\n",
      "Write summary at step 17600  Loss:  0.5843387842178345\n",
      "Write summary at step 17610  Loss:  0.6667414307594299\n",
      "Write summary at step 17620  Loss:  0.678807258605957\n",
      "Write summary at step 17630  Loss:  0.6728521585464478\n",
      "Write summary at step 17640  Loss:  0.5305875539779663\n",
      "Write summary at step 17650  Loss:  0.6147200465202332\n",
      "Write summary at step 17660  Loss:  0.667778730392456\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7922077922077922 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.22916666666666666 Acurracy Balanced 0.5845286885245902\n",
      "Loss normal: 0.5253779019886281 Loss Control: 0.3939055333046314 Loss Patient: 1.0266163125634193 Loss balanced:  0.7102609229340253 Loss1+loss2: 0.7102609229340253\n",
      "Write summary at step 17670  Loss:  0.6051523089408875\n",
      "Write summary at step 17680  Loss:  0.521935224533081\n",
      "Write summary at step 17690  Loss:  0.7428392767906189\n",
      "Write summary at step 17700  Loss:  0.646660327911377\n",
      "Write summary at step 17710  Loss:  0.5225330591201782\n",
      "Write summary at step 17720  Loss:  0.6491811275482178\n",
      "Write summary at step 17730  Loss:  0.5064987540245056\n",
      "Write summary at step 17740  Loss:  0.8057175874710083\n",
      "Write summary at step 17750  Loss:  0.5641300678253174\n",
      "Write summary at step 17760  Loss:  0.6795146465301514\n",
      "Write summary at step 17770  Loss:  0.5940920114517212\n",
      "Write summary at step 17780  Loss:  0.5670366883277893\n",
      "Write summary at step 17790  Loss:  0.553229033946991\n",
      "Write summary at step 17800  Loss:  0.4830886125564575\n",
      "Write summary at step 17810  Loss:  0.7401001453399658\n",
      "Write summary at step 17820  Loss:  0.6554896235466003\n",
      "Write summary at step 17830  Loss:  0.6748086214065552\n",
      "Write summary at step 17840  Loss:  0.7343906164169312\n",
      "Write summary at step 17850  Loss:  0.6273380517959595\n",
      "Write summary at step 17860  Loss:  0.5327523946762085\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6796536796536796 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.4791666666666667 Acurracy Balanced 0.6057035519125683\n",
      "Loss normal: 0.6021320947578975 Loss Control: 0.5613528827174765 Loss Patient: 0.7576028226564328 Loss balanced:  0.6594778526869547 Loss1+loss2: 0.6594778526869547\n",
      "Write summary at step 17870  Loss:  0.5741726756095886\n",
      "Write summary at step 17880  Loss:  0.6169320344924927\n",
      "Write summary at step 17890  Loss:  0.6847277879714966\n",
      "Write summary at step 17900  Loss:  0.6952790021896362\n",
      "Write summary at step 17910  Loss:  0.7407307624816895\n",
      "Write summary at step 17920  Loss:  0.7873364686965942\n",
      "Write summary at step 17930  Loss:  0.6423394680023193\n",
      "Write summary at step 17940  Loss:  0.5987800359725952\n",
      "Write summary at step 17950  Loss:  0.4830780327320099\n",
      "Write summary at step 17960  Loss:  0.6191732287406921\n",
      "Write summary at step 17970  Loss:  0.8766031265258789\n",
      "Write summary at step 17980  Loss:  0.5972968935966492\n",
      "Write summary at step 17990  Loss:  0.6186981797218323\n",
      "Write summary at step 18000  Loss:  0.5975043177604675\n",
      "Saved checkpoint to: result/46/panns/checkpoint_18000.pt\n",
      "Validation:\n",
      "Acurracy:  0.6277056277056277 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.4375 Acurracy Balanced 0.5575478142076502\n",
      "Loss normal: 0.6395975439063398 Loss Control: 0.6233525523722497 Loss Patient: 0.7015315927565098 Loss balanced:  0.6624420725643798 Loss1+loss2: 0.6624420725643798\n",
      "Write summary at step 18010  Loss:  0.509801983833313\n",
      "Write summary at step 18020  Loss:  0.6039586663246155\n",
      "Write summary at step 18030  Loss:  0.7186298370361328\n",
      "Write summary at step 18040  Loss:  0.6681550741195679\n",
      "Write summary at step 18050  Loss:  0.6665059924125671\n",
      "Write summary at step 18060  Loss:  0.6958203315734863\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7575757575757576 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.20833333333333334 Acurracy Balanced 0.5549863387978142\n",
      "Loss normal: 0.5340466715427704 Loss Control: 0.3938303722547052 Loss Patient: 1.068621349831422 Loss balanced:  0.7312258610430636 Loss1+loss2: 0.7312258610430636\n",
      "Write summary at step 18070  Loss:  0.5798969268798828\n",
      "Write summary at step 18080  Loss:  0.8836384415626526\n",
      "Write summary at step 18090  Loss:  0.537879228591919\n",
      "Write summary at step 18100  Loss:  0.6858110427856445\n",
      "Write summary at step 18110  Loss:  0.5083657503128052\n",
      "Write summary at step 18120  Loss:  0.5298458337783813\n",
      "Write summary at step 18130  Loss:  0.4980575442314148\n",
      "Write summary at step 18140  Loss:  0.6785152554512024\n",
      "Write summary at step 18150  Loss:  0.6188197731971741\n",
      "Write summary at step 18160  Loss:  0.5687888860702515\n",
      "Write summary at step 18170  Loss:  0.603553295135498\n",
      "Write summary at step 18180  Loss:  0.5561336278915405\n",
      "Write summary at step 18190  Loss:  0.546357274055481\n",
      "Write summary at step 18200  Loss:  0.5996736884117126\n",
      "Write summary at step 18210  Loss:  0.5842039585113525\n",
      "Write summary at step 18220  Loss:  0.5165469646453857\n",
      "Write summary at step 18230  Loss:  0.6326277256011963\n",
      "Write summary at step 18240  Loss:  0.47298145294189453\n",
      "Write summary at step 18250  Loss:  0.5844501256942749\n",
      "Write summary at step 18260  Loss:  0.7528212666511536\n",
      "Write summary at step 18270  Loss:  0.7277368307113647\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.2916666666666667 Acurracy Balanced 0.6021174863387978\n",
      "Loss normal: 0.5281004035498673 Loss Control: 0.41511085735318437 Loss Patient: 0.958873034765323 Loss balanced:  0.6869919460592537 Loss1+loss2: 0.6869919460592537\n",
      "Write summary at step 18280  Loss:  0.5936654806137085\n",
      "Write summary at step 18290  Loss:  0.6411003470420837\n",
      "Write summary at step 18300  Loss:  0.6203244924545288\n",
      "Write summary at step 18310  Loss:  0.7264730930328369\n",
      "Write summary at step 18320  Loss:  0.6043465733528137\n",
      "Write summary at step 18330  Loss:  0.7323935031890869\n",
      "Write summary at step 18340  Loss:  0.8262389898300171\n",
      "Write summary at step 18350  Loss:  0.6430399417877197\n",
      "Write summary at step 18360  Loss:  0.6490492820739746\n",
      "Write summary at step 18370  Loss:  0.605962872505188\n",
      "Write summary at step 18380  Loss:  0.7604330778121948\n",
      "Write summary at step 18390  Loss:  0.6186952590942383\n",
      "Write summary at step 18400  Loss:  0.6328461170196533\n",
      "Write summary at step 18410  Loss:  0.5214453935623169\n",
      "Write summary at step 18420  Loss:  0.5543558597564697\n",
      "Write summary at step 18430  Loss:  0.6818462610244751\n",
      "Write summary at step 18440  Loss:  0.654937744140625\n",
      "Write summary at step 18450  Loss:  0.6891084909439087\n",
      "Write summary at step 18460  Loss:  0.748908519744873\n",
      "Write summary at step 18470  Loss:  0.6950547695159912\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.25 Acurracy Balanced 0.5867486338797814\n",
      "Loss normal: 0.5415932823182185 Loss Control: 0.42000372821841736 Loss Patient: 1.0051534660160542 Loss balanced:  0.7125785971172358 Loss1+loss2: 0.7125785971172358\n",
      "Write summary at step 18480  Loss:  0.5858876705169678\n",
      "Write summary at step 18490  Loss:  0.5655076503753662\n",
      "Write summary at step 18500  Loss:  0.5380406379699707\n",
      "Saved checkpoint to: result/46/panns/checkpoint_18500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8095238095238095 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.6108265027322404\n",
      "Loss normal: 0.5105463889512148 Loss Control: 0.38056980570157367 Loss Patient: 1.0060821194201708 Loss balanced:  0.6933259625608722 Loss1+loss2: 0.6933259625608722\n",
      "Write summary at step 18510  Loss:  0.5337969064712524\n",
      "Write summary at step 18520  Loss:  0.5920910239219666\n",
      "Write summary at step 18530  Loss:  0.8098296523094177\n",
      "Write summary at step 18540  Loss:  0.6697441935539246\n",
      "Write summary at step 18550  Loss:  0.636306643486023\n",
      "Write summary at step 18560  Loss:  0.5704389810562134\n",
      "Write summary at step 18570  Loss:  0.5849826335906982\n",
      "Write summary at step 18580  Loss:  0.6753947138786316\n",
      "Write summary at step 18590  Loss:  0.51650470495224\n",
      "Write summary at step 18600  Loss:  0.5987759828567505\n",
      "Write summary at step 18610  Loss:  0.7831947207450867\n",
      "Write summary at step 18620  Loss:  0.6418349742889404\n",
      "Write summary at step 18630  Loss:  0.4758281409740448\n",
      "Write summary at step 18640  Loss:  0.6403260231018066\n",
      "Write summary at step 18650  Loss:  0.7544552087783813\n",
      "Write summary at step 18660  Loss:  0.735828161239624\n",
      "Write summary at step 18670  Loss:  0.6216118335723877\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.5930735930735931 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.375 Acurracy Balanced 0.512636612021858\n",
      "Loss normal: 0.617030871378911 Loss Control: 0.5759896541553768 Loss Patient: 0.7735005306700865 Loss balanced:  0.6747450924127316 Loss1+loss2: 0.6747450924127316\n",
      "Write summary at step 18680  Loss:  0.4660818576812744\n",
      "Write summary at step 18690  Loss:  0.5214385986328125\n",
      "Write summary at step 18700  Loss:  0.566031277179718\n",
      "Write summary at step 18710  Loss:  0.6225332021713257\n",
      "Write summary at step 18720  Loss:  0.5595282912254333\n",
      "Write summary at step 18730  Loss:  0.48489490151405334\n",
      "Write summary at step 18740  Loss:  0.7833670377731323\n",
      "Write summary at step 18750  Loss:  0.6030454039573669\n",
      "Write summary at step 18760  Loss:  0.5064682364463806\n",
      "Write summary at step 18770  Loss:  0.5589747428894043\n",
      "Write summary at step 18780  Loss:  0.5835486650466919\n",
      "Write summary at step 18790  Loss:  0.9477420449256897\n",
      "Write summary at step 18800  Loss:  0.5796182155609131\n",
      "Write summary at step 18810  Loss:  0.6630658507347107\n",
      "Write summary at step 18820  Loss:  0.6141064167022705\n",
      "Write summary at step 18830  Loss:  0.5751099586486816\n",
      "Write summary at step 18840  Loss:  0.5685567259788513\n",
      "Write summary at step 18850  Loss:  0.8055087327957153\n",
      "Write summary at step 18860  Loss:  0.5731975436210632\n",
      "Write summary at step 18870  Loss:  0.5331693887710571\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7012987012987013 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5425204918032787\n",
      "Loss normal: 0.568373914404865 Loss Control: 0.4823531179480214 Loss Patient: 0.896328154951334 Loss balanced:  0.6893406364496777 Loss1+loss2: 0.6893406364496777\n",
      "Write summary at step 18880  Loss:  0.6736533641815186\n",
      "Write summary at step 18890  Loss:  0.6335583329200745\n",
      "Write summary at step 18900  Loss:  0.5866328477859497\n",
      "Write summary at step 18910  Loss:  0.49727362394332886\n",
      "Write summary at step 18920  Loss:  0.4786466062068939\n",
      "Write summary at step 18930  Loss:  0.665836751461029\n",
      "Write summary at step 18940  Loss:  0.5303189754486084\n",
      "Write summary at step 18950  Loss:  0.5855872631072998\n",
      "Write summary at step 18960  Loss:  0.5060111284255981\n",
      "Write summary at step 18970  Loss:  0.5985532999038696\n",
      "Write summary at step 18980  Loss:  0.6209617257118225\n",
      "Write summary at step 18990  Loss:  0.7837662696838379\n",
      "Write summary at step 19000  Loss:  0.537570595741272\n",
      "Saved checkpoint to: result/46/panns/checkpoint_19000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7835497835497836 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.1875 Acurracy Balanced 0.5636953551912569\n",
      "Loss normal: 0.5173981010397791 Loss Control: 0.3714565242248806 Loss Patient: 1.0738003601630528 Loss balanced:  0.7226284421939667 Loss1+loss2: 0.7226284421939667\n",
      "Write summary at step 19010  Loss:  0.5535747408866882\n",
      "Write summary at step 19020  Loss:  0.7824563980102539\n",
      "Write summary at step 19030  Loss:  0.7385678887367249\n",
      "Write summary at step 19040  Loss:  1.0134508609771729\n",
      "Write summary at step 19050  Loss:  0.5474092960357666\n",
      "Write summary at step 19060  Loss:  0.6280523538589478\n",
      "Write summary at step 19070  Loss:  0.6758050322532654\n",
      "Write summary at step 19080  Loss:  0.6826322078704834\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.7878787878787878 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5971653005464481\n",
      "Loss normal: 0.5417757085907511 Loss Control: 0.4594619208997716 Loss Patient: 0.8555970266461372 Loss balanced:  0.6575294737729545 Loss1+loss2: 0.6575294737729545\n",
      "Write summary at step 19090  Loss:  0.5603400468826294\n",
      "Write summary at step 19100  Loss:  0.5790354609489441\n",
      "Write summary at step 19110  Loss:  0.5420117378234863\n",
      "Write summary at step 19120  Loss:  0.6046391725540161\n",
      "Write summary at step 19130  Loss:  0.6448439359664917\n",
      "Write summary at step 19140  Loss:  0.6287980079650879\n",
      "Write summary at step 19150  Loss:  0.6260274052619934\n",
      "Write summary at step 19160  Loss:  0.774275541305542\n",
      "Write summary at step 19170  Loss:  0.6988934278488159\n",
      "Write summary at step 19180  Loss:  0.5663561820983887\n",
      "Write summary at step 19190  Loss:  0.5580791234970093\n",
      "Write summary at step 19200  Loss:  0.7681809663772583\n",
      "Write summary at step 19210  Loss:  0.49967893958091736\n",
      "Write summary at step 19220  Loss:  0.8747391700744629\n",
      "Write summary at step 19230  Loss:  0.5855346322059631\n",
      "Write summary at step 19240  Loss:  0.6426361799240112\n",
      "Write summary at step 19250  Loss:  0.5409104824066162\n",
      "Write summary at step 19260  Loss:  0.8503519892692566\n",
      "Write summary at step 19270  Loss:  0.5356569290161133\n",
      "Write summary at step 19280  Loss:  0.7283896207809448\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7229437229437229 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5869193989071039\n",
      "Loss normal: 0.568485600994779 Loss Control: 0.4895387013427547 Loss Patient: 0.8694706546763579 Loss balanced:  0.6795046780095563 Loss1+loss2: 0.6795046780095563\n",
      "Write summary at step 19290  Loss:  0.6254538297653198\n",
      "Write summary at step 19300  Loss:  0.5895860195159912\n",
      "Write summary at step 19310  Loss:  0.5087873339653015\n",
      "Write summary at step 19320  Loss:  0.4929748773574829\n",
      "Write summary at step 19330  Loss:  0.6332138776779175\n",
      "Write summary at step 19340  Loss:  0.8532814979553223\n",
      "Write summary at step 19350  Loss:  0.6401516199111938\n",
      "Write summary at step 19360  Loss:  0.5026285648345947\n",
      "Write summary at step 19370  Loss:  0.4933893084526062\n",
      "Write summary at step 19380  Loss:  0.641788899898529\n",
      "Write summary at step 19390  Loss:  0.6704593300819397\n",
      "Write summary at step 19400  Loss:  0.5169969201087952\n",
      "Write summary at step 19410  Loss:  0.6428433656692505\n",
      "Write summary at step 19420  Loss:  0.602817177772522\n",
      "Write summary at step 19430  Loss:  0.476934015750885\n",
      "Write summary at step 19440  Loss:  0.7871472835540771\n",
      "Write summary at step 19450  Loss:  0.5672875046730042\n",
      "Write summary at step 19460  Loss:  0.7003414034843445\n",
      "Write summary at step 19470  Loss:  0.5778573155403137\n",
      "Write summary at step 19480  Loss:  0.8558061122894287\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7142857142857143 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.375 Acurracy Balanced 0.5891393442622951\n",
      "Loss normal: 0.5569203145060189 Loss Control: 0.46806773038509764 Loss Patient: 0.8956707852582136 Loss balanced:  0.6818692578216556 Loss1+loss2: 0.6818692578216556\n",
      "Write summary at step 19490  Loss:  0.7701208591461182\n",
      "Write summary at step 19500  Loss:  0.7608011364936829\n",
      "Saved checkpoint to: result/46/panns/checkpoint_19500.pt\n",
      "Validation:\n",
      "Acurracy:  0.6623376623376623 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.3958333333333333 Acurracy Balanced 0.5640368852459017\n",
      "Loss normal: 0.5823218143863595 Loss Control: 0.5259545451956369 Loss Patient: 0.7972220585991939 Loss balanced:  0.6615883018974154 Loss1+loss2: 0.6615883018974154\n",
      "Write summary at step 19510  Loss:  0.678708553314209\n",
      "Write summary at step 19520  Loss:  0.6132349967956543\n",
      "Write summary at step 19530  Loss:  0.5454260110855103\n",
      "Write summary at step 19540  Loss:  0.7677274346351624\n",
      "Write summary at step 19550  Loss:  0.8288458585739136\n",
      "Write summary at step 19560  Loss:  0.6634225249290466\n",
      "Write summary at step 19570  Loss:  0.48929059505462646\n",
      "Write summary at step 19580  Loss:  0.5464138984680176\n",
      "Write summary at step 19590  Loss:  0.6208469867706299\n",
      "Write summary at step 19600  Loss:  0.494087815284729\n",
      "Write summary at step 19610  Loss:  0.6667006015777588\n",
      "Write summary at step 19620  Loss:  0.5123269557952881\n",
      "Write summary at step 19630  Loss:  0.6781231164932251\n",
      "Write summary at step 19640  Loss:  0.5728997588157654\n",
      "Write summary at step 19650  Loss:  0.6598781943321228\n",
      "Write summary at step 19660  Loss:  0.787643551826477\n",
      "Write summary at step 19670  Loss:  0.6579972505569458\n",
      "Write summary at step 19680  Loss:  0.6546908617019653\n",
      "Write summary at step 19690  Loss:  0.7545903921127319\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7186147186147186 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.3541666666666667 Acurracy Balanced 0.5841871584699454\n",
      "Loss normal: 0.561663240323335 Loss Control: 0.49036594655344395 Loss Patient: 0.8334841256340345 Loss balanced:  0.6619250360937392 Loss1+loss2: 0.6619250360937392\n",
      "Write summary at step 19700  Loss:  0.6753700375556946\n",
      "Write summary at step 19710  Loss:  0.7678989171981812\n",
      "Write summary at step 19720  Loss:  0.7069385647773743\n",
      "Write summary at step 19730  Loss:  0.878034234046936\n",
      "Write summary at step 19740  Loss:  0.5906842350959778\n",
      "Write summary at step 19750  Loss:  0.5939683318138123\n",
      "Write summary at step 19760  Loss:  0.5153272151947021\n",
      "Write summary at step 19770  Loss:  0.6738162040710449\n",
      "Write summary at step 19780  Loss:  0.6418590545654297\n",
      "Write summary at step 19790  Loss:  0.7749689817428589\n",
      "Write summary at step 19800  Loss:  0.470425009727478\n",
      "Write summary at step 19810  Loss:  0.5031813383102417\n",
      "Write summary at step 19820  Loss:  0.6586695909500122\n",
      "Write summary at step 19830  Loss:  0.6441993117332458\n",
      "Write summary at step 19840  Loss:  0.49577686190605164\n",
      "Write summary at step 19850  Loss:  0.4972536265850067\n",
      "Write summary at step 19860  Loss:  0.5121023654937744\n",
      "Write summary at step 19870  Loss:  0.6258745193481445\n",
      "Write summary at step 19880  Loss:  0.7140449285507202\n",
      "Write summary at step 19890  Loss:  0.6555086374282837\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6536796536796536 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.375 Acurracy Balanced 0.5508879781420766\n",
      "Loss normal: 0.5968777594757286 Loss Control: 0.5200230356285481 Loss Patient: 0.8898864028354486 Loss balanced:  0.7049547192319984 Loss1+loss2: 0.7049547192319984\n",
      "Write summary at step 19900  Loss:  0.5805150270462036\n",
      "Write summary at step 19910  Loss:  0.575842022895813\n",
      "Write summary at step 19920  Loss:  0.4947848320007324\n",
      "Write summary at step 19930  Loss:  0.5966312885284424\n",
      "Write summary at step 19940  Loss:  0.5574666261672974\n",
      "Write summary at step 19950  Loss:  0.651807427406311\n",
      "Write summary at step 19960  Loss:  0.48766225576400757\n",
      "Write summary at step 19970  Loss:  0.458331435918808\n",
      "Write summary at step 19980  Loss:  0.7745776772499084\n",
      "Write summary at step 19990  Loss:  0.5726071000099182\n",
      "Write summary at step 20000  Loss:  0.7174733877182007\n",
      "Saved checkpoint to: result/46/panns/checkpoint_20000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8051948051948052 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.16666666666666666 Acurracy Balanced 0.569672131147541\n",
      "Loss normal: 0.49837435214292436 Loss Control: 0.2594532464208499 Loss Patient: 1.409261095027129 Loss balanced:  0.8343571707239894 Loss1+loss2: 0.8343571707239894\n",
      "Write summary at step 20010  Loss:  0.5638918280601501\n",
      "Write summary at step 20020  Loss:  0.6491787433624268\n",
      "Write summary at step 20030  Loss:  0.7016150951385498\n",
      "Write summary at step 20040  Loss:  0.49684154987335205\n",
      "Write summary at step 20050  Loss:  0.8790098428726196\n",
      "Write summary at step 20060  Loss:  0.6231997013092041\n",
      "Write summary at step 20070  Loss:  0.714657187461853\n",
      "Write summary at step 20080  Loss:  0.5079852342605591\n",
      "Write summary at step 20090  Loss:  0.5584337711334229\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6103896103896104 Acurracy Control:  0.639344262295082 Acurracy Patient:  0.5 Acurracy Balanced 0.569672131147541\n",
      "Loss normal: 0.6307946642239889 Loss Control: 0.6040111262290204 Loss Patient: 0.7329068767527739 Loss balanced:  0.6684590014908971 Loss1+loss2: 0.6684590014908971\n",
      "Write summary at step 20100  Loss:  0.5638490915298462\n",
      "Write summary at step 20110  Loss:  0.6134088039398193\n",
      "Write summary at step 20120  Loss:  0.665995717048645\n",
      "Write summary at step 20130  Loss:  0.7090669274330139\n",
      "Write summary at step 20140  Loss:  0.5638928413391113\n",
      "Write summary at step 20150  Loss:  0.5479744076728821\n",
      "Write summary at step 20160  Loss:  0.5859478712081909\n",
      "Write summary at step 20170  Loss:  0.7118433713912964\n",
      "Write summary at step 20180  Loss:  0.45608749985694885\n",
      "Write summary at step 20190  Loss:  0.751823365688324\n",
      "Write summary at step 20200  Loss:  0.6579288244247437\n",
      "Write summary at step 20210  Loss:  0.597137451171875\n",
      "Write summary at step 20220  Loss:  0.5959618091583252\n",
      "Write summary at step 20230  Loss:  0.7110323309898376\n",
      "Write summary at step 20240  Loss:  0.46497610211372375\n",
      "Write summary at step 20250  Loss:  0.6756191253662109\n",
      "Write summary at step 20260  Loss:  0.6995569467544556\n",
      "Write summary at step 20270  Loss:  0.7101684808731079\n",
      "Write summary at step 20280  Loss:  0.5426146984100342\n",
      "Write summary at step 20290  Loss:  0.551998496055603\n",
      "Write summary at step 20300  Loss:  0.7643426656723022\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7662337662337663 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.2708333333333333 Acurracy Balanced 0.5835040983606558\n",
      "Loss normal: 0.49666675731733245 Loss Control: 0.35983474821340844 Loss Patient: 1.0183387659490108 Loss balanced:  0.6890867570812096 Loss1+loss2: 0.6890867570812096\n",
      "------------------------------\n",
      "SEED: 46 Best Loss: 0.6553637637334362\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "config = 'script/config.json'\n",
    "seeds = [9,30,41,42,46]\n",
    "for seed in seeds:\n",
    "    command = f\"python script/train.py -c {config} -s {seed}\"\n",
    "    os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

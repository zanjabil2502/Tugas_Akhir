{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772d562f",
   "metadata": {},
   "source": [
    "## Downloading Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6614e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-16 21:50:16--  https://zenodo.org/record/3987831/files/MobileNetV1_mAP%3D0.389.pth\n",
      "SSL_INIT\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
      "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23639473 (23M) [application/octet-stream]\n",
      "Saving to: ‘MobileNetV1_mAP=0.389.pth’\n",
      "\n",
      "MobileNetV1_mAP=0.3 100%[===================>]  22.54M  1.17MB/s    in 23s     \n",
      "\n",
      "2022-01-16 21:50:41 (999 KB/s) - ‘MobileNetV1_mAP=0.389.pth’ saved [23639473/23639473]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/3987831/files/MobileNetV1_mAP%3D0.389.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8396638",
   "metadata": {},
   "source": [
    "## Training 5 Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85d2071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 5 (+- 0.1 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.6859045028686523\n",
      "Write summary at step 20  Loss:  0.7150888442993164\n",
      "Write summary at step 30  Loss:  0.9136483669281006\n",
      "Write summary at step 40  Loss:  0.7901280522346497\n",
      "Write summary at step 50  Loss:  0.6765488982200623\n",
      "Write summary at step 60  Loss:  0.7040785551071167\n",
      "Write summary at step 70  Loss:  0.6771621704101562\n",
      "Write summary at step 80  Loss:  0.633405327796936\n",
      "Write summary at step 90  Loss:  0.7672953009605408\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.40433673469387754 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.22462562396006655 Acurracy Balanced 0.6095805715428748\n",
      "Loss normal: 0.7138104061691128 Loss Control: 0.5253038862363888 Loss Patient: 0.7712092314305996 Loss balanced:  0.6482565588334942 Loss1+loss2: 0.6482565588334942\n",
      "\n",
      " > BEST MODEL (0.64826) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 100  Loss:  0.661252498626709\n",
      "Write summary at step 110  Loss:  0.7344169616699219\n",
      "Write summary at step 120  Loss:  0.6994000673294067\n",
      "Write summary at step 130  Loss:  0.6143826246261597\n",
      "Write summary at step 140  Loss:  0.7726696729660034\n",
      "Write summary at step 150  Loss:  0.6843472719192505\n",
      "Write summary at step 160  Loss:  0.655478835105896\n",
      "Write summary at step 170  Loss:  0.7926146388053894\n",
      "Write summary at step 180  Loss:  0.557999849319458\n",
      "Write summary at step 190  Loss:  0.48615217208862305\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8469387755102041 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.8119800332778702 Acurracy Balanced 0.8868643335788258\n",
      "Loss normal: 0.4007848726243389 Loss Control: 0.22187803775234952 Loss Patient: 0.45526066625772815 Loss balanced:  0.33856935200503885 Loss1+loss2: 0.33856935200503885\n",
      "\n",
      " > BEST MODEL (0.33857) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 200  Loss:  0.6379680633544922\n",
      "Write summary at step 210  Loss:  0.577242910861969\n",
      "Write summary at step 220  Loss:  0.5826964974403381\n",
      "Write summary at step 230  Loss:  0.7524078488349915\n",
      "Write summary at step 240  Loss:  0.5588977336883545\n",
      "Write summary at step 250  Loss:  0.5050917863845825\n",
      "Write summary at step 260  Loss:  0.6292953491210938\n",
      "Write summary at step 270  Loss:  0.39576080441474915\n",
      "Write summary at step 280  Loss:  0.5354439616203308\n",
      "Write summary at step 290  Loss:  0.8270654678344727\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8584183673469388 Acurracy Control:  0.45901639344262296 Acurracy Patient:  0.9800332778702163 Acurracy Balanced 0.7195248356564197\n",
      "Loss normal: 0.28278289742919865 Loss Control: 0.7147679472230172 Loss Patient: 0.15124668100362212 Loss balanced:  0.43300731411331966 Loss1+loss2: 0.43300731411331966\n",
      "Write summary at step 300  Loss:  0.6448206305503845\n",
      "Write summary at step 310  Loss:  0.8613918423652649\n",
      "Write summary at step 320  Loss:  0.5826033353805542\n",
      "Write summary at step 330  Loss:  0.4811150133609772\n",
      "Write summary at step 340  Loss:  0.9494513273239136\n",
      "Write summary at step 350  Loss:  0.37381109595298767\n",
      "Write summary at step 360  Loss:  0.6420977711677551\n",
      "Write summary at step 370  Loss:  0.6903752088546753\n",
      "Write summary at step 380  Loss:  0.5942310094833374\n",
      "Write summary at step 390  Loss:  0.6442404985427856\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8558673469387755 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.7463653473718665\n",
      "Loss normal: 0.30996495629755816 Loss Control: 0.817231019337972 Loss Patient: 0.15550623880001946 Loss balanced:  0.48636862906899575 Loss1+loss2: 0.48636862906899575\n",
      "Write summary at step 400  Loss:  0.6607663035392761\n",
      "Write summary at step 410  Loss:  0.7345629930496216\n",
      "Write summary at step 420  Loss:  0.7885910272598267\n",
      "Write summary at step 430  Loss:  0.4794340133666992\n",
      "Write summary at step 440  Loss:  0.48058438301086426\n",
      "Write summary at step 450  Loss:  0.5368901491165161\n",
      "Write summary at step 460  Loss:  0.5301569104194641\n",
      "Write summary at step 470  Loss:  0.34084391593933105\n",
      "Write summary at step 480  Loss:  0.6530032753944397\n",
      "Write summary at step 490  Loss:  0.2950391173362732\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.908485856905158 Acurracy Balanced 0.9241882836438359\n",
      "Loss normal: 0.25746628968995444 Loss Control: 0.18830042149199813 Loss Patient: 0.2785267778323613 Loss balanced:  0.23341359966217973 Loss1+loss2: 0.23341359966217973\n",
      "\n",
      " > BEST MODEL (0.23341) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 500  Loss:  0.7572221159934998\n",
      "Saved checkpoint to: result/42/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8788265306122449 Acurracy Control:  1.0 Acurracy Patient:  0.8419301164725458 Acurracy Balanced 0.920965058236273\n",
      "Loss normal: 0.37744831643542465 Loss Control: 0.15397049185356806 Loss Patient: 0.44549563978357043 Loss balanced:  0.29973306581856923 Loss1+loss2: 0.29973306581856923\n",
      "Write summary at step 510  Loss:  1.0118446350097656\n",
      "Write summary at step 520  Loss:  0.32873743772506714\n",
      "Write summary at step 530  Loss:  0.5357917547225952\n",
      "Write summary at step 540  Loss:  0.9776688814163208\n",
      "Write summary at step 550  Loss:  0.41237080097198486\n",
      "Write summary at step 560  Loss:  0.4006454050540924\n",
      "Write summary at step 570  Loss:  0.4890812635421753\n",
      "Write summary at step 580  Loss:  0.48408985137939453\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.913477537437604 Acurracy Balanced 0.9321486047843757\n",
      "Loss normal: 0.3008987116722428 Loss Control: 0.1486068424957046 Loss Patient: 0.3472704436636209 Loss balanced:  0.24793864307966276 Loss1+loss2: 0.24793864307966276\n",
      "Write summary at step 590  Loss:  0.4141620397567749\n",
      "Write summary at step 600  Loss:  0.34529566764831543\n",
      "Write summary at step 610  Loss:  0.6597130298614502\n",
      "Write summary at step 620  Loss:  0.4583389461040497\n",
      "Write summary at step 630  Loss:  0.6129698157310486\n",
      "Write summary at step 640  Loss:  0.43564414978027344\n",
      "Write summary at step 650  Loss:  0.3231978714466095\n",
      "Write summary at step 660  Loss:  0.3344630300998688\n",
      "Write summary at step 670  Loss:  0.46658602356910706\n",
      "Write summary at step 680  Loss:  0.4110943675041199\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.8643244865115518\n",
      "Loss normal: 0.2450404773105164 Loss Control: 0.49274460800358505 Loss Patient: 0.16961642127862192 Loss balanced:  0.3311805146411035 Loss1+loss2: 0.3311805146411035\n",
      "Write summary at step 690  Loss:  0.518841028213501\n",
      "Write summary at step 700  Loss:  0.4476671516895294\n",
      "Write summary at step 710  Loss:  0.4477563500404358\n",
      "Write summary at step 720  Loss:  0.5939425230026245\n",
      "Write summary at step 730  Loss:  0.6617733240127563\n",
      "Write summary at step 740  Loss:  0.38683605194091797\n",
      "Write summary at step 750  Loss:  0.2840467095375061\n",
      "Write summary at step 760  Loss:  0.47629159688949585\n",
      "Write summary at step 770  Loss:  0.5166391134262085\n",
      "Write summary at step 780  Loss:  0.4576804041862488\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8434212560122929\n",
      "Loss normal: 0.24352535603529946 Loss Control: 0.652423848219908 Loss Patient: 0.11901882929284244 Loss balanced:  0.3857213387563752 Loss1+loss2: 0.3857213387563752\n",
      "Write summary at step 790  Loss:  0.6337894201278687\n",
      "Write summary at step 800  Loss:  0.3346089720726013\n",
      "Write summary at step 810  Loss:  0.29407310485839844\n",
      "Write summary at step 820  Loss:  0.5426385402679443\n",
      "Write summary at step 830  Loss:  0.4252774119377136\n",
      "Write summary at step 840  Loss:  0.3877558410167694\n",
      "Write summary at step 850  Loss:  0.70238196849823\n",
      "Write summary at step 860  Loss:  0.40228524804115295\n",
      "Write summary at step 870  Loss:  0.47219744324684143\n",
      "Write summary at step 880  Loss:  0.3589295744895935\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9167098551594337\n",
      "Loss normal: 0.23880351220770757 Loss Control: 0.26018558173883155 Loss Patient: 0.2322928302498308 Loss balanced:  0.2462392059943312 Loss1+loss2: 0.2462392059943312\n",
      "Write summary at step 890  Loss:  0.5343698263168335\n",
      "Write summary at step 900  Loss:  0.5672531127929688\n",
      "Write summary at step 910  Loss:  0.6604969501495361\n",
      "Write summary at step 920  Loss:  0.4434255361557007\n",
      "Write summary at step 930  Loss:  0.4743158519268036\n",
      "Write summary at step 940  Loss:  0.5662579536437988\n",
      "Write summary at step 950  Loss:  0.3016475439071655\n",
      "Write summary at step 960  Loss:  0.41629287600517273\n",
      "Write summary at step 970  Loss:  0.34953078627586365\n",
      "Write summary at step 980  Loss:  0.5954172611236572\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.9182510024276479\n",
      "Loss normal: 0.22571072609600973 Loss Control: 0.2568308961847441 Loss Patient: 0.21623486776320192 Loss balanced:  0.23653288197397299 Loss1+loss2: 0.23653288197397299\n",
      "Write summary at step 990  Loss:  0.37416931986808777\n",
      "Write summary at step 1000  Loss:  0.4944024980068207\n",
      "Saved checkpoint to: result/42/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.8901830282861897 Acurracy Balanced 0.934162552394461\n",
      "Loss normal: 0.32092700586939343 Loss Control: 0.1529658353719555 Loss Patient: 0.37206992402846323 Loss balanced:  0.26251787970020934 Loss1+loss2: 0.26251787970020934\n",
      "Write summary at step 1010  Loss:  0.8192408084869385\n",
      "Write summary at step 1020  Loss:  0.6121123433113098\n",
      "Write summary at step 1030  Loss:  0.5094658732414246\n",
      "Write summary at step 1040  Loss:  0.2980121374130249\n",
      "Write summary at step 1050  Loss:  0.48200464248657227\n",
      "Write summary at step 1060  Loss:  0.37350767850875854\n",
      "Write summary at step 1070  Loss:  0.32376912236213684\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.9455734067992325\n",
      "Loss normal: 0.25089673652332656 Loss Control: 0.17159671731333914 Loss Patient: 0.2750429990585156 Loss balanced:  0.22331985818592737 Loss1+loss2: 0.22331985818592737\n",
      "\n",
      " > BEST MODEL (0.22332) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1080  Loss:  0.20429560542106628\n",
      "Write summary at step 1090  Loss:  0.5150320529937744\n",
      "Write summary at step 1100  Loss:  0.3987560272216797\n",
      "Write summary at step 1110  Loss:  0.4776136875152588\n",
      "Write summary at step 1120  Loss:  0.42312467098236084\n",
      "Write summary at step 1130  Loss:  0.3008240759372711\n",
      "Write summary at step 1140  Loss:  0.41053682565689087\n",
      "Write summary at step 1150  Loss:  0.6532076597213745\n",
      "Write summary at step 1160  Loss:  0.5497018098831177\n",
      "Write summary at step 1170  Loss:  0.5779792070388794\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.8785357737104825 Acurracy Balanced 0.9365356464180827\n",
      "Loss normal: 0.330078626925848 Loss Control: 0.11841302768128817 Loss Patient: 0.3945292155080151 Loss balanced:  0.25647112159465163 Loss1+loss2: 0.25647112159465163\n",
      "Write summary at step 1180  Loss:  0.42448776960372925\n",
      "Write summary at step 1190  Loss:  0.48078036308288574\n",
      "Write summary at step 1200  Loss:  0.6227269172668457\n",
      "Write summary at step 1210  Loss:  0.4878358244895935\n",
      "Write summary at step 1220  Loss:  0.21155856549739838\n",
      "Write summary at step 1230  Loss:  0.5512385368347168\n",
      "Write summary at step 1240  Loss:  0.40997838973999023\n",
      "Write summary at step 1250  Loss:  0.574185311794281\n",
      "Write summary at step 1260  Loss:  0.6396468877792358\n",
      "Write summary at step 1270  Loss:  0.3644162714481354\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9091086804324304\n",
      "Loss normal: 0.2409643980161268 Loss Control: 0.3843376884043542 Loss Patient: 0.19730830594227833 Loss balanced:  0.2908229971733163 Loss1+loss2: 0.2908229971733163\n",
      "Write summary at step 1280  Loss:  0.6639758348464966\n",
      "Write summary at step 1290  Loss:  0.47186702489852905\n",
      "Write summary at step 1300  Loss:  0.1175399199128151\n",
      "Write summary at step 1310  Loss:  0.295749306678772\n",
      "Write summary at step 1320  Loss:  0.37071463465690613\n",
      "Write summary at step 1330  Loss:  0.46239200234413147\n",
      "Write summary at step 1340  Loss:  0.4406161904335022\n",
      "Write summary at step 1350  Loss:  0.41918301582336426\n",
      "Write summary at step 1360  Loss:  0.44529545307159424\n",
      "Write summary at step 1370  Loss:  0.40132561326026917\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9234608985024958 Acurracy Balanced 0.9316758044425048\n",
      "Loss normal: 0.21478858434272055 Loss Control: 0.21325213205618937 Loss Patient: 0.21525642290686609 Loss balanced:  0.21425427748152773 Loss1+loss2: 0.21425427748152773\n",
      "\n",
      " > BEST MODEL (0.21425) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1380  Loss:  0.37139254808425903\n",
      "Write summary at step 1390  Loss:  0.7086971998214722\n",
      "Write summary at step 1400  Loss:  0.5009455680847168\n",
      "Write summary at step 1410  Loss:  0.2932995557785034\n",
      "Write summary at step 1420  Loss:  0.48521238565444946\n",
      "Write summary at step 1430  Loss:  0.4112875759601593\n",
      "Write summary at step 1440  Loss:  0.48976823687553406\n",
      "Write summary at step 1450  Loss:  0.42900070548057556\n",
      "Write summary at step 1460  Loss:  0.5420042276382446\n",
      "Write summary at step 1470  Loss:  0.7177742719650269\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9366674849749507\n",
      "Loss normal: 0.23721736411050875 Loss Control: 0.20439307578925878 Loss Patient: 0.24721211452849098 Loss balanced:  0.22580259515887488 Loss1+loss2: 0.22580259515887488\n",
      "Write summary at step 1480  Loss:  0.578049898147583\n",
      "Write summary at step 1490  Loss:  0.4579504728317261\n",
      "Write summary at step 1500  Loss:  0.5263365507125854\n",
      "Saved checkpoint to: result/42/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9448642062864261\n",
      "Loss normal: 0.21851434665066855 Loss Control: 0.24272479190201054 Loss Patient: 0.21114244952971448 Loss balanced:  0.2269336207158625 Loss1+loss2: 0.2269336207158625\n",
      "Write summary at step 1510  Loss:  0.33361130952835083\n",
      "Write summary at step 1520  Loss:  0.354250431060791\n",
      "Write summary at step 1530  Loss:  0.4208832383155823\n",
      "Write summary at step 1540  Loss:  0.4687984883785248\n",
      "Write summary at step 1550  Loss:  0.7356691360473633\n",
      "Write summary at step 1560  Loss:  0.9114941358566284\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8712164607257485\n",
      "Loss normal: 0.20532762895965453 Loss Control: 0.4904964458746988 Loss Patient: 0.11849586303638737 Loss balanced:  0.3044961544555431 Loss1+loss2: 0.3044961544555431\n",
      "Write summary at step 1570  Loss:  0.6462150812149048\n",
      "Write summary at step 1580  Loss:  0.6005905270576477\n",
      "Write summary at step 1590  Loss:  0.5433103442192078\n",
      "Write summary at step 1600  Loss:  0.32331380248069763\n",
      "Write summary at step 1610  Loss:  0.6255654096603394\n",
      "Write summary at step 1620  Loss:  0.363780677318573\n",
      "Write summary at step 1630  Loss:  0.27994728088378906\n",
      "Write summary at step 1640  Loss:  0.3624386787414551\n",
      "Write summary at step 1650  Loss:  0.806736171245575\n",
      "Write summary at step 1660  Loss:  0.23114168643951416\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8741851013338425\n",
      "Loss normal: 0.23376478619721472 Loss Control: 0.4087559584060002 Loss Patient: 0.18048128294766247 Loss balanced:  0.2946186206768313 Loss1+loss2: 0.2946186206768313\n",
      "Write summary at step 1670  Loss:  0.4662797749042511\n",
      "Write summary at step 1680  Loss:  0.30281862616539\n",
      "Write summary at step 1690  Loss:  0.41285431385040283\n",
      "Write summary at step 1700  Loss:  0.3111976981163025\n",
      "Write summary at step 1710  Loss:  0.2919374108314514\n",
      "Write summary at step 1720  Loss:  0.6856250762939453\n",
      "Write summary at step 1730  Loss:  0.39771848917007446\n",
      "Write summary at step 1740  Loss:  0.30581021308898926\n",
      "Write summary at step 1750  Loss:  0.6792064905166626\n",
      "Write summary at step 1760  Loss:  0.24775218963623047\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9000800123655474\n",
      "Loss normal: 0.23237088501301348 Loss Control: 0.3079705222056863 Loss Patient: 0.2093513623846946 Loss balanced:  0.25866094229519043 Loss1+loss2: 0.25866094229519043\n",
      "Write summary at step 1770  Loss:  0.4951392412185669\n",
      "Write summary at step 1780  Loss:  0.4942014217376709\n",
      "Write summary at step 1790  Loss:  0.5793969631195068\n",
      "Write summary at step 1800  Loss:  0.36038005352020264\n",
      "Write summary at step 1810  Loss:  0.3467199504375458\n",
      "Write summary at step 1820  Loss:  0.5336908102035522\n",
      "Write summary at step 1830  Loss:  0.4117370843887329\n",
      "Write summary at step 1840  Loss:  0.29241588711738586\n",
      "Write summary at step 1850  Loss:  0.37582919001579285\n",
      "Write summary at step 1860  Loss:  0.32205456495285034\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.9428411663620742\n",
      "Loss normal: 0.24548609851270306 Loss Control: 0.14491537408750566 Loss Patient: 0.27610912953756017 Loss balanced:  0.2105122518125329 Loss1+loss2: 0.2105122518125329\n",
      "\n",
      " > BEST MODEL (0.21051) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1870  Loss:  0.5991502404212952\n",
      "Write summary at step 1880  Loss:  0.5650485754013062\n",
      "Write summary at step 1890  Loss:  0.46542415022850037\n",
      "Write summary at step 1900  Loss:  0.2935880124568939\n",
      "Write summary at step 1910  Loss:  0.3392253518104553\n",
      "Write summary at step 1920  Loss:  0.4613185524940491\n",
      "Write summary at step 1930  Loss:  0.7348295450210571\n",
      "Write summary at step 1940  Loss:  0.5017217397689819\n",
      "Write summary at step 1950  Loss:  0.31836631894111633\n",
      "Write summary at step 1960  Loss:  0.2877786159515381\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9336988443668568\n",
      "Loss normal: 0.23127035051584244 Loss Control: 0.20020363679349096 Loss Patient: 0.24072993203328175 Loss balanced:  0.22046678441338635 Loss1+loss2: 0.22046678441338635\n",
      "Write summary at step 1970  Loss:  0.46391385793685913\n",
      "Write summary at step 1980  Loss:  0.57770836353302\n",
      "Write summary at step 1990  Loss:  0.3340260684490204\n",
      "Write summary at step 2000  Loss:  0.3240976333618164\n",
      "Saved checkpoint to: result/42/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.917900948328378\n",
      "Loss normal: 0.202841350200529 Loss Control: 0.3241209345437138 Loss Patient: 0.1659126241076211 Loss balanced:  0.24501677932566746 Loss1+loss2: 0.24501677932566746\n",
      "Write summary at step 2010  Loss:  0.42049264907836914\n",
      "Write summary at step 2020  Loss:  0.5554067492485046\n",
      "Write summary at step 2030  Loss:  0.39062827825546265\n",
      "Write summary at step 2040  Loss:  0.18763098120689392\n",
      "Write summary at step 2050  Loss:  0.2921821177005768\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9162370548175627\n",
      "Loss normal: 0.20378526429436644 Loss Control: 0.3093929714192458 Loss Patient: 0.17162850846268374 Loss balanced:  0.24051073994096478 Loss1+loss2: 0.24051073994096478\n",
      "Write summary at step 2060  Loss:  0.4657480716705322\n",
      "Write summary at step 2070  Loss:  0.3830881714820862\n",
      "Write summary at step 2080  Loss:  0.2795372009277344\n",
      "Write summary at step 2090  Loss:  0.4099782705307007\n",
      "Write summary at step 2100  Loss:  0.5055358409881592\n",
      "Write summary at step 2110  Loss:  0.45468634366989136\n",
      "Write summary at step 2120  Loss:  0.17223677039146423\n",
      "Write summary at step 2130  Loss:  0.422392874956131\n",
      "Write summary at step 2140  Loss:  0.5036349892616272\n",
      "Write summary at step 2150  Loss:  0.5654439926147461\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.947360046552649\n",
      "Loss normal: 0.21044800134033573 Loss Control: 0.2296689999559538 Loss Patient: 0.20459534867531845 Loss balanced:  0.21713217431563614 Loss1+loss2: 0.21713217431563614\n",
      "Write summary at step 2160  Loss:  0.4195127487182617\n",
      "Write summary at step 2170  Loss:  0.3954591751098633\n",
      "Write summary at step 2180  Loss:  0.40353959798812866\n",
      "Write summary at step 2190  Loss:  0.5544534921646118\n",
      "Write summary at step 2200  Loss:  0.5070062875747681\n",
      "Write summary at step 2210  Loss:  0.4470342993736267\n",
      "Write summary at step 2220  Loss:  0.3893766403198242\n",
      "Write summary at step 2230  Loss:  0.384749174118042\n",
      "Write summary at step 2240  Loss:  0.27497461438179016\n",
      "Write summary at step 2250  Loss:  0.6023643612861633\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9464285714285714 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.949855886818872\n",
      "Loss normal: 0.19795820497128427 Loss Control: 0.22998321707782848 Loss Patient: 0.1882068276554098 Loss balanced:  0.20909502236661914 Loss1+loss2: 0.20909502236661914\n",
      "\n",
      " > BEST MODEL (0.20910) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2260  Loss:  0.6835640668869019\n",
      "Write summary at step 2270  Loss:  0.6001271605491638\n",
      "Write summary at step 2280  Loss:  0.382917195558548\n",
      "Write summary at step 2290  Loss:  0.43717801570892334\n",
      "Write summary at step 2300  Loss:  0.3199048340320587\n",
      "Write summary at step 2310  Loss:  0.443838506937027\n",
      "Write summary at step 2320  Loss:  0.4154544472694397\n",
      "Write summary at step 2330  Loss:  0.2759890854358673\n",
      "Write summary at step 2340  Loss:  0.25784289836883545\n",
      "Write summary at step 2350  Loss:  0.3520107567310333\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9189692952547213\n",
      "Loss normal: 0.1936393341771802 Loss Control: 0.3124532383647773 Loss Patient: 0.1574613913373027 Loss balanced:  0.23495731485104 Loss1+loss2: 0.23495731485104\n",
      "Write summary at step 2360  Loss:  0.558989405632019\n",
      "Write summary at step 2370  Loss:  0.3277473747730255\n",
      "Write summary at step 2380  Loss:  0.17657528817653656\n",
      "Write summary at step 2390  Loss:  0.3273104429244995\n",
      "Write summary at step 2400  Loss:  0.0815005749464035\n",
      "Write summary at step 2410  Loss:  0.539901614189148\n",
      "Write summary at step 2420  Loss:  0.4242042005062103\n",
      "Write summary at step 2430  Loss:  0.3297824263572693\n",
      "Write summary at step 2440  Loss:  0.5296825170516968\n",
      "Write summary at step 2450  Loss:  0.5730095505714417\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9132684142094687\n",
      "Loss normal: 0.19865163438478295 Loss Control: 0.3009554395258752 Loss Patient: 0.16750089624608416 Loss balanced:  0.2342281678859797 Loss1+loss2: 0.2342281678859797\n",
      "Write summary at step 2460  Loss:  0.4151122570037842\n",
      "Write summary at step 2470  Loss:  0.24713173508644104\n",
      "Write summary at step 2480  Loss:  0.688779354095459\n",
      "Write summary at step 2490  Loss:  0.44629454612731934\n",
      "Write summary at step 2500  Loss:  0.522752046585083\n",
      "Saved checkpoint to: result/42/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9484283934789921\n",
      "Loss normal: 0.19402657076716423 Loss Control: 0.1883272067770932 Loss Patient: 0.1957619808577063 Loss balanced:  0.19204459381739974 Loss1+loss2: 0.19204459381739974\n",
      "\n",
      " > BEST MODEL (0.19204) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2510  Loss:  0.26576516032218933\n",
      "Write summary at step 2520  Loss:  0.45086637139320374\n",
      "Write summary at step 2530  Loss:  0.44671565294265747\n",
      "Write summary at step 2540  Loss:  0.2051112949848175\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8785812352818163\n",
      "Loss normal: 0.22034800174284955 Loss Control: 0.36842833581517953 Loss Patient: 0.1752586465905391 Loss balanced:  0.27184349120285933 Loss1+loss2: 0.27184349120285933\n",
      "Write summary at step 2550  Loss:  0.23896777629852295\n",
      "Write summary at step 2560  Loss:  0.3936041295528412\n",
      "Write summary at step 2570  Loss:  0.48353341221809387\n",
      "Write summary at step 2580  Loss:  0.35312315821647644\n",
      "Write summary at step 2590  Loss:  0.4752713143825531\n",
      "Write summary at step 2600  Loss:  0.43792665004730225\n",
      "Write summary at step 2610  Loss:  0.22389866411685944\n",
      "Write summary at step 2620  Loss:  0.49234145879745483\n",
      "Write summary at step 2630  Loss:  0.4386121332645416\n",
      "Write summary at step 2640  Loss:  0.337602823972702\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8979433185128611\n",
      "Loss normal: 0.21256562463026873 Loss Control: 0.299146711500616 Loss Patient: 0.18620233312125214 Loss balanced:  0.24267452231093406 Loss1+loss2: 0.24267452231093406\n",
      "Write summary at step 2650  Loss:  0.39072221517562866\n",
      "Write summary at step 2660  Loss:  0.3134087026119232\n",
      "Write summary at step 2670  Loss:  0.29214537143707275\n",
      "Write summary at step 2680  Loss:  0.36315780878067017\n",
      "Write summary at step 2690  Loss:  0.466888964176178\n",
      "Write summary at step 2700  Loss:  0.5328813791275024\n",
      "Write summary at step 2710  Loss:  0.3350130319595337\n",
      "Write summary at step 2720  Loss:  0.4000961184501648\n",
      "Write summary at step 2730  Loss:  0.22715936601161957\n",
      "Write summary at step 2740  Loss:  0.3719460964202881\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.882381822645318\n",
      "Loss normal: 0.2197679014002182 Loss Control: 0.3761041223025713 Loss Patient: 0.1721646894333565 Loss balanced:  0.2741344058679639 Loss1+loss2: 0.2741344058679639\n",
      "Write summary at step 2750  Loss:  0.45891934633255005\n",
      "Write summary at step 2760  Loss:  0.3416071832180023\n",
      "Write summary at step 2770  Loss:  0.4158022999763489\n",
      "Write summary at step 2780  Loss:  0.5266585350036621\n",
      "Write summary at step 2790  Loss:  0.3060399293899536\n",
      "Write summary at step 2800  Loss:  0.1966310441493988\n",
      "Write summary at step 2810  Loss:  0.33938637375831604\n",
      "Write summary at step 2820  Loss:  0.241217240691185\n",
      "Write summary at step 2830  Loss:  0.3907478451728821\n",
      "Write summary at step 2840  Loss:  0.4083554148674011\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9443914059445551\n",
      "Loss normal: 0.19691193305260066 Loss Control: 0.1980222367523798 Loss Patient: 0.19657385294727 Loss balanced:  0.19729804484982488 Loss1+loss2: 0.19729804484982488\n",
      "Write summary at step 2850  Loss:  0.21493664383888245\n",
      "Write summary at step 2860  Loss:  0.5451850295066833\n",
      "Write summary at step 2870  Loss:  0.4246741533279419\n",
      "Write summary at step 2880  Loss:  0.27178657054901123\n",
      "Write summary at step 2890  Loss:  0.2721751034259796\n",
      "Write summary at step 2900  Loss:  0.5649440288543701\n",
      "Write summary at step 2910  Loss:  0.38129591941833496\n",
      "Write summary at step 2920  Loss:  0.3868248760700226\n",
      "Write summary at step 2930  Loss:  0.37473031878471375\n",
      "Write summary at step 2940  Loss:  0.37094008922576904\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9393997254121091\n",
      "Loss normal: 0.19813737117362265 Loss Control: 0.16346403549277716 Loss Patient: 0.20869514222153016 Loss balanced:  0.18607958885715364 Loss1+loss2: 0.18607958885715364\n",
      "\n",
      " > BEST MODEL (0.18608) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2950  Loss:  0.42902955412864685\n",
      "Write summary at step 2960  Loss:  0.7032837867736816\n",
      "Write summary at step 2970  Loss:  0.37846899032592773\n",
      "Write summary at step 2980  Loss:  0.4676056504249573\n",
      "Write summary at step 2990  Loss:  0.45311012864112854\n",
      "Write summary at step 3000  Loss:  0.3067280352115631\n",
      "Saved checkpoint to: result/42/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9279979633216042\n",
      "Loss normal: 0.21313266547358767 Loss Control: 0.247067166807873 Loss Patient: 0.20279986211741824 Loss balanced:  0.22493351446264562 Loss1+loss2: 0.22493351446264562\n",
      "Write summary at step 3010  Loss:  0.3749683201313019\n",
      "Write summary at step 3020  Loss:  0.4448656439781189\n",
      "Write summary at step 3030  Loss:  0.45896318554878235\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9217970049916805 Acurracy Balanced 0.9527017811843648\n",
      "Loss normal: 0.22763856393950327 Loss Control: 0.11278082894497231 Loss Patient: 0.2626118846919493 Loss balanced:  0.1876963568184608 Loss1+loss2: 0.1876963568184608\n",
      "Write summary at step 3040  Loss:  0.26037195324897766\n",
      "Write summary at step 3050  Loss:  0.3358808755874634\n",
      "Write summary at step 3060  Loss:  0.5918289422988892\n",
      "Write summary at step 3070  Loss:  0.5349603891372681\n",
      "Write summary at step 3080  Loss:  0.15718060731887817\n",
      "Write summary at step 3090  Loss:  0.3672068417072296\n",
      "Write summary at step 3100  Loss:  0.3792889714241028\n",
      "Write summary at step 3110  Loss:  0.400152325630188\n",
      "Write summary at step 3120  Loss:  0.3884434700012207\n",
      "Write summary at step 3130  Loss:  0.4176958203315735\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8941427311493595\n",
      "Loss normal: 0.19861550515099446 Loss Control: 0.30020364939840766 Loss Patient: 0.16768267185438096 Loss balanced:  0.2339431606263943 Loss1+loss2: 0.2339431606263943\n",
      "Write summary at step 3140  Loss:  0.2582415044307709\n",
      "Write summary at step 3150  Loss:  0.3083706498146057\n",
      "Write summary at step 3160  Loss:  0.35784053802490234\n",
      "Write summary at step 3170  Loss:  0.529708743095398\n",
      "Write summary at step 3180  Loss:  0.36952710151672363\n",
      "Write summary at step 3190  Loss:  0.3145398497581482\n",
      "Write summary at step 3200  Loss:  0.2834669351577759\n",
      "Write summary at step 3210  Loss:  0.21881818771362305\n",
      "Write summary at step 3220  Loss:  0.20847147703170776\n",
      "Write summary at step 3230  Loss:  0.30130404233932495\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9250293227135102\n",
      "Loss normal: 0.2016781967665468 Loss Control: 0.2991817593574524 Loss Patient: 0.17198909449696342 Loss balanced:  0.2355854269272079 Loss1+loss2: 0.2355854269272079\n",
      "Write summary at step 3240  Loss:  0.2765936851501465\n",
      "Write summary at step 3250  Loss:  0.39452940225601196\n",
      "Write summary at step 3260  Loss:  0.21270349621772766\n",
      "Write summary at step 3270  Loss:  0.5308115482330322\n",
      "Write summary at step 3280  Loss:  0.160847008228302\n",
      "Write summary at step 3290  Loss:  0.3450641930103302\n",
      "Write summary at step 3300  Loss:  0.5330978631973267\n",
      "Write summary at step 3310  Loss:  0.3865090012550354\n",
      "Write summary at step 3320  Loss:  0.5399247407913208\n",
      "Write summary at step 3330  Loss:  0.6095199584960938\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8878463035196349\n",
      "Loss normal: 0.2203593194788816 Loss Control: 0.3202745393325722 Loss Patient: 0.18993588607640513 Loss balanced:  0.25510521270448866 Loss1+loss2: 0.25510521270448866\n",
      "Write summary at step 3340  Loss:  0.2517029047012329\n",
      "Write summary at step 3350  Loss:  0.2686588168144226\n",
      "Write summary at step 3360  Loss:  0.47501111030578613\n",
      "Write summary at step 3370  Loss:  0.4361427426338196\n",
      "Write summary at step 3380  Loss:  0.4455462694168091\n",
      "Write summary at step 3390  Loss:  0.5597586631774902\n",
      "Write summary at step 3400  Loss:  0.5413708686828613\n",
      "Write summary at step 3410  Loss:  0.37024882435798645\n",
      "Write summary at step 3420  Loss:  0.5218924283981323\n",
      "Write summary at step 3430  Loss:  0.4499407112598419\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9437958593600828\n",
      "Loss normal: 0.20931351766446415 Loss Control: 0.16406021010680277 Loss Patient: 0.223092812567503 Loss balanced:  0.19357651133715287 Loss1+loss2: 0.19357651133715287\n",
      "Write summary at step 3440  Loss:  0.30321580171585083\n",
      "Write summary at step 3450  Loss:  0.5528444051742554\n",
      "Write summary at step 3460  Loss:  0.23913273215293884\n",
      "Write summary at step 3470  Loss:  0.317125141620636\n",
      "Write summary at step 3480  Loss:  0.2657557427883148\n",
      "Write summary at step 3490  Loss:  0.27395573258399963\n",
      "Write summary at step 3500  Loss:  0.27440914511680603\n",
      "Saved checkpoint to: result/42/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9500922869898075\n",
      "Loss normal: 0.1969217970131003 Loss Control: 0.18539301489220292 Loss Patient: 0.20043222723953338 Loss balanced:  0.19291262106586815 Loss1+loss2: 0.19291262106586815\n",
      "Write summary at step 3510  Loss:  0.665264904499054\n",
      "Write summary at step 3520  Loss:  0.3375210165977478\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.905903639653401\n",
      "Loss normal: 0.1986791302963179 Loss Control: 0.3252081046990358 Loss Patient: 0.160152007136091 Loss balanced:  0.24268005591756342 Loss1+loss2: 0.24268005591756342\n",
      "Write summary at step 3530  Loss:  0.3103671669960022\n",
      "Write summary at step 3540  Loss:  0.4513826370239258\n",
      "Write summary at step 3550  Loss:  0.7276232838630676\n",
      "Write summary at step 3560  Loss:  0.34837138652801514\n",
      "Write summary at step 3570  Loss:  0.3193325996398926\n",
      "Write summary at step 3580  Loss:  0.23554271459579468\n",
      "Write summary at step 3590  Loss:  0.24884605407714844\n",
      "Write summary at step 3600  Loss:  0.5517281293869019\n",
      "Write summary at step 3610  Loss:  0.24056978523731232\n",
      "Write summary at step 3620  Loss:  0.45393747091293335\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9497331405762708\n",
      "Loss normal: 0.23238439295364885 Loss Control: 0.2172297099248959 Loss Patient: 0.23699888056407553 Loss balanced:  0.22711429524448573 Loss1+loss2: 0.22711429524448573\n",
      "Write summary at step 3630  Loss:  0.6830248832702637\n",
      "Write summary at step 3640  Loss:  0.17597365379333496\n",
      "Write summary at step 3650  Loss:  0.225436732172966\n",
      "Write summary at step 3660  Loss:  0.3176668882369995\n",
      "Write summary at step 3670  Loss:  0.686976969242096\n",
      "Write summary at step 3680  Loss:  0.3750397264957428\n",
      "Write summary at step 3690  Loss:  0.4340194761753082\n",
      "Write summary at step 3700  Loss:  0.4614741802215576\n",
      "Write summary at step 3710  Loss:  0.4824276566505432\n",
      "Write summary at step 3720  Loss:  0.44311609864234924\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8829773692297901\n",
      "Loss normal: 0.21529268465784132 Loss Control: 0.3851734657105201 Loss Patient: 0.16356526121819476 Loss balanced:  0.2743693634643574 Loss1+loss2: 0.2743693634643574\n",
      "Write summary at step 3730  Loss:  0.3666233420372009\n",
      "Write summary at step 3740  Loss:  0.47339361906051636\n",
      "Write summary at step 3750  Loss:  0.1795434206724167\n",
      "Write summary at step 3760  Loss:  0.48970910906791687\n",
      "Write summary at step 3770  Loss:  0.3972625732421875\n",
      "Write summary at step 3780  Loss:  0.49727165699005127\n",
      "Write summary at step 3790  Loss:  0.42516928911209106\n",
      "Write summary at step 3800  Loss:  0.40037086606025696\n",
      "Write summary at step 3810  Loss:  0.3246966004371643\n",
      "Write summary at step 3820  Loss:  0.36485594511032104\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8979433185128611\n",
      "Loss normal: 0.24807525939327113 Loss Control: 0.31090025253634634 Loss Patient: 0.22894552449220032 Loss balanced:  0.2699228885142733 Loss1+loss2: 0.2699228885142733\n",
      "Write summary at step 3830  Loss:  0.3181827664375305\n",
      "Write summary at step 3840  Loss:  0.33940213918685913\n",
      "Write summary at step 3850  Loss:  0.47697585821151733\n",
      "Write summary at step 3860  Loss:  0.3153746426105499\n",
      "Write summary at step 3870  Loss:  0.49903178215026855\n",
      "Write summary at step 3880  Loss:  0.2390240579843521\n",
      "Write summary at step 3890  Loss:  0.29497140645980835\n",
      "Write summary at step 3900  Loss:  0.4978562593460083\n",
      "Write summary at step 3910  Loss:  0.27969425916671753\n",
      "Write summary at step 3920  Loss:  0.37797847390174866\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.6994535519125683 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.8314239473373157\n",
      "Loss normal: 0.25797494873404503 Loss Control: 0.6341949030349815 Loss Patient: 0.14341879169923097 Loss balanced:  0.38880684736710625 Loss1+loss2: 0.38880684736710625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 3930  Loss:  0.4346660375595093\n",
      "Write summary at step 3940  Loss:  0.49415892362594604\n",
      "Write summary at step 3950  Loss:  0.75400710105896\n",
      "Write summary at step 3960  Loss:  0.39227747917175293\n",
      "Write summary at step 3970  Loss:  0.37184613943099976\n",
      "Write summary at step 3980  Loss:  0.2452903687953949\n",
      "Write summary at step 3990  Loss:  0.3424917757511139\n",
      "Write summary at step 4000  Loss:  0.25184375047683716\n",
      "Saved checkpoint to: result/42/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8480537901312022\n",
      "Loss normal: 0.224947882702156 Loss Control: 0.5681171980711932 Loss Patient: 0.12045540234783723 Loss balanced:  0.34428630020951523 Loss1+loss2: 0.34428630020951523\n",
      "Write summary at step 4010  Loss:  0.2725456953048706\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9233654292026949\n",
      "Loss normal: 0.20242862410995424 Loss Control: 0.2245526121613758 Loss Patient: 0.1956920363938749 Loss balanced:  0.21012232427762534 Loss1+loss2: 0.21012232427762534\n",
      "Write summary at step 4020  Loss:  0.27712926268577576\n",
      "Write summary at step 4030  Loss:  0.2947104871273041\n",
      "Write summary at step 4040  Loss:  0.6967720985412598\n",
      "Write summary at step 4050  Loss:  0.3473423719406128\n",
      "Write summary at step 4060  Loss:  0.5001767873764038\n",
      "Write summary at step 4070  Loss:  0.36764174699783325\n",
      "Write summary at step 4080  Loss:  0.44115149974823\n",
      "Write summary at step 4090  Loss:  0.14729835093021393\n",
      "Write summary at step 4100  Loss:  0.22646990418434143\n",
      "Write summary at step 4110  Loss:  0.215501606464386\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9078039333351517\n",
      "Loss normal: 0.19631388604793013 Loss Control: 0.3094167197988333 Loss Patient: 0.16187491670821152 Loss balanced:  0.2356458182535224 Loss1+loss2: 0.2356458182535224\n",
      "Write summary at step 4120  Loss:  0.29752838611602783\n",
      "Write summary at step 4130  Loss:  0.25439465045928955\n",
      "Write summary at step 4140  Loss:  0.4946250915527344\n",
      "Write summary at step 4150  Loss:  0.3582605719566345\n",
      "Write summary at step 4160  Loss:  0.37804511189460754\n",
      "Write summary at step 4170  Loss:  0.43148350715637207\n",
      "Write summary at step 4180  Loss:  0.4295355975627899\n",
      "Write summary at step 4190  Loss:  0.4180113673210144\n",
      "Write summary at step 4200  Loss:  0.3045342266559601\n",
      "Write summary at step 4210  Loss:  0.3142358660697937\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9105361737723103\n",
      "Loss normal: 0.2181916303020351 Loss Control: 0.2549940556124911 Loss Patient: 0.20698556721755945 Loss balanced:  0.23098981141502528 Loss1+loss2: 0.23098981141502528\n",
      "Write summary at step 4220  Loss:  0.2658487558364868\n",
      "Write summary at step 4230  Loss:  0.5551625490188599\n",
      "Write summary at step 4240  Loss:  0.19377046823501587\n",
      "Write summary at step 4250  Loss:  0.46069496870040894\n",
      "Write summary at step 4260  Loss:  0.2332264482975006\n",
      "Write summary at step 4270  Loss:  0.41298651695251465\n",
      "Write summary at step 4280  Loss:  0.3133559823036194\n",
      "Write summary at step 4290  Loss:  0.22694608569145203\n",
      "Write summary at step 4300  Loss:  0.36844688653945923\n",
      "Write summary at step 4310  Loss:  0.47025632858276367\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8668203267777748\n",
      "Loss normal: 0.24693216873827029 Loss Control: 0.41676792355834463 Loss Patient: 0.1952184534162134 Loss balanced:  0.305993188487279 Loss1+loss2: 0.305993188487279\n",
      "Write summary at step 4320  Loss:  0.23021934926509857\n",
      "Write summary at step 4330  Loss:  0.39174115657806396\n",
      "Write summary at step 4340  Loss:  0.3713371157646179\n",
      "Write summary at step 4350  Loss:  0.44413551688194275\n",
      "Write summary at step 4360  Loss:  0.3868893086910248\n",
      "Write summary at step 4370  Loss:  0.2341613471508026\n",
      "Write summary at step 4380  Loss:  0.4616475999355316\n",
      "Write summary at step 4390  Loss:  0.5925519466400146\n",
      "Write summary at step 4400  Loss:  0.2926337718963623\n",
      "Write summary at step 4410  Loss:  0.500454843044281\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8627833392433376\n",
      "Loss normal: 0.22704427757737589 Loss Control: 0.41734972970733225 Loss Patient: 0.16909769565462074 Loss balanced:  0.29322371268097647 Loss1+loss2: 0.29322371268097647\n",
      "Write summary at step 4420  Loss:  0.3142077326774597\n",
      "Write summary at step 4430  Loss:  0.3943660855293274\n",
      "Write summary at step 4440  Loss:  0.5836243629455566\n",
      "Write summary at step 4450  Loss:  0.415093332529068\n",
      "Write summary at step 4460  Loss:  0.34559911489486694\n",
      "Write summary at step 4470  Loss:  0.3447110056877136\n",
      "Write summary at step 4480  Loss:  0.20342734456062317\n",
      "Write summary at step 4490  Loss:  0.47090011835098267\n",
      "Write summary at step 4500  Loss:  0.3855457901954651\n",
      "Saved checkpoint to: result/42/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8829773692297901\n",
      "Loss normal: 0.2218316030137393 Loss Control: 0.39225395520528156 Loss Patient: 0.1699392713866694 Loss balanced:  0.28109661329597546 Loss1+loss2: 0.28109661329597546\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.7213114754098361 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.839025122064319\n",
      "Loss normal: 0.23652653650817823 Loss Control: 0.5453609762295999 Loss Patient: 0.14248876231482344 Loss balanced:  0.34392486927221166 Loss1+loss2: 0.34392486927221166\n",
      "Write summary at step 4510  Loss:  0.5061460733413696\n",
      "Write summary at step 4520  Loss:  0.352083295583725\n",
      "Write summary at step 4530  Loss:  0.26208534836769104\n",
      "Write summary at step 4540  Loss:  0.4208556115627289\n",
      "Write summary at step 4550  Loss:  0.27436402440071106\n",
      "Write summary at step 4560  Loss:  0.31135398149490356\n",
      "Write summary at step 4570  Loss:  0.471438467502594\n",
      "Write summary at step 4580  Loss:  0.34085506200790405\n",
      "Write summary at step 4590  Loss:  0.43508636951446533\n",
      "Write summary at step 4600  Loss:  0.4107707738876343\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8728803542365638\n",
      "Loss normal: 0.21547093649147725 Loss Control: 0.40098881135221387 Loss Patient: 0.1589821334835297 Loss balanced:  0.27998547241787175 Loss1+loss2: 0.27998547241787175\n",
      "Write summary at step 4610  Loss:  0.28087684512138367\n",
      "Write summary at step 4620  Loss:  0.37126272916793823\n",
      "Write summary at step 4630  Loss:  0.32939577102661133\n",
      "Write summary at step 4640  Loss:  0.49609047174453735\n",
      "Write summary at step 4650  Loss:  0.43804633617401123\n",
      "Write summary at step 4660  Loss:  0.2814542055130005\n",
      "Write summary at step 4670  Loss:  0.23363815248012543\n",
      "Write summary at step 4680  Loss:  0.25999021530151367\n",
      "Write summary at step 4690  Loss:  0.2641456425189972\n",
      "Write summary at step 4700  Loss:  0.5221023559570312\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9451530612244898 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9547248211087167\n",
      "Loss normal: 0.2124817645823469 Loss Control: 0.11747583909764316 Loss Patient: 0.2414103599881967 Loss balanced:  0.17944309954291993 Loss1+loss2: 0.17944309954291993\n",
      "\n",
      " > BEST MODEL (0.17944) : result/42/panns/best_checkpoint.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 4710  Loss:  0.28024986386299133\n",
      "Write summary at step 4720  Loss:  0.418793261051178\n",
      "Write summary at step 4730  Loss:  0.4501831829547882\n",
      "Write summary at step 4740  Loss:  0.5366822481155396\n",
      "Write summary at step 4750  Loss:  0.41321617364883423\n",
      "Write summary at step 4760  Loss:  0.3817925453186035\n",
      "Write summary at step 4770  Loss:  0.33048486709594727\n",
      "Write summary at step 4780  Loss:  0.45758503675460815\n",
      "Write summary at step 4790  Loss:  0.37938791513442993\n",
      "Write summary at step 4800  Loss:  0.6198921203613281\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.8204949855886818\n",
      "Loss normal: 0.2451543297466575 Loss Control: 0.6690730195227867 Loss Patient: 0.11607426240693114 Loss balanced:  0.3925736409648589 Loss1+loss2: 0.3925736409648589\n",
      "Write summary at step 4810  Loss:  0.7120875716209412\n",
      "Write summary at step 4820  Loss:  0.36269569396972656\n",
      "Write summary at step 4830  Loss:  0.6686528921127319\n",
      "Write summary at step 4840  Loss:  0.25223508477211\n",
      "Write summary at step 4850  Loss:  0.4692206382751465\n",
      "Write summary at step 4860  Loss:  0.41431090235710144\n",
      "Write summary at step 4870  Loss:  0.19886738061904907\n",
      "Write summary at step 4880  Loss:  0.6077033281326294\n",
      "Write summary at step 4890  Loss:  0.5147313475608826\n",
      "Write summary at step 4900  Loss:  0.4768809676170349\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.896874971586518\n",
      "Loss normal: 0.20124425051011602 Loss Control: 0.39539326930958063 Loss Patient: 0.14212732756519675 Loss balanced:  0.2687602984373887 Loss1+loss2: 0.2687602984373887\n",
      "Write summary at step 4910  Loss:  0.42592310905456543\n",
      "Write summary at step 4920  Loss:  0.3002203702926636\n",
      "Write summary at step 4930  Loss:  0.44620415568351746\n",
      "Write summary at step 4940  Loss:  0.3631197512149811\n",
      "Write summary at step 4950  Loss:  0.46106231212615967\n",
      "Write summary at step 4960  Loss:  0.4947226941585541\n",
      "Write summary at step 4970  Loss:  0.42398038506507874\n",
      "Write summary at step 4980  Loss:  0.2922299802303314\n",
      "Write summary at step 4990  Loss:  0.411244660615921\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9214651355209442\n",
      "Loss normal: 0.20561528836890142 Loss Control: 0.26245092042808327 Loss Patient: 0.18830926231606035 Loss balanced:  0.22538009137207182 Loss1+loss2: 0.22538009137207182\n",
      "Write summary at step 5000  Loss:  0.4505783021450043\n",
      "Saved checkpoint to: result/42/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9260976696398535\n",
      "Loss normal: 0.20728536482368196 Loss Control: 0.24813498173906504 Loss Patient: 0.194846958740182 Loss balanced:  0.22149097023962352 Loss1+loss2: 0.22149097023962352\n",
      "Write summary at step 5010  Loss:  0.2616174817085266\n",
      "Write summary at step 5020  Loss:  0.34592244029045105\n",
      "Write summary at step 5030  Loss:  0.25582459568977356\n",
      "Write summary at step 5040  Loss:  0.18494796752929688\n",
      "Write summary at step 5050  Loss:  0.2540006935596466\n",
      "Write summary at step 5060  Loss:  0.5190789699554443\n",
      "Write summary at step 5070  Loss:  0.3623780310153961\n",
      "Write summary at step 5080  Loss:  0.5690056085586548\n",
      "Write summary at step 5090  Loss:  0.4326643943786621\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9413000190938599\n",
      "Loss normal: 0.22120908655378282 Loss Control: 0.1495450546181267 Loss Patient: 0.24303024630379955 Loss balanced:  0.19628765046096314 Loss1+loss2: 0.19628765046096314\n",
      "Write summary at step 5100  Loss:  0.36537957191467285\n",
      "Write summary at step 5110  Loss:  0.29916179180145264\n",
      "Write summary at step 5120  Loss:  0.6100800633430481\n",
      "Write summary at step 5130  Loss:  0.33280378580093384\n",
      "Write summary at step 5140  Loss:  0.27690428495407104\n",
      "Write summary at step 5150  Loss:  0.44409307837486267\n",
      "Write summary at step 5160  Loss:  0.5072941780090332\n",
      "Write summary at step 5170  Loss:  0.2719947099685669\n",
      "Write summary at step 5180  Loss:  0.13778504729270935\n",
      "Write summary at step 5190  Loss:  0.5577925443649292\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8608830455615868\n",
      "Loss normal: 0.2363476241197513 Loss Control: 0.45604037391683444 Loss Patient: 0.16945282378529947 Loss balanced:  0.3127465988510669 Loss1+loss2: 0.3127465988510669\n",
      "Write summary at step 5200  Loss:  0.22797532379627228\n",
      "Write summary at step 5210  Loss:  0.4160258173942566\n",
      "Write summary at step 5220  Loss:  0.30740678310394287\n",
      "Write summary at step 5230  Loss:  0.2557182312011719\n",
      "Write summary at step 5240  Loss:  0.580062985420227\n",
      "Write summary at step 5250  Loss:  0.25768059492111206\n",
      "Write summary at step 5260  Loss:  0.6029257774353027\n",
      "Write summary at step 5270  Loss:  0.4242751896381378\n",
      "Write summary at step 5280  Loss:  0.42093315720558167\n",
      "Write summary at step 5290  Loss:  0.3450658917427063\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8518543774947038\n",
      "Loss normal: 0.24779490803425408 Loss Control: 0.5859942103995651 Loss Patient: 0.14481576035626717 Loss balanced:  0.36540498537791616 Loss1+loss2: 0.36540498537791616\n",
      "Write summary at step 5300  Loss:  0.1518847793340683\n",
      "Write summary at step 5310  Loss:  0.2996768653392792\n",
      "Write summary at step 5320  Loss:  0.3849956691265106\n",
      "Write summary at step 5330  Loss:  0.5470097064971924\n",
      "Write summary at step 5340  Loss:  0.43467092514038086\n",
      "Write summary at step 5350  Loss:  0.2497808039188385\n",
      "Write summary at step 5360  Loss:  0.24243347346782684\n",
      "Write summary at step 5370  Loss:  0.23238389194011688\n",
      "Write summary at step 5380  Loss:  0.36310386657714844\n",
      "Write summary at step 5390  Loss:  0.46010714769363403\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9004391587790841\n",
      "Loss normal: 0.2045416541929756 Loss Control: 0.3673135537267383 Loss Patient: 0.15497883127850423 Loss balanced:  0.2611461925026213 Loss1+loss2: 0.2611461925026213\n",
      "Write summary at step 5400  Loss:  0.4181702733039856\n",
      "Write summary at step 5410  Loss:  0.36109480261802673\n",
      "Write summary at step 5420  Loss:  0.22364872694015503\n",
      "Write summary at step 5430  Loss:  0.429947167634964\n",
      "Write summary at step 5440  Loss:  0.4334052801132202\n",
      "Write summary at step 5450  Loss:  0.4749724864959717\n",
      "Write summary at step 5460  Loss:  0.20983004570007324\n",
      "Write summary at step 5470  Loss:  0.26988935470581055\n",
      "Write summary at step 5480  Loss:  0.5792699456214905\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9456961530418337\n",
      "Loss normal: 0.22584862383652707 Loss Control: 0.15661030136496643 Loss Patient: 0.24693116996926992 Loss balanced:  0.20177073566711817 Loss1+loss2: 0.20177073566711817\n",
      "Write summary at step 5490  Loss:  0.37969812750816345\n",
      "Write summary at step 5500  Loss:  0.42963486909866333\n",
      "Saved checkpoint to: result/42/panns/checkpoint_5500.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9023394524608348\n",
      "Loss normal: 0.20142003002443484 Loss Control: 0.3164676887090089 Loss Patient: 0.16638888247596245 Loss balanced:  0.24142828559248566 Loss1+loss2: 0.24142828559248566\n",
      "Write summary at step 5510  Loss:  0.380363404750824\n",
      "Write summary at step 5520  Loss:  0.21083217859268188\n",
      "Write summary at step 5530  Loss:  0.1995263695716858\n",
      "Write summary at step 5540  Loss:  0.2764120101928711\n",
      "Write summary at step 5550  Loss:  0.5773476958274841\n",
      "Write summary at step 5560  Loss:  0.5968755483627319\n",
      "Write summary at step 5570  Loss:  0.3391449451446533\n",
      "Write summary at step 5580  Loss:  0.22110775113105774\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9004391587790841\n",
      "Loss normal: 0.19986899949762285 Loss Control: 0.32461018998766206 Loss Patient: 0.16188624565692591 Loss balanced:  0.243248217822294 Loss1+loss2: 0.243248217822294\n",
      "Write summary at step 5590  Loss:  0.35415494441986084\n",
      "Write summary at step 5600  Loss:  0.48714321851730347\n",
      "Write summary at step 5610  Loss:  0.327826589345932\n",
      "Write summary at step 5620  Loss:  0.20448225736618042\n",
      "Write summary at step 5630  Loss:  0.3369677662849426\n",
      "Write summary at step 5640  Loss:  0.48525509238243103\n",
      "Write summary at step 5650  Loss:  0.4788457751274109\n",
      "Write summary at step 5660  Loss:  0.29312658309936523\n",
      "Write summary at step 5670  Loss:  0.27420535683631897\n",
      "Write summary at step 5680  Loss:  0.25832653045654297\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9489795918367347 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9515197803296873\n",
      "Loss normal: 0.19235126465102848 Loss Control: 0.19937186472402896 Loss Patient: 0.1902135454874467 Loss balanced:  0.19479270510573782 Loss1+loss2: 0.19479270510573782\n",
      "Write summary at step 5690  Loss:  0.2762715816497803\n",
      "Write summary at step 5700  Loss:  0.2139158993959427\n",
      "Write summary at step 5710  Loss:  0.21111083030700684\n",
      "Write summary at step 5720  Loss:  0.3915608525276184\n",
      "Write summary at step 5730  Loss:  0.550725519657135\n",
      "Write summary at step 5740  Loss:  0.17097964882850647\n",
      "Write summary at step 5750  Loss:  0.36642125248908997\n",
      "Write summary at step 5760  Loss:  0.5280246138572693\n",
      "Write summary at step 5770  Loss:  0.387810617685318\n",
      "Write summary at step 5780  Loss:  0.29239141941070557\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9258612694689179\n",
      "Loss normal: 0.1939538065724227 Loss Control: 0.2598633613091349 Loss Patient: 0.1738848443113627 Loss balanced:  0.2168741028102488 Loss1+loss2: 0.2168741028102488\n",
      "Write summary at step 5790  Loss:  0.24095207452774048\n",
      "Write summary at step 5800  Loss:  0.3975529372692108\n",
      "Write summary at step 5810  Loss:  0.2578466534614563\n",
      "Write summary at step 5820  Loss:  0.21688731014728546\n",
      "Write summary at step 5830  Loss:  0.47141146659851074\n",
      "Write summary at step 5840  Loss:  0.138198122382164\n",
      "Write summary at step 5850  Loss:  0.2072773575782776\n",
      "Write summary at step 5860  Loss:  0.2587878704071045\n",
      "Write summary at step 5870  Loss:  0.5801136493682861\n",
      "Write summary at step 5880  Loss:  0.3524198532104492\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9416591655073967\n",
      "Loss normal: 0.17386647500097752 Loss Control: 0.21916852753019073 Loss Patient: 0.16007233771205742 Loss balanced:  0.18962043262112407 Loss1+loss2: 0.18962043262112407\n",
      "Write summary at step 5890  Loss:  0.33822736144065857\n",
      "Write summary at step 5900  Loss:  0.7093111276626587\n",
      "Write summary at step 5910  Loss:  0.37323707342147827\n",
      "Write summary at step 5920  Loss:  0.4553041458129883\n",
      "Write summary at step 5930  Loss:  0.28253114223480225\n",
      "Write summary at step 5940  Loss:  0.3931000828742981\n",
      "Write summary at step 5950  Loss:  0.5748263597488403\n",
      "Write summary at step 5960  Loss:  0.4714849293231964\n",
      "Write summary at step 5970  Loss:  0.5500030517578125\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9416591655073967\n",
      "Loss normal: 0.1826827475535018 Loss Control: 0.19849417623274965 Loss Patient: 0.1778682853388112 Loss balanced:  0.18818123078578042 Loss1+loss2: 0.18818123078578042\n",
      "Write summary at step 5980  Loss:  0.29486554861068726\n",
      "Write summary at step 5990  Loss:  0.3786752223968506\n",
      "Write summary at step 6000  Loss:  0.2975488603115082\n",
      "Saved checkpoint to: result/42/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9500922869898075\n",
      "Loss normal: 0.2000329778054539 Loss Control: 0.13260256698548467 Loss Patient: 0.22056503479869513 Loss balanced:  0.17658380089208991 Loss1+loss2: 0.17658380089208991\n",
      "\n",
      " > BEST MODEL (0.17658) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 6010  Loss:  0.33892008662223816\n",
      "Write summary at step 6020  Loss:  0.26790302991867065\n",
      "Write summary at step 6030  Loss:  0.3094043433666229\n",
      "Write summary at step 6040  Loss:  0.31549713015556335\n",
      "Write summary at step 6050  Loss:  0.5022596716880798\n",
      "Write summary at step 6060  Loss:  0.24343332648277283\n",
      "Write summary at step 6070  Loss:  0.18496958911418915\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9269296163952612\n",
      "Loss normal: 0.19522693441534528 Loss Control: 0.20364253084516265 Loss Patient: 0.1926644508557986 Loss balanced:  0.19815349085048062 Loss1+loss2: 0.19815349085048062\n",
      "Write summary at step 6080  Loss:  0.5299561619758606\n",
      "Write summary at step 6090  Loss:  0.325879842042923\n",
      "Write summary at step 6100  Loss:  0.17368823289871216\n",
      "Write summary at step 6110  Loss:  0.2504923939704895\n",
      "Write summary at step 6120  Loss:  0.2802111506462097\n",
      "Write summary at step 6130  Loss:  0.5778591632843018\n",
      "Write summary at step 6140  Loss:  0.23411189019680023\n",
      "Write summary at step 6150  Loss:  0.420909583568573\n",
      "Write summary at step 6160  Loss:  0.2832397222518921\n",
      "Write summary at step 6170  Loss:  0.3610963821411133\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9378585781438951\n",
      "Loss normal: 0.19811846395688398 Loss Control: 0.19428707015970365 Loss Patient: 0.1992850915192566 Loss balanced:  0.19678608083948013 Loss1+loss2: 0.19678608083948013\n",
      "Write summary at step 6180  Loss:  0.4039575159549713\n",
      "Write summary at step 6190  Loss:  0.5261693000793457\n",
      "Write summary at step 6200  Loss:  0.4797118306159973\n",
      "Write summary at step 6210  Loss:  0.3461226522922516\n",
      "Write summary at step 6220  Loss:  0.4372060000896454\n",
      "Write summary at step 6230  Loss:  0.4120749533176422\n",
      "Write summary at step 6240  Loss:  0.4506813883781433\n",
      "Write summary at step 6250  Loss:  0.4496619403362274\n",
      "Write summary at step 6260  Loss:  0.2596447467803955\n",
      "Write summary at step 6270  Loss:  0.27871859073638916\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8966385714155825\n",
      "Loss normal: 0.22418943568303876 Loss Control: 0.32951096465678814 Loss Patient: 0.19211981821179192 Loss balanced:  0.26081539143429 Loss1+loss2: 0.26081539143429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 6280  Loss:  0.5508435964584351\n",
      "Write summary at step 6290  Loss:  0.25399303436279297\n",
      "Write summary at step 6300  Loss:  0.35891327261924744\n",
      "Write summary at step 6310  Loss:  0.3260897994041443\n",
      "Write summary at step 6320  Loss:  0.21383240818977356\n",
      "Write summary at step 6330  Loss:  0.3644556999206543\n",
      "Write summary at step 6340  Loss:  0.13462771475315094\n",
      "Write summary at step 6350  Loss:  0.45972609519958496\n",
      "Write summary at step 6360  Loss:  0.24926213920116425\n",
      "Write summary at step 6370  Loss:  0.18649351596832275\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9102997736013747\n",
      "Loss normal: 0.18843542795856388 Loss Control: 0.3068607426731964 Loss Patient: 0.1523758055961469 Loss balanced:  0.22961827413467167 Loss1+loss2: 0.22961827413467167\n",
      "Write summary at step 6380  Loss:  0.38560616970062256\n",
      "Write summary at step 6390  Loss:  0.28431951999664307\n",
      "Write summary at step 6400  Loss:  0.3104310929775238\n",
      "Write summary at step 6410  Loss:  0.38212960958480835\n",
      "Write summary at step 6420  Loss:  0.2830851078033447\n",
      "Write summary at step 6430  Loss:  0.47899895906448364\n",
      "Write summary at step 6440  Loss:  0.3673979640007019\n",
      "Write summary at step 6450  Loss:  0.47002142667770386\n",
      "Write summary at step 6460  Loss:  0.23286589980125427\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9530609275979014\n",
      "Loss normal: 0.19586576802694067 Loss Control: 0.13633302814973508 Loss Patient: 0.21399304184585363 Loss balanced:  0.17516303499779434 Loss1+loss2: 0.17516303499779434\n",
      "\n",
      " > BEST MODEL (0.17516) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 6470  Loss:  0.42549729347229004\n",
      "Write summary at step 6480  Loss:  0.5700997114181519\n",
      "Write summary at step 6490  Loss:  0.1855725347995758\n",
      "Write summary at step 6500  Loss:  0.472950279712677\n",
      "Saved checkpoint to: result/42/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9195648418391933\n",
      "Loss normal: 0.2100681470973151 Loss Control: 0.24912860077586982 Loss Patient: 0.1981745292486843 Loss balanced:  0.22365156501227706 Loss1+loss2: 0.22365156501227706\n",
      "Write summary at step 6510  Loss:  0.28887444734573364\n",
      "Write summary at step 6520  Loss:  0.3444705009460449\n",
      "Write summary at step 6530  Loss:  0.40501710772514343\n",
      "Write summary at step 6540  Loss:  0.4250398576259613\n",
      "Write summary at step 6550  Loss:  0.158627450466156\n",
      "Write summary at step 6560  Loss:  0.33911848068237305\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9217970049916805 Acurracy Balanced 0.9527017811843648\n",
      "Loss normal: 0.2043786581833752 Loss Control: 0.12920702179598678 Loss Patient: 0.22726785653145262 Loss balanced:  0.1782374391637197 Loss1+loss2: 0.1782374391637197\n",
      "Write summary at step 6570  Loss:  0.18309767544269562\n",
      "Write summary at step 6580  Loss:  0.40718787908554077\n",
      "Write summary at step 6590  Loss:  0.24193406105041504\n",
      "Write summary at step 6600  Loss:  0.3370579481124878\n",
      "Write summary at step 6610  Loss:  0.3561764359474182\n",
      "Write summary at step 6620  Loss:  0.44755423069000244\n",
      "Write summary at step 6630  Loss:  0.4297093451023102\n",
      "Write summary at step 6640  Loss:  0.17594480514526367\n",
      "Write summary at step 6650  Loss:  0.3848932385444641\n",
      "Write summary at step 6660  Loss:  0.2779172956943512\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9130320140385333\n",
      "Loss normal: 0.20296525278565836 Loss Control: 0.27154947532330703 Loss Patient: 0.18208187372856052 Loss balanced:  0.22681567452593376 Loss1+loss2: 0.22681567452593376\n",
      "Write summary at step 6670  Loss:  0.3738623857498169\n",
      "Write summary at step 6680  Loss:  0.29436376690864563\n",
      "Write summary at step 6690  Loss:  0.3138272762298584\n",
      "Write summary at step 6700  Loss:  0.4251798093318939\n",
      "Write summary at step 6710  Loss:  0.3273746967315674\n",
      "Write summary at step 6720  Loss:  0.45421352982521057\n",
      "Write summary at step 6730  Loss:  0.2935022711753845\n",
      "Write summary at step 6740  Loss:  0.3974681794643402\n",
      "Write summary at step 6750  Loss:  0.3049899935722351\n",
      "Write summary at step 6760  Loss:  0.3246358036994934\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9323940972695781\n",
      "Loss normal: 0.1976324916266057 Loss Control: 0.24321596707151236 Loss Patient: 0.18375266780968316 Loss balanced:  0.21348431744059776 Loss1+loss2: 0.21348431744059776\n",
      "Write summary at step 6770  Loss:  0.3087412416934967\n",
      "Write summary at step 6780  Loss:  0.1426173746585846\n",
      "Write summary at step 6790  Loss:  0.254368394613266\n",
      "Write summary at step 6800  Loss:  0.20550723373889923\n",
      "Write summary at step 6810  Loss:  0.33503541350364685\n",
      "Write summary at step 6820  Loss:  0.2628222107887268\n",
      "Write summary at step 6830  Loss:  0.23691129684448242\n",
      "Write summary at step 6840  Loss:  0.3401068449020386\n",
      "Write summary at step 6850  Loss:  0.32462209463119507\n",
      "Write summary at step 6860  Loss:  0.4195390045642853\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8964021712446469\n",
      "Loss normal: 0.21397422316807266 Loss Control: 0.4038674771134319 Loss Patient: 0.15615314941314015 Loss balanced:  0.280010313263286 Loss1+loss2: 0.280010313263286\n",
      "Write summary at step 6870  Loss:  0.4241676330566406\n",
      "Write summary at step 6880  Loss:  0.18661543726921082\n",
      "Write summary at step 6890  Loss:  0.30149173736572266\n",
      "Write summary at step 6900  Loss:  0.340671181678772\n",
      "Write summary at step 6910  Loss:  0.3677405118942261\n",
      "Write summary at step 6920  Loss:  0.6005257368087769\n",
      "Write summary at step 6930  Loss:  0.5766481161117554\n",
      "Write summary at step 6940  Loss:  0.29319438338279724\n",
      "Write summary at step 6950  Loss:  0.26822108030319214\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.9092314266750317\n",
      "Loss normal: 0.20964195434840358 Loss Control: 0.32882555977242894 Loss Patient: 0.17335144134111294 Loss balanced:  0.25108850055677095 Loss1+loss2: 0.25108850055677095\n",
      "Write summary at step 6960  Loss:  0.3425537943840027\n",
      "Write summary at step 6970  Loss:  0.4087483882904053\n",
      "Write summary at step 6980  Loss:  0.34912988543510437\n",
      "Write summary at step 6990  Loss:  0.3429485261440277\n",
      "Write summary at step 7000  Loss:  0.6300332546234131\n",
      "Saved checkpoint to: result/42/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8636152859987453\n",
      "Loss normal: 0.21267900117958077 Loss Control: 0.5152716200208404 Loss Patient: 0.12054181890484696 Loss balanced:  0.31790671946284366 Loss1+loss2: 0.31790671946284366\n",
      "Write summary at step 7010  Loss:  0.5085264444351196\n",
      "Write summary at step 7020  Loss:  0.4357897639274597\n",
      "Write summary at step 7030  Loss:  0.4064027667045593\n",
      "Write summary at step 7040  Loss:  0.2800242602825165\n",
      "Write summary at step 7050  Loss:  0.21718671917915344\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9130320140385333\n",
      "Loss normal: 0.20115419876362597 Loss Control: 0.2968835210213896 Loss Patient: 0.17200533675646623 Loss balanced:  0.2344444288889279 Loss1+loss2: 0.2344444288889279\n",
      "Write summary at step 7060  Loss:  0.2707836627960205\n",
      "Write summary at step 7070  Loss:  0.33571016788482666\n",
      "Write summary at step 7080  Loss:  0.1710958182811737\n",
      "Write summary at step 7090  Loss:  0.41643595695495605\n",
      "Write summary at step 7100  Loss:  0.5013381838798523\n",
      "Write summary at step 7110  Loss:  0.4043217599391937\n",
      "Write summary at step 7120  Loss:  0.378019779920578\n",
      "Write summary at step 7130  Loss:  0.24195855855941772\n",
      "Write summary at step 7140  Loss:  0.38810041546821594\n",
      "Write summary at step 7150  Loss:  0.5025033354759216\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9502551020408163 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9599529018120982\n",
      "Loss normal: 0.1966197116642582 Loss Control: 0.14692528684282563 Loss Patient: 0.21175129358314237 Loss balanced:  0.179338290212984 Loss1+loss2: 0.179338290212984\n",
      "Write summary at step 7160  Loss:  0.4077889919281006\n",
      "Write summary at step 7170  Loss:  0.21296870708465576\n",
      "Write summary at step 7180  Loss:  0.5075339078903198\n",
      "Write summary at step 7190  Loss:  0.22847746312618256\n",
      "Write summary at step 7200  Loss:  0.46985214948654175\n",
      "Write summary at step 7210  Loss:  0.2270050048828125\n",
      "Write summary at step 7220  Loss:  0.3229701817035675\n",
      "Write summary at step 7230  Loss:  0.45221972465515137\n",
      "Write summary at step 7240  Loss:  0.2459309697151184\n",
      "Write summary at step 7250  Loss:  0.37516140937805176\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9176645481574426\n",
      "Loss normal: 0.210533632649755 Loss Control: 0.2800495637570574 Loss Patient: 0.18936655066052016 Loss balanced:  0.2347080572087888 Loss1+loss2: 0.2347080572087888\n",
      "Write summary at step 7260  Loss:  0.27889299392700195\n",
      "Write summary at step 7270  Loss:  0.34318315982818604\n",
      "Write summary at step 7280  Loss:  0.24284052848815918\n",
      "Write summary at step 7290  Loss:  0.08905449509620667\n",
      "Write summary at step 7300  Loss:  0.423713356256485\n",
      "Write summary at step 7310  Loss:  0.5412675142288208\n",
      "Write summary at step 7320  Loss:  0.5256697535514832\n",
      "Write summary at step 7330  Loss:  0.2948310375213623\n",
      "Write summary at step 7340  Loss:  0.3356735110282898\n",
      "Write summary at step 7350  Loss:  0.18229159712791443\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9353627378776721\n",
      "Loss normal: 0.21719051536400708 Loss Control: 0.22092105391247024 Loss Patient: 0.21605459556057927 Loss balanced:  0.21848782473652475 Loss1+loss2: 0.21848782473652475\n",
      "Write summary at step 7360  Loss:  0.5023088455200195\n",
      "Write summary at step 7370  Loss:  0.27007001638412476\n",
      "Write summary at step 7380  Loss:  0.17951053380966187\n",
      "Write summary at step 7390  Loss:  0.27488481998443604\n",
      "Write summary at step 7400  Loss:  0.3396400511264801\n",
      "Write summary at step 7410  Loss:  0.16907474398612976\n",
      "Write summary at step 7420  Loss:  0.35289356112480164\n",
      "Write summary at step 7430  Loss:  0.3608621656894684\n",
      "Write summary at step 7440  Loss:  0.23551629483699799\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.911368120527718\n",
      "Loss normal: 0.2017632907218471 Loss Control: 0.3119717776123943 Loss Patient: 0.16820563095158428 Loss balanced:  0.2400887042819893 Loss1+loss2: 0.2400887042819893\n",
      "Write summary at step 7450  Loss:  0.3616672456264496\n",
      "Write summary at step 7460  Loss:  0.45801472663879395\n",
      "Write summary at step 7470  Loss:  0.36555755138397217\n",
      "Write summary at step 7480  Loss:  0.30702659487724304\n",
      "Write summary at step 7490  Loss:  0.4528602361679077\n",
      "Write summary at step 7500  Loss:  0.3218216598033905\n",
      "Saved checkpoint to: result/42/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8783448351108808\n",
      "Loss normal: 0.21537780484222635 Loss Control: 0.4117569633520366 Loss Patient: 0.1555818173780219 Loss balanced:  0.28366939036502925 Loss1+loss2: 0.28366939036502925\n",
      "Write summary at step 7510  Loss:  0.42990124225616455\n",
      "Write summary at step 7520  Loss:  0.27712005376815796\n",
      "Write summary at step 7530  Loss:  0.29838889837265015\n",
      "Write summary at step 7540  Loss:  0.2104043960571289\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.870980060554813\n",
      "Loss normal: 0.23168628533579866 Loss Control: 0.47543515403414033 Loss Patient: 0.15746657647031317 Loss balanced:  0.31645086525222677 Loss1+loss2: 0.31645086525222677\n",
      "Write summary at step 7550  Loss:  0.277645468711853\n",
      "Write summary at step 7560  Loss:  0.29360613226890564\n",
      "Write summary at step 7570  Loss:  0.4047507345676422\n",
      "Write summary at step 7580  Loss:  0.339816689491272\n",
      "Write summary at step 7590  Loss:  0.3252483904361725\n",
      "Write summary at step 7600  Loss:  0.2551705539226532\n",
      "Write summary at step 7610  Loss:  0.2939298748970032\n",
      "Write summary at step 7620  Loss:  0.3072870969772339\n",
      "Write summary at step 7630  Loss:  0.3401936888694763\n",
      "Write summary at step 7640  Loss:  0.6209688186645508\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8953338243183038\n",
      "Loss normal: 0.21985487016488095 Loss Control: 0.39742000262593963 Loss Patient: 0.1657876205350119 Loss balanced:  0.28160381158047576 Loss1+loss2: 0.28160381158047576\n",
      "Write summary at step 7650  Loss:  0.3493024408817291\n",
      "Write summary at step 7660  Loss:  0.3181360960006714\n",
      "Write summary at step 7670  Loss:  0.3722228407859802\n",
      "Write summary at step 7680  Loss:  0.285320907831192\n",
      "Write summary at step 7690  Loss:  0.3386650085449219\n",
      "Write summary at step 7700  Loss:  0.3443446159362793\n",
      "Write summary at step 7710  Loss:  0.21517610549926758\n",
      "Write summary at step 7720  Loss:  0.2568855881690979\n",
      "Write summary at step 7730  Loss:  0.5446100234985352\n",
      "Write summary at step 7740  Loss:  0.2623685598373413\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.9193284416682579\n",
      "Loss normal: 0.21067257297738473 Loss Control: 0.3338531272007468 Loss Patient: 0.17316501556636887 Loss balanced:  0.2535090713835578 Loss1+loss2: 0.2535090713835578\n",
      "Write summary at step 7750  Loss:  0.34597527980804443\n",
      "Write summary at step 7760  Loss:  0.598956823348999\n",
      "Write summary at step 7770  Loss:  0.25916916131973267\n",
      "Write summary at step 7780  Loss:  0.5402523279190063\n",
      "Write summary at step 7790  Loss:  0.25946733355522156\n",
      "Write summary at step 7800  Loss:  0.34851938486099243\n",
      "Write summary at step 7810  Loss:  0.3297434151172638\n",
      "Write summary at step 7820  Loss:  0.4610428810119629\n",
      "Write summary at step 7830  Loss:  0.5600037574768066\n",
      "Write summary at step 7840  Loss:  0.3060533404350281\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.9111317203567824\n",
      "Loss normal: 0.2086114433727094 Loss Control: 0.3025730056840865 Loss Patient: 0.18000085122523807 Loss balanced:  0.2412869284546623 Loss1+loss2: 0.2412869284546623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 7850  Loss:  0.44228339195251465\n",
      "Write summary at step 7860  Loss:  0.2956814765930176\n",
      "Write summary at step 7870  Loss:  0.3382595181465149\n",
      "Write summary at step 7880  Loss:  0.4102095663547516\n",
      "Write summary at step 7890  Loss:  0.4785991907119751\n",
      "Write summary at step 7900  Loss:  0.21061190962791443\n",
      "Write summary at step 7910  Loss:  0.3817462921142578\n",
      "Write summary at step 7920  Loss:  0.3371032178401947\n",
      "Write summary at step 7930  Loss:  0.4813317656517029\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9258612694689179\n",
      "Loss normal: 0.19696641808413728 Loss Control: 0.28425128440387915 Loss Patient: 0.17038882913040043 Loss balanced:  0.2273200567671398 Loss1+loss2: 0.2273200567671398\n",
      "Write summary at step 7940  Loss:  0.3175227642059326\n",
      "Write summary at step 7950  Loss:  0.30125221610069275\n",
      "Write summary at step 7960  Loss:  0.33897989988327026\n",
      "Write summary at step 7970  Loss:  0.3069266676902771\n",
      "Write summary at step 7980  Loss:  0.4300121068954468\n",
      "Write summary at step 7990  Loss:  0.33431172370910645\n",
      "Write summary at step 8000  Loss:  0.43269822001457214\n",
      "Saved checkpoint to: result/42/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.6065573770491803 Acurracy Patient:  0.9750415973377704 Acurracy Balanced 0.7907994871934754\n",
      "Loss normal: 0.29095466797981334 Loss Control: 0.9588226467533841 Loss Patient: 0.0875938730174908 Loss balanced:  0.5232082598854375 Loss1+loss2: 0.5232082598854375\n",
      "Write summary at step 8010  Loss:  0.320602685213089\n",
      "Write summary at step 8020  Loss:  0.3864549398422241\n",
      "Write summary at step 8030  Loss:  0.5627033710479736\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8983024649263978\n",
      "Loss normal: 0.22385614114452382 Loss Control: 0.3645412192318609 Loss Patient: 0.1810185845302861 Loss balanced:  0.2727799018810735 Loss1+loss2: 0.2727799018810735\n",
      "Write summary at step 8040  Loss:  0.4065283536911011\n",
      "Write summary at step 8050  Loss:  0.2953519821166992\n",
      "Write summary at step 8060  Loss:  0.16713613271713257\n",
      "Write summary at step 8070  Loss:  0.18513324856758118\n",
      "Write summary at step 8080  Loss:  0.4522489905357361\n",
      "Write summary at step 8090  Loss:  0.22900135815143585\n",
      "Write summary at step 8100  Loss:  0.28370577096939087\n",
      "Write summary at step 8110  Loss:  0.3693408966064453\n",
      "Write summary at step 8120  Loss:  0.17360249161720276\n",
      "Write summary at step 8130  Loss:  0.26569557189941406\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9021030522898994\n",
      "Loss normal: 0.2006200160831213 Loss Control: 0.36731350943039026 Loss Patient: 0.14986309426497302 Loss balanced:  0.25858830184768167 Loss1+loss2: 0.25858830184768167\n",
      "Write summary at step 8140  Loss:  0.4269115626811981\n",
      "Write summary at step 8150  Loss:  0.23536726832389832\n",
      "Write summary at step 8160  Loss:  0.31653669476509094\n",
      "Write summary at step 8170  Loss:  0.3270796537399292\n",
      "Write summary at step 8180  Loss:  0.40813925862312317\n",
      "Write summary at step 8190  Loss:  0.22101490199565887\n",
      "Write summary at step 8200  Loss:  0.27361631393432617\n",
      "Write summary at step 8210  Loss:  0.2362363189458847\n",
      "Write summary at step 8220  Loss:  0.43741536140441895\n",
      "Write summary at step 8230  Loss:  0.2774665355682373\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.8751397943318513\n",
      "Loss normal: 0.22730043728132637 Loss Control: 0.4791032948780581 Loss Patient: 0.15062834986930282 Loss balanced:  0.31486582237368044 Loss1+loss2: 0.31486582237368044\n",
      "Write summary at step 8240  Loss:  0.33572453260421753\n",
      "Write summary at step 8250  Loss:  0.38180941343307495\n",
      "Write summary at step 8260  Loss:  0.4473775327205658\n",
      "Write summary at step 8270  Loss:  0.056264374405145645\n",
      "Write summary at step 8280  Loss:  0.3080682158470154\n",
      "Write summary at step 8290  Loss:  0.48416081070899963\n",
      "Write summary at step 8300  Loss:  0.24057482182979584\n",
      "Write summary at step 8310  Loss:  0.41094693541526794\n",
      "Write summary at step 8320  Loss:  0.539097011089325\n",
      "Write summary at step 8330  Loss:  0.6098432540893555\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9031713992162425\n",
      "Loss normal: 0.22828916072541353 Loss Control: 0.32695435712246296 Loss Patient: 0.19824634606449457 Loss balanced:  0.2626003515934788 Loss1+loss2: 0.2626003515934788\n",
      "Write summary at step 8340  Loss:  0.42444247007369995\n",
      "Write summary at step 8350  Loss:  0.26700252294540405\n",
      "Write summary at step 8360  Loss:  0.20954395830631256\n",
      "Write summary at step 8370  Loss:  0.3355356454849243\n",
      "Write summary at step 8380  Loss:  0.08866775035858154\n",
      "Write summary at step 8390  Loss:  0.42141830921173096\n",
      "Write summary at step 8400  Loss:  0.21261388063430786\n",
      "Write summary at step 8410  Loss:  0.3360744118690491\n",
      "Write summary at step 8420  Loss:  0.2551100254058838\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.917900948328378\n",
      "Loss normal: 0.20183149341265766 Loss Control: 0.23908958783566625 Loss Patient: 0.19048668275557817 Loss balanced:  0.2147881352956222 Loss1+loss2: 0.2147881352956222\n",
      "Write summary at step 8430  Loss:  0.269910991191864\n",
      "Write summary at step 8440  Loss:  0.43028631806373596\n",
      "Write summary at step 8450  Loss:  0.3644169270992279\n",
      "Write summary at step 8460  Loss:  0.2896236181259155\n",
      "Write summary at step 8470  Loss:  0.4905579388141632\n",
      "Write summary at step 8480  Loss:  0.30214810371398926\n",
      "Write summary at step 8490  Loss:  0.2963818907737732\n",
      "Write summary at step 8500  Loss:  0.1882784068584442\n",
      "Saved checkpoint to: result/42/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.91196366711219\n",
      "Loss normal: 0.2159157139154113 Loss Control: 0.3015034374643545 Loss Patient: 0.18985489531483707 Loss balanced:  0.24567916638959578 Loss1+loss2: 0.24567916638959578\n",
      "Write summary at step 8510  Loss:  0.7563436627388\n",
      "Write summary at step 8520  Loss:  0.3317091464996338\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7431693989071039 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.8532818708345835\n",
      "Loss normal: 0.22582759730974022 Loss Control: 0.5309508384251204 Loss Patient: 0.1329198558125242 Loss balanced:  0.3319353471188223 Loss1+loss2: 0.3319353471188223\n",
      "Write summary at step 8530  Loss:  0.31763073801994324\n",
      "Write summary at step 8540  Loss:  0.4836682081222534\n",
      "Write summary at step 8550  Loss:  0.19814951717853546\n",
      "Write summary at step 8560  Loss:  0.21273654699325562\n",
      "Write summary at step 8570  Loss:  0.131434828042984\n",
      "Write summary at step 8580  Loss:  0.4452436566352844\n",
      "Write summary at step 8590  Loss:  0.22517798840999603\n",
      "Write summary at step 8600  Loss:  0.5260447859764099\n",
      "Write summary at step 8610  Loss:  0.28546342253685\n",
      "Write summary at step 8620  Loss:  0.22513839602470398\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9351263377067365\n",
      "Loss normal: 0.18475334536360236 Loss Control: 0.211257263448069 Loss Patient: 0.1766831021315841 Loss balanced:  0.19397018278982656 Loss1+loss2: 0.19397018278982656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 8630  Loss:  0.47551602125167847\n",
      "Write summary at step 8640  Loss:  0.39451533555984497\n",
      "Write summary at step 8650  Loss:  0.19044509530067444\n",
      "Write summary at step 8660  Loss:  0.22010815143585205\n",
      "Write summary at step 8670  Loss:  0.2925751805305481\n",
      "Write summary at step 8680  Loss:  0.4459943175315857\n",
      "Write summary at step 8690  Loss:  0.3507811427116394\n",
      "Write summary at step 8700  Loss:  0.3023899793624878\n",
      "Write summary at step 8710  Loss:  0.26216554641723633\n",
      "Write summary at step 8720  Loss:  0.48016512393951416\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8772764881845376\n",
      "Loss normal: 0.22707528362468798 Loss Control: 0.4313312405771245 Loss Patient: 0.16488087247939356 Loss balanced:  0.29810605652825906 Loss1+loss2: 0.29810605652825906\n",
      "Write summary at step 8730  Loss:  0.403145432472229\n",
      "Write summary at step 8740  Loss:  0.175307959318161\n",
      "Write summary at step 8750  Loss:  0.32601532340049744\n",
      "Write summary at step 8760  Loss:  0.3526611030101776\n",
      "Write summary at step 8770  Loss:  0.3854750990867615\n",
      "Write summary at step 8780  Loss:  0.26010704040527344\n",
      "Write summary at step 8790  Loss:  0.500842809677124\n",
      "Write summary at step 8800  Loss:  0.50156569480896\n",
      "Write summary at step 8810  Loss:  0.286116361618042\n",
      "Write summary at step 8820  Loss:  0.47004812955856323\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8608830455615868\n",
      "Loss normal: 0.23288173888030708 Loss Control: 0.5331389925193265 Loss Patient: 0.14145565062711718 Loss balanced:  0.33729732157322184 Loss1+loss2: 0.33729732157322184\n",
      "Write summary at step 8830  Loss:  0.17792196571826935\n",
      "Write summary at step 8840  Loss:  0.3248756527900696\n",
      "Write summary at step 8850  Loss:  0.37986066937446594\n",
      "Write summary at step 8860  Loss:  0.32947301864624023\n",
      "Write summary at step 8870  Loss:  0.23052465915679932\n",
      "Write summary at step 8880  Loss:  0.1799483597278595\n",
      "Write summary at step 8890  Loss:  0.25280505418777466\n",
      "Write summary at step 8900  Loss:  0.3689558207988739\n",
      "Write summary at step 8910  Loss:  0.4690689146518707\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.868011419946719\n",
      "Loss normal: 0.2174403663268503 Loss Control: 0.4578660097929949 Loss Patient: 0.14423256086033712 Loss balanced:  0.301049285326666 Loss1+loss2: 0.301049285326666\n",
      "Write summary at step 8920  Loss:  0.776766836643219\n",
      "Write summary at step 8930  Loss:  0.4097256064414978\n",
      "Write summary at step 8940  Loss:  0.30420613288879395\n",
      "Write summary at step 8950  Loss:  0.4790332317352295\n",
      "Write summary at step 8960  Loss:  0.38766875863075256\n",
      "Write summary at step 8970  Loss:  0.18825069069862366\n",
      "Write summary at step 8980  Loss:  0.3088976740837097\n",
      "Write summary at step 8990  Loss:  0.4622116982936859\n",
      "Write summary at step 9000  Loss:  0.4854790270328522\n",
      "Saved checkpoint to: result/42/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8871371030068284\n",
      "Loss normal: 0.20610805121915682 Loss Control: 0.4162871990698934 Loss Patient: 0.1421100761301307 Loss balanced:  0.27919863760001207 Loss1+loss2: 0.27919863760001207\n",
      "Write summary at step 9010  Loss:  0.49429088830947876\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.8614785921460589\n",
      "Loss normal: 0.22418560057270284 Loss Control: 0.523865883141919 Loss Patient: 0.1329351989010011 Loss balanced:  0.32840054102146005 Loss1+loss2: 0.32840054102146005\n",
      "Write summary at step 9020  Loss:  0.34175631403923035\n",
      "Write summary at step 9030  Loss:  0.3720815181732178\n",
      "Write summary at step 9040  Loss:  0.20312264561653137\n",
      "Write summary at step 9050  Loss:  0.36231446266174316\n",
      "Write summary at step 9060  Loss:  0.2798764109611511\n",
      "Write summary at step 9070  Loss:  0.3440207242965698\n",
      "Write summary at step 9080  Loss:  0.3894687294960022\n",
      "Write summary at step 9090  Loss:  0.3382280766963959\n",
      "Write summary at step 9100  Loss:  0.35481569170951843\n",
      "Write summary at step 9110  Loss:  0.18939852714538574\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.9650582362728786 Acurracy Balanced 0.8459170962785159\n",
      "Loss normal: 0.23097931692490772 Loss Control: 0.5703001341533139 Loss Patient: 0.12765867032494999 Loss balanced:  0.34897940223913193 Loss1+loss2: 0.34897940223913193\n",
      "Write summary at step 9120  Loss:  0.3147261142730713\n",
      "Write summary at step 9130  Loss:  0.4371805191040039\n",
      "Write summary at step 9140  Loss:  0.5651726722717285\n",
      "Write summary at step 9150  Loss:  0.47821810841560364\n",
      "Write summary at step 9160  Loss:  0.6050252914428711\n",
      "Write summary at step 9170  Loss:  0.41790395975112915\n",
      "Write summary at step 9180  Loss:  0.338203489780426\n",
      "Write summary at step 9190  Loss:  0.4526355266571045\n",
      "Write summary at step 9200  Loss:  0.13948765397071838\n",
      "Write summary at step 9210  Loss:  0.3680095076560974\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.8606466453906513\n",
      "Loss normal: 0.23249462767675214 Loss Control: 0.5322197196099276 Loss Patient: 0.14123058551844958 Loss balanced:  0.3367251525641886 Loss1+loss2: 0.3367251525641886\n",
      "Write summary at step 9220  Loss:  0.33423054218292236\n",
      "Write summary at step 9230  Loss:  0.4114181399345398\n",
      "Write summary at step 9240  Loss:  0.3110664188861847\n",
      "Write summary at step 9250  Loss:  0.24053452908992767\n",
      "Write summary at step 9260  Loss:  0.2792891561985016\n",
      "Write summary at step 9270  Loss:  0.35783618688583374\n",
      "Write summary at step 9280  Loss:  0.38345831632614136\n",
      "Write summary at step 9290  Loss:  0.30588188767433167\n",
      "Write summary at step 9300  Loss:  0.2821192145347595\n",
      "Write summary at step 9310  Loss:  0.30714505910873413\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8827409690588546\n",
      "Loss normal: 0.23477414582989045 Loss Control: 0.46211246266716816 Loss Patient: 0.1655513271193536 Loss balanced:  0.3138318948932609 Loss1+loss2: 0.3138318948932609\n",
      "Write summary at step 9320  Loss:  0.5671496391296387\n",
      "Write summary at step 9330  Loss:  0.32559746503829956\n",
      "Write summary at step 9340  Loss:  0.3455480933189392\n",
      "Write summary at step 9350  Loss:  0.3746796250343323\n",
      "Write summary at step 9360  Loss:  0.26470085978507996\n",
      "Write summary at step 9370  Loss:  0.4261137843132019\n",
      "Write summary at step 9380  Loss:  0.475151002407074\n",
      "Write summary at step 9390  Loss:  0.5561155080795288\n",
      "Write summary at step 9400  Loss:  0.2150169312953949\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8846412627406054\n",
      "Loss normal: 0.23312927010868276 Loss Control: 0.4510268803502693 Loss Patient: 0.1667810783670369 Loss balanced:  0.3089039793586531 Loss1+loss2: 0.3089039793586531\n",
      "Write summary at step 9410  Loss:  0.3474600911140442\n",
      "Write summary at step 9420  Loss:  0.3918992877006531\n",
      "Write summary at step 9430  Loss:  0.2955108880996704\n",
      "Write summary at step 9440  Loss:  0.1693941056728363\n",
      "Write summary at step 9450  Loss:  0.21134695410728455\n",
      "Write summary at step 9460  Loss:  0.3231869041919708\n",
      "Write summary at step 9470  Loss:  0.3586435914039612\n",
      "Write summary at step 9480  Loss:  0.4100797176361084\n",
      "Write summary at step 9490  Loss:  0.38830065727233887\n",
      "Write summary at step 9500  Loss:  0.2822735607624054\n",
      "Saved checkpoint to: result/42/panns/checkpoint_9500.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8974705181709901\n",
      "Loss normal: 0.20824849502924753 Loss Control: 0.39249037458596986 Loss Patient: 0.15214822285137636 Loss balanced:  0.2723192987186731 Loss1+loss2: 0.2723192987186731\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8753761945027868\n",
      "Loss normal: 0.2248620702219861 Loss Control: 0.5026364030082369 Loss Patient: 0.14028186074608376 Loss balanced:  0.3214591318771603 Loss1+loss2: 0.3214591318771603\n",
      "Write summary at step 9510  Loss:  0.48911166191101074\n",
      "Write summary at step 9520  Loss:  0.4053151607513428\n",
      "Write summary at step 9530  Loss:  0.5784252882003784\n",
      "Write summary at step 9540  Loss:  0.4062342047691345\n",
      "Write summary at step 9550  Loss:  0.4299837648868561\n",
      "Write summary at step 9560  Loss:  0.26057109236717224\n",
      "Write summary at step 9570  Loss:  0.3647572994232178\n",
      "Write summary at step 9580  Loss:  0.2818623185157776\n",
      "Write summary at step 9590  Loss:  0.5850533246994019\n",
      "Write summary at step 9600  Loss:  0.39298534393310547\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.9247929225425748\n",
      "Loss normal: 0.19982834582274056 Loss Control: 0.3184516381044857 Loss Patient: 0.16370844347603905 Loss balanced:  0.24108004079026235 Loss1+loss2: 0.24108004079026235\n",
      "Write summary at step 9610  Loss:  0.45158851146698\n",
      "Write summary at step 9620  Loss:  0.45563387870788574\n",
      "Write summary at step 9630  Loss:  0.3839481770992279\n",
      "Write summary at step 9640  Loss:  0.5448729395866394\n",
      "Write summary at step 9650  Loss:  0.3238939642906189\n",
      "Write summary at step 9660  Loss:  0.37501469254493713\n",
      "Write summary at step 9670  Loss:  0.32098478078842163\n",
      "Write summary at step 9680  Loss:  0.4831787943840027\n",
      "Write summary at step 9690  Loss:  0.3844212293624878\n",
      "Write summary at step 9700  Loss:  0.20677201449871063\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7431693989071039 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8499540838129529\n",
      "Loss normal: 0.23990423327349886 Loss Control: 0.5422633412431498 Loss Patient: 0.14783815180452017 Loss balanced:  0.345050746523835 Loss1+loss2: 0.345050746523835\n",
      "Write summary at step 9710  Loss:  0.20969730615615845\n",
      "Write summary at step 9720  Loss:  0.6516516208648682\n",
      "Write summary at step 9730  Loss:  0.28014320135116577\n",
      "Write summary at step 9740  Loss:  0.47204408049583435\n",
      "Write summary at step 9750  Loss:  0.3088585138320923\n",
      "Write summary at step 9760  Loss:  0.3292608857154846\n",
      "Write summary at step 9770  Loss:  0.3929874300956726\n",
      "Write summary at step 9780  Loss:  0.3824102282524109\n",
      "Write summary at step 9790  Loss:  0.602759599685669\n",
      "Write summary at step 9800  Loss:  0.5133457183837891\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8827409690588546\n",
      "Loss normal: 0.21991239115595818 Loss Control: 0.36434500692972066 Loss Patient: 0.17593373930989803 Loss balanced:  0.27013937311980935 Loss1+loss2: 0.27013937311980935\n",
      "------------------------------\n",
      "SEED: 42 Best Loss: 0.17516303499779434\n",
      "______________________________\n",
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 5 (+- 0.1 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.6127039194107056\n",
      "Write summary at step 20  Loss:  0.6943434476852417\n",
      "Write summary at step 30  Loss:  0.7653681039810181\n",
      "Write summary at step 40  Loss:  0.8575043678283691\n",
      "Write summary at step 50  Loss:  0.6534160375595093\n",
      "Write summary at step 60  Loss:  0.7294111251831055\n",
      "Write summary at step 70  Loss:  0.7081061601638794\n",
      "Write summary at step 80  Loss:  0.6772556900978088\n",
      "Write summary at step 90  Loss:  0.6542683243751526\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7321428571428571 Acurracy Control:  0.2459016393442623 Acurracy Patient:  0.8801996672212978 Acurracy Balanced 0.56305065328278\n",
      "Loss normal: 0.5394139618289714 Loss Control: 0.7797484280633145 Loss Patient: 0.46623391711374684 Loss balanced:  0.6229911725885307 Loss1+loss2: 0.6229911725885307\n",
      "\n",
      " > BEST MODEL (0.62299) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 100  Loss:  0.597051203250885\n",
      "Write summary at step 110  Loss:  0.7272117137908936\n",
      "Write summary at step 120  Loss:  0.7164151668548584\n",
      "Write summary at step 130  Loss:  0.6409673690795898\n",
      "Write summary at step 140  Loss:  0.6347422003746033\n",
      "Write summary at step 150  Loss:  0.5960570573806763\n",
      "Write summary at step 160  Loss:  0.6430158615112305\n",
      "Write summary at step 170  Loss:  0.7140610218048096\n",
      "Write summary at step 180  Loss:  0.6149722337722778\n",
      "Write summary at step 190  Loss:  0.4889754056930542\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.826530612244898 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.7870216306156406 Acurracy Balanced 0.8716528918105525\n",
      "Loss normal: 0.4437061400741947 Loss Control: 0.5060065600389991 Loss Patient: 0.42473613020782663 Loss balanced:  0.4653713451234129 Loss1+loss2: 0.4653713451234129\n",
      "\n",
      " > BEST MODEL (0.46537) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 200  Loss:  0.75531405210495\n",
      "Write summary at step 210  Loss:  0.6013960242271423\n",
      "Write summary at step 220  Loss:  0.7046416997909546\n",
      "Write summary at step 230  Loss:  0.5185059905052185\n",
      "Write summary at step 240  Loss:  0.8003702163696289\n",
      "Write summary at step 250  Loss:  0.6046373844146729\n",
      "Write summary at step 260  Loss:  0.7085458040237427\n",
      "Write summary at step 270  Loss:  0.48303133249282837\n",
      "Write summary at step 280  Loss:  0.49213069677352905\n",
      "Write summary at step 290  Loss:  1.0457382202148438\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8839285714285714 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.8635607321131448 Acurracy Balanced 0.9071902021221461\n",
      "Loss normal: 0.28466489606974077 Loss Control: 0.31993124458959193 Loss Patient: 0.2739265564203064 Loss balanced:  0.29692890050494913 Loss1+loss2: 0.29692890050494913\n",
      "\n",
      " > BEST MODEL (0.29693) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 300  Loss:  0.5823589563369751\n",
      "Write summary at step 310  Loss:  0.503698468208313\n",
      "Write summary at step 320  Loss:  0.4399556815624237\n",
      "Write summary at step 330  Loss:  0.6658412218093872\n",
      "Write summary at step 340  Loss:  0.6230231523513794\n",
      "Write summary at step 350  Loss:  0.4153279662132263\n",
      "Write summary at step 360  Loss:  0.3858281970024109\n",
      "Write summary at step 370  Loss:  0.5058484077453613\n",
      "Write summary at step 380  Loss:  0.568938136100769\n",
      "Write summary at step 390  Loss:  0.34084320068359375\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8903061224489796 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.8581417128101616\n",
      "Loss normal: 0.42870098859908023 Loss Control: 0.4672798697577148 Loss Patient: 0.41695400093141294 Loss balanced:  0.44211693534456387 Loss1+loss2: 0.44211693534456387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 400  Loss:  0.5565860271453857\n",
      "Write summary at step 410  Loss:  0.6193944215774536\n",
      "Write summary at step 420  Loss:  0.610493540763855\n",
      "Write summary at step 430  Loss:  0.5276404023170471\n",
      "Write summary at step 440  Loss:  0.4050505757331848\n",
      "Write summary at step 450  Loss:  0.572717547416687\n",
      "Write summary at step 460  Loss:  0.38398969173431396\n",
      "Write summary at step 470  Loss:  0.470639169216156\n",
      "Write summary at step 480  Loss:  0.7874711155891418\n",
      "Write summary at step 490  Loss:  0.9926824569702148\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8877551020408163 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.8526772319358447\n",
      "Loss normal: 0.3159357060735323 Loss Control: 0.47360929635053123 Loss Patient: 0.2679252778730059 Loss balanced:  0.37076728711176854 Loss1+loss2: 0.37076728711176854\n",
      "Write summary at step 500  Loss:  0.42529207468032837\n",
      "Saved checkpoint to: result/43/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8864795918367347 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.908485856905158 Acurracy Balanced 0.861346753589191\n",
      "Loss normal: 0.28918691329201873 Loss Control: 0.46490081933026756 Loss Patient: 0.2356833448624254 Loss balanced:  0.3502920820963465 Loss1+loss2: 0.3502920820963465\n",
      "Write summary at step 510  Loss:  0.3719256520271301\n",
      "Write summary at step 520  Loss:  0.553206741809845\n",
      "Write summary at step 530  Loss:  0.6989890336990356\n",
      "Write summary at step 540  Loss:  0.5459955930709839\n",
      "Write summary at step 550  Loss:  0.35480618476867676\n",
      "Write summary at step 560  Loss:  0.4421043395996094\n",
      "Write summary at step 570  Loss:  0.9597327709197998\n",
      "Write summary at step 580  Loss:  0.37130290269851685\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8775510204081632 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.8552412645590682 Acurracy Balanced 0.9030304683451078\n",
      "Loss normal: 0.4132430047100904 Loss Control: 0.1569558422747857 Loss Patient: 0.49128051803830064 Loss balanced:  0.32411818015654315 Loss1+loss2: 0.32411818015654315\n",
      "Write summary at step 590  Loss:  0.36038291454315186\n",
      "Write summary at step 600  Loss:  0.8596566915512085\n",
      "Write summary at step 610  Loss:  0.47324398159980774\n",
      "Write summary at step 620  Loss:  0.5099297165870667\n",
      "Write summary at step 630  Loss:  0.5932239890098572\n",
      "Write summary at step 640  Loss:  0.43173372745513916\n",
      "Write summary at step 650  Loss:  0.49955451488494873\n",
      "Write summary at step 660  Loss:  0.8265838027000427\n",
      "Write summary at step 670  Loss:  0.5455940365791321\n",
      "Write summary at step 680  Loss:  0.6634384989738464\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.870216306156406 Acurracy Balanced 0.9269114317667275\n",
      "Loss normal: 0.4164316257347866 Loss Control: 0.26429530049933764 Loss Patient: 0.46275599893436653 Loss balanced:  0.3635256497168521 Loss1+loss2: 0.3635256497168521\n",
      "Write summary at step 690  Loss:  0.49607521295547485\n",
      "Write summary at step 700  Loss:  0.39365196228027344\n",
      "Write summary at step 710  Loss:  0.9782346487045288\n",
      "Write summary at step 720  Loss:  0.5604971051216125\n",
      "Write summary at step 730  Loss:  0.614169716835022\n",
      "Write summary at step 740  Loss:  0.3562965393066406\n",
      "Write summary at step 750  Loss:  0.2946600914001465\n",
      "Write summary at step 760  Loss:  0.4328244626522064\n",
      "Write summary at step 770  Loss:  0.5069072246551514\n",
      "Write summary at step 780  Loss:  0.5860685706138611\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.8951747088186356 Acurracy Balanced 0.936658392660684\n",
      "Loss normal: 0.28724910987883195 Loss Control: 0.2139895463901791 Loss Patient: 0.3095560978335668 Loss balanced:  0.2617728221118729 Loss1+loss2: 0.2617728221118729\n",
      "\n",
      " > BEST MODEL (0.26177) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 790  Loss:  0.5316070318222046\n",
      "Write summary at step 800  Loss:  0.3546452820301056\n",
      "Write summary at step 810  Loss:  0.7175238132476807\n",
      "Write summary at step 820  Loss:  0.45647984743118286\n",
      "Write summary at step 830  Loss:  0.4953126013278961\n",
      "Write summary at step 840  Loss:  0.30589261651039124\n",
      "Write summary at step 850  Loss:  0.2932429313659668\n",
      "Write summary at step 860  Loss:  0.7690263986587524\n",
      "Write summary at step 870  Loss:  0.8116255402565002\n",
      "Write summary at step 880  Loss:  0.3804149627685547\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.8615922460743933\n",
      "Loss normal: 0.32805427802460535 Loss Control: 0.5404947833285305 Loss Patient: 0.2633677340188558 Loss balanced:  0.40193125867369317 Loss1+loss2: 0.40193125867369317\n",
      "Write summary at step 890  Loss:  0.48560965061187744\n",
      "Write summary at step 900  Loss:  0.7657677531242371\n",
      "Write summary at step 910  Loss:  0.5767086744308472\n",
      "Write summary at step 920  Loss:  0.34754061698913574\n",
      "Write summary at step 930  Loss:  0.4805871844291687\n",
      "Write summary at step 940  Loss:  0.5267094969749451\n",
      "Write summary at step 950  Loss:  0.4425317347049713\n",
      "Write summary at step 960  Loss:  0.38070228695869446\n",
      "Write summary at step 970  Loss:  0.44805601239204407\n",
      "Write summary at step 980  Loss:  0.33062002062797546\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.8835274542429284 Acurracy Balanced 0.9362992462471473\n",
      "Loss normal: 0.32242351663964136 Loss Control: 0.1363665051147586 Loss Patient: 0.37907648532838867 Loss balanced:  0.2577214952215736 Loss1+loss2: 0.2577214952215736\n",
      "\n",
      " > BEST MODEL (0.25772) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 990  Loss:  0.5296698808670044\n",
      "Write summary at step 1000  Loss:  0.6365236639976501\n",
      "Saved checkpoint to: result/43/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.8784584890392151\n",
      "Loss normal: 0.24334973294516 Loss Control: 0.4952725308840392 Loss Patient: 0.1666411266053179 Loss balanced:  0.3309568287446786 Loss1+loss2: 0.3309568287446786\n",
      "Write summary at step 1010  Loss:  0.5069264769554138\n",
      "Write summary at step 1020  Loss:  0.3745827078819275\n",
      "Write summary at step 1030  Loss:  0.45855170488357544\n",
      "Write summary at step 1040  Loss:  0.42384499311447144\n",
      "Write summary at step 1050  Loss:  0.3117084503173828\n",
      "Write summary at step 1060  Loss:  0.3925630450248718\n",
      "Write summary at step 1070  Loss:  0.5230326056480408\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.8768718801996672 Acurracy Balanced 0.9329714592255167\n",
      "Loss normal: 0.294962365636412 Loss Control: 0.14261164919274752 Loss Patient: 0.3413520182627013 Loss balanced:  0.24198183372772442 Loss1+loss2: 0.24198183372772442\n",
      "\n",
      " > BEST MODEL (0.24198) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 1080  Loss:  0.5425974726676941\n",
      "Write summary at step 1090  Loss:  0.27126508951187134\n",
      "Write summary at step 1100  Loss:  0.47004270553588867\n",
      "Write summary at step 1110  Loss:  0.8346408605575562\n",
      "Write summary at step 1120  Loss:  0.3042728900909424\n",
      "Write summary at step 1130  Loss:  0.4401210844516754\n",
      "Write summary at step 1140  Loss:  0.41983741521835327\n",
      "Write summary at step 1150  Loss:  0.6210834383964539\n",
      "Write summary at step 1160  Loss:  0.7052505612373352\n",
      "Write summary at step 1170  Loss:  0.5296987891197205\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.8968386023294509 Acurracy Balanced 0.9429548202904086\n",
      "Loss normal: 0.31593145551730173 Loss Control: 0.11671407984905556 Loss Patient: 0.37659165962365226 Loss balanced:  0.24665286973635392 Loss1+loss2: 0.24665286973635392\n",
      "Write summary at step 1180  Loss:  0.31981098651885986\n",
      "Write summary at step 1190  Loss:  0.4924700856208801\n",
      "Write summary at step 1200  Loss:  0.19052016735076904\n",
      "Write summary at step 1210  Loss:  0.3064693808555603\n",
      "Write summary at step 1220  Loss:  0.3711247146129608\n",
      "Write summary at step 1230  Loss:  0.4603115916252136\n",
      "Write summary at step 1240  Loss:  0.34250903129577637\n",
      "Write summary at step 1250  Loss:  0.6115373373031616\n",
      "Write summary at step 1260  Loss:  0.5763083696365356\n",
      "Write summary at step 1270  Loss:  0.4957329332828522\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.8835274542429284 Acurracy Balanced 0.9390314866843057\n",
      "Loss normal: 0.2678957876502251 Loss Control: 0.1120321954208645 Loss Patient: 0.31535508370835846 Loss balanced:  0.2136936395646115 Loss1+loss2: 0.2136936395646115\n",
      "\n",
      " > BEST MODEL (0.21369) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 1280  Loss:  0.4457910358905792\n",
      "Write summary at step 1290  Loss:  0.22537821531295776\n",
      "Write summary at step 1300  Loss:  0.3682805597782135\n",
      "Write summary at step 1310  Loss:  0.5383831262588501\n",
      "Write summary at step 1320  Loss:  0.446399450302124\n",
      "Write summary at step 1330  Loss:  0.5399484634399414\n",
      "Write summary at step 1340  Loss:  0.27590978145599365\n",
      "Write summary at step 1350  Loss:  0.5274710655212402\n",
      "Write summary at step 1360  Loss:  0.934869647026062\n",
      "Write summary at step 1370  Loss:  0.3821899890899658\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9251429766418446\n",
      "Loss normal: 0.24842886778773093 Loss Control: 0.2978984469273051 Loss Patient: 0.23336575134423332 Loss balanced:  0.26563209913576924 Loss1+loss2: 0.26563209913576924\n",
      "Write summary at step 1380  Loss:  0.48163098096847534\n",
      "Write summary at step 1390  Loss:  0.43979039788246155\n",
      "Write summary at step 1400  Loss:  0.2861441671848297\n",
      "Write summary at step 1410  Loss:  0.5898826122283936\n",
      "Write summary at step 1420  Loss:  0.9589842557907104\n",
      "Write summary at step 1430  Loss:  0.8106685876846313\n",
      "Write summary at step 1440  Loss:  0.6220219135284424\n",
      "Write summary at step 1450  Loss:  0.5456283092498779\n",
      "Write summary at step 1460  Loss:  1.0564724206924438\n",
      "Write summary at step 1470  Loss:  0.5918914675712585\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9459325532127691\n",
      "Loss normal: 0.2430070055534645 Loss Control: 0.19448562544551704 Loss Patient: 0.25778140596264415 Loss balanced:  0.22613351570408058 Loss1+loss2: 0.22613351570408058\n",
      "Write summary at step 1480  Loss:  0.40036070346832275\n",
      "Write summary at step 1490  Loss:  0.3221338987350464\n",
      "Write summary at step 1500  Loss:  0.6870720982551575\n",
      "Saved checkpoint to: result/43/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8684842202885901\n",
      "Loss normal: 0.2317400800482351 Loss Control: 0.4272690145044379 Loss Patient: 0.17220298102909634 Loss balanced:  0.2997359977667671 Loss1+loss2: 0.2997359977667671\n",
      "Write summary at step 1510  Loss:  0.43702253699302673\n",
      "Write summary at step 1520  Loss:  0.3869352340698242\n",
      "Write summary at step 1530  Loss:  0.1930471509695053\n",
      "Write summary at step 1540  Loss:  0.29122722148895264\n",
      "Write summary at step 1550  Loss:  0.2839483320713043\n",
      "Write summary at step 1560  Loss:  0.2164735496044159\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9486647936499277\n",
      "Loss normal: 0.24309528390971982 Loss Control: 0.20153184226953266 Loss Patient: 0.25575103631828866 Loss balanced:  0.22864143929391068 Loss1+loss2: 0.22864143929391068\n",
      "Write summary at step 1570  Loss:  0.3169826567173004\n",
      "Write summary at step 1580  Loss:  0.26885470747947693\n",
      "Write summary at step 1590  Loss:  0.28818172216415405\n",
      "Write summary at step 1600  Loss:  0.3584751784801483\n",
      "Write summary at step 1610  Loss:  0.3778863549232483\n",
      "Write summary at step 1620  Loss:  0.3604307174682617\n",
      "Write summary at step 1630  Loss:  0.4817543625831604\n",
      "Write summary at step 1640  Loss:  0.5073024034500122\n",
      "Write summary at step 1650  Loss:  0.39700251817703247\n",
      "Write summary at step 1660  Loss:  0.359438419342041\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8941326530612245 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.8635607321131448 Acurracy Balanced 0.9290481256194139\n",
      "Loss normal: 0.3453416459414424 Loss Control: 0.07028844683873849 Loss Patient: 0.4290932821553083 Loss balanced:  0.24969086449702338 Loss1+loss2: 0.24969086449702338\n",
      "Write summary at step 1670  Loss:  0.3320223391056061\n",
      "Write summary at step 1680  Loss:  0.39129915833473206\n",
      "Write summary at step 1690  Loss:  0.5307902097702026\n",
      "Write summary at step 1700  Loss:  0.3824917674064636\n",
      "Write summary at step 1710  Loss:  0.4547174572944641\n",
      "Write summary at step 1720  Loss:  0.33652347326278687\n",
      "Write summary at step 1730  Loss:  0.3763323426246643\n",
      "Write summary at step 1740  Loss:  0.31476110219955444\n",
      "Write summary at step 1750  Loss:  0.737883448600769\n",
      "Write summary at step 1760  Loss:  0.5432553291320801\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9284525790349417 Acurracy Balanced 0.9423683660202031\n",
      "Loss normal: 0.21048673755508296 Loss Control: 0.22981529776515858 Loss Patient: 0.20460133457838398 Loss balanced:  0.21720831617177128 Loss1+loss2: 0.21720831617177128\n",
      "Write summary at step 1770  Loss:  0.5386372804641724\n",
      "Write summary at step 1780  Loss:  0.4288330674171448\n",
      "Write summary at step 1790  Loss:  0.40439409017562866\n",
      "Write summary at step 1800  Loss:  0.4026219844818115\n",
      "Write summary at step 1810  Loss:  0.29744213819503784\n",
      "Write summary at step 1820  Loss:  0.6086280345916748\n",
      "Write summary at step 1830  Loss:  0.342074990272522\n",
      "Write summary at step 1840  Loss:  0.31513285636901855\n",
      "Write summary at step 1850  Loss:  0.4118736982345581\n",
      "Write summary at step 1860  Loss:  0.23681631684303284\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9339352445377922\n",
      "Loss normal: 0.24007329489199483 Loss Control: 0.2383684066475415 Loss Patient: 0.24059242029951733 Loss balanced:  0.2394804134735294 Loss1+loss2: 0.2394804134735294\n",
      "Write summary at step 1870  Loss:  0.40669888257980347\n",
      "Write summary at step 1880  Loss:  0.4545568823814392\n",
      "Write summary at step 1890  Loss:  0.570025622844696\n",
      "Write summary at step 1900  Loss:  0.4625985026359558\n",
      "Write summary at step 1910  Loss:  0.3371284604072571\n",
      "Write summary at step 1920  Loss:  0.42431801557540894\n",
      "Write summary at step 1930  Loss:  0.3708571791648865\n",
      "Write summary at step 1940  Loss:  0.40490400791168213\n",
      "Write summary at step 1950  Loss:  0.2172583043575287\n",
      "Write summary at step 1960  Loss:  0.6614413261413574\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9551976214505877\n",
      "Loss normal: 0.2120106499262002 Loss Control: 0.16992006487533695 Loss Patient: 0.22482691682912348 Loss balanced:  0.19737349085223022 Loss1+loss2: 0.19737349085223022\n",
      "\n",
      " > BEST MODEL (0.19737) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 1970  Loss:  0.22318777441978455\n",
      "Write summary at step 1980  Loss:  0.42107605934143066\n",
      "Write summary at step 1990  Loss:  0.3452889323234558\n",
      "Write summary at step 2000  Loss:  0.3714885115623474\n",
      "Saved checkpoint to: result/43/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9484283934789921\n",
      "Loss normal: 0.20475764747480957 Loss Control: 0.22956303071454576 Loss Patient: 0.19720459209999902 Loss balanced:  0.2133838114072724 Loss1+loss2: 0.2133838114072724\n",
      "Write summary at step 2010  Loss:  0.6972792744636536\n",
      "Write summary at step 2020  Loss:  0.5416141748428345\n",
      "Write summary at step 2030  Loss:  0.29962074756622314\n",
      "Write summary at step 2040  Loss:  0.3844586908817291\n",
      "Write summary at step 2050  Loss:  0.25990334153175354\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.8985024958402662 Acurracy Balanced 0.9465190074829746\n",
      "Loss normal: 0.25206454896501135 Loss Control: 0.14928936600033701 Loss Patient: 0.28335882234890725 Loss balanced:  0.21632409417462212 Loss1+loss2: 0.21632409417462212\n",
      "Write summary at step 2060  Loss:  0.3113100230693817\n",
      "Write summary at step 2070  Loss:  0.36682865023612976\n",
      "Write summary at step 2080  Loss:  0.32318422198295593\n",
      "Write summary at step 2090  Loss:  0.5476232767105103\n",
      "Write summary at step 2100  Loss:  0.48593536019325256\n",
      "Write summary at step 2110  Loss:  0.37758058309555054\n",
      "Write summary at step 2120  Loss:  0.8105447888374329\n",
      "Write summary at step 2130  Loss:  0.3549281656742096\n",
      "Write summary at step 2140  Loss:  0.5248373746871948\n",
      "Write summary at step 2150  Loss:  0.5510022640228271\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8895101970304502\n",
      "Loss normal: 0.2280470734956313 Loss Control: 0.3635185035200067 Loss Patient: 0.18679703686528912 Loss balanced:  0.2751577701926479 Loss1+loss2: 0.2751577701926479\n",
      "Write summary at step 2160  Loss:  0.3440055847167969\n",
      "Write summary at step 2170  Loss:  0.420202374458313\n",
      "Write summary at step 2180  Loss:  0.5063096284866333\n",
      "Write summary at step 2190  Loss:  0.5348628163337708\n",
      "Write summary at step 2200  Loss:  0.18041333556175232\n",
      "Write summary at step 2210  Loss:  0.3504291772842407\n",
      "Write summary at step 2220  Loss:  0.5794998407363892\n",
      "Write summary at step 2230  Loss:  0.2680969834327698\n",
      "Write summary at step 2240  Loss:  0.48921310901641846\n",
      "Write summary at step 2250  Loss:  0.4537011384963989\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9464285714285714 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.949855886818872\n",
      "Loss normal: 0.1861821662406532 Loss Control: 0.2414549436074137 Loss Patient: 0.1693520188802689 Loss balanced:  0.2054034812438413 Loss1+loss2: 0.2054034812438413\n",
      "Write summary at step 2260  Loss:  0.31919002532958984\n",
      "Write summary at step 2270  Loss:  0.5557554364204407\n",
      "Write summary at step 2280  Loss:  0.6214385032653809\n",
      "Write summary at step 2290  Loss:  0.43981170654296875\n",
      "Write summary at step 2300  Loss:  0.6131677031517029\n",
      "Write summary at step 2310  Loss:  0.3281257748603821\n",
      "Write summary at step 2320  Loss:  0.31678658723831177\n",
      "Write summary at step 2330  Loss:  0.34060943126678467\n",
      "Write summary at step 2340  Loss:  0.3568083643913269\n",
      "Write summary at step 2350  Loss:  0.46962469816207886\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9497331405762708\n",
      "Loss normal: 0.23391968559245674 Loss Control: 0.15825037324363417 Loss Patient: 0.2569604228667531 Loss balanced:  0.20760539805519362 Loss1+loss2: 0.20760539805519362\n",
      "Write summary at step 2360  Loss:  0.44597968459129333\n",
      "Write summary at step 2370  Loss:  0.559554934501648\n",
      "Write summary at step 2380  Loss:  0.2669767141342163\n",
      "Write summary at step 2390  Loss:  0.5129139423370361\n",
      "Write summary at step 2400  Loss:  0.4969941973686218\n",
      "Write summary at step 2410  Loss:  0.23303844034671783\n",
      "Write summary at step 2420  Loss:  0.26660117506980896\n",
      "Write summary at step 2430  Loss:  0.23386554419994354\n",
      "Write summary at step 2440  Loss:  0.5206570625305176\n",
      "Write summary at step 2450  Loss:  0.3865833878517151\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9519925806715583\n",
      "Loss normal: 0.21560875645705632 Loss Control: 0.24160341942896607 Loss Patient: 0.20769357429615867 Loss balanced:  0.22464849686256239 Loss1+loss2: 0.22464849686256239\n",
      "Write summary at step 2460  Loss:  0.5549200773239136\n",
      "Write summary at step 2470  Loss:  0.24121257662773132\n",
      "Write summary at step 2480  Loss:  0.4753604531288147\n",
      "Write summary at step 2490  Loss:  0.31760895252227783\n",
      "Write summary at step 2500  Loss:  0.34408360719680786\n",
      "Saved checkpoint to: result/43/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9251247920133111 Acurracy Balanced 0.9489011938208631\n",
      "Loss normal: 0.21886647545865603 Loss Control: 0.16374626446291396 Loss Patient: 0.23565016684436957 Loss balanced:  0.19969821565364176 Loss1+loss2: 0.19969821565364176\n",
      "Write summary at step 2510  Loss:  0.3184661269187927\n",
      "Write summary at step 2520  Loss:  0.3392109274864197\n",
      "Write summary at step 2530  Loss:  0.3326197862625122\n",
      "Write summary at step 2540  Loss:  0.17892104387283325\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.9284525790349417 Acurracy Balanced 0.953297327768837\n",
      "Loss normal: 0.22194059174127725 Loss Control: 0.14896910894112508 Loss Patient: 0.24415985503529947 Loss balanced:  0.19656448198821228 Loss1+loss2: 0.19656448198821228\n",
      "\n",
      " > BEST MODEL (0.19656) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 2550  Loss:  0.22770044207572937\n",
      "Write summary at step 2560  Loss:  0.24328866600990295\n",
      "Write summary at step 2570  Loss:  0.2243814766407013\n",
      "Write summary at step 2580  Loss:  0.23187875747680664\n",
      "Write summary at step 2590  Loss:  0.26780879497528076\n",
      "Write summary at step 2600  Loss:  0.34750115871429443\n",
      "Write summary at step 2610  Loss:  0.3309045732021332\n",
      "Write summary at step 2620  Loss:  0.299618124961853\n",
      "Write summary at step 2630  Loss:  0.46869269013404846\n",
      "Write summary at step 2640  Loss:  0.5666918754577637\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9418955656783321\n",
      "Loss normal: 0.21205940637357382 Loss Control: 0.27629649932267236 Loss Patient: 0.19249969304302172 Loss balanced:  0.23439809618284704 Loss1+loss2: 0.23439809618284704\n",
      "Write summary at step 2650  Loss:  0.297404408454895\n",
      "Write summary at step 2660  Loss:  0.6733396649360657\n",
      "Write summary at step 2670  Loss:  0.34455347061157227\n",
      "Write summary at step 2680  Loss:  0.31016892194747925\n",
      "Write summary at step 2690  Loss:  0.41004228591918945\n",
      "Write summary at step 2700  Loss:  0.16662509739398956\n",
      "Write summary at step 2710  Loss:  0.4181494116783142\n",
      "Write summary at step 2720  Loss:  0.5645588636398315\n",
      "Write summary at step 2730  Loss:  0.5147651433944702\n",
      "Write summary at step 2740  Loss:  0.1644691675901413\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.8965158251729812\n",
      "Loss normal: 0.25388468855193685 Loss Control: 0.2720125107491603 Loss Patient: 0.24836490049140028 Loss balanced:  0.2601887056202803 Loss1+loss2: 0.2601887056202803\n",
      "Write summary at step 2750  Loss:  0.26740747690200806\n",
      "Write summary at step 2760  Loss:  0.3307846188545227\n",
      "Write summary at step 2770  Loss:  0.32606053352355957\n",
      "Write summary at step 2780  Loss:  0.33109819889068604\n",
      "Write summary at step 2790  Loss:  0.46779781579971313\n",
      "Write summary at step 2800  Loss:  0.4417960047721863\n",
      "Write summary at step 2810  Loss:  0.40296468138694763\n",
      "Write summary at step 2820  Loss:  0.3090028166770935\n",
      "Write summary at step 2830  Loss:  0.2105395644903183\n",
      "Write summary at step 2840  Loss:  0.3699977993965149\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9497331405762708\n",
      "Loss normal: 0.21036667528809333 Loss Control: 0.19532756466683143 Loss Patient: 0.21494597479229957 Loss balanced:  0.20513676972956552 Loss1+loss2: 0.20513676972956552\n",
      "Write summary at step 2850  Loss:  0.2620795667171478\n",
      "Write summary at step 2860  Loss:  0.4317814111709595\n",
      "Write summary at step 2870  Loss:  0.6063010692596436\n",
      "Write summary at step 2880  Loss:  0.33222949504852295\n",
      "Write summary at step 2890  Loss:  0.3580288887023926\n",
      "Write summary at step 2900  Loss:  0.5443021059036255\n",
      "Write summary at step 2910  Loss:  0.4579954445362091\n",
      "Write summary at step 2920  Loss:  0.23423273861408234\n",
      "Write summary at step 2930  Loss:  0.6059229373931885\n",
      "Write summary at step 2940  Loss:  0.1822502315044403\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9200376421810643\n",
      "Loss normal: 0.22862056239831205 Loss Control: 0.28860807288539864 Loss Patient: 0.21035481577804205 Loss balanced:  0.24948144433172034 Loss1+loss2: 0.24948144433172034\n",
      "Write summary at step 2950  Loss:  0.7534759044647217\n",
      "Write summary at step 2960  Loss:  0.42135319113731384\n",
      "Write summary at step 2970  Loss:  0.494327187538147\n",
      "Write summary at step 2980  Loss:  0.3139059841632843\n",
      "Write summary at step 2990  Loss:  0.6683951616287231\n",
      "Write summary at step 3000  Loss:  0.5114121437072754\n",
      "Saved checkpoint to: result/43/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9511606339161507\n",
      "Loss normal: 0.21874899242301377 Loss Control: 0.1789496765762079 Loss Patient: 0.23086758353398762 Loss balanced:  0.20490863005509774 Loss1+loss2: 0.20490863005509774\n",
      "Write summary at step 3010  Loss:  0.43066227436065674\n",
      "Write summary at step 3020  Loss:  0.39291077852249146\n",
      "Write summary at step 3030  Loss:  0.5477492809295654\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9454597528708982\n",
      "Loss normal: 0.21558701687929582 Loss Control: 0.22972353494883888 Loss Patient: 0.21128255392915993 Loss balanced:  0.2205030444389994 Loss1+loss2: 0.2205030444389994\n",
      "Write summary at step 3040  Loss:  0.4100976586341858\n",
      "Write summary at step 3050  Loss:  0.43393874168395996\n",
      "Write summary at step 3060  Loss:  0.3002406060695648\n",
      "Write summary at step 3070  Loss:  0.42042624950408936\n",
      "Write summary at step 3080  Loss:  0.3715749979019165\n",
      "Write summary at step 3090  Loss:  0.3805171847343445\n",
      "Write summary at step 3100  Loss:  0.19790081679821014\n",
      "Write summary at step 3110  Loss:  0.4427988529205322\n",
      "Write summary at step 3120  Loss:  0.4259943962097168\n",
      "Write summary at step 3130  Loss:  0.46238139271736145\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9551976214505877\n",
      "Loss normal: 0.21000918784007735 Loss Control: 0.1535624490409601 Loss Patient: 0.22719679472847112 Loss balanced:  0.1903796218847156 Loss1+loss2: 0.1903796218847156\n",
      "\n",
      " > BEST MODEL (0.19038) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 3140  Loss:  0.4480583369731903\n",
      "Write summary at step 3150  Loss:  0.4421696662902832\n",
      "Write summary at step 3160  Loss:  0.45192205905914307\n",
      "Write summary at step 3170  Loss:  0.4553890824317932\n",
      "Write summary at step 3180  Loss:  0.40573349595069885\n",
      "Write summary at step 3190  Loss:  0.4427090585231781\n",
      "Write summary at step 3200  Loss:  0.34837019443511963\n",
      "Write summary at step 3210  Loss:  0.46454158425331116\n",
      "Write summary at step 3220  Loss:  0.48999255895614624\n",
      "Write summary at step 3230  Loss:  0.3282363712787628\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9288299100770119\n",
      "Loss normal: 0.1995240076996234 Loss Control: 0.23678668600613953 Loss Patient: 0.1881778006892831 Loss balanced:  0.21248224334771132 Loss1+loss2: 0.21248224334771132\n",
      "Write summary at step 3240  Loss:  0.2594683766365051\n",
      "Write summary at step 3250  Loss:  0.3203481435775757\n",
      "Write summary at step 3260  Loss:  0.6879182457923889\n",
      "Write summary at step 3270  Loss:  0.3008835017681122\n",
      "Write summary at step 3280  Loss:  0.4314550459384918\n",
      "Write summary at step 3290  Loss:  0.500528872013092\n",
      "Write summary at step 3300  Loss:  0.4668511152267456\n",
      "Write summary at step 3310  Loss:  0.2153550684452057\n",
      "Write summary at step 3320  Loss:  0.29933562874794006\n",
      "Write summary at step 3330  Loss:  0.3904745578765869\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9347671912931999\n",
      "Loss normal: 0.27018228599003385 Loss Control: 0.1501201093196869 Loss Patient: 0.306740318231297 Loss balanced:  0.22843021377549194 Loss1+loss2: 0.22843021377549194\n",
      "Write summary at step 3340  Loss:  0.24232280254364014\n",
      "Write summary at step 3350  Loss:  0.2925487160682678\n",
      "Write summary at step 3360  Loss:  0.9567221999168396\n",
      "Write summary at step 3370  Loss:  0.22538642585277557\n",
      "Write summary at step 3380  Loss:  0.42232275009155273\n",
      "Write summary at step 3390  Loss:  0.29221248626708984\n",
      "Write summary at step 3400  Loss:  0.326535165309906\n",
      "Write summary at step 3410  Loss:  0.5445413589477539\n",
      "Write summary at step 3420  Loss:  0.4386560320854187\n",
      "Write summary at step 3430  Loss:  0.42496001720428467\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9160006546466273\n",
      "Loss normal: 0.1873954962939024 Loss Control: 0.32744876771676734 Loss Patient: 0.14475032368584997 Loss balanced:  0.23609954570130864 Loss1+loss2: 0.23609954570130864\n",
      "Write summary at step 3440  Loss:  0.3526208996772766\n",
      "Write summary at step 3450  Loss:  0.20119580626487732\n",
      "Write summary at step 3460  Loss:  0.5084179043769836\n",
      "Write summary at step 3470  Loss:  0.9637855887413025\n",
      "Write summary at step 3480  Loss:  0.4451924264431\n",
      "Write summary at step 3490  Loss:  0.4287545084953308\n",
      "Write summary at step 3500  Loss:  0.33970850706100464\n",
      "Saved checkpoint to: result/43/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9241973759581026\n",
      "Loss normal: 0.19747513703697797 Loss Control: 0.2862850469969661 Loss Patient: 0.17043318396152157 Loss balanced:  0.22835911547924384 Loss1+loss2: 0.22835911547924384\n",
      "Write summary at step 3510  Loss:  0.37374716997146606\n",
      "Write summary at step 3520  Loss:  0.6048979759216309\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8756125946737223\n",
      "Loss normal: 0.22872258623947903 Loss Control: 0.42253904981039914 Loss Patient: 0.1697069227807038 Loss balanced:  0.29612298629555145 Loss1+loss2: 0.29612298629555145\n",
      "Write summary at step 3530  Loss:  0.5526752471923828\n",
      "Write summary at step 3540  Loss:  0.38757583498954773\n",
      "Write summary at step 3550  Loss:  0.5222451686859131\n",
      "Write summary at step 3560  Loss:  0.40239015221595764\n",
      "Write summary at step 3570  Loss:  0.37948718667030334\n",
      "Write summary at step 3580  Loss:  0.2095370888710022\n",
      "Write summary at step 3590  Loss:  0.27682048082351685\n",
      "Write summary at step 3600  Loss:  0.6121333241462708\n",
      "Write summary at step 3610  Loss:  0.5516331791877747\n",
      "Write summary at step 3620  Loss:  0.36204177141189575\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8819090223034469\n",
      "Loss normal: 0.21489970773762587 Loss Control: 0.44006641966397647 Loss Patient: 0.14633812796256307 Loss balanced:  0.2932022738132698 Loss1+loss2: 0.2932022738132698\n",
      "Write summary at step 3630  Loss:  0.35749515891075134\n",
      "Write summary at step 3640  Loss:  0.3846467137336731\n",
      "Write summary at step 3650  Loss:  0.3063071370124817\n",
      "Write summary at step 3660  Loss:  0.6423567533493042\n",
      "Write summary at step 3670  Loss:  0.352405309677124\n",
      "Write summary at step 3680  Loss:  0.38017621636390686\n",
      "Write summary at step 3690  Loss:  0.7210808992385864\n",
      "Write summary at step 3700  Loss:  0.42039188742637634\n",
      "Write summary at step 3710  Loss:  0.31949687004089355\n",
      "Write summary at step 3720  Loss:  0.41689056158065796\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.917900948328378\n",
      "Loss normal: 0.21998262496627108 Loss Control: 0.2862443904407689 Loss Patient: 0.19980641723472545 Loss balanced:  0.24302540383774718 Loss1+loss2: 0.24302540383774718\n",
      "Write summary at step 3730  Loss:  0.3339645266532898\n",
      "Write summary at step 3740  Loss:  0.42906028032302856\n",
      "Write summary at step 3750  Loss:  0.295847088098526\n",
      "Write summary at step 3760  Loss:  0.3069351613521576\n",
      "Write summary at step 3770  Loss:  0.3261871039867401\n",
      "Write summary at step 3780  Loss:  0.27451786398887634\n",
      "Write summary at step 3790  Loss:  0.4065389633178711\n",
      "Write summary at step 3800  Loss:  0.28159594535827637\n",
      "Write summary at step 3810  Loss:  0.24583207070827484\n",
      "Write summary at step 3820  Loss:  0.3590829372406006\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8867779565932917\n",
      "Loss normal: 0.20615406018890897 Loss Control: 0.34675585604756254 Loss Patient: 0.1633418690469023 Loss balanced:  0.2550488625472324 Loss1+loss2: 0.2550488625472324\n",
      "Write summary at step 3830  Loss:  0.5173829793930054\n",
      "Write summary at step 3840  Loss:  0.4494594931602478\n",
      "Write summary at step 3850  Loss:  0.5801094770431519\n",
      "Write summary at step 3860  Loss:  0.3782895803451538\n",
      "Write summary at step 3870  Loss:  0.5867122411727905\n",
      "Write summary at step 3880  Loss:  0.46861571073532104\n",
      "Write summary at step 3890  Loss:  0.3098810315132141\n",
      "Write summary at step 3900  Loss:  0.30346375703811646\n",
      "Write summary at step 3910  Loss:  0.24835629761219025\n",
      "Write summary at step 3920  Loss:  0.3533417284488678\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9132684142094687\n",
      "Loss normal: 0.19976557802637013 Loss Control: 0.28582084993195667 Loss Patient: 0.1735623936833637 Loss balanced:  0.22969162180766017 Loss1+loss2: 0.22969162180766017\n",
      "Write summary at step 3930  Loss:  0.41655340790748596\n",
      "Write summary at step 3940  Loss:  0.2234656810760498\n",
      "Write summary at step 3950  Loss:  0.42425358295440674\n",
      "Write summary at step 3960  Loss:  0.5630054473876953\n",
      "Write summary at step 3970  Loss:  0.5184744000434875\n",
      "Write summary at step 3980  Loss:  0.16512878239154816\n",
      "Write summary at step 3990  Loss:  0.362004816532135\n",
      "Write summary at step 4000  Loss:  0.38838255405426025\n",
      "Saved checkpoint to: result/43/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9465280997972414\n",
      "Loss normal: 0.20250410499165253 Loss Control: 0.1718118601158017 Loss Patient: 0.21184966325164833 Loss balanced:  0.19183076168372504 Loss1+loss2: 0.19183076168372504\n",
      "Write summary at step 4010  Loss:  0.46680301427841187\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7431693989071039 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8499540838129529\n",
      "Loss normal: 0.24333511593238433 Loss Control: 0.5959696450520083 Loss Patient: 0.13596053862829574 Loss balanced:  0.365965091840152 Loss1+loss2: 0.365965091840152\n",
      "Write summary at step 4020  Loss:  0.27463653683662415\n",
      "Write summary at step 4030  Loss:  0.3051060438156128\n",
      "Write summary at step 4040  Loss:  0.31227758526802063\n",
      "Write summary at step 4050  Loss:  0.4224354922771454\n",
      "Write summary at step 4060  Loss:  0.42717644572257996\n",
      "Write summary at step 4070  Loss:  0.6087558269500732\n",
      "Write summary at step 4080  Loss:  0.30810150504112244\n",
      "Write summary at step 4090  Loss:  0.5282242298126221\n",
      "Write summary at step 4100  Loss:  0.42725372314453125\n",
      "Write summary at step 4110  Loss:  0.37206488847732544\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9075675331642163\n",
      "Loss normal: 0.20947975171159725 Loss Control: 0.32577278086396516 Loss Patient: 0.17406939840356442 Loss balanced:  0.2499210896337648 Loss1+loss2: 0.2499210896337648\n",
      "Write summary at step 4120  Loss:  0.3243865966796875\n",
      "Write summary at step 4130  Loss:  0.2904399037361145\n",
      "Write summary at step 4140  Loss:  0.4724527895450592\n",
      "Write summary at step 4150  Loss:  0.5773648023605347\n",
      "Write summary at step 4160  Loss:  0.4730386734008789\n",
      "Write summary at step 4170  Loss:  0.6715630888938904\n",
      "Write summary at step 4180  Loss:  0.36033889651298523\n",
      "Write summary at step 4190  Loss:  0.3703300952911377\n",
      "Write summary at step 4200  Loss:  0.5067681670188904\n",
      "Write summary at step 4210  Loss:  0.4138382375240326\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9443914059445551\n",
      "Loss normal: 0.19798967899868683 Loss Control: 0.20185163437994452 Loss Patient: 0.1968137407783859 Loss balanced:  0.19933268757916522 Loss1+loss2: 0.19933268757916522\n",
      "Write summary at step 4220  Loss:  0.3211328983306885\n",
      "Write summary at step 4230  Loss:  0.3276415765285492\n",
      "Write summary at step 4240  Loss:  0.17591147124767303\n",
      "Write summary at step 4250  Loss:  0.589186429977417\n",
      "Write summary at step 4260  Loss:  0.2916630208492279\n",
      "Write summary at step 4270  Loss:  0.46445101499557495\n",
      "Write summary at step 4280  Loss:  0.3340590298175812\n",
      "Write summary at step 4290  Loss:  0.3982088267803192\n",
      "Write summary at step 4300  Loss:  0.16095751523971558\n",
      "Write summary at step 4310  Loss:  0.3938506245613098\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8966385714155825\n",
      "Loss normal: 0.21666080383013706 Loss Control: 0.3453214380259071 Loss Patient: 0.17748460045918055 Loss balanced:  0.26140301924254383 Loss1+loss2: 0.26140301924254383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 4320  Loss:  0.42400968074798584\n",
      "Write summary at step 4330  Loss:  0.5559101104736328\n",
      "Write summary at step 4340  Loss:  0.47332265973091125\n",
      "Write summary at step 4350  Loss:  0.22470763325691223\n",
      "Write summary at step 4360  Loss:  0.591033935546875\n",
      "Write summary at step 4370  Loss:  0.23303334414958954\n",
      "Write summary at step 4380  Loss:  0.48309481143951416\n",
      "Write summary at step 4390  Loss:  0.38941770792007446\n",
      "Write summary at step 4400  Loss:  0.2870129346847534\n",
      "Write summary at step 4410  Loss:  0.34955212473869324\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8920060372966732\n",
      "Loss normal: 0.21332778230461538 Loss Control: 0.33328636813033474 Loss Patient: 0.17680129071638706 Loss balanced:  0.2550438294233609 Loss1+loss2: 0.2550438294233609\n",
      "Write summary at step 4420  Loss:  0.536468505859375\n",
      "Write summary at step 4430  Loss:  0.2756762206554413\n",
      "Write summary at step 4440  Loss:  0.3250071406364441\n",
      "Write summary at step 4450  Loss:  0.4235968589782715\n",
      "Write summary at step 4460  Loss:  0.23416799306869507\n",
      "Write summary at step 4470  Loss:  0.23693789541721344\n",
      "Write summary at step 4480  Loss:  0.14148299396038055\n",
      "Write summary at step 4490  Loss:  0.6563351154327393\n",
      "Write summary at step 4500  Loss:  0.5197799205780029\n",
      "Saved checkpoint to: result/43/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8665839266068392\n",
      "Loss normal: 0.23687880528064406 Loss Control: 0.5267626258844886 Loss Patient: 0.14861135655229976 Loss balanced:  0.3376869912183942 Loss1+loss2: 0.3376869912183942\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8821454224743824\n",
      "Loss normal: 0.2281936911904082 Loss Control: 0.3980665991866523 Loss Patient: 0.17646866583090257 Loss balanced:  0.28726763250877746 Loss1+loss2: 0.28726763250877746\n",
      "Write summary at step 4510  Loss:  0.46450963616371155\n",
      "Write summary at step 4520  Loss:  0.29165416955947876\n",
      "Write summary at step 4530  Loss:  0.22244970500469208\n",
      "Write summary at step 4540  Loss:  0.6038608551025391\n",
      "Write summary at step 4550  Loss:  0.4641529321670532\n",
      "Write summary at step 4560  Loss:  0.32812798023223877\n",
      "Write summary at step 4570  Loss:  0.2930310070514679\n",
      "Write summary at step 4580  Loss:  0.2890620827674866\n",
      "Write summary at step 4590  Loss:  0.8424013257026672\n",
      "Write summary at step 4600  Loss:  0.36718618869781494\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9168326014020349\n",
      "Loss normal: 0.21086222286887316 Loss Control: 0.2814280029203071 Loss Patient: 0.18937546861499002 Loss balanced:  0.23540173576764856 Loss1+loss2: 0.23540173576764856\n",
      "Write summary at step 4610  Loss:  0.2545534074306488\n",
      "Write summary at step 4620  Loss:  0.4672415256500244\n",
      "Write summary at step 4630  Loss:  0.37349241971969604\n",
      "Write summary at step 4640  Loss:  0.5770863890647888\n",
      "Write summary at step 4650  Loss:  0.4275639057159424\n",
      "Write summary at step 4660  Loss:  0.243195578455925\n",
      "Write summary at step 4670  Loss:  0.4450504183769226\n",
      "Write summary at step 4680  Loss:  0.3907930552959442\n",
      "Write summary at step 4690  Loss:  0.3918578624725342\n",
      "Write summary at step 4700  Loss:  0.3721972107887268\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9040033459716501\n",
      "Loss normal: 0.21389295974252176 Loss Control: 0.33761462390097113 Loss Patient: 0.17622063760823894 Loss balanced:  0.25691763075460505 Loss1+loss2: 0.25691763075460505\n",
      "Write summary at step 4710  Loss:  0.5942367315292358\n",
      "Write summary at step 4720  Loss:  0.2867724895477295\n",
      "Write summary at step 4730  Loss:  0.4242093563079834\n",
      "Write summary at step 4740  Loss:  0.24751658737659454\n",
      "Write summary at step 4750  Loss:  0.5505018830299377\n",
      "Write summary at step 4760  Loss:  0.4891509413719177\n",
      "Write summary at step 4770  Loss:  0.3302665054798126\n",
      "Write summary at step 4780  Loss:  0.19022804498672485\n",
      "Write summary at step 4790  Loss:  0.6468479633331299\n",
      "Write summary at step 4800  Loss:  0.34273242950439453\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8747806479183147\n",
      "Loss normal: 0.2454971097865883 Loss Control: 0.43492925948784 Loss Patient: 0.18781643474905343 Loss balanced:  0.3113728471184467 Loss1+loss2: 0.3113728471184467\n",
      "Write summary at step 4810  Loss:  0.42948615550994873\n",
      "Write summary at step 4820  Loss:  0.49070048332214355\n",
      "Write summary at step 4830  Loss:  0.719683051109314\n",
      "Write summary at step 4840  Loss:  0.33688533306121826\n",
      "Write summary at step 4850  Loss:  0.27266746759414673\n",
      "Write summary at step 4860  Loss:  0.33109456300735474\n",
      "Write summary at step 4870  Loss:  0.2263002097606659\n",
      "Write summary at step 4880  Loss:  0.39929330348968506\n",
      "Write summary at step 4890  Loss:  0.35972633957862854\n",
      "Write summary at step 4900  Loss:  0.3178000748157501\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8848776629115409\n",
      "Loss normal: 0.2234488018617338 Loss Control: 0.41225873479426234 Loss Patient: 0.16595758945245712 Loss balanced:  0.2891081621233597 Loss1+loss2: 0.2891081621233597\n",
      "Write summary at step 4910  Loss:  0.4773949384689331\n",
      "Write summary at step 4920  Loss:  0.3223392367362976\n",
      "Write summary at step 4930  Loss:  0.6391112804412842\n",
      "Write summary at step 4940  Loss:  0.4528016149997711\n",
      "Write summary at step 4950  Loss:  0.4548801779747009\n",
      "Write summary at step 4960  Loss:  0.41447776556015015\n",
      "Write summary at step 4970  Loss:  0.5644996166229248\n",
      "Write summary at step 4980  Loss:  0.19838201999664307\n",
      "Write summary at step 4990  Loss:  0.2048783302307129\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8655155796804961\n",
      "Loss normal: 0.23523278237909687 Loss Control: 0.4577181101496754 Loss Patient: 0.16748766816792987 Loss balanced:  0.31260288915880263 Loss1+loss2: 0.31260288915880263\n",
      "Write summary at step 5000  Loss:  0.2218402624130249\n",
      "Saved checkpoint to: result/43/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8674158733622469\n",
      "Loss normal: 0.23673338047703918 Loss Control: 0.4363724077985586 Loss Patient: 0.17594479739715574 Loss balanced:  0.3061586025978572 Loss1+loss2: 0.3061586025978572\n",
      "Write summary at step 5010  Loss:  0.33533936738967896\n",
      "Write summary at step 5020  Loss:  0.3660775423049927\n",
      "Write summary at step 5030  Loss:  0.5031614303588867\n",
      "Write summary at step 5040  Loss:  0.5486949682235718\n",
      "Write summary at step 5050  Loss:  0.37634000182151794\n",
      "Write summary at step 5060  Loss:  0.2883532643318176\n",
      "Write summary at step 5070  Loss:  0.4459080994129181\n",
      "Write summary at step 5080  Loss:  0.4286426305770874\n",
      "Write summary at step 5090  Loss:  0.7235899567604065\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8554185646872698\n",
      "Loss normal: 0.2553722856148165 Loss Control: 0.5012076005258196 Loss Patient: 0.18051727299583137 Loss balanced:  0.3408624367608255 Loss1+loss2: 0.3408624367608255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 5100  Loss:  0.4170942008495331\n",
      "Write summary at step 5110  Loss:  0.4766392111778259\n",
      "Write summary at step 5120  Loss:  0.4278675317764282\n",
      "Write summary at step 5130  Loss:  0.12805688381195068\n",
      "Write summary at step 5140  Loss:  0.3310696482658386\n",
      "Write summary at step 5150  Loss:  0.24982315301895142\n",
      "Write summary at step 5160  Loss:  0.3524829149246216\n",
      "Write summary at step 5170  Loss:  0.3005879819393158\n",
      "Write summary at step 5180  Loss:  0.3311774730682373\n",
      "Write summary at step 5190  Loss:  0.6612830758094788\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8895101970304502\n",
      "Loss normal: 0.24154786218185814 Loss Control: 0.34464317885904366 Loss Patient: 0.21015611221508654 Loss balanced:  0.2773996455370651 Loss1+loss2: 0.2773996455370651\n",
      "Write summary at step 5200  Loss:  0.3511245846748352\n",
      "Write summary at step 5210  Loss:  0.47272467613220215\n",
      "Write summary at step 5220  Loss:  0.2999712824821472\n",
      "Write summary at step 5230  Loss:  0.2899026572704315\n",
      "Write summary at step 5240  Loss:  0.40766406059265137\n",
      "Write summary at step 5250  Loss:  0.282019704580307\n",
      "Write summary at step 5260  Loss:  0.5867906808853149\n",
      "Write summary at step 5270  Loss:  0.4915739893913269\n",
      "Write summary at step 5280  Loss:  0.28365185856819153\n",
      "Write summary at step 5290  Loss:  0.24721360206604004\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9021030522898994\n",
      "Loss normal: 0.20484786186063167 Loss Control: 0.3027799461708694 Loss Patient: 0.17502827608892801 Loss balanced:  0.2389041111298987 Loss1+loss2: 0.2389041111298987\n",
      "Write summary at step 5300  Loss:  0.3134597837924957\n",
      "Write summary at step 5310  Loss:  0.3530915677547455\n",
      "Write summary at step 5320  Loss:  0.36049747467041016\n",
      "Write summary at step 5330  Loss:  0.375233918428421\n",
      "Write summary at step 5340  Loss:  0.2554614543914795\n",
      "Write summary at step 5350  Loss:  0.22837677597999573\n",
      "Write summary at step 5360  Loss:  0.2099996656179428\n",
      "Write summary at step 5370  Loss:  0.24724139273166656\n",
      "Write summary at step 5380  Loss:  0.37599796056747437\n",
      "Write summary at step 5390  Loss:  0.38332441449165344\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.947360046552649\n",
      "Loss normal: 0.21483785613458983 Loss Control: 0.1553773244873422 Loss Patient: 0.23294314298276694 Loss balanced:  0.1941602337350546 Loss1+loss2: 0.1941602337350546\n",
      "Write summary at step 5400  Loss:  0.42405441403388977\n",
      "Write summary at step 5410  Loss:  0.40840214490890503\n",
      "Write summary at step 5420  Loss:  0.40125107765197754\n",
      "Write summary at step 5430  Loss:  0.4067677855491638\n",
      "Write summary at step 5440  Loss:  0.44468462467193604\n",
      "Write summary at step 5450  Loss:  0.743943452835083\n",
      "Write summary at step 5460  Loss:  0.21401533484458923\n",
      "Write summary at step 5470  Loss:  0.4151049256324768\n",
      "Write summary at step 5480  Loss:  0.3314967453479767\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.87644454142913\n",
      "Loss normal: 0.20455552728808657 Loss Control: 0.3775957738115488 Loss Patient: 0.1518660692525981 Loss balanced:  0.26473092153207345 Loss1+loss2: 0.26473092153207345\n",
      "Write summary at step 5490  Loss:  0.2984921336174011\n",
      "Write summary at step 5500  Loss:  0.25317516922950745\n",
      "Saved checkpoint to: result/43/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.914932307720284\n",
      "Loss normal: 0.20768402402802388 Loss Control: 0.27949656537973167 Loss Patient: 0.1858176394627614 Loss balanced:  0.23265710242124654 Loss1+loss2: 0.23265710242124654\n",
      "Write summary at step 5510  Loss:  0.33111804723739624\n",
      "Write summary at step 5520  Loss:  0.3453805148601532\n",
      "Write summary at step 5530  Loss:  0.36112192273139954\n",
      "Write summary at step 5540  Loss:  0.1286746859550476\n",
      "Write summary at step 5550  Loss:  0.16464239358901978\n",
      "Write summary at step 5560  Loss:  0.47262993454933167\n",
      "Write summary at step 5570  Loss:  1.0925735235214233\n",
      "Write summary at step 5580  Loss:  0.28629010915756226\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9348899375358011\n",
      "Loss normal: 0.19594811853401514 Loss Control: 0.2798915029874916 Loss Patient: 0.17038798758670218 Loss balanced:  0.2251397452870969 Loss1+loss2: 0.2251397452870969\n",
      "Write summary at step 5590  Loss:  0.4511430263519287\n",
      "Write summary at step 5600  Loss:  0.18368196487426758\n",
      "Write summary at step 5610  Loss:  0.3105515241622925\n",
      "Write summary at step 5620  Loss:  0.3385995626449585\n",
      "Write summary at step 5630  Loss:  0.26163971424102783\n",
      "Write summary at step 5640  Loss:  0.38978907465934753\n",
      "Write summary at step 5650  Loss:  0.20577450096607208\n",
      "Write summary at step 5660  Loss:  0.5346852540969849\n",
      "Write summary at step 5670  Loss:  0.25660207867622375\n",
      "Write summary at step 5680  Loss:  0.41565608978271484\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9489795918367347 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9629215424201922\n",
      "Loss normal: 0.200535065665537 Loss Control: 0.13068522325630397 Loss Patient: 0.2218038187348307 Loss balanced:  0.17624452099556734 Loss1+loss2: 0.17624452099556734\n",
      "\n",
      " > BEST MODEL (0.17624) : result/43/panns/best_checkpoint.pt\n",
      "Write summary at step 5690  Loss:  0.2868318259716034\n",
      "Write summary at step 5700  Loss:  0.45081475377082825\n",
      "Write summary at step 5710  Loss:  0.19102616608142853\n",
      "Write summary at step 5720  Loss:  0.7631036043167114\n",
      "Write summary at step 5730  Loss:  0.5249119400978088\n",
      "Write summary at step 5740  Loss:  0.3056287467479706\n",
      "Write summary at step 5750  Loss:  0.2843359708786011\n",
      "Write summary at step 5760  Loss:  0.5167146325111389\n",
      "Write summary at step 5770  Loss:  0.46906596422195435\n",
      "Write summary at step 5780  Loss:  0.16330362856388092\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9285935099060765\n",
      "Loss normal: 0.18678984844258853 Loss Control: 0.2859802803055185 Loss Patient: 0.15658710532497844 Loss balanced:  0.22128369281524846 Loss1+loss2: 0.22128369281524846\n",
      "Write summary at step 5790  Loss:  0.38261568546295166\n",
      "Write summary at step 5800  Loss:  0.3672589659690857\n",
      "Write summary at step 5810  Loss:  0.5724263191223145\n",
      "Write summary at step 5820  Loss:  0.3632846176624298\n",
      "Write summary at step 5830  Loss:  0.2162066549062729\n",
      "Write summary at step 5840  Loss:  0.26146984100341797\n",
      "Write summary at step 5850  Loss:  0.17345046997070312\n",
      "Write summary at step 5860  Loss:  0.08383660763502121\n",
      "Write summary at step 5870  Loss:  0.3435152471065521\n",
      "Write summary at step 5880  Loss:  0.38366201519966125\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8646836329250884\n",
      "Loss normal: 0.23773895778066043 Loss Control: 0.4522728408620657 Loss Patient: 0.17241499540140348 Loss balanced:  0.31234391813173457 Loss1+loss2: 0.31234391813173457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 5890  Loss:  0.47855547070503235\n",
      "Write summary at step 5900  Loss:  0.28153228759765625\n",
      "Write summary at step 5910  Loss:  0.5130592584609985\n",
      "Write summary at step 5920  Loss:  0.3568125069141388\n",
      "Write summary at step 5930  Loss:  0.5169683694839478\n",
      "Write summary at step 5940  Loss:  0.3000326156616211\n",
      "Write summary at step 5950  Loss:  0.2464403212070465\n",
      "Write summary at step 5960  Loss:  0.3587525486946106\n",
      "Write summary at step 5970  Loss:  0.5176366567611694\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9277615631506688\n",
      "Loss normal: 0.2061634471221846 Loss Control: 0.23407981874512845 Loss Patient: 0.19766311374757928 Loss balanced:  0.21587146624635387 Loss1+loss2: 0.21587146624635387\n",
      "Write summary at step 5980  Loss:  0.5311282873153687\n",
      "Write summary at step 5990  Loss:  0.3867841362953186\n",
      "Write summary at step 6000  Loss:  0.32970789074897766\n",
      "Saved checkpoint to: result/43/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9489795918367347 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.945818899284435\n",
      "Loss normal: 0.20483963191509247 Loss Control: 0.22641868083203426 Loss Patient: 0.1982689719033519 Loss balanced:  0.21234382636769308 Loss1+loss2: 0.21234382636769308\n",
      "Write summary at step 6010  Loss:  0.33902204036712646\n",
      "Write summary at step 6020  Loss:  0.48571640253067017\n",
      "Write summary at step 6030  Loss:  0.36912697553634644\n",
      "Write summary at step 6040  Loss:  0.8225382566452026\n",
      "Write summary at step 6050  Loss:  0.30565300583839417\n",
      "Write summary at step 6060  Loss:  0.2779644727706909\n",
      "Write summary at step 6070  Loss:  0.6672036647796631\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9528061224489796 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9597165016411627\n",
      "Loss normal: 0.1950625295237619 Loss Control: 0.18529081800596311 Loss Patient: 0.19803794298612337 Loss balanced:  0.19166438049604323 Loss1+loss2: 0.19166438049604323\n",
      "Write summary at step 6080  Loss:  0.35941648483276367\n",
      "Write summary at step 6090  Loss:  0.4387924075126648\n",
      "Write summary at step 6100  Loss:  0.4169769585132599\n",
      "Write summary at step 6110  Loss:  0.2569648027420044\n",
      "Write summary at step 6120  Loss:  0.48060277104377747\n",
      "Write summary at step 6130  Loss:  0.4861743152141571\n",
      "Write summary at step 6140  Loss:  0.5836267471313477\n",
      "Write summary at step 6150  Loss:  0.24918806552886963\n",
      "Write summary at step 6160  Loss:  0.35410475730895996\n",
      "Write summary at step 6170  Loss:  0.333291620016098\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.639344262295082 Acurracy Patient:  0.9650582362728786 Acurracy Balanced 0.8022012492839803\n",
      "Loss normal: 0.24578386374122027 Loss Control: 0.6442110629681029 Loss Patient: 0.1244657657383484 Loss balanced:  0.3843384143532257 Loss1+loss2: 0.3843384143532257\n",
      "Write summary at step 6180  Loss:  0.39289289712905884\n",
      "Write summary at step 6190  Loss:  0.41687363386154175\n",
      "Write summary at step 6200  Loss:  0.2831401824951172\n",
      "Write summary at step 6210  Loss:  0.3601318895816803\n",
      "Write summary at step 6220  Loss:  0.589458703994751\n",
      "Write summary at step 6230  Loss:  0.3809075951576233\n",
      "Write summary at step 6240  Loss:  0.3753040134906769\n",
      "Write summary at step 6250  Loss:  0.6590352058410645\n",
      "Write summary at step 6260  Loss:  0.21431341767311096\n",
      "Write summary at step 6270  Loss:  0.2990775406360626\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8865415564223562\n",
      "Loss normal: 0.2206780307222994 Loss Control: 0.375680614201749 Loss Patient: 0.1734809092991364 Loss balanced:  0.27458076175044266 Loss1+loss2: 0.27458076175044266\n",
      "Write summary at step 6280  Loss:  0.3044901192188263\n",
      "Write summary at step 6290  Loss:  0.6465160846710205\n",
      "Write summary at step 6300  Loss:  0.32573819160461426\n",
      "Write summary at step 6310  Loss:  0.417583167552948\n",
      "Write summary at step 6320  Loss:  0.22200894355773926\n",
      "Write summary at step 6330  Loss:  0.7862098813056946\n",
      "Write summary at step 6340  Loss:  0.34637826681137085\n",
      "Write summary at step 6350  Loss:  0.23164306581020355\n",
      "Write summary at step 6360  Loss:  0.33187466859817505\n",
      "Write summary at step 6370  Loss:  0.2450372278690338\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.6885245901639344 Acurracy Patient:  0.9667221297836939 Acurracy Balanced 0.8276233599738141\n",
      "Loss normal: 0.23270183740829936 Loss Control: 0.5611363890392532 Loss Patient: 0.13269598040723563 Loss balanced:  0.3469161847232444 Loss1+loss2: 0.3469161847232444\n",
      "Write summary at step 6380  Loss:  0.3421406149864197\n",
      "Write summary at step 6390  Loss:  0.42444875836372375\n",
      "Write summary at step 6400  Loss:  0.26209282875061035\n",
      "Write summary at step 6410  Loss:  0.36222127079963684\n",
      "Write summary at step 6420  Loss:  0.4618656635284424\n",
      "Write summary at step 6430  Loss:  0.4989280700683594\n",
      "Write summary at step 6440  Loss:  0.3889884948730469\n",
      "Write summary at step 6450  Loss:  0.19810330867767334\n",
      "Write summary at step 6460  Loss:  0.32683974504470825\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9012711055344917\n",
      "Loss normal: 0.21697029148285485 Loss Control: 0.29650339028222966 Loss Patient: 0.1927530558132094 Loss balanced:  0.24462822304771953 Loss1+loss2: 0.24462822304771953\n",
      "Write summary at step 6470  Loss:  0.4239879548549652\n",
      "Write summary at step 6480  Loss:  0.2936340570449829\n",
      "Write summary at step 6490  Loss:  0.2984023690223694\n",
      "Write summary at step 6500  Loss:  0.3253777325153351\n",
      "Saved checkpoint to: result/43/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9231290290317595\n",
      "Loss normal: 0.1938718846447918 Loss Control: 0.2688463499637249 Loss Patient: 0.17104271888584147 Loss balanced:  0.21994453442478318 Loss1+loss2: 0.21994453442478318\n",
      "Write summary at step 6510  Loss:  0.3224000334739685\n",
      "Write summary at step 6520  Loss:  0.2681964635848999\n",
      "Write summary at step 6530  Loss:  0.35180437564849854\n",
      "Write summary at step 6540  Loss:  0.5768252611160278\n",
      "Write summary at step 6550  Loss:  0.33230674266815186\n",
      "Write summary at step 6560  Loss:  0.4723231792449951\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.8633788858278097\n",
      "Loss normal: 0.22873272872244826 Loss Control: 0.4982485774436284 Loss Patient: 0.1466671698749958 Loss balanced:  0.3224578736593121 Loss1+loss2: 0.3224578736593121\n",
      "Write summary at step 6570  Loss:  0.4180668890476227\n",
      "Write summary at step 6580  Loss:  0.6030988693237305\n",
      "Write summary at step 6590  Loss:  0.13425381481647491\n",
      "Write summary at step 6600  Loss:  0.12703922390937805\n",
      "Write summary at step 6610  Loss:  0.7467936277389526\n",
      "Write summary at step 6620  Loss:  0.3444213569164276\n",
      "Write summary at step 6630  Loss:  0.3190003037452698\n",
      "Write summary at step 6640  Loss:  0.27962958812713623\n",
      "Write summary at step 6650  Loss:  0.46030473709106445\n",
      "Write summary at step 6660  Loss:  0.2527237832546234\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8928571428571429 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.9683860232945092 Acurracy Balanced 0.8065973832319541\n",
      "Loss normal: 0.2809240548890464 Loss Control: 0.8074096812576544 Loss Patient: 0.12061312125248838 Loss balanced:  0.4640114012550714 Loss1+loss2: 0.4640114012550714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 6670  Loss:  0.5535075068473816\n",
      "Write summary at step 6680  Loss:  0.3793410062789917\n",
      "Write summary at step 6690  Loss:  0.40546363592147827\n",
      "Write summary at step 6700  Loss:  0.4055187702178955\n",
      "Write summary at step 6710  Loss:  0.4046248495578766\n",
      "Write summary at step 6720  Loss:  0.3113557696342468\n",
      "Write summary at step 6730  Loss:  0.3436625301837921\n",
      "Write summary at step 6740  Loss:  0.2714349031448364\n",
      "Write summary at step 6750  Loss:  0.2574506998062134\n",
      "Write summary at step 6760  Loss:  0.24333080649375916\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.7213114754098361 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.839025122064319\n",
      "Loss normal: 0.25401064342990215 Loss Control: 0.6144824376523169 Loss Patient: 0.1442496847243555 Loss balanced:  0.3793660611883362 Loss1+loss2: 0.3793660611883362\n",
      "Write summary at step 6770  Loss:  0.34154263138771057\n",
      "Write summary at step 6780  Loss:  0.318789005279541\n",
      "Write summary at step 6790  Loss:  0.5035978555679321\n",
      "Write summary at step 6800  Loss:  0.43624794483184814\n",
      "Write summary at step 6810  Loss:  0.4634709358215332\n",
      "Write summary at step 6820  Loss:  0.5107741355895996\n",
      "Write summary at step 6830  Loss:  0.41152817010879517\n",
      "Write summary at step 6840  Loss:  0.4833085536956787\n",
      "Write summary at step 6850  Loss:  0.3055894374847412\n",
      "Write summary at step 6860  Loss:  0.25177860260009766\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9212287353500086\n",
      "Loss normal: 0.18239652679054713 Loss Control: 0.3191265340059833 Loss Patient: 0.14076326232087394 Loss balanced:  0.2299448981634286 Loss1+loss2: 0.2299448981634286\n",
      "Write summary at step 6870  Loss:  0.2715686559677124\n",
      "Write summary at step 6880  Loss:  0.45405876636505127\n",
      "Write summary at step 6890  Loss:  0.23373641073703766\n",
      "Write summary at step 6900  Loss:  0.4619969129562378\n",
      "Write summary at step 6910  Loss:  0.49320149421691895\n",
      "Write summary at step 6920  Loss:  0.42335695028305054\n",
      "Write summary at step 6930  Loss:  0.1940709352493286\n",
      "Write summary at step 6940  Loss:  0.5615890026092529\n",
      "Write summary at step 6950  Loss:  0.2724277377128601\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.9037669458007147\n",
      "Loss normal: 0.21346902223874112 Loss Control: 0.3336334339256495 Loss Patient: 0.1768798574730878 Loss balanced:  0.2552566456993686 Loss1+loss2: 0.2552566456993686\n",
      "Write summary at step 6960  Loss:  0.45425182580947876\n",
      "Write summary at step 6970  Loss:  0.41527271270751953\n",
      "Write summary at step 6980  Loss:  0.3631132245063782\n",
      "Write summary at step 6990  Loss:  0.2849394679069519\n",
      "Write summary at step 7000  Loss:  0.33388751745224\n",
      "Saved checkpoint to: result/43/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9502551020408163 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.952351727085095\n",
      "Loss normal: 0.19119408836930382 Loss Control: 0.24561611387899013 Loss Patient: 0.17462298804630655 Loss balanced:  0.21011955096264834 Loss1+loss2: 0.21011955096264834\n",
      "Write summary at step 7010  Loss:  0.32508981227874756\n",
      "Write summary at step 7020  Loss:  0.2906248867511749\n",
      "Write summary at step 7030  Loss:  0.3756261467933655\n",
      "Write summary at step 7040  Loss:  0.23301246762275696\n",
      "Write summary at step 7050  Loss:  0.15977385640144348\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9378585781438951\n",
      "Loss normal: 0.20627745453800475 Loss Control: 0.19277904463596032 Loss Patient: 0.2103876171388761 Loss balanced:  0.2015833308874182 Loss1+loss2: 0.2015833308874182\n",
      "Write summary at step 7060  Loss:  0.36718809604644775\n",
      "Write summary at step 7070  Loss:  0.3401009440422058\n",
      "Write summary at step 7080  Loss:  0.31957578659057617\n",
      "Write summary at step 7090  Loss:  0.5184648036956787\n",
      "Write summary at step 7100  Loss:  0.4683247208595276\n",
      "Write summary at step 7110  Loss:  0.457317054271698\n",
      "Write summary at step 7120  Loss:  0.270598441362381\n",
      "Write summary at step 7130  Loss:  0.35444125533103943\n",
      "Write summary at step 7140  Loss:  0.2605155408382416\n",
      "Write summary at step 7150  Loss:  0.39636701345443726\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9443914059445551\n",
      "Loss normal: 0.17987889902932302 Loss Control: 0.18522229171841523 Loss Patient: 0.1782518778981861 Loss balanced:  0.18173708480830067 Loss1+loss2: 0.18173708480830067\n",
      "Write summary at step 7160  Loss:  0.3596232831478119\n",
      "Write summary at step 7170  Loss:  0.41976580023765564\n",
      "Write summary at step 7180  Loss:  0.3759952783584595\n",
      "Write summary at step 7190  Loss:  0.20373918116092682\n",
      "Write summary at step 7200  Loss:  0.3136409521102905\n",
      "Write summary at step 7210  Loss:  0.27812570333480835\n",
      "Write summary at step 7220  Loss:  0.3947789669036865\n",
      "Write summary at step 7230  Loss:  0.3610704839229584\n",
      "Write summary at step 7240  Loss:  0.23142990469932556\n",
      "Write summary at step 7250  Loss:  0.34968453645706177\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.9010347053635562\n",
      "Loss normal: 0.2006870829405225 Loss Control: 0.3794087744801422 Loss Patient: 0.1462676648961724 Loss balanced:  0.2628382196881573 Loss1+loss2: 0.2628382196881573\n",
      "Write summary at step 7260  Loss:  0.18864309787750244\n",
      "Write summary at step 7270  Loss:  0.411579966545105\n",
      "Write summary at step 7280  Loss:  0.5576362013816833\n",
      "Write summary at step 7290  Loss:  0.4359869062900543\n",
      "Write summary at step 7300  Loss:  0.49927157163619995\n",
      "Write summary at step 7310  Loss:  0.32701200246810913\n",
      "Write summary at step 7320  Loss:  0.17818154394626617\n",
      "Write summary at step 7330  Loss:  0.31717410683631897\n",
      "Write summary at step 7340  Loss:  0.4089513123035431\n",
      "Write summary at step 7350  Loss:  0.46065229177474976\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8638516861696808\n",
      "Loss normal: 0.2497386277786323 Loss Control: 0.5551076235015535 Loss Patient: 0.15675605551499297 Loss balanced:  0.35593183950827323 Loss1+loss2: 0.35593183950827323\n",
      "Write summary at step 7360  Loss:  0.5747783184051514\n",
      "Write summary at step 7370  Loss:  0.4481153190135956\n",
      "Write summary at step 7380  Loss:  0.3645663857460022\n",
      "Write summary at step 7390  Loss:  0.30703237652778625\n",
      "Write summary at step 7400  Loss:  0.26686587929725647\n",
      "Write summary at step 7410  Loss:  0.37432289123535156\n",
      "Write summary at step 7420  Loss:  0.09721790999174118\n",
      "Write summary at step 7430  Loss:  0.476967990398407\n",
      "Write summary at step 7440  Loss:  0.33427757024765015\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8949746779047671\n",
      "Loss normal: 0.2056632864916203 Loss Control: 0.3772776605652981 Loss Patient: 0.15340799473833522 Loss balanced:  0.26534282765181666 Loss1+loss2: 0.26534282765181666\n",
      "Write summary at step 7450  Loss:  0.5019349455833435\n",
      "Write summary at step 7460  Loss:  0.5420852303504944\n",
      "Write summary at step 7470  Loss:  0.2600475251674652\n",
      "Write summary at step 7480  Loss:  0.43929991126060486\n",
      "Write summary at step 7490  Loss:  0.28252190351486206\n",
      "Write summary at step 7500  Loss:  0.3057021498680115\n",
      "Saved checkpoint to: result/43/panns/checkpoint_7500.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9050716928979934\n",
      "Loss normal: 0.19702833957437957 Loss Control: 0.32465588590486455 Loss Patient: 0.158166705080604 Loss balanced:  0.24141129549273427 Loss1+loss2: 0.24141129549273427\n",
      "Write summary at step 7510  Loss:  0.3744114339351654\n",
      "Write summary at step 7520  Loss:  0.45997852087020874\n",
      "Write summary at step 7530  Loss:  0.3052982687950134\n",
      "Write summary at step 7540  Loss:  0.28238001465797424\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8954081632653061 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.8196630388332742\n",
      "Loss normal: 0.30021938947694643 Loss Control: 0.8670256053163705 Loss Patient: 0.1276311359047493 Loss balanced:  0.4973283706105599 Loss1+loss2: 0.4973283706105599\n",
      "Write summary at step 7550  Loss:  0.20513911545276642\n",
      "Write summary at step 7560  Loss:  0.3320166766643524\n",
      "Write summary at step 7570  Loss:  0.20862367749214172\n",
      "Write summary at step 7580  Loss:  0.29755786061286926\n",
      "Write summary at step 7590  Loss:  0.37141674757003784\n",
      "Write summary at step 7600  Loss:  0.26570385694503784\n",
      "Write summary at step 7610  Loss:  0.5389312505722046\n",
      "Write summary at step 7620  Loss:  0.25366854667663574\n",
      "Write summary at step 7630  Loss:  0.32445722818374634\n",
      "Write summary at step 7640  Loss:  0.5353991389274597\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8821454224743824\n",
      "Loss normal: 0.22096303074943777 Loss Control: 0.38575600177212493 Loss Patient: 0.1707848035691681 Loss balanced:  0.2782704026706465 Loss1+loss2: 0.2782704026706465\n",
      "Write summary at step 7650  Loss:  0.3168662190437317\n",
      "Write summary at step 7660  Loss:  0.41391468048095703\n",
      "Write summary at step 7670  Loss:  0.42576926946640015\n",
      "Write summary at step 7680  Loss:  0.4017889201641083\n",
      "Write summary at step 7690  Loss:  0.42743903398513794\n",
      "Write summary at step 7700  Loss:  0.3657703101634979\n",
      "Write summary at step 7710  Loss:  0.24339604377746582\n",
      "Write summary at step 7720  Loss:  0.46217888593673706\n",
      "Write summary at step 7730  Loss:  0.2677995264530182\n",
      "Write summary at step 7740  Loss:  0.28540319204330444\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.940827218751989\n",
      "Loss normal: 0.20741586482190355 Loss Control: 0.18323862259505225 Loss Patient: 0.21477764851092895 Loss balanced:  0.1990081355529906 Loss1+loss2: 0.1990081355529906\n",
      "Write summary at step 7750  Loss:  0.3506702184677124\n",
      "Write summary at step 7760  Loss:  0.5491509437561035\n",
      "Write summary at step 7770  Loss:  0.2434595823287964\n",
      "Write summary at step 7780  Loss:  0.28748437762260437\n",
      "Write summary at step 7790  Loss:  0.3577648997306824\n",
      "Write summary at step 7800  Loss:  0.3059355318546295\n",
      "Write summary at step 7810  Loss:  0.3353157639503479\n",
      "Write summary at step 7820  Loss:  0.45070821046829224\n",
      "Write summary at step 7830  Loss:  0.18195882439613342\n",
      "Write summary at step 7840  Loss:  0.2960043251514435\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9214651355209442\n",
      "Loss normal: 0.21385997974750948 Loss Control: 0.2606290080508248 Loss Patient: 0.19961916080082515 Loss balanced:  0.23012408442582497 Loss1+loss2: 0.23012408442582497\n",
      "Write summary at step 7850  Loss:  0.41189709305763245\n",
      "Write summary at step 7860  Loss:  0.47102034091949463\n",
      "Write summary at step 7870  Loss:  0.32425856590270996\n",
      "Write summary at step 7880  Loss:  0.35852986574172974\n",
      "Write summary at step 7890  Loss:  0.3471253514289856\n",
      "Write summary at step 7900  Loss:  0.39009490609169006\n",
      "Write summary at step 7910  Loss:  0.3795214295387268\n",
      "Write summary at step 7920  Loss:  0.40218913555145264\n",
      "Write summary at step 7930  Loss:  0.20596358180046082\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9105361737723103\n",
      "Loss normal: 0.21107457684619085 Loss Control: 0.2651566498266543 Loss Patient: 0.19460699036593446 Loss balanced:  0.22988182009629438 Loss1+loss2: 0.22988182009629438\n",
      "Write summary at step 7940  Loss:  0.4412100911140442\n",
      "Write summary at step 7950  Loss:  0.453971266746521\n",
      "Write summary at step 7960  Loss:  0.16617539525032043\n",
      "Write summary at step 7970  Loss:  0.19006338715553284\n",
      "Write summary at step 7980  Loss:  0.3765490651130676\n",
      "Write summary at step 7990  Loss:  0.4011693000793457\n",
      "Write summary at step 8000  Loss:  0.34579724073410034\n",
      "Saved checkpoint to: result/43/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8977069183419256\n",
      "Loss normal: 0.20656156482897242 Loss Control: 0.3273363380484242 Loss Patient: 0.16978654834424795 Loss balanced:  0.24856144319633608 Loss1+loss2: 0.24856144319633608\n",
      "Write summary at step 8010  Loss:  0.2513764500617981\n",
      "Write summary at step 8020  Loss:  0.3465869426727295\n",
      "Write summary at step 8030  Loss:  0.38744449615478516\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8810770755480393\n",
      "Loss normal: 0.22661425158077356 Loss Control: 0.4178283214569092 Loss Patient: 0.16839099798146975 Loss balanced:  0.29310965971918945 Loss1+loss2: 0.29310965971918945\n",
      "Write summary at step 8040  Loss:  0.3670974373817444\n",
      "Write summary at step 8050  Loss:  0.5377873182296753\n",
      "Write summary at step 8060  Loss:  0.3016960620880127\n",
      "Write summary at step 8070  Loss:  0.5289356708526611\n",
      "Write summary at step 8080  Loss:  0.3395113945007324\n",
      "Write summary at step 8090  Loss:  0.1826765537261963\n",
      "Write summary at step 8100  Loss:  0.18746745586395264\n",
      "Write summary at step 8110  Loss:  0.20643500983715057\n",
      "Write summary at step 8120  Loss:  0.2192821055650711\n",
      "Write summary at step 8130  Loss:  0.1845872849225998\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8857096096669486\n",
      "Loss normal: 0.20390803515150838 Loss Control: 0.40782562370508746 Loss Patient: 0.1418166563980988 Loss balanced:  0.27482114005159314 Loss1+loss2: 0.27482114005159314\n",
      "Write summary at step 8140  Loss:  0.40503376722335815\n",
      "Write summary at step 8150  Loss:  0.4200494885444641\n",
      "Write summary at step 8160  Loss:  0.41838744282722473\n",
      "Write summary at step 8170  Loss:  0.31360018253326416\n",
      "Write summary at step 8180  Loss:  0.3315349817276001\n",
      "Write summary at step 8190  Loss:  0.7669637203216553\n",
      "Write summary at step 8200  Loss:  0.13119134306907654\n",
      "Write summary at step 8210  Loss:  0.5255259275436401\n",
      "Write summary at step 8220  Loss:  0.33955439925193787\n",
      "Write summary at step 8230  Loss:  0.11444749683141708\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8802451287926316\n",
      "Loss normal: 0.22410822089533416 Loss Control: 0.3664678714640154 Loss Patient: 0.18076077603212806 Loss balanced:  0.2736143237480717 Loss1+loss2: 0.2736143237480717\n",
      "Write summary at step 8240  Loss:  0.31084877252578735\n",
      "Write summary at step 8250  Loss:  0.3611125648021698\n",
      "Write summary at step 8260  Loss:  0.34620535373687744\n",
      "Write summary at step 8270  Loss:  0.1222473755478859\n",
      "Write summary at step 8280  Loss:  0.19363757967948914\n",
      "Write summary at step 8290  Loss:  0.4664033055305481\n",
      "Write summary at step 8300  Loss:  0.4164402186870575\n",
      "Write summary at step 8310  Loss:  0.4861760139465332\n",
      "Write summary at step 8320  Loss:  0.149189293384552\n",
      "Write summary at step 8330  Loss:  0.4068247675895691\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.920396788594601\n",
      "Loss normal: 0.17777642123021034 Loss Control: 0.29307974850545165 Loss Patient: 0.14266742020225565 Loss balanced:  0.21787358435385365 Loss1+loss2: 0.21787358435385365\n",
      "Write summary at step 8340  Loss:  0.26705729961395264\n",
      "Write summary at step 8350  Loss:  0.4531137943267822\n",
      "Write summary at step 8360  Loss:  0.29183393716812134\n",
      "Write summary at step 8370  Loss:  0.26973891258239746\n",
      "Write summary at step 8380  Loss:  0.27842098474502563\n",
      "Write summary at step 8390  Loss:  0.5138461589813232\n",
      "Write summary at step 8400  Loss:  0.2229725420475006\n",
      "Write summary at step 8410  Loss:  0.3804716169834137\n",
      "Write summary at step 8420  Loss:  0.2977777421474457\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8537546711764545\n",
      "Loss normal: 0.23887240738436885 Loss Control: 0.5597145114440084 Loss Patient: 0.14117839149572886 Loss balanced:  0.35044645146986864 Loss1+loss2: 0.35044645146986864\n",
      "Write summary at step 8430  Loss:  0.3032596707344055\n",
      "Write summary at step 8440  Loss:  0.262805700302124\n",
      "Write summary at step 8450  Loss:  0.12471423298120499\n",
      "Write summary at step 8460  Loss:  0.2166357934474945\n",
      "Write summary at step 8470  Loss:  0.18710242211818695\n",
      "Write summary at step 8480  Loss:  0.4052789509296417\n",
      "Write summary at step 8490  Loss:  0.20856159925460815\n",
      "Write summary at step 8500  Loss:  0.3197823166847229\n",
      "Saved checkpoint to: result/43/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9122000672831256\n",
      "Loss normal: 0.19325275966251382 Loss Control: 0.2845833093090787 Loss Patient: 0.16544329378747702 Loss balanced:  0.22501330154827787 Loss1+loss2: 0.22501330154827787\n",
      "Write summary at step 8510  Loss:  0.4576184153556824\n",
      "Write summary at step 8520  Loss:  0.47240543365478516\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.888441850104107\n",
      "Loss normal: 0.21398164081026097 Loss Control: 0.35662690993866636 Loss Patient: 0.1705472271722089 Loss balanced:  0.2635870685554376 Loss1+loss2: 0.2635870685554376\n",
      "Write summary at step 8530  Loss:  0.2776043713092804\n",
      "Write summary at step 8540  Loss:  0.39228126406669617\n",
      "Write summary at step 8550  Loss:  0.30089256167411804\n",
      "Write summary at step 8560  Loss:  0.3686273992061615\n",
      "Write summary at step 8570  Loss:  0.30809485912323\n",
      "Write summary at step 8580  Loss:  0.45436641573905945\n",
      "Write summary at step 8590  Loss:  0.441875696182251\n",
      "Write summary at step 8600  Loss:  0.5399432182312012\n",
      "Write summary at step 8610  Loss:  0.39656996726989746\n",
      "Write summary at step 8620  Loss:  0.38627034425735474\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8674158733622469\n",
      "Loss normal: 0.21265399098700408 Loss Control: 0.46106494287324085 Loss Patient: 0.13701471502268175 Loss balanced:  0.29903982894796133 Loss1+loss2: 0.29903982894796133\n",
      "Write summary at step 8630  Loss:  0.30834150314331055\n",
      "Write summary at step 8640  Loss:  0.33680275082588196\n",
      "Write summary at step 8650  Loss:  0.24503593146800995\n",
      "Write summary at step 8660  Loss:  0.1394597291946411\n",
      "Write summary at step 8670  Loss:  0.4262426197528839\n",
      "Write summary at step 8680  Loss:  0.490985244512558\n",
      "Write summary at step 8690  Loss:  0.2609344720840454\n",
      "Write summary at step 8700  Loss:  0.46490782499313354\n",
      "Write summary at step 8710  Loss:  0.5099512934684753\n",
      "Write summary at step 8720  Loss:  0.47182759642601013\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8674158733622469\n",
      "Loss normal: 0.22408193205388224 Loss Control: 0.46923490560771336 Loss Patient: 0.14943468603561205 Loss balanced:  0.3093347958216627 Loss1+loss2: 0.3093347958216627\n",
      "Write summary at step 8730  Loss:  0.2270107865333557\n",
      "Write summary at step 8740  Loss:  0.16515126824378967\n",
      "Write summary at step 8750  Loss:  0.44980424642562866\n",
      "Write summary at step 8760  Loss:  0.317416787147522\n",
      "Write summary at step 8770  Loss:  0.516938328742981\n",
      "Write summary at step 8780  Loss:  0.38942068815231323\n",
      "Write summary at step 8790  Loss:  0.21761107444763184\n",
      "Write summary at step 8800  Loss:  0.2278078943490982\n",
      "Write summary at step 8810  Loss:  0.30610954761505127\n",
      "Write summary at step 8820  Loss:  0.38927868008613586\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9416591655073967\n",
      "Loss normal: 0.2127092135119803 Loss Control: 0.1971506549686682 Loss Patient: 0.21744668155214353 Loss balanced:  0.20729866826040588 Loss1+loss2: 0.20729866826040588\n",
      "Write summary at step 8830  Loss:  0.5667221546173096\n",
      "Write summary at step 8840  Loss:  0.4418449103832245\n",
      "Write summary at step 8850  Loss:  0.28184428811073303\n",
      "Write summary at step 8860  Loss:  0.39318016171455383\n",
      "Write summary at step 8870  Loss:  0.2587970495223999\n",
      "Write summary at step 8880  Loss:  0.38665080070495605\n",
      "Write summary at step 8890  Loss:  0.44327419996261597\n",
      "Write summary at step 8900  Loss:  0.4076138734817505\n",
      "Write summary at step 8910  Loss:  0.6323479413986206\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9151687078912196\n",
      "Loss normal: 0.21341674843308878 Loss Control: 0.2897389892671929 Loss Patient: 0.19017719760066062 Loss balanced:  0.23995809343392677 Loss1+loss2: 0.23995809343392677\n",
      "Write summary at step 8920  Loss:  0.517703652381897\n",
      "Write summary at step 8930  Loss:  0.4769076704978943\n",
      "Write summary at step 8940  Loss:  0.29081177711486816\n",
      "Write summary at step 8950  Loss:  0.5875392556190491\n",
      "Write summary at step 8960  Loss:  0.297535240650177\n",
      "Write summary at step 8970  Loss:  0.3382760286331177\n",
      "Write summary at step 8980  Loss:  0.3362632393836975\n",
      "Write summary at step 8990  Loss:  0.3939893841743469\n",
      "Write summary at step 9000  Loss:  0.2767159342765808\n",
      "Saved checkpoint to: result/43/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8611194457325223\n",
      "Loss normal: 0.26362237174596104 Loss Control: 0.5289535688572242 Loss Patient: 0.1828310090843929 Loss balanced:  0.35589228897080855 Loss1+loss2: 0.35589228897080855\n",
      "Write summary at step 9010  Loss:  0.5486003160476685\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8335606411900021\n",
      "Loss normal: 0.279854452959737 Loss Control: 0.6994134344038416 Loss Patient: 0.15210188104586672 Loss balanced:  0.4257576577248542 Loss1+loss2: 0.4257576577248542\n",
      "Write summary at step 9020  Loss:  0.5089689493179321\n",
      "Write summary at step 9030  Loss:  0.47317469120025635\n",
      "Write summary at step 9040  Loss:  0.22054702043533325\n",
      "Write summary at step 9050  Loss:  0.41825276613235474\n",
      "Write summary at step 9060  Loss:  0.32569581270217896\n",
      "Write summary at step 9070  Loss:  0.3573223352432251\n",
      "Write summary at step 9080  Loss:  0.2158319354057312\n",
      "Write summary at step 9090  Loss:  0.4738459289073944\n",
      "Write summary at step 9100  Loss:  0.38496336340904236\n",
      "Write summary at step 9110  Loss:  0.19012001156806946\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9244337761290382\n",
      "Loss normal: 0.21696668008000267 Loss Control: 0.2539034661699514 Loss Patient: 0.2057197039416943 Loss balanced:  0.22981158505582286 Loss1+loss2: 0.22981158505582286\n",
      "Write summary at step 9120  Loss:  0.6935780048370361\n",
      "Write summary at step 9130  Loss:  0.13295260071754456\n",
      "Write summary at step 9140  Loss:  0.3819151520729065\n",
      "Write summary at step 9150  Loss:  0.42956915497779846\n",
      "Write summary at step 9160  Loss:  0.2381725013256073\n",
      "Write summary at step 9170  Loss:  0.33947762846946716\n",
      "Write summary at step 9180  Loss:  0.20408442616462708\n",
      "Write summary at step 9190  Loss:  0.8172544240951538\n",
      "Write summary at step 9200  Loss:  0.35782355070114136\n",
      "Write summary at step 9210  Loss:  0.4976349472999573\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8638516861696808\n",
      "Loss normal: 0.2440943987850024 Loss Control: 0.5009182131355577 Loss Patient: 0.16589347159059195 Loss balanced:  0.33340584236307486 Loss1+loss2: 0.33340584236307486\n",
      "Write summary at step 9220  Loss:  0.5449228286743164\n",
      "Write summary at step 9230  Loss:  0.33190441131591797\n",
      "Write summary at step 9240  Loss:  0.28282496333122253\n",
      "Write summary at step 9250  Loss:  0.34314829111099243\n",
      "Write summary at step 9260  Loss:  0.15039026737213135\n",
      "Write summary at step 9270  Loss:  0.20337508618831635\n",
      "Write summary at step 9280  Loss:  0.31900036334991455\n",
      "Write summary at step 9290  Loss:  0.769417941570282\n",
      "Write summary at step 9300  Loss:  0.38062864542007446\n",
      "Write summary at step 9310  Loss:  0.40728747844696045\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.6885245901639344 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8242955729521835\n",
      "Loss normal: 0.2665283094559397 Loss Control: 0.7292607254017898 Loss Patient: 0.12562975640751162 Loss balanced:  0.4274452409046507 Loss1+loss2: 0.4274452409046507\n",
      "Write summary at step 9320  Loss:  0.6808117032051086\n",
      "Write summary at step 9330  Loss:  0.3438585102558136\n",
      "Write summary at step 9340  Loss:  0.28459689021110535\n",
      "Write summary at step 9350  Loss:  0.3713200092315674\n",
      "Write summary at step 9360  Loss:  0.38472646474838257\n",
      "Write summary at step 9370  Loss:  0.4297599792480469\n",
      "Write summary at step 9380  Loss:  0.2875397205352783\n",
      "Write summary at step 9390  Loss:  0.4225935637950897\n",
      "Write summary at step 9400  Loss:  0.32652947306632996\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9067355864088087\n",
      "Loss normal: 0.21812295651405442 Loss Control: 0.31018988307707945 Loss Patient: 0.19008926310252627 Loss balanced:  0.25013957308980284 Loss1+loss2: 0.25013957308980284\n",
      "Write summary at step 9410  Loss:  0.2843223512172699\n",
      "Write summary at step 9420  Loss:  0.21879824995994568\n",
      "Write summary at step 9430  Loss:  0.16831977665424347\n",
      "Write summary at step 9440  Loss:  0.3394848108291626\n",
      "Write summary at step 9450  Loss:  0.1520463526248932\n",
      "Write summary at step 9460  Loss:  0.28333231806755066\n",
      "Write summary at step 9470  Loss:  0.521762490272522\n",
      "Write summary at step 9480  Loss:  0.2628898024559021\n",
      "Write summary at step 9490  Loss:  0.20220476388931274\n",
      "Write summary at step 9500  Loss:  0.44400325417518616\n",
      "Saved checkpoint to: result/43/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8737244897959183 Acurracy Control:  0.5573770491803278 Acurracy Patient:  0.9700499168053245 Acurracy Balanced 0.7637134829928262\n",
      "Loss normal: 0.32653637123959406 Loss Control: 0.9988395868103361 Loss Patient: 0.1218250784372133 Loss balanced:  0.5603323326237747 Loss1+loss2: 0.5603323326237747\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8469387755102041 Acurracy Control:  0.41530054644808745 Acurracy Patient:  0.978369384359401 Acurracy Balanced 0.6968349654037442\n",
      "Loss normal: 0.38030143150565576 Loss Control: 1.2977361027660266 Loss Patient: 0.10094944386744559 Loss balanced:  0.6993427733167361 Loss1+loss2: 0.6993427733167361\n",
      "Write summary at step 9510  Loss:  0.30989545583724976\n",
      "Write summary at step 9520  Loss:  0.35663676261901855\n",
      "Write summary at step 9530  Loss:  0.21662238240242004\n",
      "Write summary at step 9540  Loss:  0.2865200638771057\n",
      "Write summary at step 9550  Loss:  0.504001796245575\n",
      "Write summary at step 9560  Loss:  0.12568677961826324\n",
      "Write summary at step 9570  Loss:  0.41331759095191956\n",
      "Write summary at step 9580  Loss:  0.34754857420921326\n",
      "Write summary at step 9590  Loss:  0.43114882707595825\n",
      "Write summary at step 9600  Loss:  0.3107495903968811\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.893906330978424\n",
      "Loss normal: 0.2113053044114186 Loss Control: 0.3424132150379035 Loss Patient: 0.1713839261645386 Loss balanced:  0.25689857060122107 Loss1+loss2: 0.25689857060122107\n",
      "Write summary at step 9610  Loss:  0.4392707049846649\n",
      "Write summary at step 9620  Loss:  0.30217158794403076\n",
      "Write summary at step 9630  Loss:  0.49597203731536865\n",
      "Write summary at step 9640  Loss:  0.17129935324192047\n",
      "Write summary at step 9650  Loss:  0.3415970206260681\n",
      "Write summary at step 9660  Loss:  0.34489545226097107\n",
      "Write summary at step 9670  Loss:  0.5209465026855469\n",
      "Write summary at step 9680  Loss:  0.3818953037261963\n",
      "Write summary at step 9690  Loss:  0.29195109009742737\n",
      "Write summary at step 9700  Loss:  0.15170256793498993\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8674158733622469\n",
      "Loss normal: 0.23777680460135547 Loss Control: 0.4297980317652551 Loss Patient: 0.17930777740979353 Loss balanced:  0.3045529045875243 Loss1+loss2: 0.3045529045875243\n",
      "Write summary at step 9710  Loss:  0.3075020909309387\n",
      "Write summary at step 9720  Loss:  0.5613571405410767\n",
      "Write summary at step 9730  Loss:  0.16888803243637085\n",
      "Write summary at step 9740  Loss:  0.5865676999092102\n",
      "Write summary at step 9750  Loss:  0.24805310368537903\n",
      "Write summary at step 9760  Loss:  0.40512919425964355\n",
      "Write summary at step 9770  Loss:  0.2991291880607605\n",
      "Write summary at step 9780  Loss:  0.41087332367897034\n",
      "Write summary at step 9790  Loss:  0.5117045044898987\n",
      "Write summary at step 9800  Loss:  0.5398902297019958\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8699117136284699\n",
      "Loss normal: 0.23580029184873008 Loss Control: 0.4329831508990845 Loss Patient: 0.17575958865801625 Loss balanced:  0.3043713697785504 Loss1+loss2: 0.3043713697785504\n",
      "------------------------------\n",
      "SEED: 43 Best Loss: 0.17624452099556734\n",
      "______________________________\n",
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 5 (+- 0.1 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 10  Loss:  0.7407600283622742\n",
      "Write summary at step 20  Loss:  0.7168031930923462\n",
      "Write summary at step 30  Loss:  0.7234447002410889\n",
      "Write summary at step 40  Loss:  0.6776235103607178\n",
      "Write summary at step 50  Loss:  0.7185770273208618\n",
      "Write summary at step 60  Loss:  0.6583330035209656\n",
      "Write summary at step 70  Loss:  0.6961602568626404\n",
      "Write summary at step 80  Loss:  0.581386923789978\n",
      "Write summary at step 90  Loss:  0.666588306427002\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7780612244897959 Acurracy Control:  0.6284153005464481 Acurracy Patient:  0.8236272878535774 Acurracy Balanced 0.7260212942000128\n",
      "Loss normal: 0.5756155295031411 Loss Control: 0.6873432091676472 Loss Patient: 0.5415952900880189 Loss balanced:  0.614469249627833 Loss1+loss2: 0.614469249627833\n",
      "\n",
      " > BEST MODEL (0.61447) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 100  Loss:  0.7801127433776855\n",
      "Write summary at step 110  Loss:  0.6974772214889526\n",
      "Write summary at step 120  Loss:  0.6713290214538574\n",
      "Write summary at step 130  Loss:  0.6823285818099976\n",
      "Write summary at step 140  Loss:  0.6527856588363647\n",
      "Write summary at step 150  Loss:  0.6598612070083618\n",
      "Write summary at step 160  Loss:  0.6877926588058472\n",
      "Write summary at step 170  Loss:  0.8552201986312866\n",
      "Write summary at step 180  Loss:  0.5865434408187866\n",
      "Write summary at step 190  Loss:  0.42271488904953003\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8099489795918368 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.8552412645590682 Acurracy Balanced 0.758221725175709\n",
      "Loss normal: 0.375668056499289 Loss Control: 0.5384143545327942 Loss Patient: 0.3261130303144455 Loss balanced:  0.43226369242361984 Loss1+loss2: 0.43226369242361984\n",
      "\n",
      " > BEST MODEL (0.43226) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 200  Loss:  0.6514428853988647\n",
      "Write summary at step 210  Loss:  0.9244107007980347\n",
      "Write summary at step 220  Loss:  0.3621961176395416\n",
      "Write summary at step 230  Loss:  0.5547878742218018\n",
      "Write summary at step 240  Loss:  0.5694448947906494\n",
      "Write summary at step 250  Loss:  0.5220119953155518\n",
      "Write summary at step 260  Loss:  0.7924981713294983\n",
      "Write summary at step 270  Loss:  0.4884611666202545\n",
      "Write summary at step 280  Loss:  0.4976111054420471\n",
      "Write summary at step 290  Loss:  0.44433140754699707\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9034941763727121 Acurracy Balanced 0.9244246838147714\n",
      "Loss normal: 0.28345455191269214 Loss Control: 0.21542306806220382 Loss Patient: 0.30416962955636706 Loss balanced:  0.2597963488092854 Loss1+loss2: 0.2597963488092854\n",
      "\n",
      " > BEST MODEL (0.25980) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 300  Loss:  0.6917839050292969\n",
      "Write summary at step 310  Loss:  0.4080160856246948\n",
      "Write summary at step 320  Loss:  0.5886412858963013\n",
      "Write summary at step 330  Loss:  0.47705739736557007\n",
      "Write summary at step 340  Loss:  0.5899848937988281\n",
      "Write summary at step 350  Loss:  0.4491112530231476\n",
      "Write summary at step 360  Loss:  0.6760813593864441\n",
      "Write summary at step 370  Loss:  1.0141534805297852\n",
      "Write summary at step 380  Loss:  0.4304695725440979\n",
      "Write summary at step 390  Loss:  0.507853090763092\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8775510204081632 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.8535773710482529 Acurracy Balanced 0.9049307620268587\n",
      "Loss normal: 0.46552465924498987 Loss Control: 0.11466202864555713 Loss Patient: 0.5723596992786236 Loss balanced:  0.3435108639620904 Loss1+loss2: 0.3435108639620904\n",
      "Write summary at step 400  Loss:  0.8455406427383423\n",
      "Write summary at step 410  Loss:  1.1963928937911987\n",
      "Write summary at step 420  Loss:  0.5882672071456909\n",
      "Write summary at step 430  Loss:  0.30615007877349854\n",
      "Write summary at step 440  Loss:  0.2895466089248657\n",
      "Write summary at step 450  Loss:  0.5530980229377747\n",
      "Write summary at step 460  Loss:  0.40064945816993713\n",
      "Write summary at step 470  Loss:  0.879241943359375\n",
      "Write summary at step 480  Loss:  0.35919123888015747\n",
      "Write summary at step 490  Loss:  0.3583371043205261\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.8768718801996672 Acurracy Balanced 0.9029168144167735\n",
      "Loss normal: 0.3030807460677259 Loss Control: 0.22781110591575748 Loss Patient: 0.3259997847373791 Loss balanced:  0.2769054453265683 Loss1+loss2: 0.2769054453265683\n",
      "Write summary at step 500  Loss:  0.3597959876060486\n",
      "Saved checkpoint to: result/44/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8278061224489796 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.7803660565723793 Acurracy Balanced 0.8819863069747143\n",
      "Loss normal: 0.6457566498037504 Loss Control: 0.07833775890166642 Loss Patient: 0.8185314547004001 Loss balanced:  0.44843460680103325 Loss1+loss2: 0.44843460680103325\n",
      "Write summary at step 510  Loss:  0.6075998544692993\n",
      "Write summary at step 520  Loss:  0.39082619547843933\n",
      "Write summary at step 530  Loss:  0.45086318254470825\n",
      "Write summary at step 540  Loss:  0.4770318865776062\n",
      "Write summary at step 550  Loss:  0.5848381519317627\n",
      "Write summary at step 560  Loss:  0.6514295339584351\n",
      "Write summary at step 570  Loss:  0.37821775674819946\n",
      "Write summary at step 580  Loss:  0.5224329233169556\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8941326530612245 Acurracy Control:  0.6830601092896175 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8207313857596175\n",
      "Loss normal: 0.26390841964404194 Loss Control: 0.6853406833169239 Loss Patient: 0.13558545388814416 Loss balanced:  0.410463068602534 Loss1+loss2: 0.410463068602534\n",
      "Write summary at step 590  Loss:  0.3183377981185913\n",
      "Write summary at step 600  Loss:  0.43828311562538147\n",
      "Write summary at step 610  Loss:  0.7622973918914795\n",
      "Write summary at step 620  Loss:  0.4200389087200165\n",
      "Write summary at step 630  Loss:  0.3398105502128601\n",
      "Write summary at step 640  Loss:  0.27981412410736084\n",
      "Write summary at step 650  Loss:  0.48125219345092773\n",
      "Write summary at step 660  Loss:  0.49092933535575867\n",
      "Write summary at step 670  Loss:  0.5496386885643005\n",
      "Write summary at step 680  Loss:  0.6375371217727661\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9101497504159733 Acurracy Balanced 0.9004300664648173\n",
      "Loss normal: 0.25762171807641887 Loss Control: 0.3330858164146298 Loss Patient: 0.23464346894011917 Loss balanced:  0.2838646426773745 Loss1+loss2: 0.2838646426773745\n",
      "Write summary at step 690  Loss:  0.4267539381980896\n",
      "Write summary at step 700  Loss:  0.43295493721961975\n",
      "Write summary at step 710  Loss:  0.5625160932540894\n",
      "Write summary at step 720  Loss:  0.3044416010379791\n",
      "Write summary at step 730  Loss:  0.49892497062683105\n",
      "Write summary at step 740  Loss:  0.22170157730579376\n",
      "Write summary at step 750  Loss:  1.0306944847106934\n",
      "Write summary at step 760  Loss:  0.44120991230010986\n",
      "Write summary at step 770  Loss:  0.33864712715148926\n",
      "Write summary at step 780  Loss:  0.47650137543678284\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9168053244592346 Acurracy Balanced 0.9010256130492894\n",
      "Loss normal: 0.26132646431120077 Loss Control: 0.27427138331157913 Loss Patient: 0.25738483145461105 Loss balanced:  0.2658281073830951 Loss1+loss2: 0.2658281073830951\n",
      "Write summary at step 790  Loss:  0.8515333533287048\n",
      "Write summary at step 800  Loss:  0.44340139627456665\n",
      "Write summary at step 810  Loss:  0.5408586859703064\n",
      "Write summary at step 820  Loss:  0.4212190508842468\n",
      "Write summary at step 830  Loss:  0.5114203691482544\n",
      "Write summary at step 840  Loss:  0.2817044258117676\n",
      "Write summary at step 850  Loss:  0.5330996513366699\n",
      "Write summary at step 860  Loss:  0.46292582154273987\n",
      "Write summary at step 870  Loss:  0.5832130312919617\n",
      "Write summary at step 880  Loss:  0.2894824147224426\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9068219633943427 Acurracy Balanced 0.8960339325168435\n",
      "Loss normal: 0.32355341573759 Loss Control: 0.2465377521645176 Loss Patient: 0.34700410377959445 Loss balanced:  0.296770927972056 Loss1+loss2: 0.296770927972056\n",
      "Write summary at step 890  Loss:  0.41730499267578125\n",
      "Write summary at step 900  Loss:  0.48234856128692627\n",
      "Write summary at step 910  Loss:  0.5484110713005066\n",
      "Write summary at step 920  Loss:  0.270025372505188\n",
      "Write summary at step 930  Loss:  0.4342859983444214\n",
      "Write summary at step 940  Loss:  0.5046701431274414\n",
      "Write summary at step 950  Loss:  0.5770761370658875\n",
      "Write summary at step 960  Loss:  0.42760786414146423\n",
      "Write summary at step 970  Loss:  0.4155021905899048\n",
      "Write summary at step 980  Loss:  0.5486843585968018\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.8716892610676196\n",
      "Loss normal: 0.23561395077529002 Loss Control: 0.5389619525013074 Loss Patient: 0.14324675641718404 Loss balanced:  0.3411043544592457 Loss1+loss2: 0.3411043544592457\n",
      "Write summary at step 990  Loss:  0.6138491630554199\n",
      "Write summary at step 1000  Loss:  0.3917441964149475\n",
      "Saved checkpoint to: result/44/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8941326530612245 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.8652246256239601 Acurracy Balanced 0.9271478319376631\n",
      "Loss normal: 0.33295690488754487 Loss Control: 0.09811518768795201 Loss Patient: 0.4044644470619481 Loss balanced:  0.25128981737495004 Loss1+loss2: 0.25128981737495004\n",
      "\n",
      " > BEST MODEL (0.25129) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 1010  Loss:  0.41331928968429565\n",
      "Write summary at step 1020  Loss:  0.253518283367157\n",
      "Write summary at step 1030  Loss:  0.41727495193481445\n",
      "Write summary at step 1040  Loss:  0.34818512201309204\n",
      "Write summary at step 1050  Loss:  0.38630610704421997\n",
      "Write summary at step 1060  Loss:  0.39394116401672363\n",
      "Write summary at step 1070  Loss:  0.3494020104408264\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9168053244592346 Acurracy Balanced 0.887364410863497\n",
      "Loss normal: 0.2659016231036916 Loss Control: 0.324569874448203 Loss Patient: 0.24803757925398537 Loss balanced:  0.2863037268510942 Loss1+loss2: 0.2863037268510942\n",
      "Write summary at step 1080  Loss:  0.4379887878894806\n",
      "Write summary at step 1090  Loss:  0.4078443944454193\n",
      "Write summary at step 1100  Loss:  0.2731195092201233\n",
      "Write summary at step 1110  Loss:  0.3096535801887512\n",
      "Write summary at step 1120  Loss:  0.5082952976226807\n",
      "Write summary at step 1130  Loss:  0.40817636251449585\n",
      "Write summary at step 1140  Loss:  0.2669889032840729\n",
      "Write summary at step 1150  Loss:  0.41845521330833435\n",
      "Write summary at step 1160  Loss:  0.6276187896728516\n",
      "Write summary at step 1170  Loss:  0.4031914174556732\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.9051580698835274 Acurracy Balanced 0.9471145540674468\n",
      "Loss normal: 0.24992647227279993 Loss Control: 0.14299465219179788 Loss Patient: 0.2824864079075526 Loss balanced:  0.21274053004967525 Loss1+loss2: 0.21274053004967525\n",
      "\n",
      " > BEST MODEL (0.21274) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 1180  Loss:  0.2512420415878296\n",
      "Write summary at step 1190  Loss:  0.5925707817077637\n",
      "Write summary at step 1200  Loss:  0.6652911901473999\n",
      "Write summary at step 1210  Loss:  0.4312272071838379\n",
      "Write summary at step 1220  Loss:  0.5267778038978577\n",
      "Write summary at step 1230  Loss:  0.6979200839996338\n",
      "Write summary at step 1240  Loss:  0.6377301216125488\n",
      "Write summary at step 1250  Loss:  0.4681445360183716\n",
      "Write summary at step 1260  Loss:  0.4358169138431549\n",
      "Write summary at step 1270  Loss:  0.4162490963935852\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.8786948892101507\n",
      "Loss normal: 0.2625607094746463 Loss Control: 0.3844570374228264 Loss Patient: 0.22544419100994675 Loss balanced:  0.3049506142163866 Loss1+loss2: 0.3049506142163866\n",
      "Write summary at step 1280  Loss:  0.494850218296051\n",
      "Write summary at step 1290  Loss:  0.30429407954216003\n",
      "Write summary at step 1300  Loss:  0.20732687413692474\n",
      "Write summary at step 1310  Loss:  0.5237918496131897\n",
      "Write summary at step 1320  Loss:  0.44552022218704224\n",
      "Write summary at step 1330  Loss:  0.4291393458843231\n",
      "Write summary at step 1340  Loss:  0.32216501235961914\n",
      "Write summary at step 1350  Loss:  0.456504225730896\n",
      "Write summary at step 1360  Loss:  0.5849025249481201\n",
      "Write summary at step 1370  Loss:  0.29608482122421265\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.913477537437604 Acurracy Balanced 0.9130229217242665\n",
      "Loss normal: 0.2761927838532292 Loss Control: 0.26378327021833325 Loss Patient: 0.2799713877393878 Loss balanced:  0.2718773289788605 Loss1+loss2: 0.2718773289788605\n",
      "Write summary at step 1380  Loss:  0.2960833013057709\n",
      "Write summary at step 1390  Loss:  0.34593671560287476\n",
      "Write summary at step 1400  Loss:  0.6189866065979004\n",
      "Write summary at step 1410  Loss:  0.6103853583335876\n",
      "Write summary at step 1420  Loss:  0.35616862773895264\n",
      "Write summary at step 1430  Loss:  0.6308441758155823\n",
      "Write summary at step 1440  Loss:  0.33348357677459717\n",
      "Write summary at step 1450  Loss:  0.24258729815483093\n",
      "Write summary at step 1460  Loss:  0.3562399446964264\n",
      "Write summary at step 1470  Loss:  0.9072757959365845\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9186101488411845\n",
      "Loss normal: 0.23609915474543766 Loss Control: 0.330383111870354 Loss Patient: 0.20739039151422592 Loss balanced:  0.26888675169229 Loss1+loss2: 0.26888675169229\n",
      "Write summary at step 1480  Loss:  0.6428308486938477\n",
      "Write summary at step 1490  Loss:  0.29354479908943176\n",
      "Write summary at step 1500  Loss:  0.5540236234664917\n",
      "Saved checkpoint to: result/44/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.8847549166689397\n",
      "Loss normal: 0.2772499289439649 Loss Control: 0.34730213033696994 Loss Patient: 0.2559195600462436 Loss balanced:  0.30161084519160675 Loss1+loss2: 0.30161084519160675\n",
      "Write summary at step 1510  Loss:  0.366858571767807\n",
      "Write summary at step 1520  Loss:  0.31470197439193726\n",
      "Write summary at step 1530  Loss:  0.5661087036132812\n",
      "Write summary at step 1540  Loss:  0.5418623685836792\n",
      "Write summary at step 1550  Loss:  0.3397234082221985\n",
      "Write summary at step 1560  Loss:  0.48069751262664795\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.8992480656101397\n",
      "Loss normal: 0.21606451158924977 Loss Control: 0.32707670217003326 Loss Patient: 0.1822621333544544 Loss balanced:  0.25466941776224383 Loss1+loss2: 0.25466941776224383\n",
      "Write summary at step 1570  Loss:  0.3528779149055481\n",
      "Write summary at step 1580  Loss:  0.3850019872188568\n",
      "Write summary at step 1590  Loss:  0.48048511147499084\n",
      "Write summary at step 1600  Loss:  0.4625498950481415\n",
      "Write summary at step 1610  Loss:  0.46044814586639404\n",
      "Write summary at step 1620  Loss:  0.28626200556755066\n",
      "Write summary at step 1630  Loss:  0.7629824876785278\n",
      "Write summary at step 1640  Loss:  0.8264847993850708\n",
      "Write summary at step 1650  Loss:  0.5349599123001099\n",
      "Write summary at step 1660  Loss:  0.41176795959472656\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9366674849749507\n",
      "Loss normal: 0.21179978268183008 Loss Control: 0.26007629711119856 Loss Patient: 0.19709994560866903 Loss balanced:  0.22858812135993378 Loss1+loss2: 0.22858812135993378\n",
      "Write summary at step 1670  Loss:  0.5541558861732483\n",
      "Write summary at step 1680  Loss:  0.2801954746246338\n",
      "Write summary at step 1690  Loss:  0.5867781043052673\n",
      "Write summary at step 1700  Loss:  0.27614906430244446\n",
      "Write summary at step 1710  Loss:  0.5962510704994202\n",
      "Write summary at step 1720  Loss:  0.3512405753135681\n",
      "Write summary at step 1730  Loss:  0.3705466687679291\n",
      "Write summary at step 1740  Loss:  0.4632030129432678\n",
      "Write summary at step 1750  Loss:  0.4039333164691925\n",
      "Write summary at step 1760  Loss:  0.5114229917526245\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9295391105898184\n",
      "Loss normal: 0.2408242953979239 Loss Control: 0.24281411841918862 Loss Patient: 0.2402184090380264 Loss balanced:  0.24151626372860752 Loss1+loss2: 0.24151626372860752\n",
      "Write summary at step 1770  Loss:  0.28455784916877747\n",
      "Write summary at step 1780  Loss:  0.6779570579528809\n",
      "Write summary at step 1790  Loss:  0.38860976696014404\n",
      "Write summary at step 1800  Loss:  0.3632924556732178\n",
      "Write summary at step 1810  Loss:  0.29985904693603516\n",
      "Write summary at step 1820  Loss:  0.6785759925842285\n",
      "Write summary at step 1830  Loss:  0.4763687551021576\n",
      "Write summary at step 1840  Loss:  0.3344521224498749\n",
      "Write summary at step 1850  Loss:  0.8394893407821655\n",
      "Write summary at step 1860  Loss:  0.3788585066795349\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.8985024958402662 Acurracy Balanced 0.9437867670458162\n",
      "Loss normal: 0.2559249043768766 Loss Control: 0.13228068553684838 Loss Patient: 0.29357364401841124 Loss balanced:  0.2129271647776298 Loss1+loss2: 0.2129271647776298\n",
      "Write summary at step 1870  Loss:  0.2836413085460663\n",
      "Write summary at step 1880  Loss:  0.4687562882900238\n",
      "Write summary at step 1890  Loss:  0.2890060245990753\n",
      "Write summary at step 1900  Loss:  0.46518397331237793\n",
      "Write summary at step 1910  Loss:  0.5852230191230774\n",
      "Write summary at step 1920  Loss:  0.6431524753570557\n",
      "Write summary at step 1930  Loss:  0.4276884198188782\n",
      "Write summary at step 1940  Loss:  0.3677426874637604\n",
      "Write summary at step 1950  Loss:  0.4891808032989502\n",
      "Write summary at step 1960  Loss:  0.45546483993530273\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.9284525790349417 Acurracy Balanced 0.9478328468945201\n",
      "Loss normal: 0.25452336729789266 Loss Control: 0.24005286224552844 Loss Patient: 0.2589295268951359 Loss balanced:  0.24949119457033214 Loss1+loss2: 0.24949119457033214\n",
      "Write summary at step 1970  Loss:  0.47954297065734863\n",
      "Write summary at step 1980  Loss:  0.2159118801355362\n",
      "Write summary at step 1990  Loss:  0.17442719638347626\n",
      "Write summary at step 2000  Loss:  0.36523011326789856\n",
      "Saved checkpoint to: result/44/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9099406271878381\n",
      "Loss normal: 0.22130177550169886 Loss Control: 0.30779135520340967 Loss Patient: 0.1949663469924308 Loss balanced:  0.25137885109792024 Loss1+loss2: 0.25137885109792024\n",
      "Write summary at step 2010  Loss:  0.6723644137382507\n",
      "Write summary at step 2020  Loss:  0.3512030839920044\n",
      "Write summary at step 2030  Loss:  0.33828508853912354\n",
      "Write summary at step 2040  Loss:  0.276431143283844\n",
      "Write summary at step 2050  Loss:  0.3305337429046631\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.908485856905158 Acurracy Balanced 0.9487784475782621\n",
      "Loss normal: 0.2572051627295358 Loss Control: 0.2081858548310285 Loss Patient: 0.27213117490195593 Loss balanced:  0.2401585148664922 Loss1+loss2: 0.2401585148664922\n",
      "Write summary at step 2060  Loss:  0.29906630516052246\n",
      "Write summary at step 2070  Loss:  0.3756292462348938\n",
      "Write summary at step 2080  Loss:  0.41886311769485474\n",
      "Write summary at step 2090  Loss:  0.33290332555770874\n",
      "Write summary at step 2100  Loss:  0.3621675372123718\n",
      "Write summary at step 2110  Loss:  0.4528524577617645\n",
      "Write summary at step 2120  Loss:  0.26924267411231995\n",
      "Write summary at step 2130  Loss:  0.33841341733932495\n",
      "Write summary at step 2140  Loss:  0.2963654398918152\n",
      "Write summary at step 2150  Loss:  0.2834162414073944\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9385677786567015\n",
      "Loss normal: 0.1963004580489835 Loss Control: 0.21778752439009036 Loss Patient: 0.18975780683626947 Loss balanced:  0.20377266561317992 Loss1+loss2: 0.20377266561317992\n",
      "\n",
      " > BEST MODEL (0.20377) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 2160  Loss:  0.38120168447494507\n",
      "Write summary at step 2170  Loss:  0.3961578607559204\n",
      "Write summary at step 2180  Loss:  0.4424254894256592\n",
      "Write summary at step 2190  Loss:  0.4897516965866089\n",
      "Write summary at step 2200  Loss:  0.20778417587280273\n",
      "Write summary at step 2210  Loss:  0.25064027309417725\n",
      "Write summary at step 2220  Loss:  0.7873009443283081\n",
      "Write summary at step 2230  Loss:  0.37667375802993774\n",
      "Write summary at step 2240  Loss:  0.5495696663856506\n",
      "Write summary at step 2250  Loss:  0.43342846632003784\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8878463035196349\n",
      "Loss normal: 0.2537227246378149 Loss Control: 0.3610622452907875 Loss Patient: 0.22103864051240454 Loss balanced:  0.29105044290159604 Loss1+loss2: 0.29105044290159604\n",
      "Write summary at step 2260  Loss:  0.37271445989608765\n",
      "Write summary at step 2270  Loss:  0.48677536845207214\n",
      "Write summary at step 2280  Loss:  0.3033970892429352\n",
      "Write summary at step 2290  Loss:  0.40413230657577515\n",
      "Write summary at step 2300  Loss:  0.3534793257713318\n",
      "Write summary at step 2310  Loss:  0.3197169303894043\n",
      "Write summary at step 2320  Loss:  0.5379383563995361\n",
      "Write summary at step 2330  Loss:  0.4057234525680542\n",
      "Write summary at step 2340  Loss:  0.569742739200592\n",
      "Write summary at step 2350  Loss:  0.43492391705513\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.908485856905158 Acurracy Balanced 0.9460462071411035\n",
      "Loss normal: 0.27313202916055307 Loss Control: 0.14532528125523217 Loss Patient: 0.3120482283305011 Loss balanced:  0.22868675479286665 Loss1+loss2: 0.22868675479286665\n",
      "Write summary at step 2360  Loss:  0.39850717782974243\n",
      "Write summary at step 2370  Loss:  0.41828352212905884\n",
      "Write summary at step 2380  Loss:  0.3395395278930664\n",
      "Write summary at step 2390  Loss:  0.31142473220825195\n",
      "Write summary at step 2400  Loss:  0.5472798347473145\n",
      "Write summary at step 2410  Loss:  0.44515863060951233\n",
      "Write summary at step 2420  Loss:  0.3134520947933197\n",
      "Write summary at step 2430  Loss:  0.35006260871887207\n",
      "Write summary at step 2440  Loss:  0.4458584785461426\n",
      "Write summary at step 2450  Loss:  0.5028999447822571\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9251247920133111 Acurracy Balanced 0.91884654901212\n",
      "Loss normal: 0.21549674807762614 Loss Control: 0.2880446891315648 Loss Patient: 0.19340644452020453 Loss balanced:  0.24072556682588464 Loss1+loss2: 0.24072556682588464\n",
      "Write summary at step 2460  Loss:  0.35490846633911133\n",
      "Write summary at step 2470  Loss:  0.38941359519958496\n",
      "Write summary at step 2480  Loss:  0.33029937744140625\n",
      "Write summary at step 2490  Loss:  0.47402310371398926\n",
      "Write summary at step 2500  Loss:  0.5695143938064575\n",
      "Saved checkpoint to: result/44/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.9510378876735495\n",
      "Loss normal: 0.2409126144282672 Loss Control: 0.2697311783097481 Loss Patient: 0.2321375802828746 Loss balanced:  0.25093437929631135 Loss1+loss2: 0.25093437929631135\n",
      "Write summary at step 2510  Loss:  0.3594364523887634\n",
      "Write summary at step 2520  Loss:  0.33785945177078247\n",
      "Write summary at step 2530  Loss:  0.3129222095012665\n",
      "Write summary at step 2540  Loss:  0.29333704710006714\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.9510378876735495\n",
      "Loss normal: 0.23392800013629758 Loss Control: 0.14576362537556006 Loss Patient: 0.2607733910770067 Loss balanced:  0.2032685082262834 Loss1+loss2: 0.2032685082262834\n",
      "\n",
      " > BEST MODEL (0.20327) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 2550  Loss:  0.47052326798439026\n",
      "Write summary at step 2560  Loss:  0.31928426027297974\n",
      "Write summary at step 2570  Loss:  0.3825207054615021\n",
      "Write summary at step 2580  Loss:  0.22787344455718994\n",
      "Write summary at step 2590  Loss:  0.2990356981754303\n",
      "Write summary at step 2600  Loss:  0.5633676648139954\n",
      "Write summary at step 2610  Loss:  0.4812370240688324\n",
      "Write summary at step 2620  Loss:  0.41656196117401123\n",
      "Write summary at step 2630  Loss:  0.4875624179840088\n",
      "Write summary at step 2640  Loss:  0.5832151770591736\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9320349508560414\n",
      "Loss normal: 0.2779719315621318 Loss Control: 0.22993643166588956 Loss Patient: 0.2925983815145572 Loss balanced:  0.2612674065902234 Loss1+loss2: 0.2612674065902234\n",
      "Write summary at step 2650  Loss:  0.31546515226364136\n",
      "Write summary at step 2660  Loss:  0.443606436252594\n",
      "Write summary at step 2670  Loss:  0.609603762626648\n",
      "Write summary at step 2680  Loss:  0.3920745849609375\n",
      "Write summary at step 2690  Loss:  0.2898901700973511\n",
      "Write summary at step 2700  Loss:  0.3868425488471985\n",
      "Write summary at step 2710  Loss:  0.40844422578811646\n",
      "Write summary at step 2720  Loss:  0.39194321632385254\n",
      "Write summary at step 2730  Loss:  0.2772420644760132\n",
      "Write summary at step 2740  Loss:  0.43139395117759705\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8958066246601748\n",
      "Loss normal: 0.2330412840356632 Loss Control: 0.357942063300336 Loss Patient: 0.19500993130211028 Loss balanced:  0.27647599730122313 Loss1+loss2: 0.27647599730122313\n",
      "Write summary at step 2750  Loss:  0.5485457181930542\n",
      "Write summary at step 2760  Loss:  0.21133920550346375\n",
      "Write summary at step 2770  Loss:  0.49519777297973633\n",
      "Write summary at step 2780  Loss:  0.27989938855171204\n",
      "Write summary at step 2790  Loss:  0.6381168365478516\n",
      "Write summary at step 2800  Loss:  0.44095364212989807\n",
      "Write summary at step 2810  Loss:  0.49872252345085144\n",
      "Write summary at step 2820  Loss:  0.5234082341194153\n",
      "Write summary at step 2830  Loss:  0.48570436239242554\n",
      "Write summary at step 2840  Loss:  0.42113426327705383\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.9217970049916805 Acurracy Balanced 0.9499695407472064\n",
      "Loss normal: 0.2188152422254183 Loss Control: 0.1726565738844741 Loss Patient: 0.23287021270805905 Loss balanced:  0.20276339329626658 Loss1+loss2: 0.20276339329626658\n",
      "\n",
      " > BEST MODEL (0.20276) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 2850  Loss:  0.3513914942741394\n",
      "Write summary at step 2860  Loss:  0.4738032817840576\n",
      "Write summary at step 2870  Loss:  0.22579799592494965\n",
      "Write summary at step 2880  Loss:  0.3384905755519867\n",
      "Write summary at step 2890  Loss:  0.4601691961288452\n",
      "Write summary at step 2900  Loss:  0.5794574618339539\n",
      "Write summary at step 2910  Loss:  0.4414648413658142\n",
      "Write summary at step 2920  Loss:  0.49883759021759033\n",
      "Write summary at step 2930  Loss:  0.4448744058609009\n",
      "Write summary at step 2940  Loss:  0.3010563254356384\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9432003127756108\n",
      "Loss normal: 0.22741454254303659 Loss Control: 0.1997529365977303 Loss Patient: 0.2358372978085091 Loss balanced:  0.2177951172031197 Loss1+loss2: 0.2177951172031197\n",
      "Write summary at step 2950  Loss:  0.3095150291919708\n",
      "Write summary at step 2960  Loss:  0.47843629121780396\n",
      "Write summary at step 2970  Loss:  0.5430489182472229\n",
      "Write summary at step 2980  Loss:  0.4359145164489746\n",
      "Write summary at step 2990  Loss:  0.4313013553619385\n",
      "Write summary at step 3000  Loss:  0.39451783895492554\n",
      "Saved checkpoint to: result/44/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9049489466553922\n",
      "Loss normal: 0.24507886650306837 Loss Control: 0.26648392703363805 Loss Patient: 0.23856118589193373 Loss balanced:  0.2525225564627859 Loss1+loss2: 0.2525225564627859\n",
      "Write summary at step 3010  Loss:  0.640161395072937\n",
      "Write summary at step 3020  Loss:  0.42383915185928345\n",
      "Write summary at step 3030  Loss:  0.3596172034740448\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9050716928979934\n",
      "Loss normal: 0.23104943494711602 Loss Control: 0.3103289017911817 Loss Patient: 0.20690942985840924 Loss balanced:  0.2586191658247955 Loss1+loss2: 0.2586191658247955\n",
      "Write summary at step 3040  Loss:  0.2707303762435913\n",
      "Write summary at step 3050  Loss:  0.310750812292099\n",
      "Write summary at step 3060  Loss:  0.39348897337913513\n",
      "Write summary at step 3070  Loss:  0.3759099841117859\n",
      "Write summary at step 3080  Loss:  0.4490445852279663\n",
      "Write summary at step 3090  Loss:  0.40960371494293213\n",
      "Write summary at step 3100  Loss:  0.33666694164276123\n",
      "Write summary at step 3110  Loss:  0.6287222504615784\n",
      "Write summary at step 3120  Loss:  0.30449002981185913\n",
      "Write summary at step 3130  Loss:  0.455530047416687\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8930743842230163\n",
      "Loss normal: 0.2332161239215306 Loss Control: 0.35536006239594004 Loss Patient: 0.19602421198827455 Loss balanced:  0.2756921371921073 Loss1+loss2: 0.2756921371921073\n",
      "Write summary at step 3140  Loss:  0.3528982102870941\n",
      "Write summary at step 3150  Loss:  0.17630615830421448\n",
      "Write summary at step 3160  Loss:  0.31962329149246216\n",
      "Write summary at step 3170  Loss:  0.47447848320007324\n",
      "Write summary at step 3180  Loss:  0.297953724861145\n",
      "Write summary at step 3190  Loss:  0.2977710962295532\n",
      "Write summary at step 3200  Loss:  0.5829723477363586\n",
      "Write summary at step 3210  Loss:  0.4202137887477875\n",
      "Write summary at step 3220  Loss:  0.471882164478302\n",
      "Write summary at step 3230  Loss:  0.4201796054840088\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.8779856886973442\n",
      "Loss normal: 0.23908855180655206 Loss Control: 0.398747672148741 Loss Patient: 0.1904735471960312 Loss balanced:  0.2946106096723861 Loss1+loss2: 0.2946106096723861\n",
      "Write summary at step 3240  Loss:  0.3834502696990967\n",
      "Write summary at step 3250  Loss:  0.5314023494720459\n",
      "Write summary at step 3260  Loss:  0.36021026968955994\n",
      "Write summary at step 3270  Loss:  0.33000677824020386\n",
      "Write summary at step 3280  Loss:  0.2649746835231781\n",
      "Write summary at step 3290  Loss:  0.3384033441543579\n",
      "Write summary at step 3300  Loss:  0.4950869381427765\n",
      "Write summary at step 3310  Loss:  0.43223220109939575\n",
      "Write summary at step 3320  Loss:  0.4155372083187103\n",
      "Write summary at step 3330  Loss:  0.36849796772003174\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8802451287926316\n",
      "Loss normal: 0.2530120702422395 Loss Control: 0.39804399046090133 Loss Patient: 0.20885093480398176 Loss balanced:  0.30344746263244154 Loss1+loss2: 0.30344746263244154\n",
      "Write summary at step 3340  Loss:  0.35533738136291504\n",
      "Write summary at step 3350  Loss:  0.20843905210494995\n",
      "Write summary at step 3360  Loss:  0.8115251064300537\n",
      "Write summary at step 3370  Loss:  0.3156445622444153\n",
      "Write summary at step 3380  Loss:  0.4147619307041168\n",
      "Write summary at step 3390  Loss:  0.3659875988960266\n",
      "Write summary at step 3400  Loss:  0.25175997614860535\n",
      "Write summary at step 3410  Loss:  0.5412792563438416\n",
      "Write summary at step 3420  Loss:  0.3332749605178833\n",
      "Write summary at step 3430  Loss:  0.26424986124038696\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8785812352818163\n",
      "Loss normal: 0.21751880259918316 Loss Control: 0.45741863003194005 Loss Patient: 0.1444711026157595 Loss balanced:  0.30094486632384976 Loss1+loss2: 0.30094486632384976\n",
      "Write summary at step 3440  Loss:  0.4059706926345825\n",
      "Write summary at step 3450  Loss:  0.4397839903831482\n",
      "Write summary at step 3460  Loss:  0.4331054091453552\n",
      "Write summary at step 3470  Loss:  0.3339628577232361\n",
      "Write summary at step 3480  Loss:  0.6655906438827515\n",
      "Write summary at step 3490  Loss:  0.4809120297431946\n",
      "Write summary at step 3500  Loss:  0.3792991042137146\n",
      "Saved checkpoint to: result/44/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8895101970304502\n",
      "Loss normal: 0.22564405240878768 Loss Control: 0.33288067790979897 Loss Patient: 0.19299129811975602 Loss balanced:  0.26293598801477747 Loss1+loss2: 0.26293598801477747\n",
      "Write summary at step 3510  Loss:  0.3289183974266052\n",
      "Write summary at step 3520  Loss:  0.455335795879364\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.8992480656101397\n",
      "Loss normal: 0.23212195681978245 Loss Control: 0.29853069375121527 Loss Patient: 0.21190099252043865 Loss balanced:  0.25521584313582696 Loss1+loss2: 0.25521584313582696\n",
      "Write summary at step 3530  Loss:  0.3273494839668274\n",
      "Write summary at step 3540  Loss:  0.5363756418228149\n",
      "Write summary at step 3550  Loss:  0.34417468309402466\n",
      "Write summary at step 3560  Loss:  0.3175157904624939\n",
      "Write summary at step 3570  Loss:  0.4998188018798828\n",
      "Write summary at step 3580  Loss:  0.3292925953865051\n",
      "Write summary at step 3590  Loss:  0.3103829324245453\n",
      "Write summary at step 3600  Loss:  0.3554312586784363\n",
      "Write summary at step 3610  Loss:  0.3746391832828522\n",
      "Write summary at step 3620  Loss:  0.32795077562332153\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9200376421810643\n",
      "Loss normal: 0.24656598946573782 Loss Control: 0.2757278573317606 Loss Patient: 0.2376864189514503 Loss balanced:  0.25670713814160545 Loss1+loss2: 0.25670713814160545\n",
      "Write summary at step 3630  Loss:  0.34483277797698975\n",
      "Write summary at step 3640  Loss:  0.25581663846969604\n",
      "Write summary at step 3650  Loss:  0.2628920078277588\n",
      "Write summary at step 3660  Loss:  0.6885859966278076\n",
      "Write summary at step 3670  Loss:  0.8718161582946777\n",
      "Write summary at step 3680  Loss:  0.3698265254497528\n",
      "Write summary at step 3690  Loss:  0.33506977558135986\n",
      "Write summary at step 3700  Loss:  0.3720554709434509\n",
      "Write summary at step 3710  Loss:  0.36515599489212036\n",
      "Write summary at step 3720  Loss:  0.6485691070556641\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9034077993871781\n",
      "Loss normal: 0.23334984732221584 Loss Control: 0.357518173957783 Loss Patient: 0.1955415230126627 Loss balanced:  0.2765298484852229 Loss1+loss2: 0.2765298484852229\n",
      "Write summary at step 3730  Loss:  0.27017128467559814\n",
      "Write summary at step 3740  Loss:  0.537813663482666\n",
      "Write summary at step 3750  Loss:  0.26303228735923767\n",
      "Write summary at step 3760  Loss:  0.24517932534217834\n",
      "Write summary at step 3770  Loss:  0.3390328884124756\n",
      "Write summary at step 3780  Loss:  0.38722705841064453\n",
      "Write summary at step 3790  Loss:  0.5171751976013184\n",
      "Write summary at step 3800  Loss:  0.3495122790336609\n",
      "Write summary at step 3810  Loss:  0.3400643467903137\n",
      "Write summary at step 3820  Loss:  0.5209037065505981\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9342943909513288\n",
      "Loss normal: 0.20777890656371506 Loss Control: 0.23131082080752471 Loss Patient: 0.2006136111778745 Loss balanced:  0.2159622159926996 Loss1+loss2: 0.2159622159926996\n",
      "Write summary at step 3830  Loss:  0.6294114589691162\n",
      "Write summary at step 3840  Loss:  0.45487672090530396\n",
      "Write summary at step 3850  Loss:  0.24125996232032776\n",
      "Write summary at step 3860  Loss:  0.36432453989982605\n",
      "Write summary at step 3870  Loss:  0.3819555342197418\n",
      "Write summary at step 3880  Loss:  0.4840328097343445\n",
      "Write summary at step 3890  Loss:  0.4313555955886841\n",
      "Write summary at step 3900  Loss:  0.5496883988380432\n",
      "Write summary at step 3910  Loss:  0.18250298500061035\n",
      "Write summary at step 3920  Loss:  0.15871840715408325\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9317985506851059\n",
      "Loss normal: 0.21140603728744448 Loss Control: 0.2410147896881312 Loss Patient: 0.20239039625780356 Loss balanced:  0.22170259297296738 Loss1+loss2: 0.22170259297296738\n",
      "Write summary at step 3930  Loss:  0.38658103346824646\n",
      "Write summary at step 3940  Loss:  0.24403448402881622\n",
      "Write summary at step 3950  Loss:  0.7004613876342773\n",
      "Write summary at step 3960  Loss:  0.6997474431991577\n",
      "Write summary at step 3970  Loss:  0.47502318024635315\n",
      "Write summary at step 3980  Loss:  0.35962361097335815\n",
      "Write summary at step 3990  Loss:  0.2968759536743164\n",
      "Write summary at step 4000  Loss:  0.3391474783420563\n",
      "Saved checkpoint to: result/44/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9288299100770119\n",
      "Loss normal: 0.21835518385074576 Loss Control: 0.2958293006719787 Loss Patient: 0.1947648963594992 Loss balanced:  0.24529709851573894 Loss1+loss2: 0.24529709851573894\n",
      "Write summary at step 4010  Loss:  0.4857679009437561\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9353627378776721\n",
      "Loss normal: 0.20695101553384138 Loss Control: 0.24337766242157566 Loss Patient: 0.19585937340922047 Loss balanced:  0.21961851791539805 Loss1+loss2: 0.21961851791539805\n",
      "Write summary at step 4020  Loss:  0.48980075120925903\n",
      "Write summary at step 4030  Loss:  0.3547966480255127\n",
      "Write summary at step 4040  Loss:  0.21179744601249695\n",
      "Write summary at step 4050  Loss:  0.507872998714447\n",
      "Write summary at step 4060  Loss:  0.3556625247001648\n",
      "Write summary at step 4070  Loss:  0.45804664492607117\n",
      "Write summary at step 4080  Loss:  0.4442809820175171\n",
      "Write summary at step 4090  Loss:  0.5066759586334229\n",
      "Write summary at step 4100  Loss:  0.4978020191192627\n",
      "Write summary at step 4110  Loss:  0.4280131161212921\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8537546711764545\n",
      "Loss normal: 0.26142831762530366 Loss Control: 0.5830213740223744 Loss Patient: 0.1635056392424515 Loss balanced:  0.373263506632413 Loss1+loss2: 0.373263506632413\n",
      "Write summary at step 4120  Loss:  0.2380886822938919\n",
      "Write summary at step 4130  Loss:  0.2868516743183136\n",
      "Write summary at step 4140  Loss:  0.5772424936294556\n",
      "Write summary at step 4150  Loss:  0.4477349817752838\n",
      "Write summary at step 4160  Loss:  0.5423301458358765\n",
      "Write summary at step 4170  Loss:  0.5272713899612427\n",
      "Write summary at step 4180  Loss:  0.38104212284088135\n",
      "Write summary at step 4190  Loss:  0.47462907433509827\n",
      "Write summary at step 4200  Loss:  0.4758463501930237\n",
      "Write summary at step 4210  Loss:  0.43867987394332886\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9246701762999736\n",
      "Loss normal: 0.2398281506433779 Loss Control: 0.2886859745275779 Loss Patient: 0.2249513101359572 Loss balanced:  0.25681864233176754 Loss1+loss2: 0.25681864233176754\n",
      "Write summary at step 4220  Loss:  0.30754631757736206\n",
      "Write summary at step 4230  Loss:  0.26933684945106506\n",
      "Write summary at step 4240  Loss:  0.29420340061187744\n",
      "Write summary at step 4250  Loss:  0.3701343536376953\n",
      "Write summary at step 4260  Loss:  0.30438196659088135\n",
      "Write summary at step 4270  Loss:  0.683465301990509\n",
      "Write summary at step 4280  Loss:  0.4250510632991791\n",
      "Write summary at step 4290  Loss:  0.4309405982494354\n",
      "Write summary at step 4300  Loss:  0.5808728933334351\n",
      "Write summary at step 4310  Loss:  0.32721349596977234\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9296618568324195\n",
      "Loss normal: 0.214128383112197 Loss Control: 0.25011943077129095 Loss Patient: 0.2031693793275392 Loss balanced:  0.22664440504941508 Loss1+loss2: 0.22664440504941508\n",
      "Write summary at step 4320  Loss:  0.35726553201675415\n",
      "Write summary at step 4330  Loss:  0.39733409881591797\n",
      "Write summary at step 4340  Loss:  0.4277539849281311\n",
      "Write summary at step 4350  Loss:  0.32373034954071045\n",
      "Write summary at step 4360  Loss:  0.32663437724113464\n",
      "Write summary at step 4370  Loss:  0.30522340536117554\n",
      "Write summary at step 4380  Loss:  0.3842264711856842\n",
      "Write summary at step 4390  Loss:  0.47915375232696533\n",
      "Write summary at step 4400  Loss:  0.3080936372280121\n",
      "Write summary at step 4410  Loss:  0.24834460020065308\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9315621505141705\n",
      "Loss normal: 0.21629543138705953 Loss Control: 0.24667072426425954 Loss Patient: 0.20704638238952877 Loss balanced:  0.22685855332689414 Loss1+loss2: 0.22685855332689414\n",
      "Write summary at step 4420  Loss:  0.21370957791805267\n",
      "Write summary at step 4430  Loss:  0.5178145170211792\n",
      "Write summary at step 4440  Loss:  0.35983699560165405\n",
      "Write summary at step 4450  Loss:  0.2480936199426651\n",
      "Write summary at step 4460  Loss:  0.32680824398994446\n",
      "Write summary at step 4470  Loss:  0.31632110476493835\n",
      "Write summary at step 4480  Loss:  0.3372611701488495\n",
      "Write summary at step 4490  Loss:  0.6066432595252991\n",
      "Write summary at step 4500  Loss:  0.5899796485900879\n",
      "Saved checkpoint to: result/44/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8804815289635671\n",
      "Loss normal: 0.20812031660913205 Loss Control: 0.38764553643315214 Loss Patient: 0.15345623014423493 Loss balanced:  0.27055088328869353 Loss1+loss2: 0.27055088328869353\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.891410490712201\n",
      "Loss normal: 0.2027768263099145 Loss Control: 0.3979759809097957 Loss Patient: 0.14334014601100503 Loss balanced:  0.27065806346040033 Loss1+loss2: 0.27065806346040033\n",
      "Write summary at step 4510  Loss:  0.5224953889846802\n",
      "Write summary at step 4520  Loss:  0.22994986176490784\n",
      "Write summary at step 4530  Loss:  0.2860508859157562\n",
      "Write summary at step 4540  Loss:  0.650098443031311\n",
      "Write summary at step 4550  Loss:  0.27391988039016724\n",
      "Write summary at step 4560  Loss:  0.3042834401130676\n",
      "Write summary at step 4570  Loss:  0.27408283948898315\n",
      "Write summary at step 4580  Loss:  0.3582361340522766\n",
      "Write summary at step 4590  Loss:  0.4282703697681427\n",
      "Write summary at step 4600  Loss:  0.5227519273757935\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8371248283825683\n",
      "Loss normal: 0.2408478314399111 Loss Control: 0.6126232538066927 Loss Patient: 0.12764499781532415 Loss balanced:  0.3701341258110084 Loss1+loss2: 0.3701341258110084\n",
      "Write summary at step 4610  Loss:  0.1710568368434906\n",
      "Write summary at step 4620  Loss:  0.37172025442123413\n",
      "Write summary at step 4630  Loss:  0.29743263125419617\n",
      "Write summary at step 4640  Loss:  0.4169575572013855\n",
      "Write summary at step 4650  Loss:  0.403348445892334\n",
      "Write summary at step 4660  Loss:  0.3325731158256531\n",
      "Write summary at step 4670  Loss:  0.44901567697525024\n",
      "Write summary at step 4680  Loss:  0.293942928314209\n",
      "Write summary at step 4690  Loss:  0.3322398066520691\n",
      "Write summary at step 4700  Loss:  0.3623368740081787\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8895101970304502\n",
      "Loss normal: 0.22028022571181766 Loss Control: 0.3903009442032361 Loss Patient: 0.16851018783256733 Loss balanced:  0.2794055660179017 Loss1+loss2: 0.2794055660179017\n",
      "Write summary at step 4710  Loss:  0.49614784121513367\n",
      "Write summary at step 4720  Loss:  0.2730953097343445\n",
      "Write summary at step 4730  Loss:  0.37729012966156006\n",
      "Write summary at step 4740  Loss:  0.32985422015190125\n",
      "Write summary at step 4750  Loss:  0.4642588198184967\n",
      "Write summary at step 4760  Loss:  0.1274118572473526\n",
      "Write summary at step 4770  Loss:  0.44887575507164\n",
      "Write summary at step 4780  Loss:  0.44452759623527527\n",
      "Write summary at step 4790  Loss:  0.2807292640209198\n",
      "Write summary at step 4800  Loss:  0.44191882014274597\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9405908185810534\n",
      "Loss normal: 0.19908356864233406 Loss Control: 0.2422925214298436 Loss Patient: 0.18592676264969957 Loss balanced:  0.21410964203977156 Loss1+loss2: 0.21410964203977156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 4810  Loss:  0.2581561207771301\n",
      "Write summary at step 4820  Loss:  0.3177189826965332\n",
      "Write summary at step 4830  Loss:  0.595727801322937\n",
      "Write summary at step 4840  Loss:  0.7413941621780396\n",
      "Write summary at step 4850  Loss:  0.28598183393478394\n",
      "Write summary at step 4860  Loss:  0.431338369846344\n",
      "Write summary at step 4870  Loss:  0.5973525047302246\n",
      "Write summary at step 4880  Loss:  0.48507067561149597\n",
      "Write summary at step 4890  Loss:  0.4561314284801483\n",
      "Write summary at step 4900  Loss:  0.4876231551170349\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8928379840520808\n",
      "Loss normal: 0.21971607242463803 Loss Control: 0.4000219412840129 Loss Patient: 0.16481428470667112 Loss balanced:  0.28241811299534203 Loss1+loss2: 0.28241811299534203\n",
      "Write summary at step 4910  Loss:  0.3133683204650879\n",
      "Write summary at step 4920  Loss:  0.39985793828964233\n",
      "Write summary at step 4930  Loss:  0.295438677072525\n",
      "Write summary at step 4940  Loss:  0.39346787333488464\n",
      "Write summary at step 4950  Loss:  0.43280088901519775\n",
      "Write summary at step 4960  Loss:  0.6431814432144165\n",
      "Write summary at step 4970  Loss:  0.44027507305145264\n",
      "Write summary at step 4980  Loss:  0.27019238471984863\n",
      "Write summary at step 4990  Loss:  0.3864535391330719\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9181373484993136\n",
      "Loss normal: 0.21753571091257795 Loss Control: 0.220441666457171 Loss Patient: 0.2166508661827906 Loss balanced:  0.2185462663199808 Loss1+loss2: 0.2185462663199808\n",
      "Write summary at step 5000  Loss:  0.4905669093132019\n",
      "Saved checkpoint to: result/44/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.914336761135812\n",
      "Loss normal: 0.2177128332610033 Loss Control: 0.24722333928274978 Loss Patient: 0.20872710293124797 Loss balanced:  0.22797522110699886 Loss1+loss2: 0.22797522110699886\n",
      "Write summary at step 5010  Loss:  0.2615589499473572\n",
      "Write summary at step 5020  Loss:  0.4235547184944153\n",
      "Write summary at step 5030  Loss:  0.3659888207912445\n",
      "Write summary at step 5040  Loss:  0.35668519139289856\n",
      "Write summary at step 5050  Loss:  0.5110639929771423\n",
      "Write summary at step 5060  Loss:  0.4577249586582184\n",
      "Write summary at step 5070  Loss:  0.45536893606185913\n",
      "Write summary at step 5080  Loss:  0.2436116337776184\n",
      "Write summary at step 5090  Loss:  0.6475634574890137\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.9275251629797332\n",
      "Loss normal: 0.1927944900734084 Loss Control: 0.2996357360172793 Loss Patient: 0.1602621324571119 Loss balanced:  0.2299489342371956 Loss1+loss2: 0.2299489342371956\n",
      "Write summary at step 5100  Loss:  0.32890090346336365\n",
      "Write summary at step 5110  Loss:  0.5393103361129761\n",
      "Write summary at step 5120  Loss:  0.358026385307312\n",
      "Write summary at step 5130  Loss:  0.31722813844680786\n",
      "Write summary at step 5140  Loss:  0.151633620262146\n",
      "Write summary at step 5150  Loss:  0.24085773527622223\n",
      "Write summary at step 5160  Loss:  0.3973947763442993\n",
      "Write summary at step 5170  Loss:  0.29574888944625854\n",
      "Write summary at step 5180  Loss:  0.2536296546459198\n",
      "Write summary at step 5190  Loss:  0.49713319540023804\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9427275124337398\n",
      "Loss normal: 0.2260987764718581 Loss Control: 0.1878329811851835 Loss Patient: 0.2377504216950269 Loss balanced:  0.21279170144010517 Loss1+loss2: 0.21279170144010517\n",
      "Write summary at step 5200  Loss:  0.3553773760795593\n",
      "Write summary at step 5210  Loss:  0.4134913384914398\n",
      "Write summary at step 5220  Loss:  0.36953479051589966\n",
      "Write summary at step 5230  Loss:  0.2820325195789337\n",
      "Write summary at step 5240  Loss:  0.4838753640651703\n",
      "Write summary at step 5250  Loss:  0.2057853490114212\n",
      "Write summary at step 5260  Loss:  0.35976213216781616\n",
      "Write summary at step 5270  Loss:  0.4043393135070801\n",
      "Write summary at step 5280  Loss:  0.2716906666755676\n",
      "Write summary at step 5290  Loss:  0.4229324460029602\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.8851913477537438 Acurracy Balanced 0.9398634334397133\n",
      "Loss normal: 0.27839135127712267 Loss Control: 0.07692296973994521 Loss Patient: 0.3397369631713321 Loss balanced:  0.20832996645563867 Loss1+loss2: 0.20832996645563867\n",
      "Write summary at step 5300  Loss:  0.3043578565120697\n",
      "Write summary at step 5310  Loss:  0.35651594400405884\n",
      "Write summary at step 5320  Loss:  0.41264674067497253\n",
      "Write summary at step 5330  Loss:  0.36931753158569336\n",
      "Write summary at step 5340  Loss:  0.4405372738838196\n",
      "Write summary at step 5350  Loss:  0.3084326386451721\n",
      "Write summary at step 5360  Loss:  0.2250409573316574\n",
      "Write summary at step 5370  Loss:  0.19184139370918274\n",
      "Write summary at step 5380  Loss:  0.35881686210632324\n",
      "Write summary at step 5390  Loss:  0.4477633833885193\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9040033459716501\n",
      "Loss normal: 0.23044468523288258 Loss Control: 0.3178253905043576 Loss Patient: 0.20383791315575409 Loss balanced:  0.26083165183005586 Loss1+loss2: 0.26083165183005586\n",
      "Write summary at step 5400  Loss:  0.3149780035018921\n",
      "Write summary at step 5410  Loss:  0.20752544701099396\n",
      "Write summary at step 5420  Loss:  0.35289064049720764\n",
      "Write summary at step 5430  Loss:  0.2731269598007202\n",
      "Write summary at step 5440  Loss:  0.3429080843925476\n",
      "Write summary at step 5450  Loss:  0.3665660321712494\n",
      "Write summary at step 5460  Loss:  0.39677703380584717\n",
      "Write summary at step 5470  Loss:  0.40752100944519043\n",
      "Write summary at step 5480  Loss:  0.5889058113098145\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9451530612244898 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9452233526999627\n",
      "Loss normal: 0.2069201320029643 Loss Control: 0.2086415548142188 Loss Patient: 0.20639597241473873 Loss balanced:  0.20751876361447877 Loss1+loss2: 0.20751876361447877\n",
      "Write summary at step 5490  Loss:  0.23659640550613403\n",
      "Write summary at step 5500  Loss:  0.6025393605232239\n",
      "Saved checkpoint to: result/44/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9481919933080567\n",
      "Loss normal: 0.21647483011593624 Loss Control: 0.1601107213340822 Loss Patient: 0.2336372762620945 Loss balanced:  0.19687399879808834 Loss1+loss2: 0.19687399879808834\n",
      "\n",
      " > BEST MODEL (0.19687) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 5510  Loss:  0.22877629101276398\n",
      "Write summary at step 5520  Loss:  0.31070244312286377\n",
      "Write summary at step 5530  Loss:  0.5697169303894043\n",
      "Write summary at step 5540  Loss:  0.22092634439468384\n",
      "Write summary at step 5550  Loss:  0.5237475633621216\n",
      "Write summary at step 5560  Loss:  0.2665388584136963\n",
      "Write summary at step 5570  Loss:  0.2954513728618622\n",
      "Write summary at step 5580  Loss:  0.24717289209365845\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9031713992162425\n",
      "Loss normal: 0.2121222941775103 Loss Control: 0.3311975956614552 Loss Patient: 0.1758647594793069 Loss balanced:  0.253531177570381 Loss1+loss2: 0.253531177570381\n",
      "Write summary at step 5590  Loss:  0.47187867760658264\n",
      "Write summary at step 5600  Loss:  0.24583491683006287\n",
      "Write summary at step 5610  Loss:  0.23314356803894043\n",
      "Write summary at step 5620  Loss:  0.27140530943870544\n",
      "Write summary at step 5630  Loss:  0.3550812005996704\n",
      "Write summary at step 5640  Loss:  0.39540135860443115\n",
      "Write summary at step 5650  Loss:  0.5200328826904297\n",
      "Write summary at step 5660  Loss:  0.32634833455085754\n",
      "Write summary at step 5670  Loss:  0.4429064989089966\n",
      "Write summary at step 5680  Loss:  0.29123616218566895\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.9127956138675977\n",
      "Loss normal: 0.19512473620778445 Loss Control: 0.38986199931368803 Loss Patient: 0.13582869880707213 Loss balanced:  0.2628453490603801 Loss1+loss2: 0.2628453490603801\n",
      "Write summary at step 5690  Loss:  0.2749912738800049\n",
      "Write summary at step 5700  Loss:  0.25025615096092224\n",
      "Write summary at step 5710  Loss:  0.5271081924438477\n",
      "Write summary at step 5720  Loss:  0.4381592571735382\n",
      "Write summary at step 5730  Loss:  0.28833824396133423\n",
      "Write summary at step 5740  Loss:  0.401519238948822\n",
      "Write summary at step 5750  Loss:  0.1815965175628662\n",
      "Write summary at step 5760  Loss:  0.3532432019710541\n",
      "Write summary at step 5770  Loss:  0.34537234902381897\n",
      "Write summary at step 5780  Loss:  0.3184134066104889\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.953892874353309\n",
      "Loss normal: 0.21756376067594607 Loss Control: 0.1883463045287002 Loss Patient: 0.2264602565130656 Loss balanced:  0.2074032805208829 Loss1+loss2: 0.2074032805208829\n",
      "Write summary at step 5790  Loss:  0.3405285179615021\n",
      "Write summary at step 5800  Loss:  0.2591344118118286\n",
      "Write summary at step 5810  Loss:  0.39386627078056335\n",
      "Write summary at step 5820  Loss:  0.4242853820323944\n",
      "Write summary at step 5830  Loss:  0.3237172067165375\n",
      "Write summary at step 5840  Loss:  0.33534136414527893\n",
      "Write summary at step 5850  Loss:  0.4167986810207367\n",
      "Write summary at step 5860  Loss:  0.49013715982437134\n",
      "Write summary at step 5870  Loss:  0.443695068359375\n",
      "Write summary at step 5880  Loss:  0.48914971947669983\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8974705181709901\n",
      "Loss normal: 0.19924134704075297 Loss Control: 0.4032636222943582 Loss Patient: 0.13711809053298044 Loss balanced:  0.2701908564136693 Loss1+loss2: 0.2701908564136693\n",
      "Write summary at step 5890  Loss:  0.4621436893939972\n",
      "Write summary at step 5900  Loss:  0.3065899610519409\n",
      "Write summary at step 5910  Loss:  0.6097652316093445\n",
      "Write summary at step 5920  Loss:  0.2725895047187805\n",
      "Write summary at step 5930  Loss:  0.3140137195587158\n",
      "Write summary at step 5940  Loss:  0.5124476552009583\n",
      "Write summary at step 5950  Loss:  0.15674078464508057\n",
      "Write summary at step 5960  Loss:  0.4587356448173523\n",
      "Write summary at step 5970  Loss:  0.34316015243530273\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9122000672831256\n",
      "Loss normal: 0.20010501754527188 Loss Control: 0.2917677069622311 Loss Patient: 0.17219441504327707 Loss balanced:  0.23198106100275406 Loss1+loss2: 0.23198106100275406\n",
      "Write summary at step 5980  Loss:  0.5665174722671509\n",
      "Write summary at step 5990  Loss:  0.2964800298213959\n",
      "Write summary at step 6000  Loss:  0.3864198923110962\n",
      "Saved checkpoint to: result/44/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8701481137994054\n",
      "Loss normal: 0.21391383117559004 Loss Control: 0.4529521120050566 Loss Patient: 0.14112846144225555 Loss balanced:  0.29704028672365607 Loss1+loss2: 0.29704028672365607\n",
      "Write summary at step 6010  Loss:  0.39057064056396484\n",
      "Write summary at step 6020  Loss:  0.4982486665248871\n",
      "Write summary at step 6030  Loss:  0.23258206248283386\n",
      "Write summary at step 6040  Loss:  0.3288594186306\n",
      "Write summary at step 6050  Loss:  0.5290119051933289\n",
      "Write summary at step 6060  Loss:  0.1618141084909439\n",
      "Write summary at step 6070  Loss:  0.36025989055633545\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9464285714285714 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9555567678641245\n",
      "Loss normal: 0.1913621614173967 Loss Control: 0.19507111617124798 Loss Patient: 0.19023281152355492 Loss balanced:  0.19265196384740146 Loss1+loss2: 0.19265196384740146\n",
      "\n",
      " > BEST MODEL (0.19265) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 6080  Loss:  0.38671594858169556\n",
      "Write summary at step 6090  Loss:  0.7147982120513916\n",
      "Write summary at step 6100  Loss:  0.5186451077461243\n",
      "Write summary at step 6110  Loss:  0.5553932785987854\n",
      "Write summary at step 6120  Loss:  0.24883684515953064\n",
      "Write summary at step 6130  Loss:  0.4217171370983124\n",
      "Write summary at step 6140  Loss:  0.33118313550949097\n",
      "Write summary at step 6150  Loss:  0.13780520856380463\n",
      "Write summary at step 6160  Loss:  0.20361477136611938\n",
      "Write summary at step 6170  Loss:  0.5604775547981262\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9212287353500086\n",
      "Loss normal: 0.20941639395088565 Loss Control: 0.2921967196985672 Loss Patient: 0.18421040472889105 Loss balanced:  0.23820356221372913 Loss1+loss2: 0.23820356221372913\n",
      "Write summary at step 6180  Loss:  0.3403348922729492\n",
      "Write summary at step 6190  Loss:  0.20695914328098297\n",
      "Write summary at step 6200  Loss:  0.39128538966178894\n",
      "Write summary at step 6210  Loss:  0.3084445297718048\n",
      "Write summary at step 6220  Loss:  0.4581352472305298\n",
      "Write summary at step 6230  Loss:  0.23121869564056396\n",
      "Write summary at step 6240  Loss:  0.46537017822265625\n",
      "Write summary at step 6250  Loss:  0.43797701597213745\n",
      "Write summary at step 6260  Loss:  0.3231543302536011\n",
      "Write summary at step 6270  Loss:  0.3787150979042053\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9260976696398535\n",
      "Loss normal: 0.19555542416566488 Loss Control: 0.22806591479504695 Loss Patient: 0.1856562216547682 Loss balanced:  0.20686106822490757 Loss1+loss2: 0.20686106822490757\n",
      "Write summary at step 6280  Loss:  0.37963932752609253\n",
      "Write summary at step 6290  Loss:  0.24557165801525116\n",
      "Write summary at step 6300  Loss:  0.32951709628105164\n",
      "Write summary at step 6310  Loss:  0.2951657176017761\n",
      "Write summary at step 6320  Loss:  0.39116936922073364\n",
      "Write summary at step 6330  Loss:  0.25568145513534546\n",
      "Write summary at step 6340  Loss:  0.24230174720287323\n",
      "Write summary at step 6350  Loss:  0.5579922795295715\n",
      "Write summary at step 6360  Loss:  0.20862165093421936\n",
      "Write summary at step 6370  Loss:  0.4373326301574707\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9427275124337398\n",
      "Loss normal: 0.21455007981584998 Loss Control: 0.20309624450454294 Loss Patient: 0.21803768398162726 Loss balanced:  0.2105669642430851 Loss1+loss2: 0.2105669642430851\n",
      "Write summary at step 6380  Loss:  0.4373544752597809\n",
      "Write summary at step 6390  Loss:  0.3846496343612671\n",
      "Write summary at step 6400  Loss:  0.049885619431734085\n",
      "Write summary at step 6410  Loss:  0.3634130358695984\n",
      "Write summary at step 6420  Loss:  0.3884211778640747\n",
      "Write summary at step 6430  Loss:  0.38399940729141235\n",
      "Write summary at step 6440  Loss:  0.7499157786369324\n",
      "Write summary at step 6450  Loss:  0.4981119930744171\n",
      "Write summary at step 6460  Loss:  0.40455618500709534\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8892737968595147\n",
      "Loss normal: 0.20449896217608937 Loss Control: 0.3528239459939342 Loss Patient: 0.15933511878507903 Loss balanced:  0.2560795323895066 Loss1+loss2: 0.2560795323895066\n",
      "Write summary at step 6470  Loss:  0.40361887216567993\n",
      "Write summary at step 6480  Loss:  0.4532804489135742\n",
      "Write summary at step 6490  Loss:  0.32607975602149963\n",
      "Write summary at step 6500  Loss:  0.3886822462081909\n",
      "Saved checkpoint to: result/44/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8930743842230163\n",
      "Loss normal: 0.2106059125947709 Loss Control: 0.3474683663884147 Loss Patient: 0.168932320485 Loss balanced:  0.2582003434367074 Loss1+loss2: 0.2582003434367074\n",
      "Write summary at step 6510  Loss:  0.28684675693511963\n",
      "Write summary at step 6520  Loss:  0.5679820775985718\n",
      "Write summary at step 6530  Loss:  0.3376365900039673\n",
      "Write summary at step 6540  Loss:  0.3035207688808441\n",
      "Write summary at step 6550  Loss:  0.28699466586112976\n",
      "Write summary at step 6560  Loss:  0.29913395643234253\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9031713992162425\n",
      "Loss normal: 0.2243798835089012 Loss Control: 0.2802873472046982 Loss Patient: 0.2073564828433927 Loss balanced:  0.24382191502404546 Loss1+loss2: 0.24382191502404546\n",
      "Write summary at step 6570  Loss:  0.21936625242233276\n",
      "Write summary at step 6580  Loss:  0.4611586630344391\n",
      "Write summary at step 6590  Loss:  0.4773321747779846\n",
      "Write summary at step 6600  Loss:  0.27464139461517334\n",
      "Write summary at step 6610  Loss:  0.4635852575302124\n",
      "Write summary at step 6620  Loss:  0.49244722723960876\n",
      "Write summary at step 6630  Loss:  0.2694440484046936\n",
      "Write summary at step 6640  Loss:  0.2687342166900635\n",
      "Write summary at step 6650  Loss:  0.18222397565841675\n",
      "Write summary at step 6660  Loss:  0.3926854431629181\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9021030522898994\n",
      "Loss normal: 0.20170912868818458 Loss Control: 0.33235515173667113 Loss Patient: 0.16192839325664443 Loss balanced:  0.24714177249665778 Loss1+loss2: 0.24714177249665778\n",
      "Write summary at step 6670  Loss:  0.4063275158405304\n",
      "Write summary at step 6680  Loss:  0.355817586183548\n",
      "Write summary at step 6690  Loss:  0.24066410958766937\n",
      "Write summary at step 6700  Loss:  0.2854318916797638\n",
      "Write summary at step 6710  Loss:  0.39306309819221497\n",
      "Write summary at step 6720  Loss:  0.26554936170578003\n",
      "Write summary at step 6730  Loss:  0.2738179564476013\n",
      "Write summary at step 6740  Loss:  0.2831466794013977\n",
      "Write summary at step 6750  Loss:  0.2785423696041107\n",
      "Write summary at step 6760  Loss:  0.3817317485809326\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9405908185810534\n",
      "Loss normal: 0.1889203266069597 Loss Control: 0.25602938536086367 Loss Patient: 0.16848612468869437 Loss balanced:  0.212257755024779 Loss1+loss2: 0.212257755024779\n",
      "Write summary at step 6770  Loss:  0.28035181760787964\n",
      "Write summary at step 6780  Loss:  0.2708470821380615\n",
      "Write summary at step 6790  Loss:  0.4701910614967346\n",
      "Write summary at step 6800  Loss:  0.30530476570129395\n",
      "Write summary at step 6810  Loss:  0.35278868675231934\n",
      "Write summary at step 6820  Loss:  0.2866584062576294\n",
      "Write summary at step 6830  Loss:  0.2925935387611389\n",
      "Write summary at step 6840  Loss:  0.2804744839668274\n",
      "Write summary at step 6850  Loss:  0.3541623055934906\n",
      "Write summary at step 6860  Loss:  0.4028777480125427\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.947360046552649\n",
      "Loss normal: 0.2005625058877833 Loss Control: 0.18517091642312014 Loss Patient: 0.20524913037874537 Loss balanced:  0.19521002340093274 Loss1+loss2: 0.19521002340093274\n",
      "Write summary at step 6870  Loss:  0.19544759392738342\n",
      "Write summary at step 6880  Loss:  0.22178903222084045\n",
      "Write summary at step 6890  Loss:  0.3500811457633972\n",
      "Write summary at step 6900  Loss:  0.307289183139801\n",
      "Write summary at step 6910  Loss:  0.3668918311595917\n",
      "Write summary at step 6920  Loss:  0.33106088638305664\n",
      "Write summary at step 6930  Loss:  0.4194885790348053\n",
      "Write summary at step 6940  Loss:  0.3858157694339752\n",
      "Write summary at step 6950  Loss:  0.37647342681884766\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9522289808424937\n",
      "Loss normal: 0.21065431335294732 Loss Control: 0.15063104994310056 Loss Patient: 0.22893094668124558 Loss balanced:  0.18978099831217307 Loss1+loss2: 0.18978099831217307\n",
      "\n",
      " > BEST MODEL (0.18978) : result/44/panns/best_checkpoint.pt\n",
      "Write summary at step 6960  Loss:  0.3662792444229126\n",
      "Write summary at step 6970  Loss:  0.2766299247741699\n",
      "Write summary at step 6980  Loss:  0.3423694968223572\n",
      "Write summary at step 6990  Loss:  0.3055393397808075\n",
      "Write summary at step 7000  Loss:  0.3552261292934418\n",
      "Saved checkpoint to: result/44/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9432003127756108\n",
      "Loss normal: 0.2254409632664554 Loss Control: 0.1699064351170441 Loss Patient: 0.24235081068935888 Loss balanced:  0.2061286229032015 Loss1+loss2: 0.2061286229032015\n",
      "Write summary at step 7010  Loss:  0.2460290491580963\n",
      "Write summary at step 7020  Loss:  0.31277722120285034\n",
      "Write summary at step 7030  Loss:  0.3529904782772064\n",
      "Write summary at step 7040  Loss:  0.5434448719024658\n",
      "Write summary at step 7050  Loss:  0.19701416790485382\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8966385714155825\n",
      "Loss normal: 0.21122897461969026 Loss Control: 0.389332855008339 Loss Patient: 0.1569976729407485 Loss balanced:  0.27316526397454377 Loss1+loss2: 0.27316526397454377\n",
      "Write summary at step 7060  Loss:  0.38733893632888794\n",
      "Write summary at step 7070  Loss:  0.4264135956764221\n",
      "Write summary at step 7080  Loss:  0.20845454931259155\n",
      "Write summary at step 7090  Loss:  0.28211963176727295\n",
      "Write summary at step 7100  Loss:  0.3344080150127411\n",
      "Write summary at step 7110  Loss:  0.28351733088493347\n",
      "Write summary at step 7120  Loss:  0.46089276671409607\n",
      "Write summary at step 7130  Loss:  0.3882311284542084\n",
      "Write summary at step 7140  Loss:  0.42471471428871155\n",
      "Write summary at step 7150  Loss:  0.43616747856140137\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9157642544756917\n",
      "Loss normal: 0.20345885371219138 Loss Control: 0.33168899426694776 Loss Patient: 0.16441373492338496 Loss balanced:  0.24805136459516636 Loss1+loss2: 0.24805136459516636\n",
      "Write summary at step 7160  Loss:  0.4175812005996704\n",
      "Write summary at step 7170  Loss:  0.3774681091308594\n",
      "Write summary at step 7180  Loss:  0.41646355390548706\n",
      "Write summary at step 7190  Loss:  0.2445995956659317\n",
      "Write summary at step 7200  Loss:  0.20337560772895813\n",
      "Write summary at step 7210  Loss:  0.5167032480239868\n",
      "Write summary at step 7220  Loss:  0.509147584438324\n",
      "Write summary at step 7230  Loss:  0.3675042688846588\n",
      "Write summary at step 7240  Loss:  0.23246774077415466\n",
      "Write summary at step 7250  Loss:  0.4551907181739807\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.87644454142913\n",
      "Loss normal: 0.23455067476903907 Loss Control: 0.4299751696039419 Loss Patient: 0.17504537539454348 Loss balanced:  0.30251027249924267 Loss1+loss2: 0.30251027249924267\n",
      "Write summary at step 7260  Loss:  0.5122296214103699\n",
      "Write summary at step 7270  Loss:  0.5297077298164368\n",
      "Write summary at step 7280  Loss:  0.5572531223297119\n",
      "Write summary at step 7290  Loss:  0.3535889685153961\n",
      "Write summary at step 7300  Loss:  0.40702199935913086\n",
      "Write summary at step 7310  Loss:  0.265653520822525\n",
      "Write summary at step 7320  Loss:  0.3507676124572754\n",
      "Write summary at step 7330  Loss:  0.32339876890182495\n",
      "Write summary at step 7340  Loss:  0.4803350567817688\n",
      "Write summary at step 7350  Loss:  0.17360803484916687\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8545866179318622\n",
      "Loss normal: 0.23300553426830745 Loss Control: 0.5335352143954709 Loss Patient: 0.14149649769142147 Loss balanced:  0.3375158560434462 Loss1+loss2: 0.3375158560434462\n",
      "Write summary at step 7360  Loss:  0.3311736285686493\n",
      "Write summary at step 7370  Loss:  0.4548259973526001\n",
      "Write summary at step 7380  Loss:  0.2702559530735016\n",
      "Write summary at step 7390  Loss:  0.2828870117664337\n",
      "Write summary at step 7400  Loss:  0.3551190495491028\n",
      "Write summary at step 7410  Loss:  0.2790072560310364\n",
      "Write summary at step 7420  Loss:  0.34748759865760803\n",
      "Write summary at step 7430  Loss:  0.6256336569786072\n",
      "Write summary at step 7440  Loss:  0.5001713037490845\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.914932307720284\n",
      "Loss normal: 0.20909834257802185 Loss Control: 0.28902721795879427 Loss Patient: 0.18476059762590538 Loss balanced:  0.2368939077923498 Loss1+loss2: 0.2368939077923498\n",
      "Write summary at step 7450  Loss:  0.40881043672561646\n",
      "Write summary at step 7460  Loss:  0.4805005192756653\n",
      "Write summary at step 7470  Loss:  0.3564632534980774\n",
      "Write summary at step 7480  Loss:  0.18928813934326172\n",
      "Write summary at step 7490  Loss:  0.7223294973373413\n",
      "Write summary at step 7500  Loss:  0.4793374836444855\n",
      "Saved checkpoint to: result/44/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8985388650973333\n",
      "Loss normal: 0.22389195422280808 Loss Control: 0.3481608482657886 Loss Patient: 0.1860530094899076 Loss balanced:  0.2671069288778481 Loss1+loss2: 0.2671069288778481\n",
      "Write summary at step 7510  Loss:  0.3063122034072876\n",
      "Write summary at step 7520  Loss:  0.36189255118370056\n",
      "Write summary at step 7530  Loss:  0.6977494955062866\n",
      "Write summary at step 7540  Loss:  0.40207067131996155\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.86195139248793\n",
      "Loss normal: 0.23481356451401905 Loss Control: 0.5163878834312731 Loss Patient: 0.1490762900939202 Loss balanced:  0.33273208676259663 Loss1+loss2: 0.33273208676259663\n",
      "Write summary at step 7550  Loss:  0.31968986988067627\n",
      "Write summary at step 7560  Loss:  0.5118827223777771\n",
      "Write summary at step 7570  Loss:  0.37857505679130554\n",
      "Write summary at step 7580  Loss:  0.31022903323173523\n",
      "Write summary at step 7590  Loss:  0.4008077383041382\n",
      "Write summary at step 7600  Loss:  0.2320777177810669\n",
      "Write summary at step 7610  Loss:  0.27599722146987915\n",
      "Write summary at step 7620  Loss:  0.2926294505596161\n",
      "Write summary at step 7630  Loss:  0.31150898337364197\n",
      "Write summary at step 7640  Loss:  0.17971432209014893\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8537546711764545\n",
      "Loss normal: 0.2785921236310078 Loss Control: 0.54800258829294 Loss Patient: 0.19655865539925269 Loss balanced:  0.37228062184609634 Loss1+loss2: 0.37228062184609634\n",
      "Write summary at step 7650  Loss:  0.3733493685722351\n",
      "Write summary at step 7660  Loss:  0.4022037386894226\n",
      "Write summary at step 7670  Loss:  0.37286698818206787\n",
      "Write summary at step 7680  Loss:  0.31286346912384033\n",
      "Write summary at step 7690  Loss:  0.502370297908783\n",
      "Write summary at step 7700  Loss:  0.36498749256134033\n",
      "Write summary at step 7710  Loss:  0.2281961292028427\n",
      "Write summary at step 7720  Loss:  0.7059996128082275\n",
      "Write summary at step 7730  Loss:  0.3029766082763672\n",
      "Write summary at step 7740  Loss:  0.2699352502822876\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8335606411900021\n",
      "Loss normal: 0.2376362296695612 Loss Control: 0.5501030615118684 Loss Patient: 0.14249242037633889 Loss balanced:  0.34629774094410365 Loss1+loss2: 0.34629774094410365\n",
      "Write summary at step 7750  Loss:  0.37465476989746094\n",
      "Write summary at step 7760  Loss:  0.3648313283920288\n",
      "Write summary at step 7770  Loss:  0.3705770969390869\n",
      "Write summary at step 7780  Loss:  0.30490514636039734\n",
      "Write summary at step 7790  Loss:  0.3537413477897644\n",
      "Write summary at step 7800  Loss:  0.19299311935901642\n",
      "Write summary at step 7810  Loss:  0.3807682394981384\n",
      "Write summary at step 7820  Loss:  0.4243357181549072\n",
      "Write summary at step 7830  Loss:  0.3735698163509369\n",
      "Write summary at step 7840  Loss:  0.6215592622756958\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9269296163952612\n",
      "Loss normal: 0.21116756009204046 Loss Control: 0.25430668002920725 Loss Patient: 0.19803201948941845 Loss balanced:  0.22616934975931285 Loss1+loss2: 0.22616934975931285\n",
      "Write summary at step 7850  Loss:  0.3939553499221802\n",
      "Write summary at step 7860  Loss:  0.5327303409576416\n",
      "Write summary at step 7870  Loss:  0.3116875886917114\n",
      "Write summary at step 7880  Loss:  0.3780529797077179\n",
      "Write summary at step 7890  Loss:  0.3672593832015991\n",
      "Write summary at step 7900  Loss:  0.3364713490009308\n",
      "Write summary at step 7910  Loss:  0.6077165603637695\n",
      "Write summary at step 7920  Loss:  0.4065750241279602\n",
      "Write summary at step 7930  Loss:  0.35572102665901184\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8526863242501115\n",
      "Loss normal: 0.22362435152944254 Loss Control: 0.4617791416866532 Loss Patient: 0.15110799523935142 Loss balanced:  0.3064435684630023 Loss1+loss2: 0.3064435684630023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 7940  Loss:  0.35469669103622437\n",
      "Write summary at step 7950  Loss:  0.3759317398071289\n",
      "Write summary at step 7960  Loss:  0.16595017910003662\n",
      "Write summary at step 7970  Loss:  0.4178503751754761\n",
      "Write summary at step 7980  Loss:  0.31506767868995667\n",
      "Write summary at step 7990  Loss:  0.2778885066509247\n",
      "Write summary at step 8000  Loss:  0.25533851981163025\n",
      "Saved checkpoint to: result/44/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9031713992162425\n",
      "Loss normal: 0.19354350921906988 Loss Control: 0.2995596870047147 Loss Patient: 0.1612623795098354 Loss balanced:  0.23041103325727505 Loss1+loss2: 0.23041103325727505\n",
      "Write summary at step 8010  Loss:  0.37022361159324646\n",
      "Write summary at step 8020  Loss:  0.31704962253570557\n",
      "Write summary at step 8030  Loss:  0.39594578742980957\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9342943909513288\n",
      "Loss normal: 0.18939761275767672 Loss Control: 0.20825351041848542 Loss Patient: 0.18365613055011 Loss balanced:  0.19595482048429771 Loss1+loss2: 0.19595482048429771\n",
      "Write summary at step 8040  Loss:  0.3117813467979431\n",
      "Write summary at step 8050  Loss:  0.43888580799102783\n",
      "Write summary at step 8060  Loss:  0.3624914884567261\n",
      "Write summary at step 8070  Loss:  0.3824577033519745\n",
      "Write summary at step 8080  Loss:  0.5665408372879028\n",
      "Write summary at step 8090  Loss:  0.3289150595664978\n",
      "Write summary at step 8100  Loss:  0.26761940121650696\n",
      "Write summary at step 8110  Loss:  0.4406777024269104\n",
      "Write summary at step 8120  Loss:  0.19507743418216705\n",
      "Write summary at step 8130  Loss:  0.20310355722904205\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8535182710055191\n",
      "Loss normal: 0.23820433491954998 Loss Control: 0.5842559910862823 Loss Patient: 0.13283419457826756 Loss balanced:  0.358545092832275 Loss1+loss2: 0.358545092832275\n",
      "Write summary at step 8140  Loss:  0.29980069398880005\n",
      "Write summary at step 8150  Loss:  0.3664051592350006\n",
      "Write summary at step 8160  Loss:  0.2285497784614563\n",
      "Write summary at step 8170  Loss:  0.3595184087753296\n",
      "Write summary at step 8180  Loss:  0.4412428140640259\n",
      "Write summary at step 8190  Loss:  0.4077887535095215\n",
      "Write summary at step 8200  Loss:  0.17498278617858887\n",
      "Write summary at step 8210  Loss:  0.5395355224609375\n",
      "Write summary at step 8220  Loss:  0.4108371138572693\n",
      "Write summary at step 8230  Loss:  0.36849844455718994\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.891410490712201\n",
      "Loss normal: 0.23325454641361626 Loss Control: 0.3444378273408921 Loss Patient: 0.19940006996996193 Loss balanced:  0.27191894865542704 Loss1+loss2: 0.27191894865542704\n",
      "Write summary at step 8240  Loss:  0.56346195936203\n",
      "Write summary at step 8250  Loss:  0.1502375602722168\n",
      "Write summary at step 8260  Loss:  0.17780426144599915\n",
      "Write summary at step 8270  Loss:  0.2805090546607971\n",
      "Write summary at step 8280  Loss:  0.3987653851509094\n",
      "Write summary at step 8290  Loss:  0.3154907822608948\n",
      "Write summary at step 8300  Loss:  0.38049349188804626\n",
      "Write summary at step 8310  Loss:  0.3651549816131592\n",
      "Write summary at step 8320  Loss:  0.447742760181427\n",
      "Write summary at step 8330  Loss:  0.38162630796432495\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.86195139248793\n",
      "Loss normal: 0.23727863091899423 Loss Control: 0.4915017215280585 Loss Patient: 0.15986960500280392 Loss balanced:  0.3256856632654312 Loss1+loss2: 0.3256856632654312\n",
      "Write summary at step 8340  Loss:  0.16520458459854126\n",
      "Write summary at step 8350  Loss:  0.32203027606010437\n",
      "Write summary at step 8360  Loss:  0.18497100472450256\n",
      "Write summary at step 8370  Loss:  0.277920126914978\n",
      "Write summary at step 8380  Loss:  0.39293503761291504\n",
      "Write summary at step 8390  Loss:  0.3121921122074127\n",
      "Write summary at step 8400  Loss:  0.270822137594223\n",
      "Write summary at step 8410  Loss:  0.16902589797973633\n",
      "Write summary at step 8420  Loss:  0.3069053590297699\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8545866179318622\n",
      "Loss normal: 0.2322398329115644 Loss Control: 0.5190098950120269 Loss Patient: 0.14492049751285704 Loss balanced:  0.331965196262442 Loss1+loss2: 0.331965196262442\n",
      "Write summary at step 8430  Loss:  0.29695963859558105\n",
      "Write summary at step 8440  Loss:  0.1741372048854828\n",
      "Write summary at step 8450  Loss:  0.3858773410320282\n",
      "Write summary at step 8460  Loss:  0.2683228552341461\n",
      "Write summary at step 8470  Loss:  0.3550918698310852\n",
      "Write summary at step 8480  Loss:  0.41019517183303833\n",
      "Write summary at step 8490  Loss:  0.41679832339286804\n",
      "Write summary at step 8500  Loss:  0.3944767117500305\n",
      "Saved checkpoint to: result/44/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8562505114426775\n",
      "Loss normal: 0.23725343871937724 Loss Control: 0.5213247693952967 Loss Patient: 0.15075584373339243 Loss balanced:  0.3360403065643446 Loss1+loss2: 0.3360403065643446\n",
      "Write summary at step 8510  Loss:  0.39775800704956055\n",
      "Write summary at step 8520  Loss:  0.25097471475601196\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.87644454142913\n",
      "Loss normal: 0.22272499361816717 Loss Control: 0.43657896427508913 Loss Patient: 0.157608061979297 Loss balanced:  0.29709351312719307 Loss1+loss2: 0.29709351312719307\n",
      "Write summary at step 8530  Loss:  0.3651416599750519\n",
      "Write summary at step 8540  Loss:  0.3653566837310791\n",
      "Write summary at step 8550  Loss:  0.27044329047203064\n",
      "Write summary at step 8560  Loss:  0.1777028888463974\n",
      "Write summary at step 8570  Loss:  0.5469826459884644\n",
      "Write summary at step 8580  Loss:  0.35696208477020264\n",
      "Write summary at step 8590  Loss:  0.24991077184677124\n",
      "Write summary at step 8600  Loss:  0.46198955178260803\n",
      "Write summary at step 8610  Loss:  0.5565147399902344\n",
      "Write summary at step 8620  Loss:  0.3392452597618103\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8848776629115409\n",
      "Loss normal: 0.22878970635332624 Loss Control: 0.3923055076859688 Loss Patient: 0.17900036520227022 Loss balanced:  0.2856529364441195 Loss1+loss2: 0.2856529364441195\n",
      "Write summary at step 8630  Loss:  0.7231611013412476\n",
      "Write summary at step 8640  Loss:  0.3436269164085388\n",
      "Write summary at step 8650  Loss:  0.27029502391815186\n",
      "Write summary at step 8660  Loss:  0.2666037380695343\n",
      "Write summary at step 8670  Loss:  0.32896003127098083\n",
      "Write summary at step 8680  Loss:  0.4084952771663666\n",
      "Write summary at step 8690  Loss:  0.39765968918800354\n",
      "Write summary at step 8700  Loss:  0.26333022117614746\n",
      "Write summary at step 8710  Loss:  0.44999247789382935\n",
      "Write summary at step 8720  Loss:  0.31507062911987305\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9206331887655366\n",
      "Loss normal: 0.2230880611709186 Loss Control: 0.2335073522856978 Loss Patient: 0.21991546981396176 Loss balanced:  0.22671141104982978 Loss1+loss2: 0.22671141104982978\n",
      "Write summary at step 8730  Loss:  0.3133310079574585\n",
      "Write summary at step 8740  Loss:  0.17571814358234406\n",
      "Write summary at step 8750  Loss:  0.4534183442592621\n",
      "Write summary at step 8760  Loss:  0.2871893346309662\n",
      "Write summary at step 8770  Loss:  0.37337160110473633\n",
      "Write summary at step 8780  Loss:  0.4252256751060486\n",
      "Write summary at step 8790  Loss:  0.42582815885543823\n",
      "Write summary at step 8800  Loss:  0.3246482312679291\n",
      "Write summary at step 8810  Loss:  0.40817689895629883\n",
      "Write summary at step 8820  Loss:  0.43851613998413086\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8728803542365638\n",
      "Loss normal: 0.22354554415357356 Loss Control: 0.4273593494149505 Loss Patient: 0.16148577190427335 Loss balanced:  0.2944225606596119 Loss1+loss2: 0.2944225606596119\n",
      "Write summary at step 8830  Loss:  0.21704214811325073\n",
      "Write summary at step 8840  Loss:  0.395560622215271\n",
      "Write summary at step 8850  Loss:  0.5113160014152527\n",
      "Write summary at step 8860  Loss:  0.3978273868560791\n",
      "Write summary at step 8870  Loss:  0.48809605836868286\n",
      "Write summary at step 8880  Loss:  0.30005478858947754\n",
      "Write summary at step 8890  Loss:  0.4003267288208008\n",
      "Write summary at step 8900  Loss:  0.36128613352775574\n",
      "Write summary at step 8910  Loss:  0.569892168045044\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9304938035878272\n",
      "Loss normal: 0.1793820631063106 Loss Control: 0.2551246578576135 Loss Patient: 0.15631900932918769 Loss balanced:  0.2057218335934006 Loss1+loss2: 0.2057218335934006\n",
      "Write summary at step 8920  Loss:  0.4039076864719391\n",
      "Write summary at step 8930  Loss:  0.4287680387496948\n",
      "Write summary at step 8940  Loss:  0.20673918724060059\n",
      "Write summary at step 8950  Loss:  0.2158844918012619\n",
      "Write summary at step 8960  Loss:  0.2953263521194458\n",
      "Write summary at step 8970  Loss:  0.30963096022605896\n",
      "Write summary at step 8980  Loss:  0.30462443828582764\n",
      "Write summary at step 8990  Loss:  0.5229179859161377\n",
      "Write summary at step 9000  Loss:  0.3496852517127991\n",
      "Saved checkpoint to: result/44/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8903061224489796 Acurracy Control:  0.6666666666666666 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8125346644481419\n",
      "Loss normal: 0.2671039553777296 Loss Control: 0.7292243489802209 Loss Patient: 0.12639175856891963 Loss balanced:  0.42780805377457026 Loss1+loss2: 0.42780805377457026\n",
      "Write summary at step 9010  Loss:  0.3092179298400879\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9040033459716501\n",
      "Loss normal: 0.20044035878868735 Loss Control: 0.3294999348661287 Loss Patient: 0.16114268331678458 Loss balanced:  0.24532130909145666 Loss1+loss2: 0.24532130909145666\n",
      "Write summary at step 9020  Loss:  0.4505455791950226\n",
      "Write summary at step 9030  Loss:  0.21353229880332947\n",
      "Write summary at step 9040  Loss:  0.3551940321922302\n",
      "Write summary at step 9050  Loss:  0.5339480638504028\n",
      "Write summary at step 9060  Loss:  0.3461798429489136\n",
      "Write summary at step 9070  Loss:  0.5163723230361938\n",
      "Write summary at step 9080  Loss:  0.3220820724964142\n",
      "Write summary at step 9090  Loss:  0.5511372089385986\n",
      "Write summary at step 9100  Loss:  0.5139868855476379\n",
      "Write summary at step 9110  Loss:  0.36746007204055786\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9464285714285714 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9460552994553704\n",
      "Loss normal: 0.18696990533142674 Loss Control: 0.20776693384504058 Loss Patient: 0.18063736850777007 Loss balanced:  0.19420215117640532 Loss1+loss2: 0.19420215117640532\n",
      "Write summary at step 9120  Loss:  0.21128134429454803\n",
      "Write summary at step 9130  Loss:  0.2480565905570984\n",
      "Write summary at step 9140  Loss:  0.26613062620162964\n",
      "Write summary at step 9150  Loss:  0.31206563115119934\n",
      "Write summary at step 9160  Loss:  0.2804681956768036\n",
      "Write summary at step 9170  Loss:  0.44660234451293945\n",
      "Write summary at step 9180  Loss:  0.26378896832466125\n",
      "Write summary at step 9190  Loss:  0.3765391707420349\n",
      "Write summary at step 9200  Loss:  0.21192996203899384\n",
      "Write summary at step 9210  Loss:  0.41264548897743225\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9258612694689179\n",
      "Loss normal: 0.19109053594269315 Loss Control: 0.29412753399604 Loss Patient: 0.15971654381435643 Loss balanced:  0.22692203890519824 Loss1+loss2: 0.22692203890519824\n",
      "Write summary at step 9220  Loss:  0.3921406865119934\n",
      "Write summary at step 9230  Loss:  0.287945032119751\n",
      "Write summary at step 9240  Loss:  0.3546881079673767\n",
      "Write summary at step 9250  Loss:  0.30318301916122437\n",
      "Write summary at step 9260  Loss:  0.2757011950016022\n",
      "Write summary at step 9270  Loss:  0.3254961669445038\n",
      "Write summary at step 9280  Loss:  0.19968971610069275\n",
      "Write summary at step 9290  Loss:  0.49822109937667847\n",
      "Write summary at step 9300  Loss:  0.4285528063774109\n",
      "Write summary at step 9310  Loss:  0.4580122232437134\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9307302037587628\n",
      "Loss normal: 0.21999072412751158 Loss Control: 0.23719655832306283 Loss Patient: 0.2147516770886502 Loss balanced:  0.22597411770585651 Loss1+loss2: 0.22597411770585651\n",
      "Write summary at step 9320  Loss:  0.26271331310272217\n",
      "Write summary at step 9330  Loss:  0.4774077832698822\n",
      "Write summary at step 9340  Loss:  0.3032190203666687\n",
      "Write summary at step 9350  Loss:  0.4618571400642395\n",
      "Write summary at step 9360  Loss:  0.39800047874450684\n",
      "Write summary at step 9370  Loss:  0.20198306441307068\n",
      "Write summary at step 9380  Loss:  0.3789755702018738\n",
      "Write summary at step 9390  Loss:  0.35568875074386597\n",
      "Write summary at step 9400  Loss:  0.405496209859848\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8434212560122929\n",
      "Loss normal: 0.2753024645605866 Loss Control: 0.6664661462189722 Loss Patient: 0.15619605395341674 Loss balanced:  0.41133110008619445 Loss1+loss2: 0.41133110008619445\n",
      "Write summary at step 9410  Loss:  0.35092729330062866\n",
      "Write summary at step 9420  Loss:  0.18727454543113708\n",
      "Write summary at step 9430  Loss:  0.2546207308769226\n",
      "Write summary at step 9440  Loss:  0.2997739613056183\n",
      "Write summary at step 9450  Loss:  0.3288227915763855\n",
      "Write summary at step 9460  Loss:  0.2902272045612335\n",
      "Write summary at step 9470  Loss:  0.39886417984962463\n",
      "Write summary at step 9480  Loss:  0.4646419882774353\n",
      "Write summary at step 9490  Loss:  0.24897918105125427\n",
      "Write summary at step 9500  Loss:  0.2801988124847412\n",
      "Saved checkpoint to: result/44/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.879413182037224\n",
      "Loss normal: 0.24162985901443326 Loss Control: 0.3971768344034914 Loss Patient: 0.19426697146723948 Loss balanced:  0.29572190293536543 Loss1+loss2: 0.29572190293536543\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8775128883554731\n",
      "Loss normal: 0.23903157219898943 Loss Control: 0.4219410015585644 Loss Patient: 0.18333701905910663 Loss balanced:  0.3026390103088355 Loss1+loss2: 0.3026390103088355\n",
      "Write summary at step 9510  Loss:  0.5360058546066284\n",
      "Write summary at step 9520  Loss:  0.43343061208724976\n",
      "Write summary at step 9530  Loss:  0.1899206042289734\n",
      "Write summary at step 9540  Loss:  0.4584207832813263\n",
      "Write summary at step 9550  Loss:  0.442166268825531\n",
      "Write summary at step 9560  Loss:  0.10623428225517273\n",
      "Write summary at step 9570  Loss:  0.39018765091896057\n",
      "Write summary at step 9580  Loss:  0.3270624577999115\n",
      "Write summary at step 9590  Loss:  0.49668729305267334\n",
      "Write summary at step 9600  Loss:  0.2715376913547516\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.888441850104107\n",
      "Loss normal: 0.21214017895411472 Loss Control: 0.33358198664878885 Loss Patient: 0.17516205922240227 Loss balanced:  0.2543720229355956 Loss1+loss2: 0.2543720229355956\n",
      "Write summary at step 9610  Loss:  0.2844683825969696\n",
      "Write summary at step 9620  Loss:  0.14352214336395264\n",
      "Write summary at step 9630  Loss:  0.289987176656723\n",
      "Write summary at step 9640  Loss:  0.39583510160446167\n",
      "Write summary at step 9650  Loss:  0.17964448034763336\n",
      "Write summary at step 9660  Loss:  0.3708938956260681\n",
      "Write summary at step 9670  Loss:  0.2625490427017212\n",
      "Write summary at step 9680  Loss:  0.5496163964271545\n",
      "Write summary at step 9690  Loss:  0.4346737265586853\n",
      "Write summary at step 9700  Loss:  0.1870729625225067\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8800087286216961\n",
      "Loss normal: 0.21197964213028245 Loss Control: 0.46648583255830356 Loss Patient: 0.13448441663319974 Loss balanced:  0.30048512459575166 Loss1+loss2: 0.30048512459575166\n",
      "Write summary at step 9710  Loss:  0.24955488741397858\n",
      "Write summary at step 9720  Loss:  0.6655723452568054\n",
      "Write summary at step 9730  Loss:  0.42780283093452454\n",
      "Write summary at step 9740  Loss:  0.49634864926338196\n",
      "Write summary at step 9750  Loss:  0.30553996562957764\n",
      "Write summary at step 9760  Loss:  0.48278355598449707\n",
      "Write summary at step 9770  Loss:  0.2790486812591553\n",
      "Write summary at step 9780  Loss:  0.2490393966436386\n",
      "Write summary at step 9790  Loss:  0.2702496349811554\n",
      "Write summary at step 9800  Loss:  0.4344973862171173\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8737123009919715\n",
      "Loss normal: 0.22042611902769732 Loss Control: 0.4848439836762642 Loss Patient: 0.139912861028993 Loss balanced:  0.3123784223526286 Loss1+loss2: 0.3123784223526286\n",
      "------------------------------\n",
      "SEED: 44 Best Loss: 0.18978099831217307\n",
      "______________________________\n",
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 5 (+- 0.1 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.8725188374519348\n",
      "Write summary at step 20  Loss:  0.7791585326194763\n",
      "Write summary at step 30  Loss:  0.739235520362854\n",
      "Write summary at step 40  Loss:  0.7191779613494873\n",
      "Write summary at step 50  Loss:  0.6864787340164185\n",
      "Write summary at step 60  Loss:  0.6932345628738403\n",
      "Write summary at step 70  Loss:  0.6723541021347046\n",
      "Write summary at step 80  Loss:  0.8270532488822937\n",
      "Write summary at step 90  Loss:  0.6881725788116455\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7397959183673469 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.7587354409317804 Acurracy Balanced 0.7181655346735405\n",
      "Loss normal: 0.6253837474754879 Loss Control: 0.6612852596845783 Loss Patient: 0.6144520033417447 Loss balanced:  0.6378686315131614 Loss1+loss2: 0.6378686315131614\n",
      "\n",
      " > BEST MODEL (0.63787) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 100  Loss:  0.686892569065094\n",
      "Write summary at step 110  Loss:  0.7781814336776733\n",
      "Write summary at step 120  Loss:  0.6679093837738037\n",
      "Write summary at step 130  Loss:  0.7480502128601074\n",
      "Write summary at step 140  Loss:  0.7413867712020874\n",
      "Write summary at step 150  Loss:  0.7151608467102051\n",
      "Write summary at step 160  Loss:  0.623350203037262\n",
      "Write summary at step 170  Loss:  0.6683281660079956\n",
      "Write summary at step 180  Loss:  0.6329548358917236\n",
      "Write summary at step 190  Loss:  0.5465993881225586\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6594387755102041 Acurracy Control:  1.0 Acurracy Patient:  0.5557404326123128 Acurracy Balanced 0.7778702163061564\n",
      "Loss normal: 0.7186637217825165 Loss Control: 0.1102164798095578 Loss Patient: 0.9039313527391278 Loss balanced:  0.5070739162743428 Loss1+loss2: 0.5070739162743428\n",
      "\n",
      " > BEST MODEL (0.50707) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 200  Loss:  0.5900726914405823\n",
      "Write summary at step 210  Loss:  0.5108941197395325\n",
      "Write summary at step 220  Loss:  0.8249787092208862\n",
      "Write summary at step 230  Loss:  0.48050597310066223\n",
      "Write summary at step 240  Loss:  0.5922479629516602\n",
      "Write summary at step 250  Loss:  0.5900371670722961\n",
      "Write summary at step 260  Loss:  0.3984571099281311\n",
      "Write summary at step 270  Loss:  0.3023543059825897\n",
      "Write summary at step 280  Loss:  0.5709089040756226\n",
      "Write summary at step 290  Loss:  0.9091922640800476\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8813775510204082 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.8618968386023295 Acurracy Balanced 0.9036260149295801\n",
      "Loss normal: 0.3603285865059921 Loss Control: 0.17381960275720376 Loss Patient: 0.41711917703044593 Loss balanced:  0.2954693898938249 Loss1+loss2: 0.2954693898938249\n",
      "\n",
      " > BEST MODEL (0.29547) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 300  Loss:  0.4706059396266937\n",
      "Write summary at step 310  Loss:  0.3674020767211914\n",
      "Write summary at step 320  Loss:  0.3733910322189331\n",
      "Write summary at step 330  Loss:  0.388685017824173\n",
      "Write summary at step 340  Loss:  0.5194016098976135\n",
      "Write summary at step 350  Loss:  0.8255112171173096\n",
      "Write summary at step 360  Loss:  0.8062832355499268\n",
      "Write summary at step 370  Loss:  0.5573102831840515\n",
      "Write summary at step 380  Loss:  0.6908735632896423\n",
      "Write summary at step 390  Loss:  0.5008465051651001\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9201331114808652 Acurracy Balanced 0.8753671021885201\n",
      "Loss normal: 0.268166685895044 Loss Control: 0.4640852063080001 Loss Patient: 0.2085109643650531 Loss balanced:  0.3362980853365266 Loss1+loss2: 0.3362980853365266\n",
      "Write summary at step 400  Loss:  0.46901750564575195\n",
      "Write summary at step 410  Loss:  0.43086880445480347\n",
      "Write summary at step 420  Loss:  0.5408889055252075\n",
      "Write summary at step 430  Loss:  0.7014588117599487\n",
      "Write summary at step 440  Loss:  0.28723323345184326\n",
      "Write summary at step 450  Loss:  0.5018232464790344\n",
      "Write summary at step 460  Loss:  0.7106397151947021\n",
      "Write summary at step 470  Loss:  0.5572952032089233\n",
      "Write summary at step 480  Loss:  0.4585379362106323\n",
      "Write summary at step 490  Loss:  0.5717733502388\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9251247920133111 Acurracy Balanced 0.9051853468263277\n",
      "Loss normal: 0.24460626956151457 Loss Control: 0.4001093842292744 Loss Patient: 0.19725673637056906 Loss balanced:  0.29868306029992175 Loss1+loss2: 0.29868306029992175\n",
      "Write summary at step 500  Loss:  0.751623809337616\n",
      "Saved checkpoint to: result/45/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8928571428571429 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.848403844230472\n",
      "Loss normal: 0.293239970102298 Loss Control: 0.4711634197521731 Loss Patient: 0.23906360782323383 Loss balanced:  0.35511351378770345 Loss1+loss2: 0.35511351378770345\n",
      "Write summary at step 510  Loss:  0.3494454026222229\n",
      "Write summary at step 520  Loss:  0.3946758806705475\n",
      "Write summary at step 530  Loss:  0.4063445031642914\n",
      "Write summary at step 540  Loss:  0.500034749507904\n",
      "Write summary at step 550  Loss:  0.3512812852859497\n",
      "Write summary at step 560  Loss:  1.2063637971878052\n",
      "Write summary at step 570  Loss:  0.725740373134613\n",
      "Write summary at step 580  Loss:  0.44763433933258057\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7946428571428571 Acurracy Control:  0.24043715846994534 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.6019157506160043\n",
      "Loss normal: 0.3800054589400486 Loss Control: 1.044495668567595 Loss Patient: 0.17767316648448367 Loss balanced:  0.6110844175260394 Loss1+loss2: 0.6110844175260394\n",
      "Write summary at step 590  Loss:  0.5952659845352173\n",
      "Write summary at step 600  Loss:  0.44019049406051636\n",
      "Write summary at step 610  Loss:  0.9148099422454834\n",
      "Write summary at step 620  Loss:  0.3782048523426056\n",
      "Write summary at step 630  Loss:  0.6086829900741577\n",
      "Write summary at step 640  Loss:  0.5503811240196228\n",
      "Write summary at step 650  Loss:  0.6737258434295654\n",
      "Write summary at step 660  Loss:  0.523343563079834\n",
      "Write summary at step 670  Loss:  0.626838207244873\n",
      "Write summary at step 680  Loss:  0.31760919094085693\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8954081632653061 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9068219633943427 Acurracy Balanced 0.8823727303310511\n",
      "Loss normal: 0.2975888094123529 Loss Control: 0.3059111410151414 Loss Patient: 0.29505472234798946 Loss balanced:  0.3004829316815654 Loss1+loss2: 0.3004829316815654\n",
      "Write summary at step 690  Loss:  0.19326364994049072\n",
      "Write summary at step 700  Loss:  0.615811288356781\n",
      "Write summary at step 710  Loss:  0.6229641437530518\n",
      "Write summary at step 720  Loss:  0.4606049358844757\n",
      "Write summary at step 730  Loss:  0.3255378007888794\n",
      "Write summary at step 740  Loss:  0.45516490936279297\n",
      "Write summary at step 750  Loss:  0.5641024112701416\n",
      "Write summary at step 760  Loss:  0.4809717535972595\n",
      "Write summary at step 770  Loss:  0.7647563219070435\n",
      "Write summary at step 780  Loss:  0.4846196472644806\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9001663893510815 Acurracy Balanced 0.876312702872262\n",
      "Loss normal: 0.35966308293293936 Loss Control: 0.32083358758134267 Loss Patient: 0.37148637521683475 Loss balanced:  0.3461599813990887 Loss1+loss2: 0.3461599813990887\n",
      "Write summary at step 790  Loss:  0.39960217475891113\n",
      "Write summary at step 800  Loss:  0.33866071701049805\n",
      "Write summary at step 810  Loss:  0.6632643938064575\n",
      "Write summary at step 820  Loss:  0.43760597705841064\n",
      "Write summary at step 830  Loss:  0.29487869143486023\n",
      "Write summary at step 840  Loss:  0.2754680812358856\n",
      "Write summary at step 850  Loss:  0.4887441396713257\n",
      "Write summary at step 860  Loss:  0.5980204343795776\n",
      "Write summary at step 870  Loss:  0.5202479362487793\n",
      "Write summary at step 880  Loss:  0.629899263381958\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8928571428571429 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.891846921797005 Acurracy Balanced 0.8940108925924916\n",
      "Loss normal: 0.28632175542262134 Loss Control: 0.28713030469873563 Loss Patient: 0.28607555891630454 Loss balanced:  0.28660293180752006 Loss1+loss2: 0.28660293180752006\n",
      "\n",
      " > BEST MODEL (0.28660) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 890  Loss:  0.3768968880176544\n",
      "Write summary at step 900  Loss:  0.4670599699020386\n",
      "Write summary at step 910  Loss:  0.5614619851112366\n",
      "Write summary at step 920  Loss:  0.4051809310913086\n",
      "Write summary at step 930  Loss:  1.5016937255859375\n",
      "Write summary at step 940  Loss:  0.49345463514328003\n",
      "Write summary at step 950  Loss:  0.38400986790657043\n",
      "Write summary at step 960  Loss:  0.3290085792541504\n",
      "Write summary at step 970  Loss:  0.6683704257011414\n",
      "Write summary at step 980  Loss:  0.5982893705368042\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9101497504159733 Acurracy Balanced 0.9086267877762927\n",
      "Loss normal: 0.26391718057649477 Loss Control: 0.2781955127507611 Loss Patient: 0.25956953990082576 Loss balanced:  0.26888252632579346 Loss1+loss2: 0.26888252632579346\n",
      "\n",
      " > BEST MODEL (0.26888) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 990  Loss:  0.47917354106903076\n",
      "Write summary at step 1000  Loss:  0.3634944260120392\n",
      "Saved checkpoint to: result/45/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.8738259549203058\n",
      "Loss normal: 0.27024834002463183 Loss Control: 0.4264912009239197 Loss Patient: 0.22267356460384044 Loss balanced:  0.3245823827638801 Loss1+loss2: 0.3245823827638801\n",
      "Write summary at step 1010  Loss:  0.4992995858192444\n",
      "Write summary at step 1020  Loss:  0.5714167952537537\n",
      "Write summary at step 1030  Loss:  0.39168763160705566\n",
      "Write summary at step 1040  Loss:  0.46366381645202637\n",
      "Write summary at step 1050  Loss:  0.4817083477973938\n",
      "Write summary at step 1060  Loss:  0.32264548540115356\n",
      "Write summary at step 1070  Loss:  0.5952752828598022\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.8851913477537438 Acurracy Balanced 0.9343989525653964\n",
      "Loss normal: 0.3228602973478181 Loss Control: 0.1768043953212884 Loss Patient: 0.367333223736425 Loss balanced:  0.2720688095288567 Loss1+loss2: 0.2720688095288567\n",
      "Write summary at step 1080  Loss:  0.24510541558265686\n",
      "Write summary at step 1090  Loss:  0.5007764101028442\n",
      "Write summary at step 1100  Loss:  0.18236063420772552\n",
      "Write summary at step 1110  Loss:  0.6166092157363892\n",
      "Write summary at step 1120  Loss:  0.49076375365257263\n",
      "Write summary at step 1130  Loss:  0.35598888993263245\n",
      "Write summary at step 1140  Loss:  0.36217808723449707\n",
      "Write summary at step 1150  Loss:  0.484028160572052\n",
      "Write summary at step 1160  Loss:  0.47026312351226807\n",
      "Write summary at step 1170  Loss:  0.3257129192352295\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.8935108153078203 Acurracy Balanced 0.9303619650309594\n",
      "Loss normal: 0.2847012071585169 Loss Control: 0.16980935918177412 Loss Patient: 0.31968491426521845 Loss balanced:  0.2447471367234963 Loss1+loss2: 0.2447471367234963\n",
      "\n",
      " > BEST MODEL (0.24475) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 1180  Loss:  0.5158829689025879\n",
      "Write summary at step 1190  Loss:  0.5286425352096558\n",
      "Write summary at step 1200  Loss:  0.45511987805366516\n",
      "Write summary at step 1210  Loss:  0.4961549937725067\n",
      "Write summary at step 1220  Loss:  0.38983458280563354\n",
      "Write summary at step 1230  Loss:  0.6284648180007935\n",
      "Write summary at step 1240  Loss:  0.6143134236335754\n",
      "Write summary at step 1250  Loss:  0.9164873361587524\n",
      "Write summary at step 1260  Loss:  0.5092428922653198\n",
      "Write summary at step 1270  Loss:  0.4771357774734497\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.907322040679014\n",
      "Loss normal: 0.24570523521729878 Loss Control: 0.3234707371133273 Loss Patient: 0.2220262246401655 Loss balanced:  0.2727484808767464 Loss1+loss2: 0.2727484808767464\n",
      "Write summary at step 1280  Loss:  0.5659077763557434\n",
      "Write summary at step 1290  Loss:  0.431234747171402\n",
      "Write summary at step 1300  Loss:  0.3493282198905945\n",
      "Write summary at step 1310  Loss:  0.43125081062316895\n",
      "Write summary at step 1320  Loss:  0.2624633312225342\n",
      "Write summary at step 1330  Loss:  0.5360398292541504\n",
      "Write summary at step 1340  Loss:  0.40814831852912903\n",
      "Write summary at step 1350  Loss:  0.4064127206802368\n",
      "Write summary at step 1360  Loss:  0.46596765518188477\n",
      "Write summary at step 1370  Loss:  0.2345823049545288\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.8836865697425966\n",
      "Loss normal: 0.23008946264732857 Loss Control: 0.3700338999430339 Loss Patient: 0.18747742900534994 Loss balanced:  0.2787556644741919 Loss1+loss2: 0.2787556644741919\n",
      "Write summary at step 1380  Loss:  0.3055340349674225\n",
      "Write summary at step 1390  Loss:  0.4656396806240082\n",
      "Write summary at step 1400  Loss:  0.40665382146835327\n",
      "Write summary at step 1410  Loss:  0.4189035892486572\n",
      "Write summary at step 1420  Loss:  0.41148513555526733\n",
      "Write summary at step 1430  Loss:  0.7157802581787109\n",
      "Write summary at step 1440  Loss:  0.42689746618270874\n",
      "Write summary at step 1450  Loss:  0.3777572512626648\n",
      "Write summary at step 1460  Loss:  0.42733168601989746\n",
      "Write summary at step 1470  Loss:  0.42907190322875977\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.8754898484311211\n",
      "Loss normal: 0.24842075110242076 Loss Control: 0.4489373496321381 Loss Patient: 0.18736494802397222 Loss balanced:  0.3181511488280552 Loss1+loss2: 0.3181511488280552\n",
      "Write summary at step 1480  Loss:  0.4694840908050537\n",
      "Write summary at step 1490  Loss:  0.6380525827407837\n",
      "Write summary at step 1500  Loss:  0.3478574752807617\n",
      "Saved checkpoint to: result/45/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8436576561832283\n",
      "Loss normal: 0.2852273860528153 Loss Control: 0.7689121805253576 Loss Patient: 0.1379489914053887 Loss balanced:  0.4534305859653731 Loss1+loss2: 0.4534305859653731\n",
      "Write summary at step 1510  Loss:  0.4248092770576477\n",
      "Write summary at step 1520  Loss:  0.5967987179756165\n",
      "Write summary at step 1530  Loss:  0.43200233578681946\n",
      "Write summary at step 1540  Loss:  0.40125441551208496\n",
      "Write summary at step 1550  Loss:  0.4389128088951111\n",
      "Write summary at step 1560  Loss:  0.44966796040534973\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9284525790349417 Acurracy Balanced 0.8795268359655584\n",
      "Loss normal: 0.24972336929367514 Loss Control: 0.3344354909625861 Loss Patient: 0.2239291649094834 Loss balanced:  0.27918232793603476 Loss1+loss2: 0.27918232793603476\n",
      "Write summary at step 1570  Loss:  0.15140917897224426\n",
      "Write summary at step 1580  Loss:  0.48491576313972473\n",
      "Write summary at step 1590  Loss:  0.46419382095336914\n",
      "Write summary at step 1600  Loss:  0.45162367820739746\n",
      "Write summary at step 1610  Loss:  0.46134689450263977\n",
      "Write summary at step 1620  Loss:  0.4588981866836548\n",
      "Write summary at step 1630  Loss:  0.3799769878387451\n",
      "Write summary at step 1640  Loss:  0.5843385457992554\n",
      "Write summary at step 1650  Loss:  0.2913667559623718\n",
      "Write summary at step 1660  Loss:  0.27262911200523376\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.8754898484311211\n",
      "Loss normal: 0.2176702074630528 Loss Control: 0.35150125508751373 Loss Patient: 0.17691965428445977 Loss balanced:  0.26421045468598675 Loss1+loss2: 0.26421045468598675\n",
      "Write summary at step 1670  Loss:  0.5705857276916504\n",
      "Write summary at step 1680  Loss:  0.5453851819038391\n",
      "Write summary at step 1690  Loss:  0.648079514503479\n",
      "Write summary at step 1700  Loss:  0.4814647138118744\n",
      "Write summary at step 1710  Loss:  0.4189022481441498\n",
      "Write summary at step 1720  Loss:  0.5733023881912231\n",
      "Write summary at step 1730  Loss:  0.2944178283214569\n",
      "Write summary at step 1740  Loss:  0.3725239038467407\n",
      "Write summary at step 1750  Loss:  0.6023870706558228\n",
      "Write summary at step 1760  Loss:  0.6004412174224854\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.8643244865115518\n",
      "Loss normal: 0.2634816027189396 Loss Control: 0.4279744514350683 Loss Patient: 0.21339476450707473 Loss balanced:  0.3206846079710715 Loss1+loss2: 0.3206846079710715\n",
      "Write summary at step 1770  Loss:  0.5521050691604614\n",
      "Write summary at step 1780  Loss:  0.42692506313323975\n",
      "Write summary at step 1790  Loss:  0.7596805691719055\n",
      "Write summary at step 1800  Loss:  0.5065118074417114\n",
      "Write summary at step 1810  Loss:  0.6164208054542542\n",
      "Write summary at step 1820  Loss:  0.28938210010528564\n",
      "Write summary at step 1830  Loss:  0.21891111135482788\n",
      "Write summary at step 1840  Loss:  0.2912927567958832\n",
      "Write summary at step 1850  Loss:  0.462024062871933\n",
      "Write summary at step 1860  Loss:  0.34561091661453247\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.8763217951865289\n",
      "Loss normal: 0.2465146994408296 Loss Control: 0.40942462708780675 Loss Patient: 0.1969098475530818 Loss balanced:  0.30316723732044426 Loss1+loss2: 0.30316723732044426\n",
      "Write summary at step 1870  Loss:  0.30331170558929443\n",
      "Write summary at step 1880  Loss:  0.4770882725715637\n",
      "Write summary at step 1890  Loss:  0.83310467004776\n",
      "Write summary at step 1900  Loss:  0.5894750356674194\n",
      "Write summary at step 1910  Loss:  0.45536765456199646\n",
      "Write summary at step 1920  Loss:  0.2798900008201599\n",
      "Write summary at step 1930  Loss:  0.697928786277771\n",
      "Write summary at step 1940  Loss:  0.5796040296554565\n",
      "Write summary at step 1950  Loss:  0.41596919298171997\n",
      "Write summary at step 1960  Loss:  0.2167871594429016\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9151414309484193 Acurracy Balanced 0.9193193493539911\n",
      "Loss normal: 0.2522587069139189 Loss Control: 0.23100950157707506 Loss Patient: 0.2587289286532537 Loss balanced:  0.24486921511516438 Loss1+loss2: 0.24486921511516438\n",
      "Write summary at step 1970  Loss:  0.5454654097557068\n",
      "Write summary at step 1980  Loss:  0.730370044708252\n",
      "Write summary at step 1990  Loss:  0.6828590035438538\n",
      "Write summary at step 2000  Loss:  0.3860864043235779\n",
      "Saved checkpoint to: result/45/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8722848076520917\n",
      "Loss normal: 0.22585742791392366 Loss Control: 0.48901321979168333 Loss Patient: 0.14572845818397406 Loss balanced:  0.3173708389878287 Loss1+loss2: 0.3173708389878287\n",
      "Write summary at step 2010  Loss:  0.4635871648788452\n",
      "Write summary at step 2020  Loss:  0.32371264696121216\n",
      "Write summary at step 2030  Loss:  0.6474285125732422\n",
      "Write summary at step 2040  Loss:  0.4628146290779114\n",
      "Write summary at step 2050  Loss:  0.3310808539390564\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.879885982379095\n",
      "Loss normal: 0.23558070655075872 Loss Control: 0.37821914915178645 Loss Patient: 0.1921483706713913 Loss balanced:  0.28518375991158884 Loss1+loss2: 0.28518375991158884\n",
      "Write summary at step 2060  Loss:  0.26109784841537476\n",
      "Write summary at step 2070  Loss:  0.5799674987792969\n",
      "Write summary at step 2080  Loss:  0.6224881410598755\n",
      "Write summary at step 2090  Loss:  0.4796498417854309\n",
      "Write summary at step 2100  Loss:  0.6063003540039062\n",
      "Write summary at step 2110  Loss:  0.6206015944480896\n",
      "Write summary at step 2120  Loss:  0.47409987449645996\n",
      "Write summary at step 2130  Loss:  0.3693498969078064\n",
      "Write summary at step 2140  Loss:  0.4204542636871338\n",
      "Write summary at step 2150  Loss:  0.3665768802165985\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9385677786567015\n",
      "Loss normal: 0.23776457892084607 Loss Control: 0.19312121731336 Loss Patient: 0.2513581461795356 Loss balanced:  0.22223968174644781 Loss1+loss2: 0.22223968174644781\n",
      "\n",
      " > BEST MODEL (0.22224) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 2160  Loss:  0.23294411599636078\n",
      "Write summary at step 2170  Loss:  0.2661858797073364\n",
      "Write summary at step 2180  Loss:  0.4844368100166321\n",
      "Write summary at step 2190  Loss:  0.3530014753341675\n",
      "Write summary at step 2200  Loss:  0.48615366220474243\n",
      "Write summary at step 2210  Loss:  0.4013114869594574\n",
      "Write summary at step 2220  Loss:  0.6076055765151978\n",
      "Write summary at step 2230  Loss:  0.3238224387168884\n",
      "Write summary at step 2240  Loss:  0.4321039319038391\n",
      "Write summary at step 2250  Loss:  0.5757335424423218\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9549612212796523\n",
      "Loss normal: 0.22268188912041334 Loss Control: 0.14676077737182866 Loss Patient: 0.2457992991869541 Loss balanced:  0.1962800382793914 Loss1+loss2: 0.1962800382793914\n",
      "\n",
      " > BEST MODEL (0.19628) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 2260  Loss:  0.3348742127418518\n",
      "Write summary at step 2270  Loss:  0.42032352089881897\n",
      "Write summary at step 2280  Loss:  0.2563793361186981\n",
      "Write summary at step 2290  Loss:  0.36168569326400757\n",
      "Write summary at step 2300  Loss:  0.2961800694465637\n",
      "Write summary at step 2310  Loss:  0.489353209733963\n",
      "Write summary at step 2320  Loss:  0.15111224353313446\n",
      "Write summary at step 2330  Loss:  0.42435115575790405\n",
      "Write summary at step 2340  Loss:  0.24691611528396606\n",
      "Write summary at step 2350  Loss:  0.45483845472335815\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9236018293736306\n",
      "Loss normal: 0.2108221460818028 Loss Control: 0.26396198774296076 Loss Patient: 0.19464146301224705 Loss balanced:  0.2293017253776039 Loss1+loss2: 0.2293017253776039\n",
      "Write summary at step 2360  Loss:  0.2199830412864685\n",
      "Write summary at step 2370  Loss:  0.26539987325668335\n",
      "Write summary at step 2380  Loss:  0.498771071434021\n",
      "Write summary at step 2390  Loss:  0.30853429436683655\n",
      "Write summary at step 2400  Loss:  0.5222920179367065\n",
      "Write summary at step 2410  Loss:  0.37654727697372437\n",
      "Write summary at step 2420  Loss:  0.3499141335487366\n",
      "Write summary at step 2430  Loss:  0.3287208676338196\n",
      "Write summary at step 2440  Loss:  0.4023842215538025\n",
      "Write summary at step 2450  Loss:  0.43075937032699585\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.9201331114808652 Acurracy Balanced 0.9546020748661157\n",
      "Loss normal: 0.2384077889122525 Loss Control: 0.17617388142914067 Loss Patient: 0.2573575460771951 Loss balanced:  0.2167657137531679 Loss1+loss2: 0.2167657137531679\n",
      "Write summary at step 2460  Loss:  0.3428669273853302\n",
      "Write summary at step 2470  Loss:  0.40187305212020874\n",
      "Write summary at step 2480  Loss:  0.39686357975006104\n",
      "Write summary at step 2490  Loss:  0.31631287932395935\n",
      "Write summary at step 2500  Loss:  0.526986837387085\n",
      "Saved checkpoint to: result/45/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9497331405762708\n",
      "Loss normal: 0.21373038936634453 Loss Control: 0.23297038430073222 Loss Patient: 0.2078719545719826 Loss balanced:  0.22042116943635742 Loss1+loss2: 0.22042116943635742\n",
      "Write summary at step 2510  Loss:  0.41974154114723206\n",
      "Write summary at step 2520  Loss:  0.7991340160369873\n",
      "Write summary at step 2530  Loss:  0.42783188819885254\n",
      "Write summary at step 2540  Loss:  0.36352357268333435\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.9068219633943427 Acurracy Balanced 0.9506787412600128\n",
      "Loss normal: 0.25359357787030085 Loss Control: 0.12169361847345947 Loss Patient: 0.29375612438220944 Loss balanced:  0.20772487142783447 Loss1+loss2: 0.20772487142783447\n",
      "Write summary at step 2550  Loss:  0.3467932939529419\n",
      "Write summary at step 2560  Loss:  0.3614160120487213\n",
      "Write summary at step 2570  Loss:  0.3202613592147827\n",
      "Write summary at step 2580  Loss:  0.33612215518951416\n",
      "Write summary at step 2590  Loss:  0.6976463198661804\n",
      "Write summary at step 2600  Loss:  0.37433114647865295\n",
      "Write summary at step 2610  Loss:  0.3543747365474701\n",
      "Write summary at step 2620  Loss:  0.48245903849601746\n",
      "Write summary at step 2630  Loss:  0.4069741666316986\n",
      "Write summary at step 2640  Loss:  0.2329196184873581\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9477040816326531 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9506878335742797\n",
      "Loss normal: 0.22878606412179617 Loss Control: 0.23993956260993832 Loss Patient: 0.22538990754256033 Loss balanced:  0.23266473507624932 Loss1+loss2: 0.23266473507624932\n",
      "Write summary at step 2650  Loss:  0.40694794058799744\n",
      "Write summary at step 2660  Loss:  0.3217405080795288\n",
      "Write summary at step 2670  Loss:  0.5214309096336365\n",
      "Write summary at step 2680  Loss:  0.23157259821891785\n",
      "Write summary at step 2690  Loss:  0.5763707160949707\n",
      "Write summary at step 2700  Loss:  0.4228358268737793\n",
      "Write summary at step 2710  Loss:  0.2667572498321533\n",
      "Write summary at step 2720  Loss:  0.6200495362281799\n",
      "Write summary at step 2730  Loss:  0.5329533815383911\n",
      "Write summary at step 2740  Loss:  0.5438152551651001\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9036441995581135\n",
      "Loss normal: 0.215141891406811 Loss Control: 0.2437779815470586 Loss Patient: 0.20642241535587438 Loss balanced:  0.2251001984514665 Loss1+loss2: 0.2251001984514665\n",
      "Write summary at step 2750  Loss:  0.4855254888534546\n",
      "Write summary at step 2760  Loss:  0.2670270502567291\n",
      "Write summary at step 2770  Loss:  0.5778399705886841\n",
      "Write summary at step 2780  Loss:  0.41468578577041626\n",
      "Write summary at step 2790  Loss:  0.4393298625946045\n",
      "Write summary at step 2800  Loss:  0.47479671239852905\n",
      "Write summary at step 2810  Loss:  0.2389107495546341\n",
      "Write summary at step 2820  Loss:  0.5525248050689697\n",
      "Write summary at step 2830  Loss:  0.5041266083717346\n",
      "Write summary at step 2840  Loss:  0.2904067039489746\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8537546711764545\n",
      "Loss normal: 0.23708481550672833 Loss Control: 0.5423853368055626 Loss Patient: 0.14412309333508502 Loss balanced:  0.3432542150703238 Loss1+loss2: 0.3432542150703238\n",
      "Write summary at step 2850  Loss:  0.18477576971054077\n",
      "Write summary at step 2860  Loss:  0.5876491069793701\n",
      "Write summary at step 2870  Loss:  0.2999350130558014\n",
      "Write summary at step 2880  Loss:  0.3034264147281647\n",
      "Write summary at step 2890  Loss:  0.4267618954181671\n",
      "Write summary at step 2900  Loss:  0.45187968015670776\n",
      "Write summary at step 2910  Loss:  0.4044868052005768\n",
      "Write summary at step 2920  Loss:  0.2702134847640991\n",
      "Write summary at step 2930  Loss:  0.36093658208847046\n",
      "Write summary at step 2940  Loss:  0.31429851055145264\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9023394524608348\n",
      "Loss normal: 0.2334806044034812 Loss Control: 0.37196361236884945 Loss Patient: 0.19131356383520434 Loss balanced:  0.2816385881020269 Loss1+loss2: 0.2816385881020269\n",
      "Write summary at step 2950  Loss:  0.49956488609313965\n",
      "Write summary at step 2960  Loss:  0.3302760124206543\n",
      "Write summary at step 2970  Loss:  0.29807087779045105\n",
      "Write summary at step 2980  Loss:  0.3651483654975891\n",
      "Write summary at step 2990  Loss:  0.4432162344455719\n",
      "Write summary at step 3000  Loss:  0.6784728765487671\n",
      "Saved checkpoint to: result/45/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8941427311493595\n",
      "Loss normal: 0.22142073059720652 Loss Control: 0.3798999542095622 Loss Patient: 0.1731649947394547 Loss balanced:  0.27653247447450846 Loss1+loss2: 0.27653247447450846\n",
      "Write summary at step 3010  Loss:  0.32263457775115967\n",
      "Write summary at step 3020  Loss:  0.24661177396774292\n",
      "Write summary at step 3030  Loss:  0.25081300735473633\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9320349508560414\n",
      "Loss normal: 0.21592855719583376 Loss Control: 0.24943573911333344 Loss Patient: 0.20572587336954382 Loss balanced:  0.22758080624143862 Loss1+loss2: 0.22758080624143862\n",
      "Write summary at step 3040  Loss:  0.35091954469680786\n",
      "Write summary at step 3050  Loss:  0.3918812870979309\n",
      "Write summary at step 3060  Loss:  0.25348997116088867\n",
      "Write summary at step 3070  Loss:  0.40272825956344604\n",
      "Write summary at step 3080  Loss:  0.32035744190216064\n",
      "Write summary at step 3090  Loss:  0.456912636756897\n",
      "Write summary at step 3100  Loss:  0.38711678981781006\n",
      "Write summary at step 3110  Loss:  0.2156350016593933\n",
      "Write summary at step 3120  Loss:  0.4707496166229248\n",
      "Write summary at step 3130  Loss:  0.28938090801239014\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9151414309484193 Acurracy Balanced 0.9384450324141003\n",
      "Loss normal: 0.23934830010545496 Loss Control: 0.1751768232369032 Loss Patient: 0.2588880311034483 Loss balanced:  0.21703242717017576 Loss1+loss2: 0.21703242717017576\n",
      "Write summary at step 3140  Loss:  0.6340917348861694\n",
      "Write summary at step 3150  Loss:  0.39417368173599243\n",
      "Write summary at step 3160  Loss:  0.40011370182037354\n",
      "Write summary at step 3170  Loss:  0.43917325139045715\n",
      "Write summary at step 3180  Loss:  0.4195004105567932\n",
      "Write summary at step 3190  Loss:  0.29325541853904724\n",
      "Write summary at step 3200  Loss:  0.5382977724075317\n",
      "Write summary at step 3210  Loss:  0.41481804847717285\n",
      "Write summary at step 3220  Loss:  0.3802375793457031\n",
      "Write summary at step 3230  Loss:  0.3440154492855072\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9170690015729703\n",
      "Loss normal: 0.21386219538292106 Loss Control: 0.2725329920242393 Loss Patient: 0.19599737452587945 Loss balanced:  0.23426518327505938 Loss1+loss2: 0.23426518327505938\n",
      "Write summary at step 3240  Loss:  0.43900662660598755\n",
      "Write summary at step 3250  Loss:  0.3578639626502991\n",
      "Write summary at step 3260  Loss:  0.5720883011817932\n",
      "Write summary at step 3270  Loss:  0.3204880952835083\n",
      "Write summary at step 3280  Loss:  0.2500821352005005\n",
      "Write summary at step 3290  Loss:  0.40457987785339355\n",
      "Write summary at step 3300  Loss:  0.6968052387237549\n",
      "Write summary at step 3310  Loss:  0.4607292711734772\n",
      "Write summary at step 3320  Loss:  0.3911999464035034\n",
      "Write summary at step 3330  Loss:  0.29957395792007446\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9309666039296982\n",
      "Loss normal: 0.213624362738765 Loss Control: 0.25387176887585167 Loss Patient: 0.20136933115476777 Loss balanced:  0.22762055001530973 Loss1+loss2: 0.22762055001530973\n",
      "Write summary at step 3340  Loss:  0.23431557416915894\n",
      "Write summary at step 3350  Loss:  0.2157503068447113\n",
      "Write summary at step 3360  Loss:  0.2553115785121918\n",
      "Write summary at step 3370  Loss:  0.46648579835891724\n",
      "Write summary at step 3380  Loss:  0.23393985629081726\n",
      "Write summary at step 3390  Loss:  0.4008671045303345\n",
      "Write summary at step 3400  Loss:  0.768920361995697\n",
      "Write summary at step 3410  Loss:  0.17240093648433685\n",
      "Write summary at step 3420  Loss:  0.4081416726112366\n",
      "Write summary at step 3430  Loss:  0.43970632553100586\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.912436467454061\n",
      "Loss normal: 0.22976573252556276 Loss Control: 0.2819589109368663 Loss Patient: 0.21387330448865494 Loss balanced:  0.24791610771276062 Loss1+loss2: 0.24791610771276062\n",
      "Write summary at step 3440  Loss:  0.28177064657211304\n",
      "Write summary at step 3450  Loss:  0.4775819778442383\n",
      "Write summary at step 3460  Loss:  0.5247150659561157\n",
      "Write summary at step 3470  Loss:  0.36657723784446716\n",
      "Write summary at step 3480  Loss:  0.4608946144580841\n",
      "Write summary at step 3490  Loss:  0.3336619734764099\n",
      "Write summary at step 3500  Loss:  0.22523239254951477\n",
      "Saved checkpoint to: result/45/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9107725739432457\n",
      "Loss normal: 0.19580438592452176 Loss Control: 0.2951070135408412 Loss Patient: 0.16556748251946715 Loss balanced:  0.23033724803015415 Loss1+loss2: 0.23033724803015415\n",
      "Write summary at step 3510  Loss:  0.3518524765968323\n",
      "Write summary at step 3520  Loss:  0.14066636562347412\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9126728676249967\n",
      "Loss normal: 0.20726372115314007 Loss Control: 0.2519591657516083 Loss Patient: 0.19365429365000192 Loss balanced:  0.22280672970080512 Loss1+loss2: 0.22280672970080512\n",
      "Write summary at step 3530  Loss:  0.5485115051269531\n",
      "Write summary at step 3540  Loss:  0.4260388910770416\n",
      "Write summary at step 3550  Loss:  0.45905590057373047\n",
      "Write summary at step 3560  Loss:  0.24349072575569153\n",
      "Write summary at step 3570  Loss:  0.21740180253982544\n",
      "Write summary at step 3580  Loss:  0.3567992150783539\n",
      "Write summary at step 3590  Loss:  0.4092596769332886\n",
      "Write summary at step 3600  Loss:  0.2962575852870941\n",
      "Write summary at step 3610  Loss:  0.26736366748809814\n",
      "Write summary at step 3620  Loss:  0.3400708734989166\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.9101497504159733 Acurracy Balanced 0.9523426347708281\n",
      "Loss normal: 0.242891255690127 Loss Control: 0.08990721355696193 Loss Patient: 0.2894737560816493 Loss balanced:  0.18969048481930562 Loss1+loss2: 0.18969048481930562\n",
      "\n",
      " > BEST MODEL (0.18969) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 3630  Loss:  0.49178749322891235\n",
      "Write summary at step 3640  Loss:  0.5107653737068176\n",
      "Write summary at step 3650  Loss:  0.4444757103919983\n",
      "Write summary at step 3660  Loss:  0.3159230351448059\n",
      "Write summary at step 3670  Loss:  0.36961475014686584\n",
      "Write summary at step 3680  Loss:  0.2874419689178467\n",
      "Write summary at step 3690  Loss:  0.5454864501953125\n",
      "Write summary at step 3700  Loss:  0.5503360629081726\n",
      "Write summary at step 3710  Loss:  0.5807693004608154\n",
      "Write summary at step 3720  Loss:  0.3070183992385864\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9451530612244898 Acurracy Control:  0.9562841530054644 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9490239400634644\n",
      "Loss normal: 0.20045668631792068 Loss Control: 0.19448247193638743 Loss Patient: 0.2022757888236974 Loss balanced:  0.1983791303800424 Loss1+loss2: 0.1983791303800424\n",
      "Write summary at step 3730  Loss:  0.43379637598991394\n",
      "Write summary at step 3740  Loss:  0.24286597967147827\n",
      "Write summary at step 3750  Loss:  0.24821168184280396\n",
      "Write summary at step 3760  Loss:  0.40039199590682983\n",
      "Write summary at step 3770  Loss:  0.40111660957336426\n",
      "Write summary at step 3780  Loss:  0.2973135709762573\n",
      "Write summary at step 3790  Loss:  0.29869478940963745\n",
      "Write summary at step 3800  Loss:  0.3603482246398926\n",
      "Write summary at step 3810  Loss:  0.502369225025177\n",
      "Write summary at step 3820  Loss:  0.448716402053833\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.994535519125683 Acurracy Patient:  0.9151414309484193 Acurracy Balanced 0.9548384750370511\n",
      "Loss normal: 0.21709531043865243 Loss Control: 0.13203520462161206 Loss Patient: 0.24299547874590324 Loss balanced:  0.18751534168375766 Loss1+loss2: 0.18751534168375766\n",
      "\n",
      " > BEST MODEL (0.18752) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 3830  Loss:  0.4572683870792389\n",
      "Write summary at step 3840  Loss:  0.4006691873073578\n",
      "Write summary at step 3850  Loss:  0.4132053554058075\n",
      "Write summary at step 3860  Loss:  0.33708107471466064\n",
      "Write summary at step 3870  Loss:  0.39361807703971863\n",
      "Write summary at step 3880  Loss:  0.3347211480140686\n",
      "Write summary at step 3890  Loss:  0.2795228660106659\n",
      "Write summary at step 3900  Loss:  0.5268582105636597\n",
      "Write summary at step 3910  Loss:  0.36310774087905884\n",
      "Write summary at step 3920  Loss:  0.4715127944946289\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9364310848040152\n",
      "Loss normal: 0.2388177714785751 Loss Control: 0.17150760104096002 Loss Patient: 0.25931321453929146 Loss balanced:  0.21541040779012574 Loss1+loss2: 0.21541040779012574\n",
      "Write summary at step 3930  Loss:  0.18928232789039612\n",
      "Write summary at step 3940  Loss:  0.3810061812400818\n",
      "Write summary at step 3950  Loss:  0.3116321861743927\n",
      "Write summary at step 3960  Loss:  0.3016290068626404\n",
      "Write summary at step 3970  Loss:  0.9164232015609741\n",
      "Write summary at step 3980  Loss:  0.2135033905506134\n",
      "Write summary at step 3990  Loss:  0.44176656007766724\n",
      "Write summary at step 4000  Loss:  0.4624272584915161\n",
      "Saved checkpoint to: result/45/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9132684142094687\n",
      "Loss normal: 0.21136086970111545 Loss Control: 0.308748294095524 Loss Patient: 0.18170713034525093 Loss balanced:  0.24522771222038747 Loss1+loss2: 0.24522771222038747\n",
      "Write summary at step 4010  Loss:  0.40626251697540283\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8630197394142731\n",
      "Loss normal: 0.22263082983542462 Loss Control: 0.46120141699014466 Loss Patient: 0.14998787093579075 Loss balanced:  0.3055946439629677 Loss1+loss2: 0.3055946439629677\n",
      "Write summary at step 4020  Loss:  0.4231211543083191\n",
      "Write summary at step 4030  Loss:  0.24959993362426758\n",
      "Write summary at step 4040  Loss:  0.3067445755004883\n",
      "Write summary at step 4050  Loss:  0.41461843252182007\n",
      "Write summary at step 4060  Loss:  0.4465982913970947\n",
      "Write summary at step 4070  Loss:  0.78975909948349\n",
      "Write summary at step 4080  Loss:  0.4286237061023712\n",
      "Write summary at step 4090  Loss:  0.24577167630195618\n",
      "Write summary at step 4100  Loss:  0.2675595283508301\n",
      "Write summary at step 4110  Loss:  0.43785151839256287\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8638516861696808\n",
      "Loss normal: 0.24003849307797392 Loss Control: 0.39258089482458564 Loss Patient: 0.1935904711088206 Loss balanced:  0.2930856829667031 Loss1+loss2: 0.2930856829667031\n",
      "Write summary at step 4120  Loss:  0.33922797441482544\n",
      "Write summary at step 4130  Loss:  0.6106646656990051\n",
      "Write summary at step 4140  Loss:  0.5399390459060669\n",
      "Write summary at step 4150  Loss:  0.3644888997077942\n",
      "Write summary at step 4160  Loss:  0.3721015453338623\n",
      "Write summary at step 4170  Loss:  0.23928706347942352\n",
      "Write summary at step 4180  Loss:  0.3625437617301941\n",
      "Write summary at step 4190  Loss:  0.4346344769001007\n",
      "Write summary at step 4200  Loss:  0.23589996993541718\n",
      "Write summary at step 4210  Loss:  0.5260210037231445\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9424911122628044\n",
      "Loss normal: 0.20443693670083066 Loss Control: 0.2086871657215181 Loss Patient: 0.20314277577122516 Loss balanced:  0.20591497074637163 Loss1+loss2: 0.20591497074637163\n",
      "Write summary at step 4220  Loss:  0.3885490298271179\n",
      "Write summary at step 4230  Loss:  0.4674181044101715\n",
      "Write summary at step 4240  Loss:  0.4122011661529541\n",
      "Write summary at step 4250  Loss:  0.2417706996202469\n",
      "Write summary at step 4260  Loss:  0.2812527120113373\n",
      "Write summary at step 4270  Loss:  0.3351328372955322\n",
      "Write summary at step 4280  Loss:  0.3586471676826477\n",
      "Write summary at step 4290  Loss:  0.6793843507766724\n",
      "Write summary at step 4300  Loss:  0.5084075331687927\n",
      "Write summary at step 4310  Loss:  0.5344243049621582\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9464285714285714 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9517561805006228\n",
      "Loss normal: 0.20779286404805525 Loss Control: 0.14191791073220675 Loss Patient: 0.22785129458852696 Loss balanced:  0.18488460266036685 Loss1+loss2: 0.18488460266036685\n",
      "\n",
      " > BEST MODEL (0.18488) : result/45/panns/best_checkpoint.pt\n",
      "Write summary at step 4320  Loss:  0.4369892179965973\n",
      "Write summary at step 4330  Loss:  0.5383642315864563\n",
      "Write summary at step 4340  Loss:  0.2556801438331604\n",
      "Write summary at step 4350  Loss:  0.5527998208999634\n",
      "Write summary at step 4360  Loss:  0.48076504468917847\n",
      "Write summary at step 4370  Loss:  0.23490336537361145\n",
      "Write summary at step 4380  Loss:  0.22699499130249023\n",
      "Write summary at step 4390  Loss:  0.4513183832168579\n",
      "Write summary at step 4400  Loss:  0.20948392152786255\n",
      "Write summary at step 4410  Loss:  0.4248405694961548\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.9168053244592346 Acurracy Balanced 0.9529381813553004\n",
      "Loss normal: 0.20807154940403239 Loss Control: 0.16736898852176355 Loss Patient: 0.2204651682825136 Loss balanced:  0.19391707840213857 Loss1+loss2: 0.19391707840213857\n",
      "Write summary at step 4420  Loss:  0.4068450927734375\n",
      "Write summary at step 4430  Loss:  0.3957342505455017\n",
      "Write summary at step 4440  Loss:  0.46900618076324463\n",
      "Write summary at step 4450  Loss:  0.47395071387290955\n",
      "Write summary at step 4460  Loss:  0.2492416650056839\n",
      "Write summary at step 4470  Loss:  0.2789973020553589\n",
      "Write summary at step 4480  Loss:  0.4963550567626953\n",
      "Write summary at step 4490  Loss:  0.2926845848560333\n",
      "Write summary at step 4500  Loss:  0.41877835988998413\n",
      "Saved checkpoint to: result/45/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9435594591891474\n",
      "Loss normal: 0.20808843169741484 Loss Control: 0.20034026920469733 Loss Patient: 0.21044768950903475 Loss balanced:  0.20539397935686604 Loss1+loss2: 0.20539397935686604\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9105361737723103\n",
      "Loss normal: 0.1998703877764697 Loss Control: 0.29413518423591156 Loss Patient: 0.17116746581632167 Loss balanced:  0.23265132502611663 Loss1+loss2: 0.23265132502611663\n",
      "Write summary at step 4510  Loss:  0.360245019197464\n",
      "Write summary at step 4520  Loss:  0.3198555111885071\n",
      "Write summary at step 4530  Loss:  0.3744649291038513\n",
      "Write summary at step 4540  Loss:  0.5167684555053711\n",
      "Write summary at step 4550  Loss:  0.4884676933288574\n",
      "Write summary at step 4560  Loss:  0.35335573554039\n",
      "Write summary at step 4570  Loss:  0.30973395705223083\n",
      "Write summary at step 4580  Loss:  0.3778897523880005\n",
      "Write summary at step 4590  Loss:  0.36274951696395874\n",
      "Write summary at step 4600  Loss:  0.3893173933029175\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8659883800223671\n",
      "Loss normal: 0.24243146713290895 Loss Control: 0.3401007955191565 Loss Patient: 0.2126918865519633 Loss balanced:  0.2763963410355599 Loss1+loss2: 0.2763963410355599\n",
      "Write summary at step 4610  Loss:  0.26201242208480835\n",
      "Write summary at step 4620  Loss:  0.4305003881454468\n",
      "Write summary at step 4630  Loss:  0.21824270486831665\n",
      "Write summary at step 4640  Loss:  0.3742888271808624\n",
      "Write summary at step 4650  Loss:  0.5514681339263916\n",
      "Write summary at step 4660  Loss:  0.48217520117759705\n",
      "Write summary at step 4670  Loss:  0.3495503067970276\n",
      "Write summary at step 4680  Loss:  0.281789094209671\n",
      "Write summary at step 4690  Loss:  0.42531704902648926\n",
      "Write summary at step 4700  Loss:  0.4942641258239746\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9195648418391933\n",
      "Loss normal: 0.21522562144970409 Loss Control: 0.2730346208061677 Loss Patient: 0.1976232150082977 Loss balanced:  0.2353289179072327 Loss1+loss2: 0.2353289179072327\n",
      "Write summary at step 4710  Loss:  0.4325631558895111\n",
      "Write summary at step 4720  Loss:  0.4751966595649719\n",
      "Write summary at step 4730  Loss:  0.2750859260559082\n",
      "Write summary at step 4740  Loss:  0.37165290117263794\n",
      "Write summary at step 4750  Loss:  0.4017869532108307\n",
      "Write summary at step 4760  Loss:  0.4405461549758911\n",
      "Write summary at step 4770  Loss:  0.2865690290927887\n",
      "Write summary at step 4780  Loss:  0.30322709679603577\n",
      "Write summary at step 4790  Loss:  0.6787478923797607\n",
      "Write summary at step 4800  Loss:  0.3585086166858673\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.9092314266750317\n",
      "Loss normal: 0.20902836444426556 Loss Control: 0.3694896326690424 Loss Patient: 0.16016911198315326 Loss balanced:  0.2648293723260978 Loss1+loss2: 0.2648293723260978\n",
      "Write summary at step 4810  Loss:  0.49804389476776123\n",
      "Write summary at step 4820  Loss:  0.4366133213043213\n",
      "Write summary at step 4830  Loss:  0.533757209777832\n",
      "Write summary at step 4840  Loss:  0.441010057926178\n",
      "Write summary at step 4850  Loss:  0.3203245997428894\n",
      "Write summary at step 4860  Loss:  0.3494301438331604\n",
      "Write summary at step 4870  Loss:  0.266757607460022\n",
      "Write summary at step 4880  Loss:  0.4391597509384155\n",
      "Write summary at step 4890  Loss:  0.2682410180568695\n",
      "Write summary at step 4900  Loss:  0.2691693902015686\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9085131338479583\n",
      "Loss normal: 0.22414770821223454 Loss Control: 0.1989554117937557 Loss Patient: 0.23181857379423004 Loss balanced:  0.21538699279399287 Loss1+loss2: 0.21538699279399287\n",
      "Write summary at step 4910  Loss:  0.446805864572525\n",
      "Write summary at step 4920  Loss:  0.2727884352207184\n",
      "Write summary at step 4930  Loss:  0.49185097217559814\n",
      "Write summary at step 4940  Loss:  0.5012694597244263\n",
      "Write summary at step 4950  Loss:  0.9552702903747559\n",
      "Write summary at step 4960  Loss:  0.36559969186782837\n",
      "Write summary at step 4970  Loss:  0.3113139569759369\n",
      "Write summary at step 4980  Loss:  0.6061593294143677\n",
      "Write summary at step 4990  Loss:  0.34969407320022583\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8857096096669486\n",
      "Loss normal: 0.20297517277756516 Loss Control: 0.3781653691510685 Loss Patient: 0.14963107448250998 Loss balanced:  0.26389822181678924 Loss1+loss2: 0.26389822181678924\n",
      "Write summary at step 5000  Loss:  0.42699623107910156\n",
      "Saved checkpoint to: result/45/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.6994535519125683 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8289281070710928\n",
      "Loss normal: 0.22544515684094965 Loss Control: 0.5655263082577231 Loss Patient: 0.12189299217773952 Loss balanced:  0.3437096502177313 Loss1+loss2: 0.3437096502177313\n",
      "Write summary at step 5010  Loss:  0.3883894681930542\n",
      "Write summary at step 5020  Loss:  0.3274187445640564\n",
      "Write summary at step 5030  Loss:  0.44794273376464844\n",
      "Write summary at step 5040  Loss:  0.5078564882278442\n",
      "Write summary at step 5050  Loss:  0.3028084933757782\n",
      "Write summary at step 5060  Loss:  0.6346895098686218\n",
      "Write summary at step 5070  Loss:  0.5773150324821472\n",
      "Write summary at step 5080  Loss:  0.2374356985092163\n",
      "Write summary at step 5090  Loss:  0.521562933921814\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9451530612244898 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.952824527426966\n",
      "Loss normal: 0.20780325977473843 Loss Control: 0.1696783701578776 Loss Patient: 0.21941200508650846 Loss balanced:  0.19454518762219303 Loss1+loss2: 0.19454518762219303\n",
      "Write summary at step 5100  Loss:  0.3616294264793396\n",
      "Write summary at step 5110  Loss:  0.5075337886810303\n",
      "Write summary at step 5120  Loss:  0.36315008997917175\n",
      "Write summary at step 5130  Loss:  0.30000367760658264\n",
      "Write summary at step 5140  Loss:  0.35474854707717896\n",
      "Write summary at step 5150  Loss:  0.4071089029312134\n",
      "Write summary at step 5160  Loss:  0.4303860068321228\n",
      "Write summary at step 5170  Loss:  0.5856760740280151\n",
      "Write summary at step 5180  Loss:  0.27223068475723267\n",
      "Write summary at step 5190  Loss:  0.3087683916091919\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9290663102479475\n",
      "Loss normal: 0.23629003938059417 Loss Control: 0.21296362131019758 Loss Patient: 0.24339276150538403 Loss balanced:  0.2281781914077908 Loss1+loss2: 0.2281781914077908\n",
      "Write summary at step 5200  Loss:  0.4392023980617523\n",
      "Write summary at step 5210  Loss:  0.30838051438331604\n",
      "Write summary at step 5220  Loss:  0.23086215555667877\n",
      "Write summary at step 5230  Loss:  0.34133151173591614\n",
      "Write summary at step 5240  Loss:  0.3235947787761688\n",
      "Write summary at step 5250  Loss:  0.39709335565567017\n",
      "Write summary at step 5260  Loss:  0.4259090721607208\n",
      "Write summary at step 5270  Loss:  0.2353523224592209\n",
      "Write summary at step 5280  Loss:  0.3097224235534668\n",
      "Write summary at step 5290  Loss:  0.4152893126010895\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9258612694689179\n",
      "Loss normal: 0.186323594758097 Loss Control: 0.26368561566201715 Loss Patient: 0.16276744256003725 Loss balanced:  0.21322652911102719 Loss1+loss2: 0.21322652911102719\n",
      "Write summary at step 5300  Loss:  0.4593878984451294\n",
      "Write summary at step 5310  Loss:  0.7661250829696655\n",
      "Write summary at step 5320  Loss:  0.3613901138305664\n",
      "Write summary at step 5330  Loss:  0.3987722396850586\n",
      "Write summary at step 5340  Loss:  0.6466909646987915\n",
      "Write summary at step 5350  Loss:  0.36113041639328003\n",
      "Write summary at step 5360  Loss:  0.38223206996917725\n",
      "Write summary at step 5370  Loss:  0.3465880751609802\n",
      "Write summary at step 5380  Loss:  0.5000180006027222\n",
      "Write summary at step 5390  Loss:  0.5619841814041138\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9399952719965814\n",
      "Loss normal: 0.22104183721299075 Loss Control: 0.1687403451549551 Loss Patient: 0.2369672522667839 Loss balanced:  0.2028537987108695 Loss1+loss2: 0.2028537987108695\n",
      "Write summary at step 5400  Loss:  0.37941107153892517\n",
      "Write summary at step 5410  Loss:  0.3909473717212677\n",
      "Write summary at step 5420  Loss:  0.7007014751434326\n",
      "Write summary at step 5430  Loss:  0.14554202556610107\n",
      "Write summary at step 5440  Loss:  0.3051113486289978\n",
      "Write summary at step 5450  Loss:  0.640731692314148\n",
      "Write summary at step 5460  Loss:  0.4156927168369293\n",
      "Write summary at step 5470  Loss:  0.34277668595314026\n",
      "Write summary at step 5480  Loss:  0.4012576639652252\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9271660165661966\n",
      "Loss normal: 0.21450441288856828 Loss Control: 0.22522470762169428 Loss Patient: 0.21124016348514302 Loss balanced:  0.21823243555341865 Loss1+loss2: 0.21823243555341865\n",
      "Write summary at step 5490  Loss:  0.32497096061706543\n",
      "Write summary at step 5500  Loss:  0.4384430944919586\n",
      "Saved checkpoint to: result/45/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9437958593600828\n",
      "Loss normal: 0.21303510437814557 Loss Control: 0.20173322242465827 Loss Patient: 0.2164764414710332 Loss balanced:  0.20910483194784574 Loss1+loss2: 0.20910483194784574\n",
      "Write summary at step 5510  Loss:  0.29631197452545166\n",
      "Write summary at step 5520  Loss:  0.2834503650665283\n",
      "Write summary at step 5530  Loss:  0.3123571574687958\n",
      "Write summary at step 5540  Loss:  0.3142487406730652\n",
      "Write summary at step 5550  Loss:  0.31304022669792175\n",
      "Write summary at step 5560  Loss:  0.3195914626121521\n",
      "Write summary at step 5570  Loss:  0.5322166681289673\n",
      "Write summary at step 5580  Loss:  0.28754088282585144\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.908485856905158 Acurracy Balanced 0.9433139667039452\n",
      "Loss normal: 0.23670487820493932 Loss Control: 0.17138724867763416 Loss Patient: 0.2565936053453785 Loss balanced:  0.21399042701150633 Loss1+loss2: 0.21399042701150633\n",
      "Write summary at step 5590  Loss:  0.5319299101829529\n",
      "Write summary at step 5600  Loss:  0.6050546169281006\n",
      "Write summary at step 5610  Loss:  0.2594704031944275\n",
      "Write summary at step 5620  Loss:  0.291695773601532\n",
      "Write summary at step 5630  Loss:  0.26195117831230164\n",
      "Write summary at step 5640  Loss:  0.5107728242874146\n",
      "Write summary at step 5650  Loss:  0.5397186279296875\n",
      "Write summary at step 5660  Loss:  0.502906322479248\n",
      "Write summary at step 5670  Loss:  0.28092271089553833\n",
      "Write summary at step 5680  Loss:  0.5970573425292969\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9122000672831256\n",
      "Loss normal: 0.18563735160064332 Loss Control: 0.3302180203583723 Loss Patient: 0.1416136189030728 Loss balanced:  0.23591581963072256 Loss1+loss2: 0.23591581963072256\n",
      "Write summary at step 5690  Loss:  0.4100578725337982\n",
      "Write summary at step 5700  Loss:  0.23449482023715973\n",
      "Write summary at step 5710  Loss:  0.3638167977333069\n",
      "Write summary at step 5720  Loss:  0.34544235467910767\n",
      "Write summary at step 5730  Loss:  0.28660520911216736\n",
      "Write summary at step 5740  Loss:  0.46832719445228577\n",
      "Write summary at step 5750  Loss:  0.19542339444160461\n",
      "Write summary at step 5760  Loss:  0.528793454170227\n",
      "Write summary at step 5770  Loss:  0.5683286786079407\n",
      "Write summary at step 5780  Loss:  0.16528235375881195\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.938331378485766\n",
      "Loss normal: 0.2172167094006222 Loss Control: 0.19390898942947388 Loss Patient: 0.22431373566438673 Loss balanced:  0.2091113625469303 Loss1+loss2: 0.2091113625469303\n",
      "Write summary at step 5790  Loss:  0.45676565170288086\n",
      "Write summary at step 5800  Loss:  0.2778284549713135\n",
      "Write summary at step 5810  Loss:  0.3181251287460327\n",
      "Write summary at step 5820  Loss:  0.7076723575592041\n",
      "Write summary at step 5830  Loss:  0.2908865809440613\n",
      "Write summary at step 5840  Loss:  0.4939565360546112\n",
      "Write summary at step 5850  Loss:  0.3122978210449219\n",
      "Write summary at step 5860  Loss:  0.38547563552856445\n",
      "Write summary at step 5870  Loss:  0.259357750415802\n",
      "Write summary at step 5880  Loss:  0.28070518374443054\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8985388650973333\n",
      "Loss normal: 0.20935120931541434 Loss Control: 0.3394117299976245 Loss Patient: 0.16974875613575965 Loss balanced:  0.2545802430666921 Loss1+loss2: 0.2545802430666921\n",
      "Write summary at step 5890  Loss:  0.31868335604667664\n",
      "Write summary at step 5900  Loss:  0.4007002115249634\n",
      "Write summary at step 5910  Loss:  0.5862389802932739\n",
      "Write summary at step 5920  Loss:  0.2519277334213257\n",
      "Write summary at step 5930  Loss:  0.2626986801624298\n",
      "Write summary at step 5940  Loss:  0.39134857058525085\n",
      "Write summary at step 5950  Loss:  0.23109719157218933\n",
      "Write summary at step 5960  Loss:  0.4290553331375122\n",
      "Write summary at step 5970  Loss:  0.5049049854278564\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9184964949128502\n",
      "Loss normal: 0.19012439182522345 Loss Control: 0.3037682856366934 Loss Patient: 0.1555206760293037 Loss balanced:  0.22964448083299854 Loss1+loss2: 0.22964448083299854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 5980  Loss:  0.31745004653930664\n",
      "Write summary at step 5990  Loss:  0.4141794443130493\n",
      "Write summary at step 6000  Loss:  0.3549092710018158\n",
      "Saved checkpoint to: result/45/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8977069183419256\n",
      "Loss normal: 0.2131452795726304 Loss Control: 0.3361425285782319 Loss Patient: 0.17569353212036826 Loss balanced:  0.25591803034930005 Loss1+loss2: 0.25591803034930005\n",
      "Write summary at step 6010  Loss:  0.36136943101882935\n",
      "Write summary at step 6020  Loss:  0.5263559818267822\n",
      "Write summary at step 6030  Loss:  0.3250356614589691\n",
      "Write summary at step 6040  Loss:  0.6757241487503052\n",
      "Write summary at step 6050  Loss:  0.5596718788146973\n",
      "Write summary at step 6060  Loss:  0.19288663566112518\n",
      "Write summary at step 6070  Loss:  0.3866626024246216\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9141003609648763\n",
      "Loss normal: 0.19228973289077378 Loss Control: 0.3136340428571232 Loss Patient: 0.15534129995425014 Loss balanced:  0.23448767140568666 Loss1+loss2: 0.23448767140568666\n",
      "Write summary at step 6080  Loss:  0.6028492450714111\n",
      "Write summary at step 6090  Loss:  0.35147982835769653\n",
      "Write summary at step 6100  Loss:  0.4703684449195862\n",
      "Write summary at step 6110  Loss:  0.506371259689331\n",
      "Write summary at step 6120  Loss:  0.4380071759223938\n",
      "Write summary at step 6130  Loss:  0.233445405960083\n",
      "Write summary at step 6140  Loss:  0.5265892744064331\n",
      "Write summary at step 6150  Loss:  0.46206602454185486\n",
      "Write summary at step 6160  Loss:  0.2563197910785675\n",
      "Write summary at step 6170  Loss:  0.47642096877098083\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9293027104188829\n",
      "Loss normal: 0.23776516284109378 Loss Control: 0.2087556968946926 Loss Patient: 0.2465983269714476 Loss balanced:  0.2276770119330701 Loss1+loss2: 0.2276770119330701\n",
      "Write summary at step 6180  Loss:  0.49526476860046387\n",
      "Write summary at step 6190  Loss:  0.32654958963394165\n",
      "Write summary at step 6200  Loss:  0.6071470379829407\n",
      "Write summary at step 6210  Loss:  0.5347252488136292\n",
      "Write summary at step 6220  Loss:  0.4464886784553528\n",
      "Write summary at step 6230  Loss:  0.2977842092514038\n",
      "Write summary at step 6240  Loss:  0.24346230924129486\n",
      "Write summary at step 6250  Loss:  0.38742074370384216\n",
      "Write summary at step 6260  Loss:  0.19278967380523682\n",
      "Write summary at step 6270  Loss:  0.49296748638153076\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9323940972695781\n",
      "Loss normal: 0.2130997683852911 Loss Control: 0.257865131878462 Loss Patient: 0.19946904929227718 Loss balanced:  0.2286670905853696 Loss1+loss2: 0.2286670905853696\n",
      "Write summary at step 6280  Loss:  0.3593745827674866\n",
      "Write summary at step 6290  Loss:  0.3506878614425659\n",
      "Write summary at step 6300  Loss:  0.8306962251663208\n",
      "Write summary at step 6310  Loss:  0.4733179807662964\n",
      "Write summary at step 6320  Loss:  0.16426846385002136\n",
      "Write summary at step 6330  Loss:  0.2986425459384918\n",
      "Write summary at step 6340  Loss:  0.3923097848892212\n",
      "Write summary at step 6350  Loss:  0.39587029814720154\n",
      "Write summary at step 6360  Loss:  0.35002437233924866\n",
      "Write summary at step 6370  Loss:  0.41019541025161743\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8903421437858579\n",
      "Loss normal: 0.21637042357149172 Loss Control: 0.356242510138965 Loss Patient: 0.1737804189324379 Loss balanced:  0.26501146453570146 Loss1+loss2: 0.26501146453570146\n",
      "Write summary at step 6380  Loss:  0.5512528419494629\n",
      "Write summary at step 6390  Loss:  0.15237705409526825\n",
      "Write summary at step 6400  Loss:  0.22944281995296478\n",
      "Write summary at step 6410  Loss:  0.4903862178325653\n",
      "Write summary at step 6420  Loss:  0.4443659484386444\n",
      "Write summary at step 6430  Loss:  0.24890118837356567\n",
      "Write summary at step 6440  Loss:  0.31690266728401184\n",
      "Write summary at step 6450  Loss:  0.24797013401985168\n",
      "Write summary at step 6460  Loss:  0.4052134156227112\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8583872052953638\n",
      "Loss normal: 0.22823975820626533 Loss Control: 0.4245069626250554 Loss Patient: 0.1684778674866713 Loss balanced:  0.2964924150558633 Loss1+loss2: 0.2964924150558633\n",
      "Write summary at step 6470  Loss:  0.4823582172393799\n",
      "Write summary at step 6480  Loss:  0.16104499995708466\n",
      "Write summary at step 6490  Loss:  0.31530821323394775\n",
      "Write summary at step 6500  Loss:  0.16734829545021057\n",
      "Saved checkpoint to: result/45/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.7540983606557377 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8529227244210469\n",
      "Loss normal: 0.22337455471635473 Loss Control: 0.4893063459891439 Loss Patient: 0.14240031292702315 Loss balanced:  0.31585332945808353 Loss1+loss2: 0.31585332945808353\n",
      "Write summary at step 6510  Loss:  0.2780737280845642\n",
      "Write summary at step 6520  Loss:  0.2794157862663269\n",
      "Write summary at step 6530  Loss:  0.4472977817058563\n",
      "Write summary at step 6540  Loss:  0.4621005952358246\n",
      "Write summary at step 6550  Loss:  0.3799406886100769\n",
      "Write summary at step 6560  Loss:  0.5589612722396851\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9313257503432348\n",
      "Loss normal: 0.1963537369227531 Loss Control: 0.2665974224200014 Loss Patient: 0.17496506207794596 Loss balanced:  0.22078124224897366 Loss1+loss2: 0.22078124224897366\n",
      "Write summary at step 6570  Loss:  0.18090079724788666\n",
      "Write summary at step 6580  Loss:  0.4459158480167389\n",
      "Write summary at step 6590  Loss:  0.27930644154548645\n",
      "Write summary at step 6600  Loss:  0.31297430396080017\n",
      "Write summary at step 6610  Loss:  0.484153151512146\n",
      "Write summary at step 6620  Loss:  0.2654723823070526\n",
      "Write summary at step 6630  Loss:  0.3472718596458435\n",
      "Write summary at step 6640  Loss:  0.6658389568328857\n",
      "Write summary at step 6650  Loss:  0.3261753022670746\n",
      "Write summary at step 6660  Loss:  0.19291111826896667\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9048352927270578\n",
      "Loss normal: 0.200546725786158 Loss Control: 0.3523289958635966 Loss Patient: 0.15433016414451917 Loss balanced:  0.2533295800040579 Loss1+loss2: 0.2533295800040579\n",
      "Write summary at step 6670  Loss:  0.4122762680053711\n",
      "Write summary at step 6680  Loss:  0.14791131019592285\n",
      "Write summary at step 6690  Loss:  0.18418988585472107\n",
      "Write summary at step 6700  Loss:  0.28918254375457764\n",
      "Write summary at step 6710  Loss:  0.5297132134437561\n",
      "Write summary at step 6720  Loss:  0.3825579285621643\n",
      "Write summary at step 6730  Loss:  0.08245038986206055\n",
      "Write summary at step 6740  Loss:  0.5739661455154419\n",
      "Write summary at step 6750  Loss:  0.243703693151474\n",
      "Write summary at step 6760  Loss:  0.2541663646697998\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8453215496940436\n",
      "Loss normal: 0.24545876313076945 Loss Control: 0.6481105799232024 Loss Patient: 0.12285429802095632 Loss balanced:  0.38548243897207934 Loss1+loss2: 0.38548243897207934\n",
      "Write summary at step 6770  Loss:  0.44901373982429504\n",
      "Write summary at step 6780  Loss:  0.3198404908180237\n",
      "Write summary at step 6790  Loss:  0.433294415473938\n",
      "Write summary at step 6800  Loss:  0.41049724817276\n",
      "Write summary at step 6810  Loss:  0.22391225397586823\n",
      "Write summary at step 6820  Loss:  0.4052654504776001\n",
      "Write summary at step 6830  Loss:  0.31332114338874817\n",
      "Write summary at step 6840  Loss:  0.15505316853523254\n",
      "Write summary at step 6850  Loss:  0.3921307325363159\n",
      "Write summary at step 6860  Loss:  0.24297481775283813\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9269296163952612\n",
      "Loss normal: 0.21951128017841554 Loss Control: 0.29276356768738376 Loss Patient: 0.19720650790336725 Loss balanced:  0.2449850377953755 Loss1+loss2: 0.2449850377953755\n",
      "Write summary at step 6870  Loss:  0.41770485043525696\n",
      "Write summary at step 6880  Loss:  0.272154301404953\n",
      "Write summary at step 6890  Loss:  0.5150604844093323\n",
      "Write summary at step 6900  Loss:  0.5033844709396362\n",
      "Write summary at step 6910  Loss:  0.4556024968624115\n",
      "Write summary at step 6920  Loss:  0.38360732793807983\n",
      "Write summary at step 6930  Loss:  0.4659038484096527\n",
      "Write summary at step 6940  Loss:  0.16572216153144836\n",
      "Write summary at step 6950  Loss:  0.41061294078826904\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8933107843939518\n",
      "Loss normal: 0.20810667033858446 Loss Control: 0.31007908602229883 Loss Patient: 0.17705683679182002 Loss balanced:  0.24356796140705944 Loss1+loss2: 0.24356796140705944\n",
      "Write summary at step 6960  Loss:  0.2911898195743561\n",
      "Write summary at step 6970  Loss:  0.3123694360256195\n",
      "Write summary at step 6980  Loss:  0.402931272983551\n",
      "Write summary at step 6990  Loss:  0.46808764338493347\n",
      "Write summary at step 7000  Loss:  0.3149745464324951\n",
      "Saved checkpoint to: result/45/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9086358800905594\n",
      "Loss normal: 0.20137138569689528 Loss Control: 0.33810784517090176 Loss Patient: 0.15973615542227734 Loss balanced:  0.24892200029658956 Loss1+loss2: 0.24892200029658956\n",
      "Write summary at step 7010  Loss:  0.4430572986602783\n",
      "Write summary at step 7020  Loss:  0.20012551546096802\n",
      "Write summary at step 7030  Loss:  0.4128574728965759\n",
      "Write summary at step 7040  Loss:  0.32287687063217163\n",
      "Write summary at step 7050  Loss:  0.30506834387779236\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8829773692297901\n",
      "Loss normal: 0.22767580574264332 Loss Control: 0.37085942948450806 Loss Patient: 0.18407746234570882 Loss balanced:  0.27746844591510844 Loss1+loss2: 0.27746844591510844\n",
      "Write summary at step 7060  Loss:  0.3106831908226013\n",
      "Write summary at step 7070  Loss:  0.31954818964004517\n",
      "Write summary at step 7080  Loss:  0.22767622768878937\n",
      "Write summary at step 7090  Loss:  0.36251720786094666\n",
      "Write summary at step 7100  Loss:  0.32723891735076904\n",
      "Write summary at step 7110  Loss:  0.4902760982513428\n",
      "Write summary at step 7120  Loss:  0.2974632978439331\n",
      "Write summary at step 7130  Loss:  0.28212693333625793\n",
      "Write summary at step 7140  Loss:  0.15481305122375488\n",
      "Write summary at step 7150  Loss:  0.33733946084976196\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9233654292026949\n",
      "Loss normal: 0.2139628881550565 Loss Control: 0.23441121226451436 Loss Patient: 0.20773652562880873 Loss balanced:  0.22107386894666153 Loss1+loss2: 0.22107386894666153\n",
      "Write summary at step 7160  Loss:  0.2875708341598511\n",
      "Write summary at step 7170  Loss:  0.22770871222019196\n",
      "Write summary at step 7180  Loss:  0.5272736549377441\n",
      "Write summary at step 7190  Loss:  0.28443822264671326\n",
      "Write summary at step 7200  Loss:  0.1615620255470276\n",
      "Write summary at step 7210  Loss:  0.5758572220802307\n",
      "Write summary at step 7220  Loss:  0.4644247591495514\n",
      "Write summary at step 7230  Loss:  0.34170812368392944\n",
      "Write summary at step 7240  Loss:  0.39986124634742737\n",
      "Write summary at step 7250  Loss:  0.23401053249835968\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8758489948446578\n",
      "Loss normal: 0.22714223644259024 Loss Control: 0.4126651788669857 Loss Patient: 0.17065188985398524 Loss balanced:  0.2916585343604855 Loss1+loss2: 0.2916585343604855\n",
      "Write summary at step 7260  Loss:  0.15542438626289368\n",
      "Write summary at step 7270  Loss:  0.15340806543827057\n",
      "Write summary at step 7280  Loss:  0.43864262104034424\n",
      "Write summary at step 7290  Loss:  0.432468444108963\n",
      "Write summary at step 7300  Loss:  0.4393048882484436\n",
      "Write summary at step 7310  Loss:  0.42132335901260376\n",
      "Write summary at step 7320  Loss:  0.4204365313053131\n",
      "Write summary at step 7330  Loss:  0.20325984060764313\n",
      "Write summary at step 7340  Loss:  0.33013826608657837\n",
      "Write summary at step 7350  Loss:  0.3372030258178711\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8712164607257485\n",
      "Loss normal: 0.24217927813225862 Loss Control: 0.4587896362028487 Loss Patient: 0.1762230445238794 Loss balanced:  0.31750634036336406 Loss1+loss2: 0.31750634036336406\n",
      "Write summary at step 7360  Loss:  0.43197503685951233\n",
      "Write summary at step 7370  Loss:  0.33144333958625793\n",
      "Write summary at step 7380  Loss:  0.4918689727783203\n",
      "Write summary at step 7390  Loss:  0.33507585525512695\n",
      "Write summary at step 7400  Loss:  0.4152381122112274\n",
      "Write summary at step 7410  Loss:  0.3591417074203491\n",
      "Write summary at step 7420  Loss:  0.32966148853302\n",
      "Write summary at step 7430  Loss:  0.4246805012226105\n",
      "Write summary at step 7440  Loss:  0.41751712560653687\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8750170480892502\n",
      "Loss normal: 0.2313962561287442 Loss Control: 0.41670246804998223 Loss Patient: 0.17497190710981556 Loss balanced:  0.2958371875798989 Loss1+loss2: 0.2958371875798989\n",
      "Write summary at step 7450  Loss:  0.2844376266002655\n",
      "Write summary at step 7460  Loss:  0.652535080909729\n",
      "Write summary at step 7470  Loss:  0.2972520589828491\n",
      "Write summary at step 7480  Loss:  0.5402828454971313\n",
      "Write summary at step 7490  Loss:  0.4922455847263336\n",
      "Write summary at step 7500  Loss:  0.3590524196624756\n",
      "Saved checkpoint to: result/45/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.856486911613613\n",
      "Loss normal: 0.27364187375927457 Loss Control: 0.6376657995695625 Loss Patient: 0.162799316425862 Loss balanced:  0.40023255799771223 Loss1+loss2: 0.40023255799771223\n",
      "Write summary at step 7510  Loss:  0.3360767364501953\n",
      "Write summary at step 7520  Loss:  0.28195953369140625\n",
      "Write summary at step 7530  Loss:  0.2586000859737396\n",
      "Write summary at step 7540  Loss:  0.10271072387695312\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9184964949128502\n",
      "Loss normal: 0.19004487713836893 Loss Control: 0.30380137028589926 Loss Patient: 0.15540687832826386 Loss balanced:  0.22960412430708155 Loss1+loss2: 0.22960412430708155\n",
      "Write summary at step 7550  Loss:  0.29401883482933044\n",
      "Write summary at step 7560  Loss:  0.512932300567627\n",
      "Write summary at step 7570  Loss:  0.3695324659347534\n",
      "Write summary at step 7580  Loss:  0.25273919105529785\n",
      "Write summary at step 7590  Loss:  0.2771517038345337\n",
      "Write summary at step 7600  Loss:  0.16487781703472137\n",
      "Write summary at step 7610  Loss:  0.30048859119415283\n",
      "Write summary at step 7620  Loss:  0.44058141112327576\n",
      "Write summary at step 7630  Loss:  0.3823217749595642\n",
      "Write summary at step 7640  Loss:  0.5449873208999634\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.9284525790349417 Acurracy Balanced 0.958761808643154\n",
      "Loss normal: 0.21997676622502657 Loss Control: 0.17485380824146374 Loss Patient: 0.23371637016286867 Loss balanced:  0.2042850892021662 Loss1+loss2: 0.2042850892021662\n",
      "Write summary at step 7650  Loss:  0.25889652967453003\n",
      "Write summary at step 7660  Loss:  0.33617955446243286\n",
      "Write summary at step 7670  Loss:  0.37657472491264343\n",
      "Write summary at step 7680  Loss:  0.2875664234161377\n",
      "Write summary at step 7690  Loss:  0.3758559226989746\n",
      "Write summary at step 7700  Loss:  0.3456675112247467\n",
      "Write summary at step 7710  Loss:  0.1206311360001564\n",
      "Write summary at step 7720  Loss:  0.26258623600006104\n",
      "Write summary at step 7730  Loss:  0.5062583088874817\n",
      "Write summary at step 7740  Loss:  0.33943045139312744\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9464285714285714 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9441550057736197\n",
      "Loss normal: 0.19050059091223745 Loss Control: 0.21072092114901933 Loss Patient: 0.18434365244951106 Loss balanced:  0.1975322867992652 Loss1+loss2: 0.1975322867992652\n",
      "Write summary at step 7750  Loss:  0.20347124338150024\n",
      "Write summary at step 7760  Loss:  0.4089081585407257\n",
      "Write summary at step 7770  Loss:  0.3599209785461426\n",
      "Write summary at step 7780  Loss:  0.3920212686061859\n",
      "Write summary at step 7790  Loss:  0.37321391701698303\n",
      "Write summary at step 7800  Loss:  0.2627131938934326\n",
      "Write summary at step 7810  Loss:  0.3249719738960266\n",
      "Write summary at step 7820  Loss:  0.46917998790740967\n",
      "Write summary at step 7830  Loss:  0.3096782863140106\n",
      "Write summary at step 7840  Loss:  0.42610985040664673\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8646836329250884\n",
      "Loss normal: 0.23564514681240734 Loss Control: 0.4385455582962661 Loss Patient: 0.17386348761878473 Loss balanced:  0.3062045229575254 Loss1+loss2: 0.3062045229575254\n",
      "Write summary at step 7850  Loss:  0.2915586233139038\n",
      "Write summary at step 7860  Loss:  0.300728976726532\n",
      "Write summary at step 7870  Loss:  0.32972046732902527\n",
      "Write summary at step 7880  Loss:  0.3665826618671417\n",
      "Write summary at step 7890  Loss:  0.2899112105369568\n",
      "Write summary at step 7900  Loss:  0.39709770679473877\n",
      "Write summary at step 7910  Loss:  0.4016663134098053\n",
      "Write summary at step 7920  Loss:  0.37966617941856384\n",
      "Write summary at step 7930  Loss:  0.4188466966152191\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.9048352927270578\n",
      "Loss normal: 0.21630040681635848 Loss Control: 0.31421479159365584 Loss Patient: 0.18648620986204575 Loss balanced:  0.2503505007278508 Loss1+loss2: 0.2503505007278508\n",
      "Write summary at step 7940  Loss:  0.3449801206588745\n",
      "Write summary at step 7950  Loss:  0.2503988742828369\n",
      "Write summary at step 7960  Loss:  0.4516019821166992\n",
      "Write summary at step 7970  Loss:  0.3812066912651062\n",
      "Write summary at step 7980  Loss:  0.29266637563705444\n",
      "Write summary at step 7990  Loss:  0.35015377402305603\n",
      "Write summary at step 8000  Loss:  0.6137802600860596\n",
      "Saved checkpoint to: result/45/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8712164607257485\n",
      "Loss normal: 0.2368709852120706 Loss Control: 0.4751053664202247 Loss Patient: 0.16433040313608635 Loss balanced:  0.31971788477815555 Loss1+loss2: 0.31971788477815555\n",
      "Write summary at step 8010  Loss:  0.4697844684123993\n",
      "Write summary at step 8020  Loss:  0.39001840353012085\n",
      "Write summary at step 8030  Loss:  0.40276503562927246\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8693161670439977\n",
      "Loss normal: 0.22538415867151046 Loss Control: 0.4338560146712215 Loss Patient: 0.16190604259339028 Loss balanced:  0.29788102863230587 Loss1+loss2: 0.29788102863230587\n",
      "Write summary at step 8040  Loss:  0.5981541275978088\n",
      "Write summary at step 8050  Loss:  0.46573349833488464\n",
      "Write summary at step 8060  Loss:  0.3405243754386902\n",
      "Write summary at step 8070  Loss:  0.5175858736038208\n",
      "Write summary at step 8080  Loss:  0.3380388915538788\n",
      "Write summary at step 8090  Loss:  0.34968769550323486\n",
      "Write summary at step 8100  Loss:  0.5252507925033569\n",
      "Write summary at step 8110  Loss:  0.5303249955177307\n",
      "Write summary at step 8120  Loss:  0.2101982980966568\n",
      "Write summary at step 8130  Loss:  0.1683931052684784\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.86195139248793\n",
      "Loss normal: 0.24355506999608206 Loss Control: 0.5110354853458092 Loss Patient: 0.16210928641123304 Loss balanced:  0.3365723858785211 Loss1+loss2: 0.3365723858785211\n",
      "Write summary at step 8140  Loss:  0.3130379021167755\n",
      "Write summary at step 8150  Loss:  0.3199950158596039\n",
      "Write summary at step 8160  Loss:  0.39433810114860535\n",
      "Write summary at step 8170  Loss:  0.43252092599868774\n",
      "Write summary at step 8180  Loss:  0.37367919087409973\n",
      "Write summary at step 8190  Loss:  0.25221216678619385\n",
      "Write summary at step 8200  Loss:  0.431934118270874\n",
      "Write summary at step 8210  Loss:  0.31138521432876587\n",
      "Write summary at step 8220  Loss:  0.3537678122520447\n",
      "Write summary at step 8230  Loss:  0.22294272482395172\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9132684142094687\n",
      "Loss normal: 0.20548145484407337 Loss Control: 0.304624355881592 Loss Patient: 0.17529318506477676 Loss balanced:  0.23995877047318437 Loss1+loss2: 0.23995877047318437\n",
      "Write summary at step 8240  Loss:  0.40536266565322876\n",
      "Write summary at step 8250  Loss:  0.20876909792423248\n",
      "Write summary at step 8260  Loss:  0.5285414457321167\n",
      "Write summary at step 8270  Loss:  0.3169631063938141\n",
      "Write summary at step 8280  Loss:  0.5303352475166321\n",
      "Write summary at step 8290  Loss:  0.27074602246284485\n",
      "Write summary at step 8300  Loss:  0.2687617242336273\n",
      "Write summary at step 8310  Loss:  0.30862921476364136\n",
      "Write summary at step 8320  Loss:  0.3428381383419037\n",
      "Write summary at step 8330  Loss:  0.3654397428035736\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9289617486338798 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9370266313884874\n",
      "Loss normal: 0.2153035680554351 Loss Control: 0.20582562978150415 Loss Patient: 0.2181895335829397 Loss balanced:  0.21200758168222192 Loss1+loss2: 0.21200758168222192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 8340  Loss:  0.2521477937698364\n",
      "Write summary at step 8350  Loss:  0.2924884557723999\n",
      "Write summary at step 8360  Loss:  0.27424922585487366\n",
      "Write summary at step 8370  Loss:  0.39330920577049255\n",
      "Write summary at step 8380  Loss:  0.3329594135284424\n",
      "Write summary at step 8390  Loss:  0.2736167907714844\n",
      "Write summary at step 8400  Loss:  0.2082275003194809\n",
      "Write summary at step 8410  Loss:  0.4287225902080536\n",
      "Write summary at step 8420  Loss:  0.38750743865966797\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9023394524608348\n",
      "Loss normal: 0.23139278826360798 Loss Control: 0.27971639268385257 Loss Patient: 0.21667861327305807 Loss balanced:  0.24819750297845533 Loss1+loss2: 0.24819750297845533\n",
      "Write summary at step 8430  Loss:  0.1316719353199005\n",
      "Write summary at step 8440  Loss:  0.4087529480457306\n",
      "Write summary at step 8450  Loss:  0.3363679349422455\n",
      "Write summary at step 8460  Loss:  0.19449536502361298\n",
      "Write summary at step 8470  Loss:  0.5598794221878052\n",
      "Write summary at step 8480  Loss:  0.374999463558197\n",
      "Write summary at step 8490  Loss:  0.41191577911376953\n",
      "Write summary at step 8500  Loss:  0.2761828303337097\n",
      "Saved checkpoint to: result/45/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8720484074811562\n",
      "Loss normal: 0.21425734319705136 Loss Control: 0.3898190751753218 Loss Patient: 0.16080011012103912 Loss balanced:  0.27530959264818045 Loss1+loss2: 0.27530959264818045\n",
      "Write summary at step 8510  Loss:  0.4859575033187866\n",
      "Write summary at step 8520  Loss:  0.35959863662719727\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8775128883554731\n",
      "Loss normal: 0.22489336516936215 Loss Control: 0.36077773799010315 Loss Patient: 0.1835175900039776 Loss balanced:  0.2721476639970404 Loss1+loss2: 0.2721476639970404\n",
      "Write summary at step 8530  Loss:  0.17778225243091583\n",
      "Write summary at step 8540  Loss:  0.39863476157188416\n",
      "Write summary at step 8550  Loss:  0.2980222702026367\n",
      "Write summary at step 8560  Loss:  0.21879985928535461\n",
      "Write summary at step 8570  Loss:  0.3610948324203491\n",
      "Write summary at step 8580  Loss:  0.31509143114089966\n",
      "Write summary at step 8590  Loss:  0.3466833531856537\n",
      "Write summary at step 8600  Loss:  0.37779495120048523\n",
      "Write summary at step 8610  Loss:  0.20644840598106384\n",
      "Write summary at step 8620  Loss:  0.25082698464393616\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8876099033486994\n",
      "Loss normal: 0.2266124049011542 Loss Control: 0.3132453254663228 Loss Patient: 0.2002333279159819 Loss balanced:  0.25673932669115235 Loss1+loss2: 0.25673932669115235\n",
      "Write summary at step 8630  Loss:  0.4612402319908142\n",
      "Write summary at step 8640  Loss:  0.34004318714141846\n",
      "Write summary at step 8650  Loss:  0.28653618693351746\n",
      "Write summary at step 8660  Loss:  0.33293890953063965\n",
      "Write summary at step 8670  Loss:  0.3106354773044586\n",
      "Write summary at step 8680  Loss:  0.48016372323036194\n",
      "Write summary at step 8690  Loss:  0.3299269378185272\n",
      "Write summary at step 8700  Loss:  0.32707542181015015\n",
      "Write summary at step 8710  Loss:  0.36022233963012695\n",
      "Write summary at step 8720  Loss:  0.2311789095401764\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8583872052953638\n",
      "Loss normal: 0.25319763364232317 Loss Control: 0.4760696749543883 Loss Patient: 0.1853347645945438 Loss balanced:  0.330702219774466 Loss1+loss2: 0.330702219774466\n",
      "Write summary at step 8730  Loss:  0.6177669763565063\n",
      "Write summary at step 8740  Loss:  0.32475587725639343\n",
      "Write summary at step 8750  Loss:  0.4712589383125305\n",
      "Write summary at step 8760  Loss:  0.4381319284439087\n",
      "Write summary at step 8770  Loss:  0.3333436846733093\n",
      "Write summary at step 8780  Loss:  0.46774643659591675\n",
      "Write summary at step 8790  Loss:  0.40811944007873535\n",
      "Write summary at step 8800  Loss:  0.2952190637588501\n",
      "Write summary at step 8810  Loss:  0.3924753665924072\n",
      "Write summary at step 8820  Loss:  0.5223371982574463\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9198012420101289\n",
      "Loss normal: 0.19762592500417817 Loss Control: 0.22154306282436914 Loss Patient: 0.19034333160757622 Loss balanced:  0.20594319721597268 Loss1+loss2: 0.20594319721597268\n",
      "Write summary at step 8830  Loss:  0.38201993703842163\n",
      "Write summary at step 8840  Loss:  0.5576238632202148\n",
      "Write summary at step 8850  Loss:  0.26440176367759705\n",
      "Write summary at step 8860  Loss:  0.26227325201034546\n",
      "Write summary at step 8870  Loss:  0.40663474798202515\n",
      "Write summary at step 8880  Loss:  0.396240770816803\n",
      "Write summary at step 8890  Loss:  0.5416961312294006\n",
      "Write summary at step 8900  Loss:  0.1715030074119568\n",
      "Write summary at step 8910  Loss:  0.39114779233932495\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8996072120236764\n",
      "Loss normal: 0.2105889738138233 Loss Control: 0.29548826585701904 Loss Patient: 0.1847377763611703 Loss balanced:  0.24011302110909466 Loss1+loss2: 0.24011302110909466\n",
      "Write summary at step 8920  Loss:  0.32968276739120483\n",
      "Write summary at step 8930  Loss:  0.25446152687072754\n",
      "Write summary at step 8940  Loss:  0.26197537779808044\n",
      "Write summary at step 8950  Loss:  0.4510301351547241\n",
      "Write summary at step 8960  Loss:  0.4958376884460449\n",
      "Write summary at step 8970  Loss:  0.22450560331344604\n",
      "Write summary at step 8980  Loss:  0.4067942500114441\n",
      "Write summary at step 8990  Loss:  0.48124629259109497\n",
      "Write summary at step 9000  Loss:  0.3198181390762329\n",
      "Saved checkpoint to: result/45/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8901057436149223\n",
      "Loss normal: 0.20148776258741105 Loss Control: 0.38915130707735573 Loss Patient: 0.1443456176748986 Loss balanced:  0.26674846237612715 Loss1+loss2: 0.26674846237612715\n",
      "Write summary at step 9010  Loss:  0.3506678640842438\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.6939890710382514 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8270278133893421\n",
      "Loss normal: 0.2532547784361 Loss Control: 0.6542478031148025 Loss Patient: 0.1311554040747405 Loss balanced:  0.39270160359477146 Loss1+loss2: 0.39270160359477146\n",
      "Write summary at step 9020  Loss:  0.4184153079986572\n",
      "Write summary at step 9030  Loss:  0.2801664173603058\n",
      "Write summary at step 9040  Loss:  0.32172152400016785\n",
      "Write summary at step 9050  Loss:  0.4970861077308655\n",
      "Write summary at step 9060  Loss:  0.2676003575325012\n",
      "Write summary at step 9070  Loss:  0.5382136106491089\n",
      "Write summary at step 9080  Loss:  0.3833335041999817\n",
      "Write summary at step 9090  Loss:  0.2591356635093689\n",
      "Write summary at step 9100  Loss:  0.3497491180896759\n",
      "Write summary at step 9110  Loss:  0.23170410096645355\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9288299100770119\n",
      "Loss normal: 0.19862841396611564 Loss Control: 0.23967829232658844 Loss Patient: 0.18612903656558863 Loss balanced:  0.21290366444608855 Loss1+loss2: 0.21290366444608855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 9120  Loss:  0.33296439051628113\n",
      "Write summary at step 9130  Loss:  0.4099392592906952\n",
      "Write summary at step 9140  Loss:  0.4977707862854004\n",
      "Write summary at step 9150  Loss:  0.5348016023635864\n",
      "Write summary at step 9160  Loss:  0.3049470782279968\n",
      "Write summary at step 9170  Loss:  0.3561316430568695\n",
      "Write summary at step 9180  Loss:  0.2161788046360016\n",
      "Write summary at step 9190  Loss:  0.4843534231185913\n",
      "Write summary at step 9200  Loss:  0.31951838731765747\n",
      "Write summary at step 9210  Loss:  0.39870452880859375\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9462916996263059\n",
      "Loss normal: 0.20693242709551538 Loss Control: 0.1736346292284017 Loss Patient: 0.21707135689957766 Loss balanced:  0.19535299306398968 Loss1+loss2: 0.19535299306398968\n",
      "Write summary at step 9220  Loss:  0.4446718990802765\n",
      "Write summary at step 9230  Loss:  0.4237312078475952\n",
      "Write summary at step 9240  Loss:  0.2563440203666687\n",
      "Write summary at step 9250  Loss:  0.2911311388015747\n",
      "Write summary at step 9260  Loss:  0.23818205296993256\n",
      "Write summary at step 9270  Loss:  0.5137262344360352\n",
      "Write summary at step 9280  Loss:  0.44289982318878174\n",
      "Write summary at step 9290  Loss:  0.29363253712654114\n",
      "Write summary at step 9300  Loss:  0.3502240777015686\n",
      "Write summary at step 9310  Loss:  0.2824256718158722\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8756125946737223\n",
      "Loss normal: 0.22303175610699216 Loss Control: 0.45415071662657897 Loss Patient: 0.15265775858091435 Loss balanced:  0.3034042376037467 Loss1+loss2: 0.3034042376037467\n",
      "Write summary at step 9320  Loss:  0.39531126618385315\n",
      "Write summary at step 9330  Loss:  0.431296706199646\n",
      "Write summary at step 9340  Loss:  0.4353787302970886\n",
      "Write summary at step 9350  Loss:  0.395356684923172\n",
      "Write summary at step 9360  Loss:  0.2494172751903534\n",
      "Write summary at step 9370  Loss:  0.32858017086982727\n",
      "Write summary at step 9380  Loss:  0.34501951932907104\n",
      "Write summary at step 9390  Loss:  0.531500518321991\n",
      "Write summary at step 9400  Loss:  0.4000150263309479\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9078039333351517\n",
      "Loss normal: 0.20112108201624787 Loss Control: 0.31932862534549067 Loss Patient: 0.16512777063121614 Loss balanced:  0.2422281979883534 Loss1+loss2: 0.2422281979883534\n",
      "Write summary at step 9410  Loss:  0.2990899682044983\n",
      "Write summary at step 9420  Loss:  0.45310086011886597\n",
      "Write summary at step 9430  Loss:  0.2770703434944153\n",
      "Write summary at step 9440  Loss:  0.2481997311115265\n",
      "Write summary at step 9450  Loss:  0.36260008811950684\n",
      "Write summary at step 9460  Loss:  0.32649773359298706\n",
      "Write summary at step 9470  Loss:  0.315188467502594\n",
      "Write summary at step 9480  Loss:  0.2472958266735077\n",
      "Write summary at step 9490  Loss:  0.23743128776550293\n",
      "Write summary at step 9500  Loss:  0.19134652614593506\n",
      "Saved checkpoint to: result/45/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9364310848040152\n",
      "Loss normal: 0.21182849809375345 Loss Control: 0.21322550750821015 Loss Patient: 0.21140312014175533 Loss balanced:  0.21231431382498273 Loss1+loss2: 0.21231431382498273\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9105361737723103\n",
      "Loss normal: 0.20480287816299467 Loss Control: 0.3034505995570636 Loss Patient: 0.1747653827988566 Loss balanced:  0.2391079911779601 Loss1+loss2: 0.2391079911779601\n",
      "Write summary at step 9510  Loss:  0.36267244815826416\n",
      "Write summary at step 9520  Loss:  0.2986375689506531\n",
      "Write summary at step 9530  Loss:  0.2807765305042267\n",
      "Write summary at step 9540  Loss:  0.29932430386543274\n",
      "Write summary at step 9550  Loss:  0.3145720064640045\n",
      "Write summary at step 9560  Loss:  0.1587245762348175\n",
      "Write summary at step 9570  Loss:  0.41203486919403076\n",
      "Write summary at step 9580  Loss:  0.42874661087989807\n",
      "Write summary at step 9590  Loss:  0.2578448951244354\n",
      "Write summary at step 9600  Loss:  0.4423925280570984\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8775128883554731\n",
      "Loss normal: 0.21205252336756308 Loss Control: 0.39830973662965286 Loss Patient: 0.15533859726543633 Loss balanced:  0.2768241669475446 Loss1+loss2: 0.2768241669475446\n",
      "Write summary at step 9610  Loss:  0.46836864948272705\n",
      "Write summary at step 9620  Loss:  0.21591898798942566\n",
      "Write summary at step 9630  Loss:  0.5147302150726318\n",
      "Write summary at step 9640  Loss:  0.39777857065200806\n",
      "Write summary at step 9650  Loss:  0.27512866258621216\n",
      "Write summary at step 9660  Loss:  0.4518912434577942\n",
      "Write summary at step 9670  Loss:  0.31090205907821655\n",
      "Write summary at step 9680  Loss:  0.4728495180606842\n",
      "Write summary at step 9690  Loss:  0.8317789435386658\n",
      "Write summary at step 9700  Loss:  0.281549870967865\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9269296163952612\n",
      "Loss normal: 0.19483975957774993 Loss Control: 0.2586279565193614 Loss Patient: 0.1754167263524703 Loss balanced:  0.21702234143591584 Loss1+loss2: 0.21702234143591584\n",
      "Write summary at step 9710  Loss:  0.3103305697441101\n",
      "Write summary at step 9720  Loss:  0.4093020558357239\n",
      "Write summary at step 9730  Loss:  0.19989177584648132\n",
      "Write summary at step 9740  Loss:  0.3108753561973572\n",
      "Write summary at step 9750  Loss:  0.47526395320892334\n",
      "Write summary at step 9760  Loss:  0.40297290682792664\n",
      "Write summary at step 9770  Loss:  0.20928531885147095\n",
      "Write summary at step 9780  Loss:  0.4321722388267517\n",
      "Write summary at step 9790  Loss:  0.4438123404979706\n",
      "Write summary at step 9800  Loss:  0.22029846906661987\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9279979633216042\n",
      "Loss normal: 0.18263640988390056 Loss Control: 0.2606335702489634 Loss Patient: 0.15888686176891534 Loss balanced:  0.20976021600893935 Loss1+loss2: 0.20976021600893935\n",
      "------------------------------\n",
      "SEED: 45 Best Loss: 0.18488460266036685\n",
      "______________________________\n",
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 5 (+- 0.1 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.8310050964355469\n",
      "Write summary at step 20  Loss:  0.7563614845275879\n",
      "Write summary at step 30  Loss:  0.7241374254226685\n",
      "Write summary at step 40  Loss:  0.8853819370269775\n",
      "Write summary at step 50  Loss:  0.7571487426757812\n",
      "Write summary at step 60  Loss:  0.7194317579269409\n",
      "Write summary at step 70  Loss:  0.6854099035263062\n",
      "Write summary at step 80  Loss:  0.7662990093231201\n",
      "Write summary at step 90  Loss:  0.6190190315246582\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.6288265306122449 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.5424292845257903 Acurracy Balanced 0.7274987952683596\n",
      "Loss normal: 0.6654208375483143 Loss Control: 0.6262383682480275 Loss Patient: 0.6773516094426744 Loss balanced:  0.6517949888453509 Loss1+loss2: 0.6517949888453509\n",
      "\n",
      " > BEST MODEL (0.65179) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 100  Loss:  0.6134671568870544\n",
      "Write summary at step 110  Loss:  0.7658509016036987\n",
      "Write summary at step 120  Loss:  0.6914784908294678\n",
      "Write summary at step 130  Loss:  0.7225409746170044\n",
      "Write summary at step 140  Loss:  0.7866717576980591\n",
      "Write summary at step 150  Loss:  0.7893824577331543\n",
      "Write summary at step 160  Loss:  0.6560283899307251\n",
      "Write summary at step 170  Loss:  0.7018557786941528\n",
      "Write summary at step 180  Loss:  0.6427680850028992\n",
      "Write summary at step 190  Loss:  0.7481058835983276\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8176020408163265 Acurracy Control:  0.32786885245901637 Acurracy Patient:  0.9667221297836939 Acurracy Balanced 0.6472954911213551\n",
      "Loss normal: 0.3496762603065189 Loss Control: 0.9113313422177007 Loss Patient: 0.1786564965414723 Loss balanced:  0.5449939193795865 Loss1+loss2: 0.5449939193795865\n",
      "\n",
      " > BEST MODEL (0.54499) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 200  Loss:  0.5340275764465332\n",
      "Write summary at step 210  Loss:  0.7927448749542236\n",
      "Write summary at step 220  Loss:  0.5856099128723145\n",
      "Write summary at step 230  Loss:  0.5312812328338623\n",
      "Write summary at step 240  Loss:  0.5504838228225708\n",
      "Write summary at step 250  Loss:  0.4576604962348938\n",
      "Write summary at step 260  Loss:  0.5431641936302185\n",
      "Write summary at step 270  Loss:  0.5385130643844604\n",
      "Write summary at step 280  Loss:  0.4334685206413269\n",
      "Write summary at step 290  Loss:  0.7229448556900024\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8788265306122449 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.8602329450915142 Acurracy Balanced 0.9000618277370139\n",
      "Loss normal: 0.31442771969857264 Loss Control: 0.2918343697089315 Loss Patient: 0.32130722495759784 Loss balanced:  0.30657079733326464 Loss1+loss2: 0.30657079733326464\n",
      "\n",
      " > BEST MODEL (0.30657) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 300  Loss:  0.4159160256385803\n",
      "Write summary at step 310  Loss:  0.55752032995224\n",
      "Write summary at step 320  Loss:  0.5517034530639648\n",
      "Write summary at step 330  Loss:  0.5799869298934937\n",
      "Write summary at step 340  Loss:  0.47487276792526245\n",
      "Write summary at step 350  Loss:  0.30383312702178955\n",
      "Write summary at step 360  Loss:  0.733676552772522\n",
      "Write summary at step 370  Loss:  0.6131812930107117\n",
      "Write summary at step 380  Loss:  0.5413460731506348\n",
      "Write summary at step 390  Loss:  0.38813871145248413\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8903061224489796 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.908485856905158 Acurracy Balanced 0.8695434749006665\n",
      "Loss normal: 0.31969732380643184 Loss Control: 0.31118462206236003 Loss Patient: 0.3222893785914645 Loss balanced:  0.31673700032691227 Loss1+loss2: 0.31673700032691227\n",
      "Write summary at step 400  Loss:  0.2420872151851654\n",
      "Write summary at step 410  Loss:  0.47925740480422974\n",
      "Write summary at step 420  Loss:  0.41404467821121216\n",
      "Write summary at step 430  Loss:  0.5237712264060974\n",
      "Write summary at step 440  Loss:  0.3046572208404541\n",
      "Write summary at step 450  Loss:  0.6462242603302002\n",
      "Write summary at step 460  Loss:  0.3234601616859436\n",
      "Write summary at step 470  Loss:  0.9436020255088806\n",
      "Write summary at step 480  Loss:  0.702621579170227\n",
      "Write summary at step 490  Loss:  0.6439088582992554\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8405612244897959 Acurracy Control:  0.9508196721311475 Acurracy Patient:  0.8069883527454242 Acurracy Balanced 0.8789040124382859\n",
      "Loss normal: 0.45857472109551334 Loss Control: 0.2247555014865646 Loss Patient: 0.5297709215500589 Loss balanced:  0.37726321151831177 Loss1+loss2: 0.37726321151831177\n",
      "Write summary at step 500  Loss:  0.5571281909942627\n",
      "Saved checkpoint to: result/46/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7487244897959183 Acurracy Control:  1.0 Acurracy Patient:  0.6722129783693843 Acurracy Balanced 0.8361064891846921\n",
      "Loss normal: 1.3890413678612332 Loss Control: 0.0238607138436023 Loss Patient: 1.8047286539823562 Loss balanced:  0.9142946839129792 Loss1+loss2: 0.9142946839129792\n",
      "Write summary at step 510  Loss:  0.7278693914413452\n",
      "Write summary at step 520  Loss:  0.5202046632766724\n",
      "Write summary at step 530  Loss:  0.6790333986282349\n",
      "Write summary at step 540  Loss:  0.38153883814811707\n",
      "Write summary at step 550  Loss:  0.43764787912368774\n",
      "Write summary at step 560  Loss:  0.8812482357025146\n",
      "Write summary at step 570  Loss:  0.48285579681396484\n",
      "Write summary at step 580  Loss:  0.31326887011528015\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8660714285714286 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.8585690515806988 Acurracy Balanced 0.87463971704718\n",
      "Loss normal: 0.3691517394416186 Loss Control: 0.2670282853431389 Loss Patient: 0.40024756472836714 Loss balanced:  0.333637925035753 Loss1+loss2: 0.333637925035753\n",
      "Write summary at step 590  Loss:  0.4335934817790985\n",
      "Write summary at step 600  Loss:  1.0385655164718628\n",
      "Write summary at step 610  Loss:  0.34208694100379944\n",
      "Write summary at step 620  Loss:  0.5789302587509155\n",
      "Write summary at step 630  Loss:  0.4512345790863037\n",
      "Write summary at step 640  Loss:  0.5191535353660583\n",
      "Write summary at step 650  Loss:  0.42730027437210083\n",
      "Write summary at step 660  Loss:  0.41580361127853394\n",
      "Write summary at step 670  Loss:  0.5705082416534424\n",
      "Write summary at step 680  Loss:  0.6580153703689575\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9068219633943427 Acurracy Balanced 0.9124273751397943\n",
      "Loss normal: 0.2297132415126781 Loss Control: 0.31133568547462503 Loss Patient: 0.20485982125293395 Loss balanced:  0.2580977533637795 Loss1+loss2: 0.2580977533637795\n",
      "\n",
      " > BEST MODEL (0.25810) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 690  Loss:  0.32532256841659546\n",
      "Write summary at step 700  Loss:  0.6083146929740906\n",
      "Write summary at step 710  Loss:  0.4674474596977234\n",
      "Write summary at step 720  Loss:  0.7270201444625854\n",
      "Write summary at step 730  Loss:  0.4766750931739807\n",
      "Write summary at step 740  Loss:  0.39363276958465576\n",
      "Write summary at step 750  Loss:  0.577974259853363\n",
      "Write summary at step 760  Loss:  0.3070828318595886\n",
      "Write summary at step 770  Loss:  0.35734444856643677\n",
      "Write summary at step 780  Loss:  0.48357680439949036\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8801020408163265 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.8752079866888519 Acurracy Balanced 0.885691425038415\n",
      "Loss normal: 0.29620593603776424 Loss Control: 0.23518609381764313 Loss Patient: 0.3147860188254104 Loss balanced:  0.2749860563215268 Loss1+loss2: 0.2749860563215268\n",
      "Write summary at step 790  Loss:  0.443689227104187\n",
      "Write summary at step 800  Loss:  0.2931203246116638\n",
      "Write summary at step 810  Loss:  0.597139835357666\n",
      "Write summary at step 820  Loss:  0.631241500377655\n",
      "Write summary at step 830  Loss:  0.4695936441421509\n",
      "Write summary at step 840  Loss:  0.6817396283149719\n",
      "Write summary at step 850  Loss:  0.5031948089599609\n",
      "Write summary at step 860  Loss:  0.9964197278022766\n",
      "Write summary at step 870  Loss:  0.4253581166267395\n",
      "Write summary at step 880  Loss:  0.3294473886489868\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9217970049916805 Acurracy Balanced 0.9035214533155124\n",
      "Loss normal: 0.27829788412366596 Loss Control: 0.2734406600232984 Loss Patient: 0.2797768717994309 Loss balanced:  0.27660876591136463 Loss1+loss2: 0.27660876591136463\n",
      "Write summary at step 890  Loss:  0.2740646004676819\n",
      "Write summary at step 900  Loss:  0.5487415790557861\n",
      "Write summary at step 910  Loss:  0.45169222354888916\n",
      "Write summary at step 920  Loss:  0.3523447811603546\n",
      "Write summary at step 930  Loss:  0.3721097409725189\n",
      "Write summary at step 940  Loss:  0.5117987990379333\n",
      "Write summary at step 950  Loss:  0.4047777056694031\n",
      "Write summary at step 960  Loss:  0.4892774820327759\n",
      "Write summary at step 970  Loss:  0.4031723141670227\n",
      "Write summary at step 980  Loss:  0.32169800996780396\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.8784584890392151\n",
      "Loss normal: 0.28222545494838636 Loss Control: 0.3385796986642431 Loss Patient: 0.2650660082028432 Loss balanced:  0.30182285343354315 Loss1+loss2: 0.30182285343354315\n",
      "Write summary at step 990  Loss:  0.48478978872299194\n",
      "Write summary at step 1000  Loss:  0.5939153432846069\n",
      "Saved checkpoint to: result/46/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8954081632653061 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.8868552412645591 Acurracy Balanced 0.905176254512061\n",
      "Loss normal: 0.3009559460440461 Loss Control: 0.22102640056219258 Loss Patient: 0.3252938937228452 Loss balanced:  0.2731601471425189 Loss1+loss2: 0.2731601471425189\n",
      "Write summary at step 1010  Loss:  0.5180186033248901\n",
      "Write summary at step 1020  Loss:  0.7985012531280518\n",
      "Write summary at step 1030  Loss:  0.4305720925331116\n",
      "Write summary at step 1040  Loss:  0.5406935214996338\n",
      "Write summary at step 1050  Loss:  0.817510724067688\n",
      "Write summary at step 1060  Loss:  0.44560495018959045\n",
      "Write summary at step 1070  Loss:  0.2942613363265991\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9251247920133111 Acurracy Balanced 0.9024531063891692\n",
      "Loss normal: 0.2403174788520044 Loss Control: 0.3189642041758761 Loss Patient: 0.21637014045493178 Loss balanced:  0.26766717231540393 Loss1+loss2: 0.26766717231540393\n",
      "Write summary at step 1080  Loss:  0.7691700458526611\n",
      "Write summary at step 1090  Loss:  0.46212852001190186\n",
      "Write summary at step 1100  Loss:  0.4400479793548584\n",
      "Write summary at step 1110  Loss:  0.44524288177490234\n",
      "Write summary at step 1120  Loss:  0.38045114278793335\n",
      "Write summary at step 1130  Loss:  0.3721480667591095\n",
      "Write summary at step 1140  Loss:  0.2769937515258789\n",
      "Write summary at step 1150  Loss:  0.33875229954719543\n",
      "Write summary at step 1160  Loss:  0.34689998626708984\n",
      "Write summary at step 1170  Loss:  0.24694156646728516\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.6994535519125683 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8280961603156851\n",
      "Loss normal: 0.299228399497818 Loss Control: 0.8963254787882821 Loss Patient: 0.1174168115274085 Loss balanced:  0.5068711451578453 Loss1+loss2: 0.5068711451578453\n",
      "Write summary at step 1180  Loss:  0.5077998638153076\n",
      "Write summary at step 1190  Loss:  0.3998714089393616\n",
      "Write summary at step 1200  Loss:  0.357194721698761\n",
      "Write summary at step 1210  Loss:  0.48674875497817993\n",
      "Write summary at step 1220  Loss:  0.38557225465774536\n",
      "Write summary at step 1230  Loss:  0.40150028467178345\n",
      "Write summary at step 1240  Loss:  0.38209009170532227\n",
      "Write summary at step 1250  Loss:  0.31673479080200195\n",
      "Write summary at step 1260  Loss:  0.34467411041259766\n",
      "Write summary at step 1270  Loss:  0.7222989797592163\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8878463035196349\n",
      "Loss normal: 0.2093129408146654 Loss Control: 0.38333912429913797 Loss Patient: 0.15632327409234895 Loss balanced:  0.26983119919574344 Loss1+loss2: 0.26983119919574344\n",
      "Write summary at step 1280  Loss:  0.4193289875984192\n",
      "Write summary at step 1290  Loss:  0.49271613359451294\n",
      "Write summary at step 1300  Loss:  0.3500900864601135\n",
      "Write summary at step 1310  Loss:  0.4774937033653259\n",
      "Write summary at step 1320  Loss:  0.8256714940071106\n",
      "Write summary at step 1330  Loss:  0.44911977648735046\n",
      "Write summary at step 1340  Loss:  0.34074556827545166\n",
      "Write summary at step 1350  Loss:  0.45094186067581177\n",
      "Write summary at step 1360  Loss:  0.4642370343208313\n",
      "Write summary at step 1370  Loss:  0.37759244441986084\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9068877551020408 Acurracy Control:  0.7377049180327869 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8480537901312022\n",
      "Loss normal: 0.2645374580609555 Loss Control: 0.6065423853410398 Loss Patient: 0.16039951981204917 Loss balanced:  0.38347095257654445 Loss1+loss2: 0.38347095257654445\n",
      "Write summary at step 1380  Loss:  0.6234339475631714\n",
      "Write summary at step 1390  Loss:  0.4052172899246216\n",
      "Write summary at step 1400  Loss:  0.29602083563804626\n",
      "Write summary at step 1410  Loss:  0.4008541703224182\n",
      "Write summary at step 1420  Loss:  0.5497650504112244\n",
      "Write summary at step 1430  Loss:  0.21848773956298828\n",
      "Write summary at step 1440  Loss:  0.39339640736579895\n",
      "Write summary at step 1450  Loss:  0.2592781186103821\n",
      "Write summary at step 1460  Loss:  0.2257460355758667\n",
      "Write summary at step 1470  Loss:  0.4603249132633209\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8712164607257485\n",
      "Loss normal: 0.25795695231277116 Loss Control: 0.5882302594315159 Loss Patient: 0.15739120228119977 Loss balanced:  0.3728107308563578 Loss1+loss2: 0.3728107308563578\n",
      "Write summary at step 1480  Loss:  0.5327415466308594\n",
      "Write summary at step 1490  Loss:  0.45704886317253113\n",
      "Write summary at step 1500  Loss:  0.44339680671691895\n",
      "Saved checkpoint to: result/46/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.8645608866824872\n",
      "Loss normal: 0.2818169175666206 Loss Control: 0.44047250317745523 Loss Patient: 0.23350747467674154 Loss balanced:  0.3369899889270984 Loss1+loss2: 0.3369899889270984\n",
      "Write summary at step 1510  Loss:  0.5562277436256409\n",
      "Write summary at step 1520  Loss:  0.6981923580169678\n",
      "Write summary at step 1530  Loss:  0.46011456847190857\n",
      "Write summary at step 1540  Loss:  0.5014225244522095\n",
      "Write summary at step 1550  Loss:  0.456914484500885\n",
      "Write summary at step 1560  Loss:  0.4281293749809265\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9118136439267887 Acurracy Balanced 0.936781138903285\n",
      "Loss normal: 0.2845368085771191 Loss Control: 0.26055751276797934 Loss Patient: 0.2918383242088229 Loss balanced:  0.27619791848840114 Loss1+loss2: 0.27619791848840114\n",
      "Write summary at step 1570  Loss:  0.3412831425666809\n",
      "Write summary at step 1580  Loss:  0.584539532661438\n",
      "Write summary at step 1590  Loss:  0.6752398014068604\n",
      "Write summary at step 1600  Loss:  0.3447602093219757\n",
      "Write summary at step 1610  Loss:  0.5497233867645264\n",
      "Write summary at step 1620  Loss:  0.26898193359375\n",
      "Write summary at step 1630  Loss:  0.3980528712272644\n",
      "Write summary at step 1640  Loss:  0.5375258326530457\n",
      "Write summary at step 1650  Loss:  0.3166821599006653\n",
      "Write summary at step 1660  Loss:  0.33075082302093506\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9076811870925506\n",
      "Loss normal: 0.24616382331872472 Loss Control: 0.2979620955680889 Loss Patient: 0.23039163656520367 Loss balanced:  0.26417686606664625 Loss1+loss2: 0.26417686606664625\n",
      "Write summary at step 1670  Loss:  0.45286640524864197\n",
      "Write summary at step 1680  Loss:  0.5186787843704224\n",
      "Write summary at step 1690  Loss:  0.5290927290916443\n",
      "Write summary at step 1700  Loss:  0.6185758709907532\n",
      "Write summary at step 1710  Loss:  0.27644944190979004\n",
      "Write summary at step 1720  Loss:  0.34094133973121643\n",
      "Write summary at step 1730  Loss:  0.36107608675956726\n",
      "Write summary at step 1740  Loss:  0.39674293994903564\n",
      "Write summary at step 1750  Loss:  0.36265867948532104\n",
      "Write summary at step 1760  Loss:  0.33243173360824585\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9101770273587736\n",
      "Loss normal: 0.2390874602964946 Loss Control: 0.2953816189791987 Loss Patient: 0.2219463100845921 Loss balanced:  0.2586639645318954 Loss1+loss2: 0.2586639645318954\n",
      "Write summary at step 1770  Loss:  0.354690283536911\n",
      "Write summary at step 1780  Loss:  0.44265344738960266\n",
      "Write summary at step 1790  Loss:  0.4405871629714966\n",
      "Write summary at step 1800  Loss:  0.31169816851615906\n",
      "Write summary at step 1810  Loss:  0.7537697553634644\n",
      "Write summary at step 1820  Loss:  0.5730640888214111\n",
      "Write summary at step 1830  Loss:  0.4277820289134979\n",
      "Write summary at step 1840  Loss:  0.3553178906440735\n",
      "Write summary at step 1850  Loss:  0.32444310188293457\n",
      "Write summary at step 1860  Loss:  0.46893686056137085\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8501904839838885\n",
      "Loss normal: 0.25411247066697296 Loss Control: 0.5280971781152194 Loss Patient: 0.1706861774754802 Loss balanced:  0.3493916777953498 Loss1+loss2: 0.3493916777953498\n",
      "Write summary at step 1870  Loss:  0.31308823823928833\n",
      "Write summary at step 1880  Loss:  0.3790392577648163\n",
      "Write summary at step 1890  Loss:  0.37338554859161377\n",
      "Write summary at step 1900  Loss:  0.6810311079025269\n",
      "Write summary at step 1910  Loss:  0.720700204372406\n",
      "Write summary at step 1920  Loss:  0.3592075705528259\n",
      "Write summary at step 1930  Loss:  0.72037672996521\n",
      "Write summary at step 1940  Loss:  0.5160033106803894\n",
      "Write summary at step 1950  Loss:  0.3846561908721924\n",
      "Write summary at step 1960  Loss:  0.4007296562194824\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9107142857142857 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.8866552103506906\n",
      "Loss normal: 0.25357841867573405 Loss Control: 0.3103783970973531 Loss Patient: 0.23628325083489823 Loss balanced:  0.2733308239661257 Loss1+loss2: 0.2733308239661257\n",
      "Write summary at step 1970  Loss:  0.4813762307167053\n",
      "Write summary at step 1980  Loss:  0.48239821195602417\n",
      "Write summary at step 1990  Loss:  0.4572082757949829\n",
      "Write summary at step 2000  Loss:  0.6476379632949829\n",
      "Saved checkpoint to: result/46/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.923469387755102 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.915877908404026\n",
      "Loss normal: 0.23649182482337466 Loss Control: 0.24417939293579977 Loss Patient: 0.23415101605921537 Loss balanced:  0.23916520449750756 Loss1+loss2: 0.23916520449750756\n",
      "\n",
      " > BEST MODEL (0.23917) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 2010  Loss:  0.6725594997406006\n",
      "Write summary at step 2020  Loss:  0.49938493967056274\n",
      "Write summary at step 2030  Loss:  0.5192520618438721\n",
      "Write summary at step 2040  Loss:  0.2921597957611084\n",
      "Write summary at step 2050  Loss:  0.21487465500831604\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9236018293736306\n",
      "Loss normal: 0.2174772186851015 Loss Control: 0.26844134780227163 Loss Patient: 0.2019590198398628 Loss balanced:  0.23520018382106722 Loss1+loss2: 0.23520018382106722\n",
      "\n",
      " > BEST MODEL (0.23520) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 2060  Loss:  0.4765588641166687\n",
      "Write summary at step 2070  Loss:  0.34407904744148254\n",
      "Write summary at step 2080  Loss:  0.4036446213722229\n",
      "Write summary at step 2090  Loss:  0.28003978729248047\n",
      "Write summary at step 2100  Loss:  0.5890762805938721\n",
      "Write summary at step 2110  Loss:  0.14953908324241638\n",
      "Write summary at step 2120  Loss:  0.3575376868247986\n",
      "Write summary at step 2130  Loss:  0.3466967046260834\n",
      "Write summary at step 2140  Loss:  0.5464473962783813\n",
      "Write summary at step 2150  Loss:  0.42654454708099365\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.9175418019148414\n",
      "Loss normal: 0.25994267443917235 Loss Control: 0.2641865454736303 Loss Patient: 0.25865044897288925 Loss balanced:  0.26141849722325977 Loss1+loss2: 0.26141849722325977\n",
      "Write summary at step 2160  Loss:  0.4638200104236603\n",
      "Write summary at step 2170  Loss:  0.25515076518058777\n",
      "Write summary at step 2180  Loss:  0.32038843631744385\n",
      "Write summary at step 2190  Loss:  0.3027045726776123\n",
      "Write summary at step 2200  Loss:  0.49548619985580444\n",
      "Write summary at step 2210  Loss:  0.5900841951370239\n",
      "Write summary at step 2220  Loss:  0.6519929766654968\n",
      "Write summary at step 2230  Loss:  0.4807579517364502\n",
      "Write summary at step 2240  Loss:  0.40016818046569824\n",
      "Write summary at step 2250  Loss:  0.4652770757675171\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8804815289635671\n",
      "Loss normal: 0.2206601074383575 Loss Control: 0.365218101954851 Loss Patient: 0.1766432819023307 Loss balanced:  0.27093069192859087 Loss1+loss2: 0.27093069192859087\n",
      "Write summary at step 2260  Loss:  0.601146936416626\n",
      "Write summary at step 2270  Loss:  0.495445191860199\n",
      "Write summary at step 2280  Loss:  0.45236992835998535\n",
      "Write summary at step 2290  Loss:  0.4981801509857178\n",
      "Write summary at step 2300  Loss:  0.28791284561157227\n",
      "Write summary at step 2310  Loss:  0.14527396857738495\n",
      "Write summary at step 2320  Loss:  0.4180665910243988\n",
      "Write summary at step 2330  Loss:  0.2656063437461853\n",
      "Write summary at step 2340  Loss:  0.28610026836395264\n",
      "Write summary at step 2350  Loss:  0.4755217730998993\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8760853950155933\n",
      "Loss normal: 0.2550612564141653 Loss Control: 0.4003187981459612 Loss Patient: 0.21083142441045027 Loss balanced:  0.30557511127820575 Loss1+loss2: 0.30557511127820575\n",
      "Write summary at step 2360  Loss:  0.47865962982177734\n",
      "Write summary at step 2370  Loss:  0.8635320067405701\n",
      "Write summary at step 2380  Loss:  0.43674010038375854\n",
      "Write summary at step 2390  Loss:  0.47454211115837097\n",
      "Write summary at step 2400  Loss:  0.6138691902160645\n",
      "Write summary at step 2410  Loss:  0.5796892642974854\n",
      "Write summary at step 2420  Loss:  0.3133382201194763\n",
      "Write summary at step 2430  Loss:  0.3815804719924927\n",
      "Write summary at step 2440  Loss:  0.33623600006103516\n",
      "Write summary at step 2450  Loss:  0.47641029953956604\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.9219379358628151\n",
      "Loss normal: 0.2337631342970595 Loss Control: 0.24375531663660144 Loss Patient: 0.23072058983928154 Loss balanced:  0.2372379532379415 Loss1+loss2: 0.2372379532379415\n",
      "Write summary at step 2460  Loss:  0.49348998069763184\n",
      "Write summary at step 2470  Loss:  0.28742530941963196\n",
      "Write summary at step 2480  Loss:  0.47477978467941284\n",
      "Write summary at step 2490  Loss:  0.35483455657958984\n",
      "Write summary at step 2500  Loss:  0.46790751814842224\n",
      "Saved checkpoint to: result/46/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.8834501695716611\n",
      "Loss normal: 0.23817736492017094 Loss Control: 0.3379920395345636 Loss Patient: 0.20778454086447318 Loss balanced:  0.2728882901995184 Loss1+loss2: 0.2728882901995184\n",
      "Write summary at step 2510  Loss:  0.472859650850296\n",
      "Write summary at step 2520  Loss:  0.44684359431266785\n",
      "Write summary at step 2530  Loss:  0.45818835496902466\n",
      "Write summary at step 2540  Loss:  0.3794236183166504\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.9276388169080676\n",
      "Loss normal: 0.22031044633108743 Loss Control: 0.2550709146619495 Loss Patient: 0.20972614493623945 Loss balanced:  0.23239852979909448 Loss1+loss2: 0.23239852979909448\n",
      "\n",
      " > BEST MODEL (0.23240) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 2550  Loss:  0.17422235012054443\n",
      "Write summary at step 2560  Loss:  0.3764427900314331\n",
      "Write summary at step 2570  Loss:  0.2981123924255371\n",
      "Write summary at step 2580  Loss:  0.5240367650985718\n",
      "Write summary at step 2590  Loss:  0.24643412232398987\n",
      "Write summary at step 2600  Loss:  0.40470921993255615\n",
      "Write summary at step 2610  Loss:  0.5237716436386108\n",
      "Write summary at step 2620  Loss:  0.26166296005249023\n",
      "Write summary at step 2630  Loss:  0.6944270133972168\n",
      "Write summary at step 2640  Loss:  0.45610958337783813\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8659883800223671\n",
      "Loss normal: 0.2404447832734001 Loss Control: 0.4606386833503598 Loss Patient: 0.17339738603439586 Loss balanced:  0.3170180346923778 Loss1+loss2: 0.3170180346923778\n",
      "Write summary at step 2650  Loss:  0.33781641721725464\n",
      "Write summary at step 2660  Loss:  0.6203997731208801\n",
      "Write summary at step 2670  Loss:  0.7464233636856079\n",
      "Write summary at step 2680  Loss:  0.5026400685310364\n",
      "Write summary at step 2690  Loss:  0.2915976643562317\n",
      "Write summary at step 2700  Loss:  0.4510933756828308\n",
      "Write summary at step 2710  Loss:  0.38258641958236694\n",
      "Write summary at step 2720  Loss:  0.49684497714042664\n",
      "Write summary at step 2730  Loss:  0.3732672929763794\n",
      "Write summary at step 2740  Loss:  0.5392661094665527\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9255021230553813\n",
      "Loss normal: 0.23303720963244534 Loss Control: 0.21315452961322387 Loss Patient: 0.23909133707425756 Loss balanced:  0.22612293334374073 Loss1+loss2: 0.22612293334374073\n",
      "\n",
      " > BEST MODEL (0.22612) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 2750  Loss:  0.33909347653388977\n",
      "Write summary at step 2760  Loss:  0.2788875997066498\n",
      "Write summary at step 2770  Loss:  0.3647172451019287\n",
      "Write summary at step 2780  Loss:  0.5810494422912598\n",
      "Write summary at step 2790  Loss:  0.17682164907455444\n",
      "Write summary at step 2800  Loss:  0.29659754037857056\n",
      "Write summary at step 2810  Loss:  0.340839684009552\n",
      "Write summary at step 2820  Loss:  0.5601433515548706\n",
      "Write summary at step 2830  Loss:  0.33276015520095825\n",
      "Write summary at step 2840  Loss:  0.5866976380348206\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9251247920133111 Acurracy Balanced 0.9352399916350709\n",
      "Loss normal: 0.22494620905846965 Loss Control: 0.21126694040871707 Loss Patient: 0.22911144463274125 Loss balanced:  0.22018919252072916 Loss1+loss2: 0.22018919252072916\n",
      "\n",
      " > BEST MODEL (0.22019) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 2850  Loss:  0.3811904788017273\n",
      "Write summary at step 2860  Loss:  0.594389796257019\n",
      "Write summary at step 2870  Loss:  0.2127579003572464\n",
      "Write summary at step 2880  Loss:  0.3499363362789154\n",
      "Write summary at step 2890  Loss:  0.5927836298942566\n",
      "Write summary at step 2900  Loss:  0.3925003111362457\n",
      "Write summary at step 2910  Loss:  0.6937729120254517\n",
      "Write summary at step 2920  Loss:  0.4615715742111206\n",
      "Write summary at step 2930  Loss:  0.4333983063697815\n",
      "Write summary at step 2940  Loss:  0.24221491813659668\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9068219633943427 Acurracy Balanced 0.9452142603856959\n",
      "Loss normal: 0.27763182320156876 Loss Control: 0.14308625427100177 Loss Patient: 0.31859993617268845 Loss balanced:  0.2308430952218451 Loss1+loss2: 0.2308430952218451\n",
      "Write summary at step 2950  Loss:  0.4352167546749115\n",
      "Write summary at step 2960  Loss:  0.362993061542511\n",
      "Write summary at step 2970  Loss:  0.38861340284347534\n",
      "Write summary at step 2980  Loss:  0.6373093724250793\n",
      "Write summary at step 2990  Loss:  0.4519902467727661\n",
      "Write summary at step 3000  Loss:  0.2957695424556732\n",
      "Saved checkpoint to: result/46/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8630197394142731\n",
      "Loss normal: 0.22731185164682718 Loss Control: 0.436313218432046 Loss Patient: 0.1636725020487971 Loss balanced:  0.29999286024042154 Loss1+loss2: 0.29999286024042154\n",
      "Write summary at step 3010  Loss:  0.29158520698547363\n",
      "Write summary at step 3020  Loss:  0.4085562825202942\n",
      "Write summary at step 3030  Loss:  0.6969168186187744\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  1.0 Acurracy Patient:  0.8851913477537438 Acurracy Balanced 0.9425956738768719\n",
      "Loss normal: 0.27443522769881756 Loss Control: 0.1117329947609719 Loss Patient: 0.32397683795398957 Loss balanced:  0.21785491635748072 Loss1+loss2: 0.21785491635748072\n",
      "\n",
      " > BEST MODEL (0.21785) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 3040  Loss:  0.5688287615776062\n",
      "Write summary at step 3050  Loss:  0.23021236062049866\n",
      "Write summary at step 3060  Loss:  0.3801416754722595\n",
      "Write summary at step 3070  Loss:  0.6645641326904297\n",
      "Write summary at step 3080  Loss:  0.4609913229942322\n",
      "Write summary at step 3090  Loss:  0.4586757719516754\n",
      "Write summary at step 3100  Loss:  0.37790030241012573\n",
      "Write summary at step 3110  Loss:  0.3864026367664337\n",
      "Write summary at step 3120  Loss:  0.3121519088745117\n",
      "Write summary at step 3130  Loss:  0.5277156233787537\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.9672131147540983 Acurracy Patient:  0.9267886855241264 Acurracy Balanced 0.9470009001391124\n",
      "Loss normal: 0.24301880780531435 Loss Control: 0.19830681408037903 Loss Patient: 0.25663327476545894 Loss balanced:  0.227470044422919 Loss1+loss2: 0.227470044422919\n",
      "Write summary at step 3140  Loss:  0.5205342769622803\n",
      "Write summary at step 3150  Loss:  0.1857881397008896\n",
      "Write summary at step 3160  Loss:  0.44568008184432983\n",
      "Write summary at step 3170  Loss:  0.4503898620605469\n",
      "Write summary at step 3180  Loss:  0.43715810775756836\n",
      "Write summary at step 3190  Loss:  0.24848967790603638\n",
      "Write summary at step 3200  Loss:  0.5775860548019409\n",
      "Write summary at step 3210  Loss:  0.2912197411060333\n",
      "Write summary at step 3220  Loss:  0.4633491635322571\n",
      "Write summary at step 3230  Loss:  0.5473326444625854\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9435594591891474\n",
      "Loss normal: 0.20507739241025885 Loss Control: 0.2551247112737979 Loss Patient: 0.18983835953840994 Loss balanced:  0.2224815354061039 Loss1+loss2: 0.2224815354061039\n",
      "Write summary at step 3240  Loss:  0.2519195079803467\n",
      "Write summary at step 3250  Loss:  0.3905631899833679\n",
      "Write summary at step 3260  Loss:  0.5000847578048706\n",
      "Write summary at step 3270  Loss:  0.3059450685977936\n",
      "Write summary at step 3280  Loss:  0.4058457612991333\n",
      "Write summary at step 3290  Loss:  0.14770394563674927\n",
      "Write summary at step 3300  Loss:  0.28269362449645996\n",
      "Write summary at step 3310  Loss:  0.44525495171546936\n",
      "Write summary at step 3320  Loss:  0.30927348136901855\n",
      "Write summary at step 3330  Loss:  0.23603424429893494\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8804815289635671\n",
      "Loss normal: 0.22380012585496417 Loss Control: 0.3844069082880281 Loss Patient: 0.17489656510944177 Loss balanced:  0.27965173669873494 Loss1+loss2: 0.27965173669873494\n",
      "Write summary at step 3340  Loss:  0.46725571155548096\n",
      "Write summary at step 3350  Loss:  0.37665948271751404\n",
      "Write summary at step 3360  Loss:  0.31363213062286377\n",
      "Write summary at step 3370  Loss:  0.3788678050041199\n",
      "Write summary at step 3380  Loss:  0.45456281304359436\n",
      "Write summary at step 3390  Loss:  0.2448192834854126\n",
      "Write summary at step 3400  Loss:  0.39463871717453003\n",
      "Write summary at step 3410  Loss:  0.3312218189239502\n",
      "Write summary at step 3420  Loss:  0.48788028955459595\n",
      "Write summary at step 3430  Loss:  0.3836583197116852\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9387755102040817 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9372630315594228\n",
      "Loss normal: 0.23854639457196605 Loss Control: 0.2692277405431362 Loss Patient: 0.22920415167403896 Loss balanced:  0.24921594610858758 Loss1+loss2: 0.24921594610858758\n",
      "Write summary at step 3440  Loss:  0.3253565728664398\n",
      "Write summary at step 3450  Loss:  0.5838972330093384\n",
      "Write summary at step 3460  Loss:  0.6293840408325195\n",
      "Write summary at step 3470  Loss:  0.3944243788719177\n",
      "Write summary at step 3480  Loss:  0.6423047184944153\n",
      "Write summary at step 3490  Loss:  0.3037770390510559\n",
      "Write summary at step 3500  Loss:  0.4309732913970947\n",
      "Saved checkpoint to: result/46/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9005102040816326 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8400934689906623\n",
      "Loss normal: 0.25648299642667477 Loss Control: 0.6020584015246949 Loss Patient: 0.15125787263106982 Loss balanced:  0.37665813707788237 Loss1+loss2: 0.37665813707788237\n",
      "Write summary at step 3510  Loss:  0.5925748348236084\n",
      "Write summary at step 3520  Loss:  0.2906102240085602\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8979433185128611\n",
      "Loss normal: 0.22589240337208827 Loss Control: 0.33210832173707056 Loss Patient: 0.19355044790393303 Loss balanced:  0.2628293848205018 Loss1+loss2: 0.2628293848205018\n",
      "Write summary at step 3530  Loss:  0.27299684286117554\n",
      "Write summary at step 3540  Loss:  0.5188534259796143\n",
      "Write summary at step 3550  Loss:  0.5156270265579224\n",
      "Write summary at step 3560  Loss:  0.35491228103637695\n",
      "Write summary at step 3570  Loss:  0.521148145198822\n",
      "Write summary at step 3580  Loss:  0.25591379404067993\n",
      "Write summary at step 3590  Loss:  0.5792068839073181\n",
      "Write summary at step 3600  Loss:  0.4249742925167084\n",
      "Write summary at step 3610  Loss:  0.32961010932922363\n",
      "Write summary at step 3620  Loss:  0.34566718339920044\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9187328950837856\n",
      "Loss normal: 0.21259727382234164 Loss Control: 0.2756017241321626 Loss Patient: 0.19341288717733246 Loss balanced:  0.23450730565474753 Loss1+loss2: 0.23450730565474753\n",
      "Write summary at step 3630  Loss:  0.5607243776321411\n",
      "Write summary at step 3640  Loss:  0.2728811502456665\n",
      "Write summary at step 3650  Loss:  0.42451801896095276\n",
      "Write summary at step 3660  Loss:  0.14536787569522858\n",
      "Write summary at step 3670  Loss:  0.18277370929718018\n",
      "Write summary at step 3680  Loss:  0.13667917251586914\n",
      "Write summary at step 3690  Loss:  0.648402988910675\n",
      "Write summary at step 3700  Loss:  0.41889703273773193\n",
      "Write summary at step 3710  Loss:  0.3584749400615692\n",
      "Write summary at step 3720  Loss:  0.3394312858581543\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9500922869898075\n",
      "Loss normal: 0.2206860653751967 Loss Control: 0.23112812752280731 Loss Patient: 0.21750653469423684 Loss balanced:  0.2243173311085221 Loss1+loss2: 0.2243173311085221\n",
      "Write summary at step 3730  Loss:  0.39117467403411865\n",
      "Write summary at step 3740  Loss:  0.44276806712150574\n",
      "Write summary at step 3750  Loss:  0.33479756116867065\n",
      "Write summary at step 3760  Loss:  0.4305163621902466\n",
      "Write summary at step 3770  Loss:  0.3096151351928711\n",
      "Write summary at step 3780  Loss:  0.5816346406936646\n",
      "Write summary at step 3790  Loss:  0.22962796688079834\n",
      "Write summary at step 3800  Loss:  0.29630979895591736\n",
      "Write summary at step 3810  Loss:  0.6354813575744629\n",
      "Write summary at step 3820  Loss:  0.35446897149086\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9309666039296982\n",
      "Loss normal: 0.23453812552045802 Loss Control: 0.20526303505636956 Loss Patient: 0.24345217112098477 Loss balanced:  0.22435760308867717 Loss1+loss2: 0.22435760308867717\n",
      "Write summary at step 3830  Loss:  0.6231433153152466\n",
      "Write summary at step 3840  Loss:  0.5508466958999634\n",
      "Write summary at step 3850  Loss:  0.43114733695983887\n",
      "Write summary at step 3860  Loss:  0.313931405544281\n",
      "Write summary at step 3870  Loss:  0.40666699409484863\n",
      "Write summary at step 3880  Loss:  0.7013389468193054\n",
      "Write summary at step 3890  Loss:  0.43930649757385254\n",
      "Write summary at step 3900  Loss:  0.4531811773777008\n",
      "Write summary at step 3910  Loss:  0.5680605173110962\n",
      "Write summary at step 3920  Loss:  0.49884170293807983\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9290663102479475\n",
      "Loss normal: 0.211638227865404 Loss Control: 0.23155353108390433 Loss Patient: 0.20557416420113822 Loss balanced:  0.2185638476425213 Loss1+loss2: 0.2185638476425213\n",
      "Write summary at step 3930  Loss:  0.5191630721092224\n",
      "Write summary at step 3940  Loss:  0.40421047806739807\n",
      "Write summary at step 3950  Loss:  0.42196735739707947\n",
      "Write summary at step 3960  Loss:  0.25482895970344543\n",
      "Write summary at step 3970  Loss:  0.4412563741207123\n",
      "Write summary at step 3980  Loss:  0.4703613221645355\n",
      "Write summary at step 3990  Loss:  0.3660280108451843\n",
      "Write summary at step 4000  Loss:  0.34120458364486694\n",
      "Saved checkpoint to: result/46/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.9236018293736306\n",
      "Loss normal: 0.22760708075092764 Loss Control: 0.2533692518870036 Loss Patient: 0.21976269337777884 Loss balanced:  0.2365659726323912 Loss1+loss2: 0.2365659726323912\n",
      "Write summary at step 4010  Loss:  0.27985653281211853\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9116045206986534\n",
      "Loss normal: 0.22650993250462473 Loss Control: 0.2914123772923412 Loss Patient: 0.20674762204165467 Loss balanced:  0.24907999966699795 Loss1+loss2: 0.24907999966699795\n",
      "Write summary at step 4020  Loss:  0.5263279676437378\n",
      "Write summary at step 4030  Loss:  0.30135470628738403\n",
      "Write summary at step 4040  Loss:  0.4240332245826721\n",
      "Write summary at step 4050  Loss:  0.24077311158180237\n",
      "Write summary at step 4060  Loss:  0.32000330090522766\n",
      "Write summary at step 4070  Loss:  0.39014512300491333\n",
      "Write summary at step 4080  Loss:  0.6602692008018494\n",
      "Write summary at step 4090  Loss:  0.26175493001937866\n",
      "Write summary at step 4100  Loss:  0.4660441279411316\n",
      "Write summary at step 4110  Loss:  0.24702276289463043\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.9836065573770492 Acurracy Patient:  0.9201331114808652 Acurracy Balanced 0.9518698344289571\n",
      "Loss normal: 0.2477934476064176 Loss Control: 0.11890288234734145 Loss Patient: 0.28703965992975156 Loss balanced:  0.20297127113854652 Loss1+loss2: 0.20297127113854652\n",
      "\n",
      " > BEST MODEL (0.20297) : result/46/panns/best_checkpoint.pt\n",
      "Write summary at step 4120  Loss:  0.3560861349105835\n",
      "Write summary at step 4130  Loss:  0.5501933097839355\n",
      "Write summary at step 4140  Loss:  0.42443475127220154\n",
      "Write summary at step 4150  Loss:  0.28583765029907227\n",
      "Write summary at step 4160  Loss:  0.4339287281036377\n",
      "Write summary at step 4170  Loss:  0.43465089797973633\n",
      "Write summary at step 4180  Loss:  0.36599409580230713\n",
      "Write summary at step 4190  Loss:  0.33448314666748047\n",
      "Write summary at step 4200  Loss:  0.2917676568031311\n",
      "Write summary at step 4210  Loss:  0.5157451033592224\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8493585372284809\n",
      "Loss normal: 0.2584846881883485 Loss Control: 0.5098796923303864 Loss Patient: 0.18193679413263888 Loss balanced:  0.34590824323151265 Loss1+loss2: 0.34590824323151265\n",
      "Write summary at step 4220  Loss:  0.341605544090271\n",
      "Write summary at step 4230  Loss:  0.3712809681892395\n",
      "Write summary at step 4240  Loss:  0.3373519480228424\n",
      "Write summary at step 4250  Loss:  0.3188256025314331\n",
      "Write summary at step 4260  Loss:  0.21567991375923157\n",
      "Write summary at step 4270  Loss:  0.46363356709480286\n",
      "Write summary at step 4280  Loss:  0.23102928698062897\n",
      "Write summary at step 4290  Loss:  0.5188966989517212\n",
      "Write summary at step 4300  Loss:  0.4951232969760895\n",
      "Write summary at step 4310  Loss:  0.4175357222557068\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.9513970340870861\n",
      "Loss normal: 0.2313407294604243 Loss Control: 0.18501190425919706 Loss Patient: 0.2454475094494526 Loss balanced:  0.21522970685432483 Loss1+loss2: 0.21522970685432483\n",
      "Write summary at step 4320  Loss:  0.3733832836151123\n",
      "Write summary at step 4330  Loss:  0.8602579236030579\n",
      "Write summary at step 4340  Loss:  0.25588008761405945\n",
      "Write summary at step 4350  Loss:  0.3594416379928589\n",
      "Write summary at step 4360  Loss:  0.6324062347412109\n",
      "Write summary at step 4370  Loss:  0.1651799976825714\n",
      "Write summary at step 4380  Loss:  0.17163416743278503\n",
      "Write summary at step 4390  Loss:  0.41275185346603394\n",
      "Write summary at step 4400  Loss:  0.49536341428756714\n",
      "Write summary at step 4410  Loss:  0.3705049157142639\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.891410490712201\n",
      "Loss normal: 0.23294153102502532 Loss Control: 0.3790090369070814 Loss Patient: 0.1884650704071248 Loss balanced:  0.2837370536571031 Loss1+loss2: 0.2837370536571031\n",
      "Write summary at step 4420  Loss:  0.335448294878006\n",
      "Write summary at step 4430  Loss:  0.34250694513320923\n",
      "Write summary at step 4440  Loss:  0.3000085949897766\n",
      "Write summary at step 4450  Loss:  0.5158237218856812\n",
      "Write summary at step 4460  Loss:  0.4237252473831177\n",
      "Write summary at step 4470  Loss:  0.4018395245075226\n",
      "Write summary at step 4480  Loss:  0.5762027502059937\n",
      "Write summary at step 4490  Loss:  0.3662469685077667\n",
      "Write summary at step 4500  Loss:  0.34226274490356445\n",
      "Saved checkpoint to: result/46/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9413265306122449 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9351263377067365\n",
      "Loss normal: 0.20829898293833343 Loss Control: 0.19604905332372488 Loss Patient: 0.212028993867003 Loss balanced:  0.20403902359536394 Loss1+loss2: 0.20403902359536394\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9269296163952612\n",
      "Loss normal: 0.20897433511456665 Loss Control: 0.2424487412952986 Loss Patient: 0.19878163118033162 Loss balanced:  0.22061518623781512 Loss1+loss2: 0.22061518623781512\n",
      "Write summary at step 4510  Loss:  0.1264537274837494\n",
      "Write summary at step 4520  Loss:  0.1825142800807953\n",
      "Write summary at step 4530  Loss:  0.27022629976272583\n",
      "Write summary at step 4540  Loss:  0.39231666922569275\n",
      "Write summary at step 4550  Loss:  0.2632536292076111\n",
      "Write summary at step 4560  Loss:  0.26018962264060974\n",
      "Write summary at step 4570  Loss:  0.3154812753200531\n",
      "Write summary at step 4580  Loss:  0.388544499874115\n",
      "Write summary at step 4590  Loss:  0.4386877715587616\n",
      "Write summary at step 4600  Loss:  0.44781729578971863\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9326304974405135\n",
      "Loss normal: 0.24027036502957344 Loss Control: 0.20050176237124562 Loss Patient: 0.25237960508480645 Loss balanced:  0.22644068372802603 Loss1+loss2: 0.22644068372802603\n",
      "Write summary at step 4610  Loss:  0.2890213131904602\n",
      "Write summary at step 4620  Loss:  0.34152358770370483\n",
      "Write summary at step 4630  Loss:  0.2543086111545563\n",
      "Write summary at step 4640  Loss:  0.21406912803649902\n",
      "Write summary at step 4650  Loss:  0.32399219274520874\n",
      "Write summary at step 4660  Loss:  0.31129932403564453\n",
      "Write summary at step 4670  Loss:  0.2903544008731842\n",
      "Write summary at step 4680  Loss:  0.6551685333251953\n",
      "Write summary at step 4690  Loss:  0.5981268882751465\n",
      "Write summary at step 4700  Loss:  0.25922349095344543\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9119897959183674 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8760853950155933\n",
      "Loss normal: 0.25824455947292096 Loss Control: 0.37002804907944686 Loss Patient: 0.22420732312511882 Loss balanced:  0.29711768610228284 Loss1+loss2: 0.29711768610228284\n",
      "Write summary at step 4710  Loss:  0.3754907250404358\n",
      "Write summary at step 4720  Loss:  0.46430015563964844\n",
      "Write summary at step 4730  Loss:  0.26331111788749695\n",
      "Write summary at step 4740  Loss:  0.33864355087280273\n",
      "Write summary at step 4750  Loss:  0.3964676260948181\n",
      "Write summary at step 4760  Loss:  0.450633704662323\n",
      "Write summary at step 4770  Loss:  0.3997802734375\n",
      "Write summary at step 4780  Loss:  0.39606010913848877\n",
      "Write summary at step 4790  Loss:  0.373629629611969\n",
      "Write summary at step 4800  Loss:  0.6086302995681763\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.917900948328378\n",
      "Loss normal: 0.21242232248187065 Loss Control: 0.2503269945011764 Loss Patient: 0.20088063494090033 Loss balanced:  0.22560381472103835 Loss1+loss2: 0.22560381472103835\n",
      "Write summary at step 4810  Loss:  0.39472582936286926\n",
      "Write summary at step 4820  Loss:  0.6892774105072021\n",
      "Write summary at step 4830  Loss:  0.4380377233028412\n",
      "Write summary at step 4840  Loss:  0.26213887333869934\n",
      "Write summary at step 4850  Loss:  0.3657788634300232\n",
      "Write summary at step 4860  Loss:  0.2945096492767334\n",
      "Write summary at step 4870  Loss:  0.3600216507911682\n",
      "Write summary at step 4880  Loss:  0.32790830731391907\n",
      "Write summary at step 4890  Loss:  0.2251681089401245\n",
      "Write summary at step 4900  Loss:  0.3293907344341278\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9417637271214643 Acurracy Balanced 0.9162370548175627\n",
      "Loss normal: 0.19838776716924444 Loss Control: 0.26431756527697453 Loss Patient: 0.17831263826313906 Loss balanced:  0.2213151017700568 Loss1+loss2: 0.2213151017700568\n",
      "Write summary at step 4910  Loss:  0.31999337673187256\n",
      "Write summary at step 4920  Loss:  0.37022972106933594\n",
      "Write summary at step 4930  Loss:  0.2964650094509125\n",
      "Write summary at step 4940  Loss:  0.5090022087097168\n",
      "Write summary at step 4950  Loss:  0.2552081048488617\n",
      "Write summary at step 4960  Loss:  0.48773542046546936\n",
      "Write summary at step 4970  Loss:  0.3520868122577667\n",
      "Write summary at step 4980  Loss:  0.2572314441204071\n",
      "Write summary at step 4990  Loss:  0.4653705358505249\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.920396788594601\n",
      "Loss normal: 0.20908924359448103 Loss Control: 0.333174155709522 Loss Patient: 0.1713063164975203 Loss balanced:  0.25224023610352114 Loss1+loss2: 0.25224023610352114\n",
      "Write summary at step 5000  Loss:  0.45271825790405273\n",
      "Saved checkpoint to: result/46/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.914932307720284\n",
      "Loss normal: 0.20900737091290708 Loss Control: 0.34923642776051506 Loss Patient: 0.16630867111206848 Loss balanced:  0.2577725494362918 Loss1+loss2: 0.2577725494362918\n",
      "Write summary at step 5010  Loss:  0.2630307972431183\n",
      "Write summary at step 5020  Loss:  0.2677583694458008\n",
      "Write summary at step 5030  Loss:  0.2909066677093506\n",
      "Write summary at step 5040  Loss:  0.16478770971298218\n",
      "Write summary at step 5050  Loss:  0.15784724056720734\n",
      "Write summary at step 5060  Loss:  0.36104702949523926\n",
      "Write summary at step 5070  Loss:  0.3511764407157898\n",
      "Write summary at step 5080  Loss:  0.4169401228427887\n",
      "Write summary at step 5090  Loss:  0.40715354681015015\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8886782502750425\n",
      "Loss normal: 0.2431964304450215 Loss Control: 0.3353280804522051 Loss Patient: 0.21514303821097197 Loss balanced:  0.2752355593315885 Loss1+loss2: 0.2752355593315885\n",
      "Write summary at step 5100  Loss:  0.20767922699451447\n",
      "Write summary at step 5110  Loss:  0.2280343919992447\n",
      "Write summary at step 5120  Loss:  0.376627117395401\n",
      "Write summary at step 5130  Loss:  0.39890268445014954\n",
      "Write summary at step 5140  Loss:  0.14805611968040466\n",
      "Write summary at step 5150  Loss:  0.6043805480003357\n",
      "Write summary at step 5160  Loss:  0.614916205406189\n",
      "Write summary at step 5170  Loss:  0.3278855085372925\n",
      "Write summary at step 5180  Loss:  0.35247278213500977\n",
      "Write summary at step 5190  Loss:  0.6461206078529358\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9050716928979934\n",
      "Loss normal: 0.20793365782164797 Loss Control: 0.3051009285645407 Loss Patient: 0.1783469526373011 Loss balanced:  0.2417239406009209 Loss1+loss2: 0.2417239406009209\n",
      "Write summary at step 5200  Loss:  0.3277179002761841\n",
      "Write summary at step 5210  Loss:  0.2915136218070984\n",
      "Write summary at step 5220  Loss:  0.2949618995189667\n",
      "Write summary at step 5230  Loss:  0.5119017362594604\n",
      "Write summary at step 5240  Loss:  0.33036813139915466\n",
      "Write summary at step 5250  Loss:  0.3467329442501068\n",
      "Write summary at step 5260  Loss:  0.3684924840927124\n",
      "Write summary at step 5270  Loss:  0.3607881963253021\n",
      "Write summary at step 5280  Loss:  0.23673194646835327\n",
      "Write summary at step 5290  Loss:  0.3922964632511139\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9061400398243364\n",
      "Loss normal: 0.21552397630044393 Loss Control: 0.3045236041637066 Loss Patient: 0.18842425771342736 Loss balanced:  0.24647393093856698 Loss1+loss2: 0.24647393093856698\n",
      "Write summary at step 5300  Loss:  0.30902689695358276\n",
      "Write summary at step 5310  Loss:  0.2814788818359375\n",
      "Write summary at step 5320  Loss:  0.33915162086486816\n",
      "Write summary at step 5330  Loss:  0.42624643445014954\n",
      "Write summary at step 5340  Loss:  0.4191640317440033\n",
      "Write summary at step 5350  Loss:  0.3218831419944763\n",
      "Write summary at step 5360  Loss:  0.443938672542572\n",
      "Write summary at step 5370  Loss:  0.2753397524356842\n",
      "Write summary at step 5380  Loss:  0.3835298717021942\n",
      "Write summary at step 5390  Loss:  0.3925476670265198\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9298469387755102 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9086358800905594\n",
      "Loss normal: 0.21842997916498963 Loss Control: 0.3398744561633126 Loss Patient: 0.18145104645195104 Loss balanced:  0.26066275130763183 Loss1+loss2: 0.26066275130763183\n",
      "Write summary at step 5400  Loss:  0.6346101760864258\n",
      "Write summary at step 5410  Loss:  0.2584848999977112\n",
      "Write summary at step 5420  Loss:  0.45991265773773193\n",
      "Write summary at step 5430  Loss:  0.25265440344810486\n",
      "Write summary at step 5440  Loss:  0.41898468136787415\n",
      "Write summary at step 5450  Loss:  0.35086536407470703\n",
      "Write summary at step 5460  Loss:  0.13063523173332214\n",
      "Write summary at step 5470  Loss:  0.4105466902256012\n",
      "Write summary at step 5480  Loss:  0.45087873935699463\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9061400398243364\n",
      "Loss normal: 0.2263394510563539 Loss Control: 0.28983353216791413 Loss Patient: 0.2070059826389922 Loss balanced:  0.24841975740345318 Loss1+loss2: 0.24841975740345318\n",
      "Write summary at step 5490  Loss:  0.34096214175224304\n",
      "Write summary at step 5500  Loss:  0.5541156530380249\n",
      "Saved checkpoint to: result/46/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9069719865797441\n",
      "Loss normal: 0.22390165457463995 Loss Control: 0.3121937265813025 Loss Patient: 0.1970173835060164 Loss balanced:  0.25460555504365945 Loss1+loss2: 0.25460555504365945\n",
      "Write summary at step 5510  Loss:  0.19893541932106018\n",
      "Write summary at step 5520  Loss:  0.4335218667984009\n",
      "Write summary at step 5530  Loss:  0.3395538628101349\n",
      "Write summary at step 5540  Loss:  0.23414036631584167\n",
      "Write summary at step 5550  Loss:  0.31328123807907104\n",
      "Write summary at step 5560  Loss:  0.33696961402893066\n",
      "Write summary at step 5570  Loss:  0.3083581328392029\n",
      "Write summary at step 5580  Loss:  0.5050627589225769\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9206331887655366\n",
      "Loss normal: 0.20525908359915626 Loss Control: 0.2316601851273104 Loss Patient: 0.197220147288282 Loss balanced:  0.2144401662077962 Loss1+loss2: 0.2144401662077962\n",
      "Write summary at step 5590  Loss:  0.4586622416973114\n",
      "Write summary at step 5600  Loss:  0.5314967632293701\n",
      "Write summary at step 5610  Loss:  0.46094465255737305\n",
      "Write summary at step 5620  Loss:  0.18572720885276794\n",
      "Write summary at step 5630  Loss:  0.4188833236694336\n",
      "Write summary at step 5640  Loss:  0.3138502538204193\n",
      "Write summary at step 5650  Loss:  0.3032231628894806\n",
      "Write summary at step 5660  Loss:  0.46273165941238403\n",
      "Write summary at step 5670  Loss:  0.34115898609161377\n",
      "Write summary at step 5680  Loss:  0.2821383476257324\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8346289881163453\n",
      "Loss normal: 0.25844699889421463 Loss Control: 0.6638761133444114 Loss Patient: 0.1349968706782963 Loss balanced:  0.3994364920113539 Loss1+loss2: 0.3994364920113539\n",
      "Write summary at step 5690  Loss:  0.37058016657829285\n",
      "Write summary at step 5700  Loss:  0.35365548729896545\n",
      "Write summary at step 5710  Loss:  0.2361244559288025\n",
      "Write summary at step 5720  Loss:  0.16243448853492737\n",
      "Write summary at step 5730  Loss:  0.540995717048645\n",
      "Write summary at step 5740  Loss:  0.2919451594352722\n",
      "Write summary at step 5750  Loss:  0.42545467615127563\n",
      "Write summary at step 5760  Loss:  0.4307188093662262\n",
      "Write summary at step 5770  Loss:  0.5329364538192749\n",
      "Write summary at step 5780  Loss:  0.2899261713027954\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9250293227135102\n",
      "Loss normal: 0.21567169725134663 Loss Control: 0.26475064334322196 Loss Patient: 0.20072752450547876 Loss balanced:  0.23273908392435036 Loss1+loss2: 0.23273908392435036\n",
      "Write summary at step 5790  Loss:  0.30494850873947144\n",
      "Write summary at step 5800  Loss:  0.3748003840446472\n",
      "Write summary at step 5810  Loss:  0.30151256918907166\n",
      "Write summary at step 5820  Loss:  0.26461493968963623\n",
      "Write summary at step 5830  Loss:  0.33732324838638306\n",
      "Write summary at step 5840  Loss:  0.4167444109916687\n",
      "Write summary at step 5850  Loss:  0.3697150647640228\n",
      "Write summary at step 5860  Loss:  0.3699710965156555\n",
      "Write summary at step 5870  Loss:  0.5971691608428955\n",
      "Write summary at step 5880  Loss:  0.42675408720970154\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.888441850104107\n",
      "Loss normal: 0.21620720480473674 Loss Control: 0.42573090264054597 Loss Patient: 0.15240880938714832 Loss balanced:  0.28906985601384716 Loss1+loss2: 0.28906985601384716\n",
      "Write summary at step 5890  Loss:  0.4973626136779785\n",
      "Write summary at step 5900  Loss:  0.45588362216949463\n",
      "Write summary at step 5910  Loss:  0.45975300669670105\n",
      "Write summary at step 5920  Loss:  0.38806405663490295\n",
      "Write summary at step 5930  Loss:  0.2574882209300995\n",
      "Write summary at step 5940  Loss:  0.39408132433891296\n",
      "Write summary at step 5950  Loss:  0.4812840521335602\n",
      "Write summary at step 5960  Loss:  0.6249979734420776\n",
      "Write summary at step 5970  Loss:  0.42992568016052246\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9221938775510204 Acurracy Control:  0.8360655737704918 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8922424374676087\n",
      "Loss normal: 0.23356063899641133 Loss Control: 0.3679321898462994 Loss Patient: 0.19264550839307504 Loss balanced:  0.2802888491196872 Loss1+loss2: 0.2802888491196872\n",
      "Write summary at step 5980  Loss:  0.42964285612106323\n",
      "Write summary at step 5990  Loss:  0.26333385705947876\n",
      "Write summary at step 6000  Loss:  0.36259615421295166\n",
      "Saved checkpoint to: result/46/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8958066246601748\n",
      "Loss normal: 0.22539297377272527 Loss Control: 0.37909889351474785 Loss Patient: 0.17859067356279013 Loss balanced:  0.27884478353876896 Loss1+loss2: 0.27884478353876896\n",
      "Write summary at step 6010  Loss:  0.2439129650592804\n",
      "Write summary at step 6020  Loss:  0.42240169644355774\n",
      "Write summary at step 6030  Loss:  0.240606427192688\n",
      "Write summary at step 6040  Loss:  0.8271045088768005\n",
      "Write summary at step 6050  Loss:  0.4194501042366028\n",
      "Write summary at step 6060  Loss:  0.2763538360595703\n",
      "Write summary at step 6070  Loss:  0.18910101056098938\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9209183673469388 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8952110780757027\n",
      "Loss normal: 0.21415128555072813 Loss Control: 0.3562082602678101 Loss Patient: 0.17089600132130545 Loss balanced:  0.26355213079455775 Loss1+loss2: 0.26355213079455775\n",
      "Write summary at step 6080  Loss:  0.5269072651863098\n",
      "Write summary at step 6090  Loss:  0.33993998169898987\n",
      "Write summary at step 6100  Loss:  0.47610387206077576\n",
      "Write summary at step 6110  Loss:  0.36916637420654297\n",
      "Write summary at step 6120  Loss:  0.4475732445716858\n",
      "Write summary at step 6130  Loss:  0.4571109414100647\n",
      "Write summary at step 6140  Loss:  0.24265892803668976\n",
      "Write summary at step 6150  Loss:  0.3057820200920105\n",
      "Write summary at step 6160  Loss:  0.4370015263557434\n",
      "Write summary at step 6170  Loss:  0.2659943103790283\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.6939890710382514 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8270278133893421\n",
      "Loss normal: 0.3002081083856067 Loss Control: 0.7823108988381474 Loss Patient: 0.1534114223153341 Loss balanced:  0.46786116057674076 Loss1+loss2: 0.46786116057674076\n",
      "Write summary at step 6180  Loss:  0.36157217621803284\n",
      "Write summary at step 6190  Loss:  0.2530522346496582\n",
      "Write summary at step 6200  Loss:  0.46375975012779236\n",
      "Write summary at step 6210  Loss:  0.26807668805122375\n",
      "Write summary at step 6220  Loss:  0.2874848246574402\n",
      "Write summary at step 6230  Loss:  0.19384323060512543\n",
      "Write summary at step 6240  Loss:  0.16028231382369995\n",
      "Write summary at step 6250  Loss:  0.44979923963546753\n",
      "Write summary at step 6260  Loss:  0.31967031955718994\n",
      "Write summary at step 6270  Loss:  0.3665691614151001\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8958066246601748\n",
      "Loss normal: 0.240623162641209 Loss Control: 0.33372289235474634 Loss Patient: 0.2122749933312816 Loss balanced:  0.27299894284301396 Loss1+loss2: 0.27299894284301396\n",
      "Write summary at step 6280  Loss:  0.33033281564712524\n",
      "Write summary at step 6290  Loss:  0.26224252581596375\n",
      "Write summary at step 6300  Loss:  0.3126251697540283\n",
      "Write summary at step 6310  Loss:  0.19939571619033813\n",
      "Write summary at step 6320  Loss:  0.11387518048286438\n",
      "Write summary at step 6330  Loss:  0.31079068779945374\n",
      "Write summary at step 6340  Loss:  0.35320931673049927\n",
      "Write summary at step 6350  Loss:  0.23132461309432983\n",
      "Write summary at step 6360  Loss:  0.19924218952655792\n",
      "Write summary at step 6370  Loss:  0.6202312707901001\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.7049180327868853 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8316603475082514\n",
      "Loss normal: 0.26478780635005356 Loss Control: 0.5925499099851306 Loss Patient: 0.16498670139398036 Loss balanced:  0.37876830568955544 Loss1+loss2: 0.37876830568955544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 6380  Loss:  0.1870507299900055\n",
      "Write summary at step 6390  Loss:  0.43440547585487366\n",
      "Write summary at step 6400  Loss:  0.41793715953826904\n",
      "Write summary at step 6410  Loss:  0.27050289511680603\n",
      "Write summary at step 6420  Loss:  0.42566657066345215\n",
      "Write summary at step 6430  Loss:  0.26223257184028625\n",
      "Write summary at step 6440  Loss:  0.4737403094768524\n",
      "Write summary at step 6450  Loss:  0.3688194453716278\n",
      "Write summary at step 6460  Loss:  0.37881040573120117\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8785812352818163\n",
      "Loss normal: 0.2729660541731484 Loss Control: 0.38380593468582697 Loss Patient: 0.23921614436559788 Loss balanced:  0.3115110395257124 Loss1+loss2: 0.3115110395257124\n",
      "Write summary at step 6470  Loss:  0.28499650955200195\n",
      "Write summary at step 6480  Loss:  0.33447352051734924\n",
      "Write summary at step 6490  Loss:  0.3729226887226105\n",
      "Write summary at step 6500  Loss:  0.31415659189224243\n",
      "Saved checkpoint to: result/46/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9145408163265306 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8720484074811562\n",
      "Loss normal: 0.23991932294198445 Loss Control: 0.3782772123813629 Loss Patient: 0.19779038082145017 Loss balanced:  0.28803379660140654 Loss1+loss2: 0.28803379660140654\n",
      "Write summary at step 6510  Loss:  0.5239084959030151\n",
      "Write summary at step 6520  Loss:  0.3452759385108948\n",
      "Write summary at step 6530  Loss:  0.26609086990356445\n",
      "Write summary at step 6540  Loss:  0.7380143404006958\n",
      "Write summary at step 6550  Loss:  0.4180411100387573\n",
      "Write summary at step 6560  Loss:  0.3388432264328003\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9342943909513288\n",
      "Loss normal: 0.20077690790046235 Loss Control: 0.20974749522130998 Loss Patient: 0.1980454300758049 Loss balanced:  0.20389646264855743 Loss1+loss2: 0.20389646264855743\n",
      "Write summary at step 6570  Loss:  0.3321712613105774\n",
      "Write summary at step 6580  Loss:  0.5451982021331787\n",
      "Write summary at step 6590  Loss:  0.5505837202072144\n",
      "Write summary at step 6600  Loss:  0.2583959698677063\n",
      "Write summary at step 6610  Loss:  0.6673358678817749\n",
      "Write summary at step 6620  Loss:  0.33740687370300293\n",
      "Write summary at step 6630  Loss:  0.22846640646457672\n",
      "Write summary at step 6640  Loss:  0.44237324595451355\n",
      "Write summary at step 6650  Loss:  0.3790377378463745\n",
      "Write summary at step 6660  Loss:  0.3337140381336212\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8766809416000655\n",
      "Loss normal: 0.23381455618964167 Loss Control: 0.40219047909877337 Loss Patient: 0.182545348295257 Loss balanced:  0.2923679136970152 Loss1+loss2: 0.2923679136970152\n",
      "Write summary at step 6670  Loss:  0.30926647782325745\n",
      "Write summary at step 6680  Loss:  0.4470178484916687\n",
      "Write summary at step 6690  Loss:  0.16254252195358276\n",
      "Write summary at step 6700  Loss:  0.19887655973434448\n",
      "Write summary at step 6710  Loss:  0.27526307106018066\n",
      "Write summary at step 6720  Loss:  0.643965482711792\n",
      "Write summary at step 6730  Loss:  0.41970622539520264\n",
      "Write summary at step 6740  Loss:  0.4270598292350769\n",
      "Write summary at step 6750  Loss:  0.3183259963989258\n",
      "Write summary at step 6760  Loss:  0.3461061418056488\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9311224489795918 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9132684142094687\n",
      "Loss normal: 0.21775378016945052 Loss Control: 0.29874651809859143 Loss Patient: 0.19309210030984958 Loss balanced:  0.2459193092042205 Loss1+loss2: 0.2459193092042205\n",
      "Write summary at step 6770  Loss:  0.3790014386177063\n",
      "Write summary at step 6780  Loss:  0.34405866265296936\n",
      "Write summary at step 6790  Loss:  0.627505898475647\n",
      "Write summary at step 6800  Loss:  0.19219213724136353\n",
      "Write summary at step 6810  Loss:  0.21716010570526123\n",
      "Write summary at step 6820  Loss:  0.19289466738700867\n",
      "Write summary at step 6830  Loss:  0.3093997836112976\n",
      "Write summary at step 6840  Loss:  0.2793838083744049\n",
      "Write summary at step 6850  Loss:  0.434890478849411\n",
      "Write summary at step 6860  Loss:  0.30975064635276794\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9168326014020349\n",
      "Loss normal: 0.20328036855374063 Loss Control: 0.2914830390872851 Loss Patient: 0.17642331589478225 Loss balanced:  0.23395317749103367 Loss1+loss2: 0.23395317749103367\n",
      "Write summary at step 6870  Loss:  0.28906428813934326\n",
      "Write summary at step 6880  Loss:  0.3120415210723877\n",
      "Write summary at step 6890  Loss:  0.22408083081245422\n",
      "Write summary at step 6900  Loss:  0.6156444549560547\n",
      "Write summary at step 6910  Loss:  0.47042182087898254\n",
      "Write summary at step 6920  Loss:  0.41592705249786377\n",
      "Write summary at step 6930  Loss:  0.35275429487228394\n",
      "Write summary at step 6940  Loss:  0.38829201459884644\n",
      "Write summary at step 6950  Loss:  0.32417094707489014\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9031713992162425\n",
      "Loss normal: 0.24804865572677584 Loss Control: 0.3006392454351884 Loss Patient: 0.2320352147849348 Loss balanced:  0.2663372301100616 Loss1+loss2: 0.2663372301100616\n",
      "Write summary at step 6960  Loss:  0.22185489535331726\n",
      "Write summary at step 6970  Loss:  0.30322498083114624\n",
      "Write summary at step 6980  Loss:  0.3419952392578125\n",
      "Write summary at step 6990  Loss:  0.5738829374313354\n",
      "Write summary at step 7000  Loss:  0.2644953429698944\n",
      "Saved checkpoint to: result/46/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8766809416000655\n",
      "Loss normal: 0.23751458457233954 Loss Control: 0.4021754277859881 Loss Patient: 0.1873765923268783 Loss balanced:  0.29477601005643317 Loss1+loss2: 0.29477601005643317\n",
      "Write summary at step 7010  Loss:  0.4190753400325775\n",
      "Write summary at step 7020  Loss:  0.3251510262489319\n",
      "Write summary at step 7030  Loss:  0.4252367615699768\n",
      "Write summary at step 7040  Loss:  0.13968543708324432\n",
      "Write summary at step 7050  Loss:  0.25167372822761536\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9005102040816326 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8343925879454097\n",
      "Loss normal: 0.2935634300264777 Loss Control: 0.8044493986609204 Loss Patient: 0.13800247532382187 Loss balanced:  0.47122593699237114 Loss1+loss2: 0.47122593699237114\n",
      "Write summary at step 7060  Loss:  0.3386385440826416\n",
      "Write summary at step 7070  Loss:  0.28688088059425354\n",
      "Write summary at step 7080  Loss:  0.24954375624656677\n",
      "Write summary at step 7090  Loss:  0.31386423110961914\n",
      "Write summary at step 7100  Loss:  0.3429145812988281\n",
      "Write summary at step 7110  Loss:  0.4832187592983246\n",
      "Write summary at step 7120  Loss:  0.19259333610534668\n",
      "Write summary at step 7130  Loss:  0.4864029884338379\n",
      "Write summary at step 7140  Loss:  0.3335290849208832\n",
      "Write summary at step 7150  Loss:  0.20017008483409882\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9196428571428571 Acurracy Control:  0.8306010928961749 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8886782502750425\n",
      "Loss normal: 0.2732666839598393 Loss Control: 0.35973550607272187 Loss Patient: 0.24693757510076147 Loss balanced:  0.30333654058674164 Loss1+loss2: 0.30333654058674164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 7160  Loss:  0.4311833381652832\n",
      "Write summary at step 7170  Loss:  0.30780673027038574\n",
      "Write summary at step 7180  Loss:  0.2092023640871048\n",
      "Write summary at step 7190  Loss:  0.22598743438720703\n",
      "Write summary at step 7200  Loss:  0.22896483540534973\n",
      "Write summary at step 7210  Loss:  0.2407171130180359\n",
      "Write summary at step 7220  Loss:  0.4607807695865631\n",
      "Write summary at step 7230  Loss:  0.500896692276001\n",
      "Write summary at step 7240  Loss:  0.11207868158817291\n",
      "Write summary at step 7250  Loss:  0.45314252376556396\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9004391587790841\n",
      "Loss normal: 0.23148824829532175 Loss Control: 0.3394608377107506 Loss Patient: 0.19861140766625793 Loss balanced:  0.26903612268850424 Loss1+loss2: 0.26903612268850424\n",
      "Write summary at step 7260  Loss:  0.17235562205314636\n",
      "Write summary at step 7270  Loss:  0.2868911325931549\n",
      "Write summary at step 7280  Loss:  0.5197879076004028\n",
      "Write summary at step 7290  Loss:  0.24566340446472168\n",
      "Write summary at step 7300  Loss:  0.27742019295692444\n",
      "Write summary at step 7310  Loss:  0.15212807059288025\n",
      "Write summary at step 7320  Loss:  0.27760550379753113\n",
      "Write summary at step 7330  Loss:  0.3189536929130554\n",
      "Write summary at step 7340  Loss:  0.3321838974952698\n",
      "Write summary at step 7350  Loss:  0.18173673748970032\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9285714285714286 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.905903639653401\n",
      "Loss normal: 0.21823280631583564 Loss Control: 0.326166629954114 Loss Patient: 0.18536776745577224 Loss balanced:  0.25576719870494313 Loss1+loss2: 0.25576719870494313\n",
      "Write summary at step 7360  Loss:  0.5439707040786743\n",
      "Write summary at step 7370  Loss:  0.36996376514434814\n",
      "Write summary at step 7380  Loss:  0.22612784802913666\n",
      "Write summary at step 7390  Loss:  0.22408659756183624\n",
      "Write summary at step 7400  Loss:  0.4247586131095886\n",
      "Write summary at step 7410  Loss:  0.25369518995285034\n",
      "Write summary at step 7420  Loss:  0.4021229147911072\n",
      "Write summary at step 7430  Loss:  0.37407559156417847\n",
      "Write summary at step 7440  Loss:  0.3645208477973938\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9438775510204082 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9443914059445551\n",
      "Loss normal: 0.19600318934844466 Loss Control: 0.24100354460419202 Loss Patient: 0.1823009153868315 Loss balanced:  0.21165222999551175 Loss1+loss2: 0.21165222999551175\n",
      "Write summary at step 7450  Loss:  0.3382258713245392\n",
      "Write summary at step 7460  Loss:  0.36778292059898376\n",
      "Write summary at step 7470  Loss:  0.5598185062408447\n",
      "Write summary at step 7480  Loss:  0.3447294235229492\n",
      "Write summary at step 7490  Loss:  0.5060322880744934\n",
      "Write summary at step 7500  Loss:  0.31079232692718506\n",
      "Saved checkpoint to: result/46/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.9187328950837856\n",
      "Loss normal: 0.21354275143572263 Loss Control: 0.2784583757483894 Loss Patient: 0.19377642960447242 Loss balanced:  0.2361174026764309 Loss1+loss2: 0.2361174026764309\n",
      "Write summary at step 7510  Loss:  0.3561246693134308\n",
      "Write summary at step 7520  Loss:  0.12477900087833405\n",
      "Write summary at step 7530  Loss:  0.19856995344161987\n",
      "Write summary at step 7540  Loss:  0.29209184646606445\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9362244897959183 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.920396788594601\n",
      "Loss normal: 0.1988432510394831 Loss Control: 0.298624803134001 Loss Patient: 0.1684605141051002 Loss balanced:  0.23354265861955062 Loss1+loss2: 0.23354265861955062\n",
      "Write summary at step 7550  Loss:  0.3084988296031952\n",
      "Write summary at step 7560  Loss:  0.4147173762321472\n",
      "Write summary at step 7570  Loss:  0.49083107709884644\n",
      "Write summary at step 7580  Loss:  0.24145612120628357\n",
      "Write summary at step 7590  Loss:  0.48994114995002747\n",
      "Write summary at step 7600  Loss:  0.3807203769683838\n",
      "Write summary at step 7610  Loss:  0.3038718104362488\n",
      "Write summary at step 7620  Loss:  0.2552627921104431\n",
      "Write summary at step 7630  Loss:  0.5034424066543579\n",
      "Write summary at step 7640  Loss:  0.38029128313064575\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7868852459016393 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8693161670439977\n",
      "Loss normal: 0.23779773563906856 Loss Control: 0.4335110262443459 Loss Patient: 0.17820450137934946 Loss balanced:  0.3058577638118477 Loss1+loss2: 0.3058577638118477\n",
      "Write summary at step 7650  Loss:  0.39918673038482666\n",
      "Write summary at step 7660  Loss:  0.4440973997116089\n",
      "Write summary at step 7670  Loss:  0.3009400963783264\n",
      "Write summary at step 7680  Loss:  0.18258774280548096\n",
      "Write summary at step 7690  Loss:  0.2321246862411499\n",
      "Write summary at step 7700  Loss:  0.25212961435317993\n",
      "Write summary at step 7710  Loss:  0.3131466805934906\n",
      "Write summary at step 7720  Loss:  0.4652925431728363\n",
      "Write summary at step 7730  Loss:  0.18976810574531555\n",
      "Write summary at step 7740  Loss:  0.37928351759910583\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.836056481456225\n",
      "Loss normal: 0.257135520480117 Loss Control: 0.6555120078592352 Loss Patient: 0.13583286198324054 Loss balanced:  0.3956724349212379 Loss1+loss2: 0.3956724349212379\n",
      "Write summary at step 7750  Loss:  0.36562955379486084\n",
      "Write summary at step 7760  Loss:  0.2861207127571106\n",
      "Write summary at step 7770  Loss:  0.21075759828090668\n",
      "Write summary at step 7780  Loss:  0.3744630217552185\n",
      "Write summary at step 7790  Loss:  0.2509308457374573\n",
      "Write summary at step 7800  Loss:  0.28042760491371155\n",
      "Write summary at step 7810  Loss:  0.2903323769569397\n",
      "Write summary at step 7820  Loss:  0.3350399136543274\n",
      "Write summary at step 7830  Loss:  0.34769153594970703\n",
      "Write summary at step 7840  Loss:  0.263992577791214\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9081632653061225 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8621877926588655\n",
      "Loss normal: 0.23887116640654146 Loss Control: 0.44874556207917426 Loss Patient: 0.1749659750839934 Loss balanced:  0.3118557685815838 Loss1+loss2: 0.3118557685815838\n",
      "Write summary at step 7850  Loss:  0.29603105783462524\n",
      "Write summary at step 7860  Loss:  0.41119828820228577\n",
      "Write summary at step 7870  Loss:  0.213652566075325\n",
      "Write summary at step 7880  Loss:  0.25771471858024597\n",
      "Write summary at step 7890  Loss:  0.41274183988571167\n",
      "Write summary at step 7900  Loss:  0.41213536262512207\n",
      "Write summary at step 7910  Loss:  0.5606009364128113\n",
      "Write summary at step 7920  Loss:  0.3861091136932373\n",
      "Write summary at step 7930  Loss:  0.41281256079673767\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9158163265306123 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8747806479183147\n",
      "Loss normal: 0.22667379912977315 Loss Control: 0.4290745528669305 Loss Patient: 0.1650442907434831 Loss balanced:  0.29705942180520684 Loss1+loss2: 0.29705942180520684\n",
      "Write summary at step 7940  Loss:  0.38147827982902527\n",
      "Write summary at step 7950  Loss:  0.3525233864784241\n",
      "Write summary at step 7960  Loss:  0.28611546754837036\n",
      "Write summary at step 7970  Loss:  0.13134589791297913\n",
      "Write summary at step 7980  Loss:  0.48812761902809143\n",
      "Write summary at step 7990  Loss:  0.17528018355369568\n",
      "Write summary at step 8000  Loss:  0.2819630801677704\n",
      "Saved checkpoint to: result/46/panns/checkpoint_8000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.9042397461425857\n",
      "Loss normal: 0.21816688456705638 Loss Control: 0.31267835484827805 Loss Patient: 0.18938885277103068 Loss balanced:  0.25103360380965434 Loss1+loss2: 0.25103360380965434\n",
      "Write summary at step 8010  Loss:  0.4337240755558014\n",
      "Write summary at step 8020  Loss:  0.3060144782066345\n",
      "Write summary at step 8030  Loss:  0.5619380474090576\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9260204081632653 Acurracy Control:  0.8415300546448088 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8966385714155825\n",
      "Loss normal: 0.22394182966375836 Loss Control: 0.34676804633739866 Loss Patient: 0.18654216312727395 Loss balanced:  0.26665510473233633 Loss1+loss2: 0.26665510473233633\n",
      "Write summary at step 8040  Loss:  0.28339913487434387\n",
      "Write summary at step 8050  Loss:  0.4677819013595581\n",
      "Write summary at step 8060  Loss:  0.37057650089263916\n",
      "Write summary at step 8070  Loss:  0.5008818507194519\n",
      "Write summary at step 8080  Loss:  0.4640583395957947\n",
      "Write summary at step 8090  Loss:  0.19492630660533905\n",
      "Write summary at step 8100  Loss:  0.2770012319087982\n",
      "Write summary at step 8110  Loss:  0.47865283489227295\n",
      "Write summary at step 8120  Loss:  0.3304136395454407\n",
      "Write summary at step 8130  Loss:  0.26233211159706116\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.6939890710382514 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.8278597601447497\n",
      "Loss normal: 0.27038081431267214 Loss Control: 0.7582345595125293 Loss Patient: 0.1218330019127311 Loss balanced:  0.44003378071263016 Loss1+loss2: 0.44003378071263016\n",
      "Write summary at step 8140  Loss:  0.44115227460861206\n",
      "Write summary at step 8150  Loss:  0.592226505279541\n",
      "Write summary at step 8160  Loss:  0.29322272539138794\n",
      "Write summary at step 8170  Loss:  0.5721423625946045\n",
      "Write summary at step 8180  Loss:  0.46587929129600525\n",
      "Write summary at step 8190  Loss:  0.16297845542430878\n",
      "Write summary at step 8200  Loss:  0.3989834785461426\n",
      "Write summary at step 8210  Loss:  0.3231833577156067\n",
      "Write summary at step 8220  Loss:  0.26237353682518005\n",
      "Write summary at step 8230  Loss:  0.3645974099636078\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9336734693877551 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9168326014020349\n",
      "Loss normal: 0.22609265312096294 Loss Control: 0.25698063086942247 Loss Patient: 0.21668749111712277 Loss balanced:  0.23683406099327262 Loss1+loss2: 0.23683406099327262\n",
      "Write summary at step 8240  Loss:  0.29023799300193787\n",
      "Write summary at step 8250  Loss:  0.32392609119415283\n",
      "Write summary at step 8260  Loss:  0.28760677576065063\n",
      "Write summary at step 8270  Loss:  0.42010170221328735\n",
      "Write summary at step 8280  Loss:  0.46221989393234253\n",
      "Write summary at step 8290  Loss:  0.27914154529571533\n",
      "Write summary at step 8300  Loss:  0.38547641038894653\n",
      "Write summary at step 8310  Loss:  0.2269609570503235\n",
      "Write summary at step 8320  Loss:  0.424000084400177\n",
      "Write summary at step 8330  Loss:  0.3544307351112366\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8743169398907104 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9122000672831256\n",
      "Loss normal: 0.2092120140714913 Loss Control: 0.28317108717772477 Loss Patient: 0.18669203119646888 Loss balanced:  0.23493155918709682 Loss1+loss2: 0.23493155918709682\n",
      "Write summary at step 8340  Loss:  0.19992570579051971\n",
      "Write summary at step 8350  Loss:  0.3632707893848419\n",
      "Write summary at step 8360  Loss:  0.4515420198440552\n",
      "Write summary at step 8370  Loss:  0.6367683410644531\n",
      "Write summary at step 8380  Loss:  0.23668721318244934\n",
      "Write summary at step 8390  Loss:  0.4261006712913513\n",
      "Write summary at step 8400  Loss:  0.32698556780815125\n",
      "Write summary at step 8410  Loss:  0.23666886985301971\n",
      "Write summary at step 8420  Loss:  0.33247795701026917\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9323979591836735 Acurracy Control:  0.8797814207650273 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9141003609648763\n",
      "Loss normal: 0.23286155120906782 Loss Control: 0.3169795802382172 Loss Patient: 0.20724824142213075 Loss balanced:  0.262113910830174 Loss1+loss2: 0.262113910830174\n",
      "Write summary at step 8430  Loss:  0.2597479224205017\n",
      "Write summary at step 8440  Loss:  0.39372092485427856\n",
      "Write summary at step 8450  Loss:  0.32410290837287903\n",
      "Write summary at step 8460  Loss:  0.09119085967540741\n",
      "Write summary at step 8470  Loss:  0.36211881041526794\n",
      "Write summary at step 8480  Loss:  0.47764140367507935\n",
      "Write summary at step 8490  Loss:  0.3213157653808594\n",
      "Write summary at step 8500  Loss:  0.46029922366142273\n",
      "Saved checkpoint to: result/46/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8993708118527409\n",
      "Loss normal: 0.22688596136868 Loss Control: 0.31939120175408536 Loss Patient: 0.19871881087860727 Loss balanced:  0.2590550063163463 Loss1+loss2: 0.2590550063163463\n",
      "Write summary at step 8510  Loss:  0.5226793885231018\n",
      "Write summary at step 8520  Loss:  0.3082277476787567\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9183673469387755 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8802451287926316\n",
      "Loss normal: 0.25185845782790256 Loss Control: 0.4746115829775242 Loss Patient: 0.18403179694072477 Loss balanced:  0.3293216899591245 Loss1+loss2: 0.3293216899591245\n",
      "Write summary at step 8530  Loss:  0.2745991051197052\n",
      "Write summary at step 8540  Loss:  0.555998682975769\n",
      "Write summary at step 8550  Loss:  0.12922266125679016\n",
      "Write summary at step 8560  Loss:  0.3281835913658142\n",
      "Write summary at step 8570  Loss:  0.24009744822978973\n",
      "Write summary at step 8580  Loss:  0.46690478920936584\n",
      "Write summary at step 8590  Loss:  0.21018263697624207\n",
      "Write summary at step 8600  Loss:  0.4468309283256531\n",
      "Write summary at step 8610  Loss:  0.3448672890663147\n",
      "Write summary at step 8620  Loss:  0.3573867082595825\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9426020408163265 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9340579907803934\n",
      "Loss normal: 0.20976711410496915 Loss Control: 0.2188375603631546 Loss Patient: 0.20700523238660096 Loss balanced:  0.21292139637487778 Loss1+loss2: 0.21292139637487778\n",
      "Write summary at step 8630  Loss:  0.3553817868232727\n",
      "Write summary at step 8640  Loss:  0.3224654197692871\n",
      "Write summary at step 8650  Loss:  0.21754585206508636\n",
      "Write summary at step 8660  Loss:  0.28199484944343567\n",
      "Write summary at step 8670  Loss:  0.46396827697753906\n",
      "Write summary at step 8680  Loss:  0.3474552035331726\n",
      "Write summary at step 8690  Loss:  0.35038718581199646\n",
      "Write summary at step 8700  Loss:  0.4353041648864746\n",
      "Write summary at step 8710  Loss:  0.34138959646224976\n",
      "Write summary at step 8720  Loss:  0.35940754413604736\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8903061224489796 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.9650582362728786 Acurracy Balanced 0.8049334897211388\n",
      "Loss normal: 0.31108762850338706 Loss Control: 0.9913354519286443 Loss Patient: 0.10395725953474814 Loss balanced:  0.5476463557316962 Loss1+loss2: 0.5476463557316962\n",
      "Write summary at step 8730  Loss:  0.358104407787323\n",
      "Write summary at step 8740  Loss:  0.3021654188632965\n",
      "Write summary at step 8750  Loss:  0.3733006417751312\n",
      "Write summary at step 8760  Loss:  0.5511283278465271\n",
      "Write summary at step 8770  Loss:  0.4516070485115051\n",
      "Write summary at step 8780  Loss:  0.17318542301654816\n",
      "Write summary at step 8790  Loss:  0.5447475910186768\n",
      "Write summary at step 8800  Loss:  0.42305272817611694\n",
      "Write summary at step 8810  Loss:  0.28037938475608826\n",
      "Write summary at step 8820  Loss:  0.4667973816394806\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.844489602938636\n",
      "Loss normal: 0.2883174710773996 Loss Control: 0.7450835903485616 Loss Patient: 0.14923561293439638 Loss balanced:  0.447159601641479 Loss1+loss2: 0.447159601641479\n",
      "Write summary at step 8830  Loss:  0.23907668888568878\n",
      "Write summary at step 8840  Loss:  0.550691545009613\n",
      "Write summary at step 8850  Loss:  0.3482215106487274\n",
      "Write summary at step 8860  Loss:  0.33142831921577454\n",
      "Write summary at step 8870  Loss:  0.2713989317417145\n",
      "Write summary at step 8880  Loss:  0.37389075756073\n",
      "Write summary at step 8890  Loss:  0.3611643314361572\n",
      "Write summary at step 8900  Loss:  0.35815006494522095\n",
      "Write summary at step 8910  Loss:  0.3021713197231293\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9170918367346939 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8756125946737223\n",
      "Loss normal: 0.2236661888582974 Loss Control: 0.38804525104376786 Loss Patient: 0.17361399271647862 Loss balanced:  0.2808296218801232 Loss1+loss2: 0.2808296218801232\n",
      "Write summary at step 8920  Loss:  0.2990179657936096\n",
      "Write summary at step 8930  Loss:  0.4370926022529602\n",
      "Write summary at step 8940  Loss:  0.2488725632429123\n",
      "Write summary at step 8950  Loss:  0.6722288131713867\n",
      "Write summary at step 8960  Loss:  0.4046667814254761\n",
      "Write summary at step 8970  Loss:  0.4847870469093323\n",
      "Write summary at step 8980  Loss:  0.324781596660614\n",
      "Write summary at step 8990  Loss:  0.16443027555942535\n",
      "Write summary at step 9000  Loss:  0.3290894627571106\n",
      "Saved checkpoint to: result/46/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.9031713992162425\n",
      "Loss normal: 0.24939489851192553 Loss Control: 0.3067180248883253 Loss Patient: 0.23194043184576335 Loss balanced:  0.2693292283670443 Loss1+loss2: 0.2693292283670443\n",
      "Write summary at step 9010  Loss:  0.44584429264068604\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8548230181027977\n",
      "Loss normal: 0.2680590907681961 Loss Control: 0.5087158916100778 Loss Patient: 0.19478089533461113 Loss balanced:  0.35174839347234443 Loss1+loss2: 0.35174839347234443\n",
      "Write summary at step 9020  Loss:  0.3786153197288513\n",
      "Write summary at step 9030  Loss:  0.2186942994594574\n",
      "Write summary at step 9040  Loss:  0.4649549722671509\n",
      "Write summary at step 9050  Loss:  0.4119078516960144\n",
      "Write summary at step 9060  Loss:  0.29125985503196716\n",
      "Write summary at step 9070  Loss:  0.33615168929100037\n",
      "Write summary at step 9080  Loss:  0.21090096235275269\n",
      "Write summary at step 9090  Loss:  0.3835442066192627\n",
      "Write summary at step 9100  Loss:  0.18283870816230774\n",
      "Write summary at step 9110  Loss:  0.30102550983428955\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8346289881163453\n",
      "Loss normal: 0.2874278692832711 Loss Control: 0.7194109031411468 Loss Patient: 0.15589227230317532 Loss balanced:  0.43765158772216106 Loss1+loss2: 0.43765158772216106\n",
      "Write summary at step 9120  Loss:  0.21838441491127014\n",
      "Write summary at step 9130  Loss:  0.32808005809783936\n",
      "Write summary at step 9140  Loss:  0.2981657087802887\n",
      "Write summary at step 9150  Loss:  0.32414472103118896\n",
      "Write summary at step 9160  Loss:  0.47274085879325867\n",
      "Write summary at step 9170  Loss:  0.37176501750946045\n",
      "Write summary at step 9180  Loss:  0.2724001705646515\n",
      "Write summary at step 9190  Loss:  0.2978936731815338\n",
      "Write summary at step 9200  Loss:  0.19984807074069977\n",
      "Write summary at step 9210  Loss:  0.5774364471435547\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9349489795918368 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.9252657228844459\n",
      "Loss normal: 0.2116839987206824 Loss Control: 0.23057978237912954 Loss Patient: 0.20593037217012458 Loss balanced:  0.21825507727462706 Loss1+loss2: 0.21825507727462706\n",
      "Write summary at step 9220  Loss:  0.5381669402122498\n",
      "Write summary at step 9230  Loss:  0.2874898314476013\n",
      "Write summary at step 9240  Loss:  0.13825613260269165\n",
      "Write summary at step 9250  Loss:  0.18761977553367615\n",
      "Write summary at step 9260  Loss:  0.19617953896522522\n",
      "Write summary at step 9270  Loss:  0.2720159888267517\n",
      "Write summary at step 9280  Loss:  0.404620885848999\n",
      "Write summary at step 9290  Loss:  0.5373079180717468\n",
      "Write summary at step 9300  Loss:  0.22239011526107788\n",
      "Write summary at step 9310  Loss:  0.2242359071969986\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.8636152859987453\n",
      "Loss normal: 0.25151698831088687 Loss Control: 0.45331294321623006 Loss Patient: 0.190071632059759 Loss balanced:  0.3216922876379945 Loss1+loss2: 0.3216922876379945\n",
      "Write summary at step 9320  Loss:  0.3226606547832489\n",
      "Write summary at step 9330  Loss:  0.3888530731201172\n",
      "Write summary at step 9340  Loss:  0.1646764874458313\n",
      "Write summary at step 9350  Loss:  0.4308888912200928\n",
      "Write summary at step 9360  Loss:  0.3048844039440155\n",
      "Write summary at step 9370  Loss:  0.3397336006164551\n",
      "Write summary at step 9380  Loss:  0.3924389183521271\n",
      "Write summary at step 9390  Loss:  0.4142712354660034\n",
      "Write summary at step 9400  Loss:  0.4420872926712036\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9247448979591837 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9129092677959321\n",
      "Loss normal: 0.24333445009376323 Loss Control: 0.26219062775862023 Loss Patient: 0.23759288592465508 Loss balanced:  0.24989175684163767 Loss1+loss2: 0.24989175684163767\n",
      "Write summary at step 9410  Loss:  0.44322651624679565\n",
      "Write summary at step 9420  Loss:  0.3845733404159546\n",
      "Write summary at step 9430  Loss:  0.31481269001960754\n",
      "Write summary at step 9440  Loss:  0.30367398262023926\n",
      "Write summary at step 9450  Loss:  0.2595747113227844\n",
      "Write summary at step 9460  Loss:  0.20692811906337738\n",
      "Write summary at step 9470  Loss:  0.4354567527770996\n",
      "Write summary at step 9480  Loss:  0.31305360794067383\n",
      "Write summary at step 9490  Loss:  0.4704034924507141\n",
      "Write summary at step 9500  Loss:  0.2762874960899353\n",
      "Saved checkpoint to: result/46/panns/checkpoint_9500.pt\n",
      "Validation:\n",
      "Acurracy:  0.9400510204081632 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.9418955656783321\n",
      "Loss normal: 0.23637075136814797 Loss Control: 0.17041320699811632 Loss Patient: 0.2564543310596225 Loss balanced:  0.2134337690288694 Loss1+loss2: 0.2134337690288694\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9375 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.9402316721675168\n",
      "Loss normal: 0.23717995159023877 Loss Control: 0.15759463844403543 Loss Patient: 0.26141308432757954 Loss balanced:  0.20950386138580748 Loss1+loss2: 0.20950386138580748\n",
      "Write summary at step 9510  Loss:  0.2887845039367676\n",
      "Write summary at step 9520  Loss:  0.261757493019104\n",
      "Write summary at step 9530  Loss:  0.36612468957901\n",
      "Write summary at step 9540  Loss:  0.2353878915309906\n",
      "Write summary at step 9550  Loss:  0.3620261549949646\n",
      "Write summary at step 9560  Loss:  0.309214323759079\n",
      "Write summary at step 9570  Loss:  0.356227308511734\n",
      "Write summary at step 9580  Loss:  0.3681216835975647\n",
      "Write summary at step 9590  Loss:  0.41955772042274475\n",
      "Write summary at step 9600  Loss:  0.27696049213409424\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8428257094278206\n",
      "Loss normal: 0.2502370569854975 Loss Control: 0.554797549065345 Loss Patient: 0.15750067102135518 Loss balanced:  0.35614911004335004 Loss1+loss2: 0.35614911004335004\n",
      "Write summary at step 9610  Loss:  0.20875652134418488\n",
      "Write summary at step 9620  Loss:  0.17959274351596832\n",
      "Write summary at step 9630  Loss:  0.49285653233528137\n",
      "Write summary at step 9640  Loss:  0.24918508529663086\n",
      "Write summary at step 9650  Loss:  0.36264944076538086\n",
      "Write summary at step 9660  Loss:  0.34881293773651123\n",
      "Write summary at step 9670  Loss:  0.376808226108551\n",
      "Write summary at step 9680  Loss:  0.39820918440818787\n",
      "Write summary at step 9690  Loss:  0.345058798789978\n",
      "Write summary at step 9700  Loss:  0.1780906319618225\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9132653061224489 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8674158733622469\n",
      "Loss normal: 0.24720212307815648 Loss Control: 0.5253400942666935 Loss Patient: 0.16251119280144102 Loss balanced:  0.34392564353406724 Loss1+loss2: 0.34392564353406724\n",
      "Write summary at step 9710  Loss:  0.25583815574645996\n",
      "Write summary at step 9720  Loss:  0.3055802881717682\n",
      "Write summary at step 9730  Loss:  0.324666291475296\n",
      "Write summary at step 9740  Loss:  0.43464452028274536\n",
      "Write summary at step 9750  Loss:  0.43838727474212646\n",
      "Write summary at step 9760  Loss:  0.3491823673248291\n",
      "Write summary at step 9770  Loss:  0.2736823558807373\n",
      "Write summary at step 9780  Loss:  0.41063567996025085\n",
      "Write summary at step 9790  Loss:  0.48583200573921204\n",
      "Write summary at step 9800  Loss:  0.5677682161331177\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9272959183673469 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.9012711055344917\n",
      "Loss normal: 0.22426515836648794 Loss Control: 0.31470302056745103 Loss Patient: 0.19672750819245113 Loss balanced:  0.25571526437995107 Loss1+loss2: 0.25571526437995107\n",
      "------------------------------\n",
      "SEED: 46 Best Loss: 0.20297127113854652\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "config = 'script/config.json'\n",
    "seeds = [42,43,44,45,46]\n",
    "for seed in seeds:\n",
    "    command = f\"python script/train.py -c {config} -s {seed}\"\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaefcd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Max Time dim Lenght is: 1502 (+- 30.04 seconds)\n",
      "The Min Time dim Lenght is: 5 (+- 0.1 seconds)\n",
      "['noise']\n",
      "Using Class Batch Balancer\n",
      "['noise']\n",
      "Enable Mixup with alpha: 0.9\n",
      " > Partial model initialization.\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_real.weight\n",
      " | > Layer missing in the model definition: spectrogram_extractor.stft.conv_imag.weight\n",
      " | > Layer missing in the model definition: logmel_extractor.melW\n",
      " | > 81 / 81 layers are restored.\n",
      "Partial Pretrained checkpoint loaded:  Cnn14_16k_mAP=0.438.pth\n",
      "Starting new training run\n",
      "Write summary at step 10  Loss:  0.9040305614471436\n",
      "Write summary at step 20  Loss:  0.7568168640136719\n",
      "Write summary at step 30  Loss:  0.7249448299407959\n",
      "Write summary at step 40  Loss:  0.8779512643814087\n",
      "Write summary at step 50  Loss:  0.6779804229736328\n",
      "Write summary at step 60  Loss:  0.9965670704841614\n",
      "Write summary at step 70  Loss:  0.7140737771987915\n",
      "Write summary at step 80  Loss:  0.7419352531433105\n",
      "Write summary at step 90  Loss:  0.7192400693893433\n",
      "=================================================\n",
      "Epoch 0 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.2869897959183674 Acurracy Control:  0.9781420765027322 Acurracy Patient:  0.07653910149750416 Acurracy Balanced 0.5273405890001182\n",
      "Loss normal: 0.749952174875201 Loss Control: 0.5925981803018538 Loss Patient: 0.7978652878331265 Loss balanced:  0.6952317340674902 Loss1+loss2: 0.6952317340674902\n",
      "\n",
      " > BEST MODEL (0.69523) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 100  Loss:  0.7003298997879028\n",
      "Write summary at step 110  Loss:  0.7295730710029602\n",
      "Write summary at step 120  Loss:  0.7727053761482239\n",
      "Write summary at step 130  Loss:  0.666584312915802\n",
      "Write summary at step 140  Loss:  0.6602959632873535\n",
      "Write summary at step 150  Loss:  0.6366438865661621\n",
      "Write summary at step 160  Loss:  0.6277872323989868\n",
      "Write summary at step 170  Loss:  0.6918167471885681\n",
      "Write summary at step 180  Loss:  0.6253615617752075\n",
      "Write summary at step 190  Loss:  0.6221093535423279\n",
      "=================================================\n",
      "Epoch 1 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7321428571428571 Acurracy Control:  0.22950819672131148 Acurracy Patient:  0.8851913477537438 Acurracy Balanced 0.5573497722375276\n",
      "Loss normal: 0.7671232466795006 Loss Control: 0.7610251056691988 Loss Patient: 0.768980089023387 Loss balanced:  0.7650025973462928 Loss1+loss2: 0.7650025973462928\n",
      "Write summary at step 200  Loss:  0.6924374103546143\n",
      "Write summary at step 210  Loss:  0.7000263929367065\n",
      "Write summary at step 220  Loss:  0.7091203927993774\n",
      "Write summary at step 230  Loss:  0.6922057867050171\n",
      "Write summary at step 240  Loss:  0.7171350717544556\n",
      "Write summary at step 250  Loss:  0.6565918326377869\n",
      "Write summary at step 260  Loss:  0.6341307163238525\n",
      "Write summary at step 270  Loss:  0.9641567468643188\n",
      "Write summary at step 280  Loss:  0.6751701235771179\n",
      "Write summary at step 290  Loss:  0.8883323073387146\n",
      "=================================================\n",
      "Epoch 2 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7793367346938775 Acurracy Control:  0.17486338797814208 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.5691288653701027\n",
      "Loss normal: 0.5778389439290884 Loss Control: 0.8783534550275959 Loss Patient: 0.4863345280364032 Loss balanced:  0.6823439915319995 Loss1+loss2: 0.6823439915319995\n",
      "\n",
      " > BEST MODEL (0.68234) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 300  Loss:  0.8076128959655762\n",
      "Write summary at step 310  Loss:  0.6566833257675171\n",
      "Write summary at step 320  Loss:  0.6801819801330566\n",
      "Write summary at step 330  Loss:  0.6750710010528564\n",
      "Write summary at step 340  Loss:  0.6838086843490601\n",
      "Write summary at step 350  Loss:  0.5680541396141052\n",
      "Write summary at step 360  Loss:  0.9488261938095093\n",
      "Write summary at step 370  Loss:  0.6973446607589722\n",
      "Write summary at step 380  Loss:  0.7737128734588623\n",
      "Write summary at step 390  Loss:  0.7834435105323792\n",
      "=================================================\n",
      "Epoch 3 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7997448979591837 Acurracy Control:  0.3442622950819672 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.6413491175909004\n",
      "Loss normal: 0.5535405986771291 Loss Control: 0.7866540372045965 Loss Patient: 0.4825593013930043 Loss balanced:  0.6346066692988004 Loss1+loss2: 0.6346066692988004\n",
      "\n",
      " > BEST MODEL (0.63461) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 400  Loss:  0.6518123745918274\n",
      "Write summary at step 410  Loss:  0.7128332257270813\n",
      "Write summary at step 420  Loss:  0.8927494287490845\n",
      "Write summary at step 430  Loss:  0.6244416236877441\n",
      "Write summary at step 440  Loss:  0.509662389755249\n",
      "Write summary at step 450  Loss:  0.7830430269241333\n",
      "Write summary at step 460  Loss:  0.6286771297454834\n",
      "Write summary at step 470  Loss:  0.7741765975952148\n",
      "Write summary at step 480  Loss:  0.829580545425415\n",
      "Write summary at step 490  Loss:  0.5719189643859863\n",
      "=================================================\n",
      "Epoch 4 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7806122448979592 Acurracy Control:  0.26229508196721313 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.6003655110335234\n",
      "Loss normal: 0.5021441948353028 Loss Control: 1.0777461854486519 Loss Patient: 0.32687769294677677 Loss balanced:  0.7023119391977143 Loss1+loss2: 0.7023119391977143\n",
      "Write summary at step 500  Loss:  0.8994656801223755\n",
      "Saved checkpoint to: result/42/panns/checkpoint_500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7346938775510204 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.7603993344425957 Acurracy Balanced 0.7053362792431557\n",
      "Loss normal: 0.6210284351694341 Loss Control: 0.5558763527479328 Loss Patient: 0.6408667595136582 Loss balanced:  0.5983715561307955 Loss1+loss2: 0.5983715561307955\n",
      "\n",
      " > BEST MODEL (0.59837) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 510  Loss:  0.7678504586219788\n",
      "Write summary at step 520  Loss:  0.6941633820533752\n",
      "Write summary at step 530  Loss:  0.6711077690124512\n",
      "Write summary at step 540  Loss:  0.883324146270752\n",
      "Write summary at step 550  Loss:  0.6619013547897339\n",
      "Write summary at step 560  Loss:  0.5350978374481201\n",
      "Write summary at step 570  Loss:  0.6641120314598083\n",
      "Write summary at step 580  Loss:  0.7166792154312134\n",
      "=================================================\n",
      "Epoch 5 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7321428571428571 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.7371048252911814 Acurracy Balanced 0.7264759099133502\n",
      "Loss normal: 0.5279799952190749 Loss Control: 0.6030979117409128 Loss Patient: 0.5051071542174169 Loss balanced:  0.5541025329791649 Loss1+loss2: 0.5541025329791649\n",
      "\n",
      " > BEST MODEL (0.55410) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 590  Loss:  0.5405739545822144\n",
      "Write summary at step 600  Loss:  0.561077892780304\n",
      "Write summary at step 610  Loss:  0.6669625043869019\n",
      "Write summary at step 620  Loss:  0.5986332297325134\n",
      "Write summary at step 630  Loss:  0.6779515743255615\n",
      "Write summary at step 640  Loss:  0.6588988900184631\n",
      "Write summary at step 650  Loss:  0.48908746242523193\n",
      "Write summary at step 660  Loss:  0.7074909210205078\n",
      "Write summary at step 670  Loss:  0.6178920865058899\n",
      "Write summary at step 680  Loss:  0.9808499217033386\n",
      "=================================================\n",
      "Epoch 6 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7869897959183674 Acurracy Control:  0.48633879781420764 Acurracy Patient:  0.8785357737104825 Acurracy Balanced 0.6824372857623451\n",
      "Loss normal: 0.48174902477434706 Loss Control: 0.805730738926455 Loss Patient: 0.38309901687448317 Loss balanced:  0.5944148779004691 Loss1+loss2: 0.5944148779004691\n",
      "Write summary at step 690  Loss:  0.6773180365562439\n",
      "Write summary at step 700  Loss:  0.7885189056396484\n",
      "Write summary at step 710  Loss:  0.780552327632904\n",
      "Write summary at step 720  Loss:  0.7088795900344849\n",
      "Write summary at step 730  Loss:  0.5697187185287476\n",
      "Write summary at step 740  Loss:  0.7859314680099487\n",
      "Write summary at step 750  Loss:  0.5705975294113159\n",
      "Write summary at step 760  Loss:  0.5814713835716248\n",
      "Write summary at step 770  Loss:  0.5455331206321716\n",
      "Write summary at step 780  Loss:  0.7255248427391052\n",
      "=================================================\n",
      "Epoch 7 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.798469387755102 Acurracy Control:  0.2568306010928962 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.6101124719274797\n",
      "Loss normal: 0.4479271270790879 Loss Control: 1.1380281526534284 Loss Patient: 0.23779653518549018 Loss balanced:  0.6879123439194593 Loss1+loss2: 0.6879123439194593\n",
      "Write summary at step 790  Loss:  0.8206363916397095\n",
      "Write summary at step 800  Loss:  0.5785666108131409\n",
      "Write summary at step 810  Loss:  0.9993451833724976\n",
      "Write summary at step 820  Loss:  0.7700356841087341\n",
      "Write summary at step 830  Loss:  0.7712917327880859\n",
      "Write summary at step 840  Loss:  0.57687908411026\n",
      "Write summary at step 850  Loss:  0.6921833753585815\n",
      "Write summary at step 860  Loss:  0.608730673789978\n",
      "Write summary at step 870  Loss:  0.7020924091339111\n",
      "Write summary at step 880  Loss:  0.5811353921890259\n",
      "=================================================\n",
      "Epoch 8 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7691326530612245 Acurracy Control:  0.3005464480874317 Acurracy Patient:  0.9118136439267887 Acurracy Balanced 0.6061800460071102\n",
      "Loss normal: 0.5914814186339475 Loss Control: 0.743534247080485 Loss Patient: 0.5451824664077822 Loss balanced:  0.6443583567441336 Loss1+loss2: 0.6443583567441336\n",
      "Write summary at step 890  Loss:  0.5795661211013794\n",
      "Write summary at step 900  Loss:  0.6720921993255615\n",
      "Write summary at step 910  Loss:  0.9936748743057251\n",
      "Write summary at step 920  Loss:  0.5461403131484985\n",
      "Write summary at step 930  Loss:  0.5443205237388611\n",
      "Write summary at step 940  Loss:  0.6622295379638672\n",
      "Write summary at step 950  Loss:  0.6916284561157227\n",
      "Write summary at step 960  Loss:  0.7559434175491333\n",
      "Write summary at step 970  Loss:  0.7840629816055298\n",
      "Write summary at step 980  Loss:  0.6616197228431702\n",
      "=================================================\n",
      "Epoch 9 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7882653061224489 Acurracy Control:  0.15300546448087432 Acurracy Patient:  0.9816971713810316 Acurracy Balanced 0.567351317930953\n",
      "Loss normal: 0.4894240502724234 Loss Control: 1.714678451663158 Loss Patient: 0.11634325874526172 Loss balanced:  0.9155108552042098 Loss1+loss2: 0.9155108552042098\n",
      "Write summary at step 990  Loss:  0.7586162090301514\n",
      "Write summary at step 1000  Loss:  0.6197841763496399\n",
      "Saved checkpoint to: result/42/panns/checkpoint_1000.pt\n",
      "Validation:\n",
      "Acurracy:  0.7869897959183674 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.8302828618968386 Acurracy Balanced 0.7375458025331187\n",
      "Loss normal: 0.5084146069628852 Loss Control: 0.5807765494278871 Loss Patient: 0.4863809380872476 Loss balanced:  0.5335787437575674 Loss1+loss2: 0.5335787437575674\n",
      "\n",
      " > BEST MODEL (0.53358) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1010  Loss:  0.7494381666183472\n",
      "Write summary at step 1020  Loss:  0.6332985162734985\n",
      "Write summary at step 1030  Loss:  0.5664833784103394\n",
      "Write summary at step 1040  Loss:  0.8398070335388184\n",
      "Write summary at step 1050  Loss:  0.7777304649353027\n",
      "Write summary at step 1060  Loss:  0.6803922653198242\n",
      "Write summary at step 1070  Loss:  0.5490137934684753\n",
      "=================================================\n",
      "Epoch 10 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7971938775510204 Acurracy Control:  0.2896174863387978 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.620682287262577\n",
      "Loss normal: 0.431772877519228 Loss Control: 1.1335030097127612 Loss Patient: 0.2181013030884865 Loss balanced:  0.6758021564006238 Loss1+loss2: 0.6758021564006238\n",
      "Write summary at step 1080  Loss:  0.6101971864700317\n",
      "Write summary at step 1090  Loss:  0.6436667442321777\n",
      "Write summary at step 1100  Loss:  0.7348591089248657\n",
      "Write summary at step 1110  Loss:  0.6420794725418091\n",
      "Write summary at step 1120  Loss:  0.6560406684875488\n",
      "Write summary at step 1130  Loss:  0.5444515943527222\n",
      "Write summary at step 1140  Loss:  0.5785653591156006\n",
      "Write summary at step 1150  Loss:  0.6659846305847168\n",
      "Write summary at step 1160  Loss:  0.802402675151825\n",
      "Write summary at step 1170  Loss:  0.5669800639152527\n",
      "=================================================\n",
      "Epoch 11 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8137755102040817 Acurracy Control:  0.453551912568306 Acurracy Patient:  0.9234608985024958 Acurracy Balanced 0.6885064055354009\n",
      "Loss normal: 0.4536917416416869 Loss Control: 0.7908781369527181 Loss Patient: 0.35102100781910434 Loss balanced:  0.5709495723859113 Loss1+loss2: 0.5709495723859113\n",
      "Write summary at step 1180  Loss:  0.5807317495346069\n",
      "Write summary at step 1190  Loss:  0.48440468311309814\n",
      "Write summary at step 1200  Loss:  0.6821412444114685\n",
      "Write summary at step 1210  Loss:  0.7000020146369934\n",
      "Write summary at step 1220  Loss:  0.46902182698249817\n",
      "Write summary at step 1230  Loss:  0.7561885118484497\n",
      "Write summary at step 1240  Loss:  0.5678075551986694\n",
      "Write summary at step 1250  Loss:  0.7986209392547607\n",
      "Write summary at step 1260  Loss:  0.5892677903175354\n",
      "Write summary at step 1270  Loss:  0.5440961122512817\n",
      "=================================================\n",
      "Epoch 12 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8278061224489796 Acurracy Control:  0.3989071038251366 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.678654883027377\n",
      "Loss normal: 0.4009229277013516 Loss Control: 0.9526993368492752 Loss Patient: 0.23291114582594938 Loss balanced:  0.5928052413376123 Loss1+loss2: 0.5928052413376123\n",
      "Write summary at step 1280  Loss:  0.7384289503097534\n",
      "Write summary at step 1290  Loss:  0.5360181927680969\n",
      "Write summary at step 1300  Loss:  0.5159563422203064\n",
      "Write summary at step 1310  Loss:  0.5719147324562073\n",
      "Write summary at step 1320  Loss:  0.6400705575942993\n",
      "Write summary at step 1330  Loss:  0.4495994448661804\n",
      "Write summary at step 1340  Loss:  0.5437925457954407\n",
      "Write summary at step 1350  Loss:  0.5499773621559143\n",
      "Write summary at step 1360  Loss:  0.6841961145401001\n",
      "Write summary at step 1370  Loss:  0.6823471188545227\n",
      "=================================================\n",
      "Epoch 13 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7908163265306123 Acurracy Control:  0.16939890710382513 Acurracy Patient:  0.9800332778702163 Acurracy Balanced 0.5747160924870207\n",
      "Loss normal: 0.45628628727732873 Loss Control: 1.3140922244129285 Loss Patient: 0.19509080297835854 Loss balanced:  0.7545915136956435 Loss1+loss2: 0.7545915136956435\n",
      "Write summary at step 1380  Loss:  0.6065255403518677\n",
      "Write summary at step 1390  Loss:  0.7329068779945374\n",
      "Write summary at step 1400  Loss:  0.5781019926071167\n",
      "Write summary at step 1410  Loss:  0.5263522863388062\n",
      "Write summary at step 1420  Loss:  0.572524905204773\n",
      "Write summary at step 1430  Loss:  0.5505399703979492\n",
      "Write summary at step 1440  Loss:  0.5434972643852234\n",
      "Write summary at step 1450  Loss:  0.5856430530548096\n",
      "Write summary at step 1460  Loss:  0.504112184047699\n",
      "Write summary at step 1470  Loss:  0.6340659260749817\n",
      "=================================================\n",
      "Epoch 14 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8137755102040817 Acurracy Control:  0.5245901639344263 Acurracy Patient:  0.9018302828618968 Acurracy Balanced 0.7132102233981615\n",
      "Loss normal: 0.4677523651293346 Loss Control: 0.674376018711778 Loss Patient: 0.4048370113983726 Loss balanced:  0.5396065150550753 Loss1+loss2: 0.5396065150550753\n",
      "Write summary at step 1480  Loss:  0.7590373158454895\n",
      "Write summary at step 1490  Loss:  0.8152871131896973\n",
      "Write summary at step 1500  Loss:  0.6262840032577515\n",
      "Saved checkpoint to: result/42/panns/checkpoint_1500.pt\n",
      "Validation:\n",
      "Acurracy:  0.7946428571428571 Acurracy Control:  0.6010928961748634 Acurracy Patient:  0.8535773710482529 Acurracy Balanced 0.7273351336115581\n",
      "Loss normal: 0.5020241828597322 Loss Control: 0.6047960721729883 Loss Patient: 0.47073091107874665 Loss balanced:  0.5377634916258675 Loss1+loss2: 0.5377634916258675\n",
      "Write summary at step 1510  Loss:  0.7045625448226929\n",
      "Write summary at step 1520  Loss:  0.5796017646789551\n",
      "Write summary at step 1530  Loss:  0.5340416431427002\n",
      "Write summary at step 1540  Loss:  0.7007091641426086\n",
      "Write summary at step 1550  Loss:  0.8307321071624756\n",
      "Write summary at step 1560  Loss:  0.7506120204925537\n",
      "=================================================\n",
      "Epoch 15 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8150510204081632 Acurracy Control:  0.366120218579235 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.6589336533827955\n",
      "Loss normal: 0.40569009981593307 Loss Control: 0.9774569162254125 Loss Patient: 0.2315913883600378 Loss balanced:  0.6045241522927252 Loss1+loss2: 0.6045241522927252\n",
      "Write summary at step 1570  Loss:  0.8028866648674011\n",
      "Write summary at step 1580  Loss:  0.6890237927436829\n",
      "Write summary at step 1590  Loss:  0.8097953796386719\n",
      "Write summary at step 1600  Loss:  0.5373597145080566\n",
      "Write summary at step 1610  Loss:  0.6946446895599365\n",
      "Write summary at step 1620  Loss:  0.619349479675293\n",
      "Write summary at step 1630  Loss:  0.45597830414772034\n",
      "Write summary at step 1640  Loss:  0.5109353065490723\n",
      "Write summary at step 1650  Loss:  0.7813960313796997\n",
      "Write summary at step 1660  Loss:  0.5276403427124023\n",
      "=================================================\n",
      "Epoch 16 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8214285714285714 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.8752079866888519 Acurracy Balanced 0.7600083649291254\n",
      "Loss normal: 0.48152722479129323 Loss Control: 0.6006317711918732 Loss Patient: 0.4452607852845343 Loss balanced:  0.5229462782382037 Loss1+loss2: 0.5229462782382037\n",
      "\n",
      " > BEST MODEL (0.52295) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1670  Loss:  0.4744865596294403\n",
      "Write summary at step 1680  Loss:  0.4837844967842102\n",
      "Write summary at step 1690  Loss:  0.5148236751556396\n",
      "Write summary at step 1700  Loss:  0.6404116153717041\n",
      "Write summary at step 1710  Loss:  0.6042463779449463\n",
      "Write summary at step 1720  Loss:  0.6626027822494507\n",
      "Write summary at step 1730  Loss:  0.8569770455360413\n",
      "Write summary at step 1740  Loss:  0.547717273235321\n",
      "Write summary at step 1750  Loss:  0.578592836856842\n",
      "Write summary at step 1760  Loss:  0.5570871233940125\n",
      "=================================================\n",
      "Epoch 17 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.4260204081632653 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.259567387687188 Acurracy Balanced 0.6161224916578016\n",
      "Loss normal: 0.9909171176960274 Loss Control: 0.17686205776662775 Loss Patient: 1.2387907897771495 Loss balanced:  0.7078264237718886 Loss1+loss2: 0.7078264237718886\n",
      "Write summary at step 1770  Loss:  0.6201387643814087\n",
      "Write summary at step 1780  Loss:  0.6253591179847717\n",
      "Write summary at step 1790  Loss:  0.6834883689880371\n",
      "Write summary at step 1800  Loss:  0.38744986057281494\n",
      "Write summary at step 1810  Loss:  0.5680920481681824\n",
      "Write summary at step 1820  Loss:  0.4649450480937958\n",
      "Write summary at step 1830  Loss:  0.48906466364860535\n",
      "Write summary at step 1840  Loss:  0.5168546438217163\n",
      "Write summary at step 1850  Loss:  0.4778751730918884\n",
      "Write summary at step 1860  Loss:  0.6641137003898621\n",
      "=================================================\n",
      "Epoch 18 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7130102040816326 Acurracy Control:  0.912568306010929 Acurracy Patient:  0.6522462562396006 Acurracy Balanced 0.7824072811252648\n",
      "Loss normal: 0.730428220742211 Loss Control: 0.2009886451106254 Loss Patient: 0.8916386102082924 Loss balanced:  0.5463136276594589 Loss1+loss2: 0.5463136276594589\n",
      "Write summary at step 1870  Loss:  0.7078675031661987\n",
      "Write summary at step 1880  Loss:  0.5817019939422607\n",
      "Write summary at step 1890  Loss:  0.6215007305145264\n",
      "Write summary at step 1900  Loss:  0.48368120193481445\n",
      "Write summary at step 1910  Loss:  0.6124487519264221\n",
      "Write summary at step 1920  Loss:  0.6117631793022156\n",
      "Write summary at step 1930  Loss:  0.6031630039215088\n",
      "Write summary at step 1940  Loss:  0.567031979560852\n",
      "Write summary at step 1950  Loss:  0.5525003671646118\n",
      "Write summary at step 1960  Loss:  0.43580329418182373\n",
      "=================================================\n",
      "Epoch 19 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8380102040816326 Acurracy Control:  0.7595628415300546 Acurracy Patient:  0.8618968386023295 Acurracy Balanced 0.810729840066192\n",
      "Loss normal: 0.4520382605949227 Loss Control: 0.48416129878309905 Loss Patient: 0.44225703450090276 Loss balanced:  0.4632091666420009 Loss1+loss2: 0.4632091666420009\n",
      "\n",
      " > BEST MODEL (0.46321) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 1970  Loss:  0.7183640003204346\n",
      "Write summary at step 1980  Loss:  0.6161648631095886\n",
      "Write summary at step 1990  Loss:  0.6944949626922607\n",
      "Write summary at step 2000  Loss:  0.49708542227745056\n",
      "Saved checkpoint to: result/42/panns/checkpoint_2000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8405612244897959 Acurracy Control:  0.5136612021857924 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.7268805178982207\n",
      "Loss normal: 0.3668925268005352 Loss Control: 0.9210559370739212 Loss Patient: 0.19815391128551146 Loss balanced:  0.5596049241797163 Loss1+loss2: 0.5596049241797163\n",
      "Write summary at step 2010  Loss:  0.5303909778594971\n",
      "Write summary at step 2020  Loss:  0.5703756809234619\n",
      "Write summary at step 2030  Loss:  0.5333684086799622\n",
      "Write summary at step 2040  Loss:  0.41030800342559814\n",
      "Write summary at step 2050  Loss:  0.5725241899490356\n",
      "=================================================\n",
      "Epoch 20 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8494897959183674 Acurracy Control:  0.5846994535519126 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.7574079630488348\n",
      "Loss normal: 0.3760824529644178 Loss Control: 0.7568826037026494 Loss Patient: 0.26013166004925126 Loss balanced:  0.5085071318759503 Loss1+loss2: 0.5085071318759503\n",
      "Write summary at step 2060  Loss:  0.6150342226028442\n",
      "Write summary at step 2070  Loss:  0.5373252034187317\n",
      "Write summary at step 2080  Loss:  0.43635275959968567\n",
      "Write summary at step 2090  Loss:  0.5587655305862427\n",
      "Write summary at step 2100  Loss:  0.5550695657730103\n",
      "Write summary at step 2110  Loss:  0.6005073189735413\n",
      "Write summary at step 2120  Loss:  0.3902179002761841\n",
      "Write summary at step 2130  Loss:  0.6284263134002686\n",
      "Write summary at step 2140  Loss:  0.6709403395652771\n",
      "Write summary at step 2150  Loss:  0.49244436621665955\n",
      "=================================================\n",
      "Epoch 21 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.7806122448979592 Acurracy Control:  0.1092896174863388 Acurracy Patient:  0.9850249584026622 Acurracy Balanced 0.5471572879445005\n",
      "Loss normal: 0.5508848411810338 Loss Control: 2.091224988301595 Loss Patient: 0.0818627949450754 Loss balanced:  1.0865438916233352 Loss1+loss2: 1.0865438916233352\n",
      "Write summary at step 2160  Loss:  0.5835245847702026\n",
      "Write summary at step 2170  Loss:  0.5600787401199341\n",
      "Write summary at step 2180  Loss:  0.615747332572937\n",
      "Write summary at step 2190  Loss:  0.6606029272079468\n",
      "Write summary at step 2200  Loss:  0.9274771213531494\n",
      "Write summary at step 2210  Loss:  0.6598749160766602\n",
      "Write summary at step 2220  Loss:  0.5838847160339355\n",
      "Write summary at step 2230  Loss:  0.7414608001708984\n",
      "Write summary at step 2240  Loss:  0.5213007926940918\n",
      "Write summary at step 2250  Loss:  0.7284427881240845\n",
      "=================================================\n",
      "Epoch 22 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.6454081632653061 Acurracy Control:  0.9726775956284153 Acurracy Patient:  0.5457570715474209 Acurracy Balanced 0.7592173335879181\n",
      "Loss normal: 0.6395116653673503 Loss Control: 0.210404612327534 Loss Patient: 0.7701715464996617 Loss balanced:  0.49028807941359787 Loss1+loss2: 0.49028807941359787\n",
      "Write summary at step 2260  Loss:  0.6049871444702148\n",
      "Write summary at step 2270  Loss:  0.677380383014679\n",
      "Write summary at step 2280  Loss:  0.6438815593719482\n",
      "Write summary at step 2290  Loss:  0.5412539839744568\n",
      "Write summary at step 2300  Loss:  0.6926225423812866\n",
      "Write summary at step 2310  Loss:  0.5152995586395264\n",
      "Write summary at step 2320  Loss:  0.667068600654602\n",
      "Write summary at step 2330  Loss:  0.7010184526443481\n",
      "Write summary at step 2340  Loss:  0.5801240801811218\n",
      "Write summary at step 2350  Loss:  0.5328708291053772\n",
      "=================================================\n",
      "Epoch 23 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8673469387755102 Acurracy Control:  0.6174863387978142 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.7804569797150469\n",
      "Loss normal: 0.3754441379284372 Loss Control: 0.6813465923559471 Loss Patient: 0.2822991308574867 Loss balanced:  0.4818228616067169 Loss1+loss2: 0.4818228616067169\n",
      "Write summary at step 2360  Loss:  0.7232314348220825\n",
      "Write summary at step 2370  Loss:  0.455390989780426\n",
      "Write summary at step 2380  Loss:  0.5750699639320374\n",
      "Write summary at step 2390  Loss:  0.5752076506614685\n",
      "Write summary at step 2400  Loss:  0.3579646348953247\n",
      "Write summary at step 2410  Loss:  0.6586686372756958\n",
      "Write summary at step 2420  Loss:  0.5365104675292969\n",
      "Write summary at step 2430  Loss:  0.2919166386127472\n",
      "Write summary at step 2440  Loss:  0.6107853651046753\n",
      "Write summary at step 2450  Loss:  0.7096778154373169\n",
      "=================================================\n",
      "Epoch 24 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8507653061224489 Acurracy Control:  0.5191256830601093 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.7354363856232327\n",
      "Loss normal: 0.3649834044733826 Loss Control: 0.8943647647815975 Loss Patient: 0.20379074448456186 Loss balanced:  0.5490777546330797 Loss1+loss2: 0.5490777546330797\n",
      "Write summary at step 2460  Loss:  0.4975997507572174\n",
      "Write summary at step 2470  Loss:  0.3441416323184967\n",
      "Write summary at step 2480  Loss:  0.5879507064819336\n",
      "Write summary at step 2490  Loss:  0.5223172903060913\n",
      "Write summary at step 2500  Loss:  0.7385251522064209\n",
      "Saved checkpoint to: result/42/panns/checkpoint_2500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8647959183673469 Acurracy Control:  0.5573770491803278 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.7578898557049726\n",
      "Loss normal: 0.3440955519980314 Loss Control: 0.8338913696059764 Loss Patient: 0.19495639571929335 Loss balanced:  0.5144238826626348 Loss1+loss2: 0.5144238826626348\n",
      "Write summary at step 2510  Loss:  0.506730854511261\n",
      "Write summary at step 2520  Loss:  0.7199315428733826\n",
      "Write summary at step 2530  Loss:  0.6053934097290039\n",
      "Write summary at step 2540  Loss:  0.35983699560165405\n",
      "=================================================\n",
      "Epoch 25 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8214285714285714 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.78369384359401 Acurracy Balanced 0.8645245174254204\n",
      "Loss normal: 0.43128721780922946 Loss Control: 0.32849110736221565 Loss Patient: 0.4625878665292521 Loss balanced:  0.3955394869457339 Loss1+loss2: 0.3955394869457339\n",
      "\n",
      " > BEST MODEL (0.39554) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2550  Loss:  0.47396332025527954\n",
      "Write summary at step 2560  Loss:  0.4476579427719116\n",
      "Write summary at step 2570  Loss:  0.4776538610458374\n",
      "Write summary at step 2580  Loss:  0.5202314257621765\n",
      "Write summary at step 2590  Loss:  0.35454216599464417\n",
      "Write summary at step 2600  Loss:  0.4867071509361267\n",
      "Write summary at step 2610  Loss:  0.7909544706344604\n",
      "Write summary at step 2620  Loss:  0.5105995535850525\n",
      "Write summary at step 2630  Loss:  0.5775526762008667\n",
      "Write summary at step 2640  Loss:  0.5158843994140625\n",
      "=================================================\n",
      "Epoch 26 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.860969387755102 Acurracy Control:  0.8907103825136612 Acurracy Patient:  0.8519134775374376 Acurracy Balanced 0.8713119300255494\n",
      "Loss normal: 0.40167073677388987 Loss Control: 0.3931391115397052 Loss Patient: 0.4042685494050012 Loss balanced:  0.3987038304723532 Loss1+loss2: 0.3987038304723532\n",
      "Write summary at step 2650  Loss:  0.4528670012950897\n",
      "Write summary at step 2660  Loss:  0.4394237697124481\n",
      "Write summary at step 2670  Loss:  0.3252856731414795\n",
      "Write summary at step 2680  Loss:  0.6743517518043518\n",
      "Write summary at step 2690  Loss:  0.6441249847412109\n",
      "Write summary at step 2700  Loss:  0.5723239779472351\n",
      "Write summary at step 2710  Loss:  0.596554696559906\n",
      "Write summary at step 2720  Loss:  0.6820686459541321\n",
      "Write summary at step 2730  Loss:  0.617411732673645\n",
      "Write summary at step 2740  Loss:  0.5356432199478149\n",
      "=================================================\n",
      "Epoch 27 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8303571428571429 Acurracy Control:  0.9234972677595629 Acurracy Patient:  0.8019966722129783 Acurracy Balanced 0.8627469699862707\n",
      "Loss normal: 0.4208017472101718 Loss Control: 0.3210354997812073 Loss Patient: 0.45117982126115364 Loss balanced:  0.3861076605211805 Loss1+loss2: 0.3861076605211805\n",
      "\n",
      " > BEST MODEL (0.38611) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2750  Loss:  0.42557045817375183\n",
      "Write summary at step 2760  Loss:  0.43325507640838623\n",
      "Write summary at step 2770  Loss:  0.5696353316307068\n",
      "Write summary at step 2780  Loss:  0.6043676137924194\n",
      "Write summary at step 2790  Loss:  0.5733089447021484\n",
      "Write summary at step 2800  Loss:  0.5156932473182678\n",
      "Write summary at step 2810  Loss:  0.433163046836853\n",
      "Write summary at step 2820  Loss:  0.4670847952365875\n",
      "Write summary at step 2830  Loss:  0.3895229697227478\n",
      "Write summary at step 2840  Loss:  0.6511602401733398\n",
      "=================================================\n",
      "Epoch 28 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8826530612244898 Acurracy Control:  0.8633879781420765 Acurracy Patient:  0.8885191347753744 Acurracy Balanced 0.8759535564587254\n",
      "Loss normal: 0.3108472275186558 Loss Control: 0.4142988379535779 Loss Patient: 0.2793469823239845 Loss balanced:  0.3468229101387812 Loss1+loss2: 0.3468229101387812\n",
      "\n",
      " > BEST MODEL (0.34682) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 2850  Loss:  0.7121222019195557\n",
      "Write summary at step 2860  Loss:  0.6677233576774597\n",
      "Write summary at step 2870  Loss:  0.521183431148529\n",
      "Write summary at step 2880  Loss:  0.4576559066772461\n",
      "Write summary at step 2890  Loss:  0.4793104827404022\n",
      "Write summary at step 2900  Loss:  0.8203089237213135\n",
      "Write summary at step 2910  Loss:  0.4808741807937622\n",
      "Write summary at step 2920  Loss:  0.6127867102622986\n",
      "Write summary at step 2930  Loss:  0.5394918918609619\n",
      "Write summary at step 2940  Loss:  0.5482094287872314\n",
      "=================================================\n",
      "Epoch 29 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8635204081632653 Acurracy Control:  0.5737704918032787 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.7627587899948174\n",
      "Loss normal: 0.3709902056321806 Loss Control: 0.7038718924496343 Loss Patient: 0.2696302236118253 Loss balanced:  0.4867510580307298 Loss1+loss2: 0.4867510580307298\n",
      "Write summary at step 2950  Loss:  0.41563543677330017\n",
      "Write summary at step 2960  Loss:  0.4455639123916626\n",
      "Write summary at step 2970  Loss:  0.4923156499862671\n",
      "Write summary at step 2980  Loss:  0.5617873668670654\n",
      "Write summary at step 2990  Loss:  0.9063469767570496\n",
      "Write summary at step 3000  Loss:  0.4698450565338135\n",
      "Saved checkpoint to: result/42/panns/checkpoint_3000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8775510204081632 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9101497504159733 Acurracy Balanced 0.8403207768473309\n",
      "Loss normal: 0.3673557347180892 Loss Control: 0.5269203889565389 Loss Patient: 0.31876949318831854 Loss balanced:  0.42284494107242876 Loss1+loss2: 0.42284494107242876\n",
      "Write summary at step 3010  Loss:  0.39398854970932007\n",
      "Write summary at step 3020  Loss:  0.7777752876281738\n",
      "Write summary at step 3030  Loss:  0.5259776711463928\n",
      "=================================================\n",
      "Epoch 30 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8775510204081632 Acurracy Control:  0.9016393442622951 Acurracy Patient:  0.870216306156406 Acurracy Balanced 0.8859278252093505\n",
      "Loss normal: 0.3749025871559065 Loss Control: 0.3624836864367209 Loss Patient: 0.3786840495372969 Loss balanced:  0.37058386798700893 Loss1+loss2: 0.37058386798700893\n",
      "Write summary at step 3040  Loss:  0.30418089032173157\n",
      "Write summary at step 3050  Loss:  0.456717312335968\n",
      "Write summary at step 3060  Loss:  0.5703883767127991\n",
      "Write summary at step 3070  Loss:  0.577250063419342\n",
      "Write summary at step 3080  Loss:  0.2356104552745819\n",
      "Write summary at step 3090  Loss:  0.6570255756378174\n",
      "Write summary at step 3100  Loss:  0.48896217346191406\n",
      "Write summary at step 3110  Loss:  0.6853266954421997\n",
      "Write summary at step 3120  Loss:  0.8197804689407349\n",
      "Write summary at step 3130  Loss:  0.6065024137496948\n",
      "=================================================\n",
      "Epoch 31 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8533163265306123 Acurracy Control:  0.47540983606557374 Acurracy Patient:  0.9683860232945092 Acurracy Balanced 0.7218979296800414\n",
      "Loss normal: 0.3385598927888335 Loss Control: 0.9664949015841457 Loss Patient: 0.14735838453503894 Loss balanced:  0.5569266430595924 Loss1+loss2: 0.5569266430595924\n",
      "Write summary at step 3140  Loss:  0.5728402733802795\n",
      "Write summary at step 3150  Loss:  0.6137440204620361\n",
      "Write summary at step 3160  Loss:  0.6072331666946411\n",
      "Write summary at step 3170  Loss:  0.42958253622055054\n",
      "Write summary at step 3180  Loss:  0.45795804262161255\n",
      "Write summary at step 3190  Loss:  0.965135931968689\n",
      "Write summary at step 3200  Loss:  0.4999985098838806\n",
      "Write summary at step 3210  Loss:  0.5810708999633789\n",
      "Write summary at step 3220  Loss:  0.3005469739437103\n",
      "Write summary at step 3230  Loss:  0.412436306476593\n",
      "=================================================\n",
      "Epoch 32 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9251247920133111 Acurracy Balanced 0.8669339807061092\n",
      "Loss normal: 0.3115384855440685 Loss Control: 0.5269932812028896 Loss Patient: 0.2459341133642514 Loss balanced:  0.3864636972835705 Loss1+loss2: 0.3864636972835705\n",
      "Write summary at step 3240  Loss:  0.49053847789764404\n",
      "Write summary at step 3250  Loss:  0.45152610540390015\n",
      "Write summary at step 3260  Loss:  0.575265645980835\n",
      "Write summary at step 3270  Loss:  0.5250133275985718\n",
      "Write summary at step 3280  Loss:  0.28776800632476807\n",
      "Write summary at step 3290  Loss:  0.5327970385551453\n",
      "Write summary at step 3300  Loss:  0.5797596573829651\n",
      "Write summary at step 3310  Loss:  0.5797164440155029\n",
      "Write summary at step 3320  Loss:  0.5431464910507202\n",
      "Write summary at step 3330  Loss:  0.5945098996162415\n",
      "=================================================\n",
      "Epoch 33 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8278061224489796 Acurracy Control:  0.39344262295081966 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.6767545893456262\n",
      "Loss normal: 0.37808526600045816 Loss Control: 1.0525422734640986 Loss Patient: 0.17271815868909665 Loss balanced:  0.6126302160765976 Loss1+loss2: 0.6126302160765976\n",
      "Write summary at step 3340  Loss:  0.3663467764854431\n",
      "Write summary at step 3350  Loss:  0.4683294892311096\n",
      "Write summary at step 3360  Loss:  0.4858890771865845\n",
      "Write summary at step 3370  Loss:  0.43168312311172485\n",
      "Write summary at step 3380  Loss:  0.5345485210418701\n",
      "Write summary at step 3390  Loss:  0.792059600353241\n",
      "Write summary at step 3400  Loss:  0.7176719307899475\n",
      "Write summary at step 3410  Loss:  0.5859733819961548\n",
      "Write summary at step 3420  Loss:  0.6794954538345337\n",
      "Write summary at step 3430  Loss:  0.5273113250732422\n",
      "=================================================\n",
      "Epoch 34 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8737244897959183 Acurracy Control:  0.9453551912568307 Acurracy Patient:  0.8519134775374376 Acurracy Balanced 0.8986343343971341\n",
      "Loss normal: 0.3765983576981389 Loss Control: 0.2542389650813869 Loss Patient: 0.4138558741020482 Loss balanced:  0.3340474195917176 Loss1+loss2: 0.3340474195917176\n",
      "\n",
      " > BEST MODEL (0.33405) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 3440  Loss:  0.6619077920913696\n",
      "Write summary at step 3450  Loss:  0.5612601637840271\n",
      "Write summary at step 3460  Loss:  0.4081273674964905\n",
      "Write summary at step 3470  Loss:  0.5666945576667786\n",
      "Write summary at step 3480  Loss:  0.43662646412849426\n",
      "Write summary at step 3490  Loss:  0.4258107542991638\n",
      "Write summary at step 3500  Loss:  0.504539430141449\n",
      "Saved checkpoint to: result/42/panns/checkpoint_3500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8903061224489796 Acurracy Control:  0.8961748633879781 Acurracy Patient:  0.8885191347753744 Acurracy Balanced 0.8923469990816763\n",
      "Loss normal: 0.3335824918990232 Loss Control: 0.3174353987792802 Loss Patient: 0.33849916025723475 Loss balanced:  0.32796727951825744 Loss1+loss2: 0.32796727951825744\n",
      "\n",
      " > BEST MODEL (0.32797) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 3510  Loss:  0.833127498626709\n",
      "Write summary at step 3520  Loss:  0.2792535424232483\n",
      "=================================================\n",
      "Epoch 35 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8979591836734694 Acurracy Control:  0.8524590163934426 Acurracy Patient:  0.9118136439267887 Acurracy Balanced 0.8821363301601156\n",
      "Loss normal: 0.31194662819711527 Loss Control: 0.3919097354503277 Loss Patient: 0.2875984600945043 Loss balanced:  0.339754097772416 Loss1+loss2: 0.339754097772416\n",
      "Write summary at step 3530  Loss:  0.37902945280075073\n",
      "Write summary at step 3540  Loss:  0.6308324337005615\n",
      "Write summary at step 3550  Loss:  0.7571794390678406\n",
      "Write summary at step 3560  Loss:  0.5887421369552612\n",
      "Write summary at step 3570  Loss:  0.5340757369995117\n",
      "Write summary at step 3580  Loss:  0.33330631256103516\n",
      "Write summary at step 3590  Loss:  0.5417607426643372\n",
      "Write summary at step 3600  Loss:  0.5305713415145874\n",
      "Write summary at step 3610  Loss:  0.4377595782279968\n",
      "Write summary at step 3620  Loss:  0.5062359571456909\n",
      "=================================================\n",
      "Epoch 36 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8826530612244898 Acurracy Control:  0.6666666666666666 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.807542983915696\n",
      "Loss normal: 0.3362945005753819 Loss Control: 0.6714334996020208 Loss Patient: 0.2342471839633837 Loss balanced:  0.45284034178270227 Loss1+loss2: 0.45284034178270227\n",
      "Write summary at step 3630  Loss:  0.6009080410003662\n",
      "Write summary at step 3640  Loss:  0.4475308656692505\n",
      "Write summary at step 3650  Loss:  0.47887474298477173\n",
      "Write summary at step 3660  Loss:  0.37784692645072937\n",
      "Write summary at step 3670  Loss:  0.6932294368743896\n",
      "Write summary at step 3680  Loss:  0.3752436637878418\n",
      "Write summary at step 3690  Loss:  0.4344121217727661\n",
      "Write summary at step 3700  Loss:  0.42313987016677856\n",
      "Write summary at step 3710  Loss:  0.5779200792312622\n",
      "Write summary at step 3720  Loss:  0.6261496543884277\n",
      "=================================================\n",
      "Epoch 37 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.7814207650273224 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.8582644590527626\n",
      "Loss normal: 0.29182060671095944 Loss Control: 0.5537662616844385 Loss Patient: 0.21206011121066756 Loss balanced:  0.38291318644755307 Loss1+loss2: 0.38291318644755307\n",
      "Write summary at step 3730  Loss:  0.438706636428833\n",
      "Write summary at step 3740  Loss:  0.4793468117713928\n",
      "Write summary at step 3750  Loss:  0.49741339683532715\n",
      "Write summary at step 3760  Loss:  0.5895987749099731\n",
      "Write summary at step 3770  Loss:  0.7590732574462891\n",
      "Write summary at step 3780  Loss:  0.8217968344688416\n",
      "Write summary at step 3790  Loss:  0.4423721730709076\n",
      "Write summary at step 3800  Loss:  0.4607079029083252\n",
      "Write summary at step 3810  Loss:  0.7226261496543884\n",
      "Write summary at step 3820  Loss:  0.43634530901908875\n",
      "=================================================\n",
      "Epoch 38 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.6939890710382514 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.8261958666339344\n",
      "Loss normal: 0.29463296558479873 Loss Control: 0.6498560332209686 Loss Patient: 0.18647020053546162 Loss balanced:  0.4181631168782151 Loss1+loss2: 0.4181631168782151\n",
      "Write summary at step 3830  Loss:  0.5091276168823242\n",
      "Write summary at step 3840  Loss:  0.6058446168899536\n",
      "Write summary at step 3850  Loss:  0.49063050746917725\n",
      "Write summary at step 3860  Loss:  0.4142829179763794\n",
      "Write summary at step 3870  Loss:  0.6640998125076294\n",
      "Write summary at step 3880  Loss:  0.4878760576248169\n",
      "Write summary at step 3890  Loss:  0.2945501208305359\n",
      "Write summary at step 3900  Loss:  0.6270719170570374\n",
      "Write summary at step 3910  Loss:  0.6573288440704346\n",
      "Write summary at step 3920  Loss:  0.44672340154647827\n",
      "=================================================\n",
      "Epoch 39 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8801020408163265 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.913477537437604 Acurracy Balanced 0.8419846703581462\n",
      "Loss normal: 0.33555098699063673 Loss Control: 0.5029686220356675 Loss Patient: 0.2845735759683536 Loss balanced:  0.39377109900201057 Loss1+loss2: 0.39377109900201057\n",
      "Write summary at step 3930  Loss:  0.621612548828125\n",
      "Write summary at step 3940  Loss:  0.5113791227340698\n",
      "Write summary at step 3950  Loss:  0.4560152292251587\n",
      "Write summary at step 3960  Loss:  0.4130447506904602\n",
      "Write summary at step 3970  Loss:  0.33326494693756104\n",
      "Write summary at step 3980  Loss:  0.5087510347366333\n",
      "Write summary at step 3990  Loss:  0.4192997217178345\n",
      "Write summary at step 4000  Loss:  0.4538717269897461\n",
      "Saved checkpoint to: result/42/panns/checkpoint_4000.pt\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.8985024958402662 Acurracy Balanced 0.8782129965540129\n",
      "Loss normal: 0.34582674974689676 Loss Control: 0.34839366303115593 Loss Patient: 0.3450451436733049 Loss balanced:  0.3467194033522304 Loss1+loss2: 0.3467194033522304\n",
      "Write summary at step 4010  Loss:  0.505533754825592\n",
      "=================================================\n",
      "Epoch 40 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.8951747088186356 Acurracy Balanced 0.8820135839175145\n",
      "Loss normal: 0.3600739120524757 Loss Control: 0.3489361747366483 Loss Patient: 0.36346526719171074 Loss balanced:  0.35620072096417954 Loss1+loss2: 0.35620072096417954\n",
      "Write summary at step 4020  Loss:  0.6107587814331055\n",
      "Write summary at step 4030  Loss:  0.5604712963104248\n",
      "Write summary at step 4040  Loss:  0.4045042097568512\n",
      "Write summary at step 4050  Loss:  0.4820960760116577\n",
      "Write summary at step 4060  Loss:  0.4704105854034424\n",
      "Write summary at step 4070  Loss:  0.4899698495864868\n",
      "Write summary at step 4080  Loss:  0.5408498048782349\n",
      "Write summary at step 4090  Loss:  0.21032337844371796\n",
      "Write summary at step 4100  Loss:  0.38506925106048584\n",
      "Write summary at step 4110  Loss:  0.3135991096496582\n",
      "=================================================\n",
      "Epoch 41 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8469387755102041 Acurracy Control:  0.45901639344262296 Acurracy Patient:  0.9650582362728786 Acurracy Balanced 0.7120373148577508\n",
      "Loss normal: 0.33361918486806813 Loss Control: 0.9266056050368345 Loss Patient: 0.15305925920580865 Loss balanced:  0.5398324321213216 Loss1+loss2: 0.5398324321213216\n",
      "Write summary at step 4120  Loss:  0.4269246757030487\n",
      "Write summary at step 4130  Loss:  0.27715003490448\n",
      "Write summary at step 4140  Loss:  0.48785483837127686\n",
      "Write summary at step 4150  Loss:  0.41115590929985046\n",
      "Write summary at step 4160  Loss:  0.5215739011764526\n",
      "Write summary at step 4170  Loss:  0.5427998304367065\n",
      "Write summary at step 4180  Loss:  0.37788695096969604\n",
      "Write summary at step 4190  Loss:  0.5715247392654419\n",
      "Write summary at step 4200  Loss:  0.6085987687110901\n",
      "Write summary at step 4210  Loss:  0.46623343229293823\n",
      "=================================================\n",
      "Epoch 42 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8290816326530612 Acurracy Control:  0.36065573770491804 Acurracy Patient:  0.9717138103161398 Acurracy Balanced 0.6661847740105289\n",
      "Loss normal: 0.3424589543090183 Loss Control: 1.0452500484028802 Loss Patient: 0.1284643303286811 Loss balanced:  0.5868571893657806 Loss1+loss2: 0.5868571893657806\n",
      "Write summary at step 4220  Loss:  0.46573108434677124\n",
      "Write summary at step 4230  Loss:  0.5691964626312256\n",
      "Write summary at step 4240  Loss:  0.270143985748291\n",
      "Write summary at step 4250  Loss:  0.4359544515609741\n",
      "Write summary at step 4260  Loss:  0.38170376420021057\n",
      "Write summary at step 4270  Loss:  0.5311899185180664\n",
      "Write summary at step 4280  Loss:  0.49540460109710693\n",
      "Write summary at step 4290  Loss:  0.39590704441070557\n",
      "Write summary at step 4300  Loss:  0.4197366237640381\n",
      "Write summary at step 4310  Loss:  0.6213672757148743\n",
      "=================================================\n",
      "Epoch 43 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8941326530612245 Acurracy Control:  0.7704918032786885 Acurracy Patient:  0.9317803660565723 Acurracy Balanced 0.8511360846676304\n",
      "Loss normal: 0.2910803517668831 Loss Control: 0.5260972768231168 Loss Patient: 0.21951945768219858 Loss balanced:  0.3728083672526577 Loss1+loss2: 0.3728083672526577\n",
      "Write summary at step 4320  Loss:  0.4938713312149048\n",
      "Write summary at step 4330  Loss:  0.4886974096298218\n",
      "Write summary at step 4340  Loss:  0.4373486638069153\n",
      "Write summary at step 4350  Loss:  0.6840869188308716\n",
      "Write summary at step 4360  Loss:  0.5666669607162476\n",
      "Write summary at step 4370  Loss:  0.47464519739151\n",
      "Write summary at step 4380  Loss:  0.7974830269813538\n",
      "Write summary at step 4390  Loss:  0.7552364468574524\n",
      "Write summary at step 4400  Loss:  0.4016968011856079\n",
      "Write summary at step 4410  Loss:  0.5668388605117798\n",
      "=================================================\n",
      "Epoch 44 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8762755102040817 Acurracy Control:  0.8852459016393442 Acurracy Patient:  0.8735440931780366 Acurracy Balanced 0.8793949974086904\n",
      "Loss normal: 0.3405950586406552 Loss Control: 0.3491402805828657 Loss Patient: 0.3379930999632088 Loss balanced:  0.34356669027303727 Loss1+loss2: 0.34356669027303727\n",
      "Write summary at step 4420  Loss:  0.3967418670654297\n",
      "Write summary at step 4430  Loss:  0.42057910561561584\n",
      "Write summary at step 4440  Loss:  0.54130619764328\n",
      "Write summary at step 4450  Loss:  0.5275992155075073\n",
      "Write summary at step 4460  Loss:  0.5082014203071594\n",
      "Write summary at step 4470  Loss:  0.47314882278442383\n",
      "Write summary at step 4480  Loss:  0.34843575954437256\n",
      "Write summary at step 4490  Loss:  0.516075849533081\n",
      "Write summary at step 4500  Loss:  0.5907533168792725\n",
      "Saved checkpoint to: result/42/panns/checkpoint_4500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8915816326530612 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9217970049916805 Acurracy Balanced 0.8570733658838183\n",
      "Loss normal: 0.2877665236972424 Loss Control: 0.577209739085755 Loss Patient: 0.19963322940612593 Loss balanced:  0.3884214842459405 Loss1+loss2: 0.3884214842459405\n",
      "=================================================\n",
      "Epoch 45 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8494897959183674 Acurracy Control:  0.4972677595628415 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.7270032641408217\n",
      "Loss normal: 0.3345281089066851 Loss Control: 1.0315157285804957 Loss Patient: 0.12230059731373573 Loss balanced:  0.5769081629471157 Loss1+loss2: 0.5769081629471157\n",
      "Write summary at step 4510  Loss:  0.5607210397720337\n",
      "Write summary at step 4520  Loss:  0.562454104423523\n",
      "Write summary at step 4530  Loss:  0.39878129959106445\n",
      "Write summary at step 4540  Loss:  0.4998830258846283\n",
      "Write summary at step 4550  Loss:  0.7390587329864502\n",
      "Write summary at step 4560  Loss:  0.19927145540714264\n",
      "Write summary at step 4570  Loss:  0.39139246940612793\n",
      "Write summary at step 4580  Loss:  0.45344558358192444\n",
      "Write summary at step 4590  Loss:  0.4926966726779938\n",
      "Write summary at step 4600  Loss:  0.43827301263809204\n",
      "=================================================\n",
      "Epoch 46 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8545918367346939 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.7455334006164589\n",
      "Loss normal: 0.3253450228699616 Loss Control: 0.8244324863934126 Loss Patient: 0.17337662179934205 Loss balanced:  0.49890455409637735 Loss1+loss2: 0.49890455409637735\n",
      "Write summary at step 4610  Loss:  0.4061797857284546\n",
      "Write summary at step 4620  Loss:  0.5091155767440796\n",
      "Write summary at step 4630  Loss:  0.5772219300270081\n",
      "Write summary at step 4640  Loss:  0.3467556834220886\n",
      "Write summary at step 4650  Loss:  0.49271640181541443\n",
      "Write summary at step 4660  Loss:  0.2892514765262604\n",
      "Write summary at step 4670  Loss:  0.5795163512229919\n",
      "Write summary at step 4680  Loss:  0.38611435890197754\n",
      "Write summary at step 4690  Loss:  0.34585586190223694\n",
      "Write summary at step 4700  Loss:  0.6332311630249023\n",
      "=================================================\n",
      "Epoch 47 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8737244897959183 Acurracy Control:  0.9180327868852459 Acurracy Patient:  0.8602329450915142 Acurracy Balanced 0.88913286598838\n",
      "Loss normal: 0.32858663736557475 Loss Control: 0.26014370573022977 Loss Patient: 0.34942699857242093 Loss balanced:  0.30478535215132535 Loss1+loss2: 0.30478535215132535\n",
      "\n",
      " > BEST MODEL (0.30479) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 4710  Loss:  0.4564976990222931\n",
      "Write summary at step 4720  Loss:  0.43711787462234497\n",
      "Write summary at step 4730  Loss:  0.46489453315734863\n",
      "Write summary at step 4740  Loss:  0.6600237488746643\n",
      "Write summary at step 4750  Loss:  0.4643043577671051\n",
      "Write summary at step 4760  Loss:  0.527784526348114\n",
      "Write summary at step 4770  Loss:  0.37454310059547424\n",
      "Write summary at step 4780  Loss:  0.44242990016937256\n",
      "Write summary at step 4790  Loss:  0.585887610912323\n",
      "Write summary at step 4800  Loss:  0.5093623399734497\n",
      "=================================================\n",
      "Epoch 48 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8099489795918368 Acurracy Control:  0.2677595628415301 Acurracy Patient:  0.9750415973377704 Acurracy Balanced 0.6214005800896503\n",
      "Loss normal: 0.4040040801450306 Loss Control: 1.4592694167882367 Loss Patient: 0.08268368846044168 Loss balanced:  0.7709765526243392 Loss1+loss2: 0.7709765526243392\n",
      "Write summary at step 4810  Loss:  0.5755847096443176\n",
      "Write summary at step 4820  Loss:  0.5524802207946777\n",
      "Write summary at step 4830  Loss:  0.5407416820526123\n",
      "Write summary at step 4840  Loss:  0.5180631875991821\n",
      "Write summary at step 4850  Loss:  0.4860948920249939\n",
      "Write summary at step 4860  Loss:  0.34406161308288574\n",
      "Write summary at step 4870  Loss:  0.3602465093135834\n",
      "Write summary at step 4880  Loss:  0.7598224878311157\n",
      "Write summary at step 4890  Loss:  0.6516615748405457\n",
      "Write summary at step 4900  Loss:  0.7420203685760498\n",
      "=================================================\n",
      "Epoch 49 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.7978142076502732 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.8672931271196458\n",
      "Loss normal: 0.26416249212105664 Loss Control: 0.5378030330105558 Loss Patient: 0.1808409991359552 Loss balanced:  0.3593220160732555 Loss1+loss2: 0.3593220160732555\n",
      "Write summary at step 4910  Loss:  0.5682775974273682\n",
      "Write summary at step 4920  Loss:  0.3901976943016052\n",
      "Write summary at step 4930  Loss:  0.51423180103302\n",
      "Write summary at step 4940  Loss:  0.40994250774383545\n",
      "Write summary at step 4950  Loss:  0.49583861231803894\n",
      "Write summary at step 4960  Loss:  0.5591670274734497\n",
      "Write summary at step 4970  Loss:  0.6421976089477539\n",
      "Write summary at step 4980  Loss:  0.4406861960887909\n",
      "Write summary at step 4990  Loss:  0.6098830699920654\n",
      "=================================================\n",
      "Epoch 50 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8826530612244898 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.8652246256239601 Acurracy Balanced 0.9025576680032369\n",
      "Loss normal: 0.33107454063636915 Loss Control: 0.29609150508713855 Loss Patient: 0.3417266115372669 Loss balanced:  0.31890905831220273 Loss1+loss2: 0.31890905831220273\n",
      "Write summary at step 5000  Loss:  0.5202398896217346\n",
      "Saved checkpoint to: result/42/panns/checkpoint_5000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8864795918367347 Acurracy Control:  0.9398907103825137 Acurracy Patient:  0.870216306156406 Acurracy Balanced 0.9050535082694598\n",
      "Loss normal: 0.33114928797799714 Loss Control: 0.29614916981243694 Loss Patient: 0.34180656001095766 Loss balanced:  0.31897786491169733 Loss1+loss2: 0.31897786491169733\n",
      "Write summary at step 5010  Loss:  0.31824618577957153\n",
      "Write summary at step 5020  Loss:  0.4373345971107483\n",
      "Write summary at step 5030  Loss:  0.3957139253616333\n",
      "Write summary at step 5040  Loss:  0.23335686326026917\n",
      "Write summary at step 5050  Loss:  0.2814509868621826\n",
      "Write summary at step 5060  Loss:  0.5910422205924988\n",
      "Write summary at step 5070  Loss:  0.3731082081794739\n",
      "Write summary at step 5080  Loss:  0.4896555244922638\n",
      "Write summary at step 5090  Loss:  0.6159144639968872\n",
      "=================================================\n",
      "Epoch 51 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8877551020408163 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.8818635607321131 Acurracy Balanced 0.8944836929343626\n",
      "Loss normal: 0.32930106027241873 Loss Control: 0.2759263129507909 Loss Patient: 0.34555327098897215 Loss balanced:  0.31073979196988155 Loss1+loss2: 0.31073979196988155\n",
      "Write summary at step 5100  Loss:  0.49468183517456055\n",
      "Write summary at step 5110  Loss:  0.45095205307006836\n",
      "Write summary at step 5120  Loss:  0.7350426316261292\n",
      "Write summary at step 5130  Loss:  0.35455551743507385\n",
      "Write summary at step 5140  Loss:  0.5551754236221313\n",
      "Write summary at step 5150  Loss:  0.6511856317520142\n",
      "Write summary at step 5160  Loss:  0.590768039226532\n",
      "Write summary at step 5170  Loss:  0.5923967361450195\n",
      "Write summary at step 5180  Loss:  0.3122301697731018\n",
      "Write summary at step 5190  Loss:  0.7289201021194458\n",
      "=================================================\n",
      "Epoch 52 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.726775956284153 Acurracy Patient:  0.9484193011647255 Acurracy Balanced 0.8375976287244393\n",
      "Loss normal: 0.28976920277488477 Loss Control: 0.5881243269951617 Loss Patient: 0.1989223036214635 Loss balanced:  0.3935233153083126 Loss1+loss2: 0.3935233153083126\n",
      "Write summary at step 5200  Loss:  0.3668436110019684\n",
      "Write summary at step 5210  Loss:  0.4499843716621399\n",
      "Write summary at step 5220  Loss:  0.44276753067970276\n",
      "Write summary at step 5230  Loss:  0.3131047487258911\n",
      "Write summary at step 5240  Loss:  0.5112432241439819\n",
      "Write summary at step 5250  Loss:  0.42006975412368774\n",
      "Write summary at step 5260  Loss:  0.9471988677978516\n",
      "Write summary at step 5270  Loss:  0.5212056636810303\n",
      "Write summary at step 5280  Loss:  0.5398196578025818\n",
      "Write summary at step 5290  Loss:  0.5305653810501099\n",
      "=================================================\n",
      "Epoch 53 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8635204081632653 Acurracy Control:  0.5573770491803278 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.7570579089495649\n",
      "Loss normal: 0.3014472288706777 Loss Control: 0.8108464981037411 Loss Patient: 0.1463389649441754 Loss balanced:  0.47859273152395826 Loss1+loss2: 0.47859273152395826\n",
      "Write summary at step 5300  Loss:  0.4579712748527527\n",
      "Write summary at step 5310  Loss:  0.4643201231956482\n",
      "Write summary at step 5320  Loss:  0.6328449249267578\n",
      "Write summary at step 5330  Loss:  0.5918050408363342\n",
      "Write summary at step 5340  Loss:  0.39851558208465576\n",
      "Write summary at step 5350  Loss:  0.42266374826431274\n",
      "Write summary at step 5360  Loss:  0.3836629092693329\n",
      "Write summary at step 5370  Loss:  0.38181397318840027\n",
      "Write summary at step 5380  Loss:  0.49838948249816895\n",
      "Write summary at step 5390  Loss:  0.5440442562103271\n",
      "=================================================\n",
      "Epoch 54 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.73224043715847 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.8345062418737441\n",
      "Loss normal: 0.2824730641227596 Loss Control: 0.5715866707713226 Loss Patient: 0.19444013628705767 Loss balanced:  0.38301340352919017 Loss1+loss2: 0.38301340352919017\n",
      "Write summary at step 5400  Loss:  0.4447861611843109\n",
      "Write summary at step 5410  Loss:  0.4040672183036804\n",
      "Write summary at step 5420  Loss:  0.26082897186279297\n",
      "Write summary at step 5430  Loss:  0.4770798683166504\n",
      "Write summary at step 5440  Loss:  0.6372765302658081\n",
      "Write summary at step 5450  Loss:  0.496087908744812\n",
      "Write summary at step 5460  Loss:  0.2719759941101074\n",
      "Write summary at step 5470  Loss:  0.4364246129989624\n",
      "Write summary at step 5480  Loss:  0.6328869462013245\n",
      "=================================================\n",
      "Epoch 55 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8188775510204082 Acurracy Control:  0.9890710382513661 Acurracy Patient:  0.7670549084858569 Acurracy Balanced 0.8780629733686115\n",
      "Loss normal: 0.46496969883387185 Loss Control: 0.09875869832403673 Loss Patient: 0.5764782039972391 Loss balanced:  0.33761845116063793 Loss1+loss2: 0.33761845116063793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 5490  Loss:  0.4295021593570709\n",
      "Write summary at step 5500  Loss:  0.33801427483558655\n",
      "Saved checkpoint to: result/42/panns/checkpoint_5500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8826530612244898 Acurracy Control:  0.9344262295081968 Acurracy Patient:  0.8668885191347754 Acurracy Balanced 0.9006573743214861\n",
      "Loss normal: 0.3187724583763249 Loss Control: 0.22628785710517174 Loss Patient: 0.34693332589208187 Loss balanced:  0.2866105914986268 Loss1+loss2: 0.2866105914986268\n",
      "\n",
      " > BEST MODEL (0.28661) : result/42/panns/best_checkpoint.pt\n",
      "Write summary at step 5510  Loss:  0.39364588260650635\n",
      "Write summary at step 5520  Loss:  0.31205859780311584\n",
      "Write summary at step 5530  Loss:  0.2901649475097656\n",
      "Write summary at step 5540  Loss:  0.4537157416343689\n",
      "Write summary at step 5550  Loss:  0.7422983646392822\n",
      "Write summary at step 5560  Loss:  0.5130676627159119\n",
      "Write summary at step 5570  Loss:  0.34044694900512695\n",
      "Write summary at step 5580  Loss:  0.37548571825027466\n",
      "=================================================\n",
      "Epoch 56 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8915816326530612 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9118136439267887 Acurracy Balanced 0.8684751279743232\n",
      "Loss normal: 0.28777450285091694 Loss Control: 0.43900847956131067 Loss Patient: 0.24172488633487466 Loss balanced:  0.3403666829480927 Loss1+loss2: 0.3403666829480927\n",
      "Write summary at step 5590  Loss:  0.3738808035850525\n",
      "Write summary at step 5600  Loss:  0.6479148864746094\n",
      "Write summary at step 5610  Loss:  0.47058016061782837\n",
      "Write summary at step 5620  Loss:  0.33419322967529297\n",
      "Write summary at step 5630  Loss:  0.5336905717849731\n",
      "Write summary at step 5640  Loss:  0.5056581497192383\n",
      "Write summary at step 5650  Loss:  0.511323094367981\n",
      "Write summary at step 5660  Loss:  0.3773762583732605\n",
      "Write summary at step 5670  Loss:  0.3770396113395691\n",
      "Write summary at step 5680  Loss:  0.3822517395019531\n",
      "=================================================\n",
      "Epoch 57 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8711734693877551 Acurracy Control:  0.5846994535519126 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.771551057890765\n",
      "Loss normal: 0.30925286234337457 Loss Control: 0.7984640253046171 Loss Patient: 0.16029172956001342 Loss balanced:  0.4793778774323153 Loss1+loss2: 0.4793778774323153\n",
      "Write summary at step 5690  Loss:  0.4452579617500305\n",
      "Write summary at step 5700  Loss:  0.3111892342567444\n",
      "Write summary at step 5710  Loss:  0.37864261865615845\n",
      "Write summary at step 5720  Loss:  0.4335305690765381\n",
      "Write summary at step 5730  Loss:  0.9431132674217224\n",
      "Write summary at step 5740  Loss:  0.3158925473690033\n",
      "Write summary at step 5750  Loss:  0.4223060607910156\n",
      "Write summary at step 5760  Loss:  0.43069642782211304\n",
      "Write summary at step 5770  Loss:  0.55877685546875\n",
      "Write summary at step 5780  Loss:  0.377874493598938\n",
      "=================================================\n",
      "Epoch 58 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.8469945355191257 Acurracy Patient:  0.9118136439267887 Acurracy Balanced 0.8794040897229571\n",
      "Loss normal: 0.2838243150285312 Loss Control: 0.4124803289038236 Loss Patient: 0.24464951983704147 Loss balanced:  0.3285649243704325 Loss1+loss2: 0.3285649243704325\n",
      "Write summary at step 5790  Loss:  0.3806520700454712\n",
      "Write summary at step 5800  Loss:  0.498492032289505\n",
      "Write summary at step 5810  Loss:  0.37776798009872437\n",
      "Write summary at step 5820  Loss:  0.3565307557582855\n",
      "Write summary at step 5830  Loss:  0.5930081009864807\n",
      "Write summary at step 5840  Loss:  0.3183213472366333\n",
      "Write summary at step 5850  Loss:  0.257010817527771\n",
      "Write summary at step 5860  Loss:  0.24677537381649017\n",
      "Write summary at step 5870  Loss:  0.5259577035903931\n",
      "Write summary at step 5880  Loss:  0.43666014075279236\n",
      "=================================================\n",
      "Epoch 59 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.875 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.7968504223379977\n",
      "Loss normal: 0.2879416435880929 Loss Control: 0.7100118229297993 Loss Patient: 0.15942443733703276 Loss balanced:  0.434718130133416 Loss1+loss2: 0.434718130133416\n",
      "Write summary at step 5890  Loss:  0.4342835545539856\n",
      "Write summary at step 5900  Loss:  0.5911166667938232\n",
      "Write summary at step 5910  Loss:  0.43729668855667114\n",
      "Write summary at step 5920  Loss:  0.5089889764785767\n",
      "Write summary at step 5930  Loss:  0.40655583143234253\n",
      "Write summary at step 5940  Loss:  0.3442128002643585\n",
      "Write summary at step 5950  Loss:  0.42824113368988037\n",
      "Write summary at step 5960  Loss:  0.5537825226783752\n",
      "Write summary at step 5970  Loss:  0.7569907307624817\n",
      "=================================================\n",
      "Epoch 60 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8788265306122449 Acurracy Control:  0.6284153005464481 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.7917450878772174\n",
      "Loss normal: 0.301149064560934 Loss Control: 0.6903041562096017 Loss Patient: 0.18265425085327192 Loss balanced:  0.4364792035314368 Loss1+loss2: 0.4364792035314368\n",
      "Write summary at step 5980  Loss:  0.41844481229782104\n",
      "Write summary at step 5990  Loss:  0.4537031054496765\n",
      "Write summary at step 6000  Loss:  0.5068463087081909\n",
      "Saved checkpoint to: result/42/panns/checkpoint_6000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8915816326530612 Acurracy Control:  0.6994535519125683 Acurracy Patient:  0.9500831946755408 Acurracy Balanced 0.8247683732940545\n",
      "Loss normal: 0.27877795741874345 Loss Control: 0.5986218680449522 Loss Patient: 0.181387883293351 Loss balanced:  0.3900048756691516 Loss1+loss2: 0.3900048756691516\n",
      "Write summary at step 6010  Loss:  0.5438157916069031\n",
      "Write summary at step 6020  Loss:  0.2752920091152191\n",
      "Write summary at step 6030  Loss:  0.4249280095100403\n",
      "Write summary at step 6040  Loss:  0.3718499541282654\n",
      "Write summary at step 6050  Loss:  0.6707274913787842\n",
      "Write summary at step 6060  Loss:  0.29361677169799805\n",
      "Write summary at step 6070  Loss:  0.20846763253211975\n",
      "=================================================\n",
      "Epoch 61 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.6775956284153005 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8155033050562359\n",
      "Loss normal: 0.266953137836286 Loss Control: 0.6285587008533582 Loss Patient: 0.15684695187305253 Loss balanced:  0.39270282636320536 Loss1+loss2: 0.39270282636320536\n",
      "Write summary at step 6080  Loss:  0.7075997591018677\n",
      "Write summary at step 6090  Loss:  0.4824519455432892\n",
      "Write summary at step 6100  Loss:  0.39468830823898315\n",
      "Write summary at step 6110  Loss:  0.3493492901325226\n",
      "Write summary at step 6120  Loss:  0.668806254863739\n",
      "Write summary at step 6130  Loss:  0.7915624380111694\n",
      "Write summary at step 6140  Loss:  0.4586116671562195\n",
      "Write summary at step 6150  Loss:  0.48095715045928955\n",
      "Write summary at step 6160  Loss:  0.5217217803001404\n",
      "Write summary at step 6170  Loss:  0.38313907384872437\n",
      "=================================================\n",
      "Epoch 62 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8941326530612245 Acurracy Control:  0.825136612021858 Acurracy Patient:  0.9151414309484193 Acurracy Balanced 0.8701390214851386\n",
      "Loss normal: 0.2864836161690099 Loss Control: 0.40536128920935544 Loss Patient: 0.25028625755460804 Loss balanced:  0.32782377338198176 Loss1+loss2: 0.32782377338198176\n",
      "Write summary at step 6180  Loss:  0.41568899154663086\n",
      "Write summary at step 6190  Loss:  0.5723679065704346\n",
      "Write summary at step 6200  Loss:  0.4968741536140442\n",
      "Write summary at step 6210  Loss:  0.3819482624530792\n",
      "Write summary at step 6220  Loss:  0.5143843293190002\n",
      "Write summary at step 6230  Loss:  0.5338183641433716\n",
      "Write summary at step 6240  Loss:  0.469174861907959\n",
      "Write summary at step 6250  Loss:  0.6640549898147583\n",
      "Write summary at step 6260  Loss:  0.28997671604156494\n",
      "Write summary at step 6270  Loss:  0.4147172272205353\n",
      "=================================================\n",
      "Epoch 63 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8928571428571429 Acurracy Control:  0.6885245901639344 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8217997326859605\n",
      "Loss normal: 0.2886445330721991 Loss Control: 0.6382248115018417 Loss Patient: 0.18219995793705177 Loss balanced:  0.41021238471944677 Loss1+loss2: 0.41021238471944677\n",
      "Write summary at step 6280  Loss:  0.5102114081382751\n",
      "Write summary at step 6290  Loss:  0.2949080467224121\n",
      "Write summary at step 6300  Loss:  0.3846468925476074\n",
      "Write summary at step 6310  Loss:  0.5603916645050049\n",
      "Write summary at step 6320  Loss:  0.3227648138999939\n",
      "Write summary at step 6330  Loss:  0.3572376072406769\n",
      "Write summary at step 6340  Loss:  0.25432437658309937\n",
      "Write summary at step 6350  Loss:  0.4435325562953949\n",
      "Write summary at step 6360  Loss:  0.3033992350101471\n",
      "Write summary at step 6370  Loss:  0.2451675981283188\n",
      "=================================================\n",
      "Epoch 64 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8520408163265306 Acurracy Control:  0.48633879781420764 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.7248665702881354\n",
      "Loss normal: 0.3248608700398888 Loss Control: 0.918102441589689 Loss Patient: 0.14422325572981415 Loss balanced:  0.5311628486597516 Loss1+loss2: 0.5311628486597516\n",
      "Write summary at step 6380  Loss:  0.4606354236602783\n",
      "Write summary at step 6390  Loss:  0.3715837597846985\n",
      "Write summary at step 6400  Loss:  0.40302419662475586\n",
      "Write summary at step 6410  Loss:  0.41966989636421204\n",
      "Write summary at step 6420  Loss:  0.24200868606567383\n",
      "Write summary at step 6430  Loss:  0.6706786155700684\n",
      "Write summary at step 6440  Loss:  0.5498725175857544\n",
      "Write summary at step 6450  Loss:  0.5209862589836121\n",
      "Write summary at step 6460  Loss:  0.3994092047214508\n",
      "=================================================\n",
      "Epoch 65 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.889030612244898 Acurracy Control:  0.6502732240437158 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.8060018366474819\n",
      "Loss normal: 0.2946669868364626 Loss Control: 0.7581518608364252 Loss Patient: 0.1535393089155191 Loss balanced:  0.45584558487597215 Loss1+loss2: 0.45584558487597215\n",
      "Write summary at step 6470  Loss:  0.5390470027923584\n",
      "Write summary at step 6480  Loss:  0.5318418741226196\n",
      "Write summary at step 6490  Loss:  0.4126315712928772\n",
      "Write summary at step 6500  Loss:  0.46636712551116943\n",
      "Saved checkpoint to: result/42/panns/checkpoint_6500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8737244897959183 Acurracy Control:  0.5792349726775956 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.7713146577198294\n",
      "Loss normal: 0.32159543447956745 Loss Control: 0.8900683076003861 Loss Patient: 0.14849969712450184 Loss balanced:  0.519284002362444 Loss1+loss2: 0.519284002362444\n",
      "Write summary at step 6510  Loss:  0.527977466583252\n",
      "Write summary at step 6520  Loss:  0.4044775068759918\n",
      "Write summary at step 6530  Loss:  0.49817466735839844\n",
      "Write summary at step 6540  Loss:  0.4909292459487915\n",
      "Write summary at step 6550  Loss:  0.45054638385772705\n",
      "Write summary at step 6560  Loss:  0.5152724385261536\n",
      "=================================================\n",
      "Epoch 66 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8418367346938775 Acurracy Control:  0.9617486338797814 Acurracy Patient:  0.8053244592346089 Acurracy Balanced 0.8835365465571952\n",
      "Loss normal: 0.4190838430456969 Loss Control: 0.1494742179991769 Loss Patient: 0.5011779575697 Loss balanced:  0.32532608778443844 Loss1+loss2: 0.32532608778443844\n",
      "Write summary at step 6570  Loss:  0.3797358572483063\n",
      "Write summary at step 6580  Loss:  0.47807741165161133\n",
      "Write summary at step 6590  Loss:  0.3668612241744995\n",
      "Write summary at step 6600  Loss:  0.41948267817497253\n",
      "Write summary at step 6610  Loss:  0.4349415898323059\n",
      "Write summary at step 6620  Loss:  0.540381908416748\n",
      "Write summary at step 6630  Loss:  0.40791571140289307\n",
      "Write summary at step 6640  Loss:  0.2723323106765747\n",
      "Write summary at step 6650  Loss:  0.533318042755127\n",
      "Write summary at step 6660  Loss:  0.442641943693161\n",
      "=================================================\n",
      "Epoch 67 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8839285714285714 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9051580698835274 Acurracy Balanced 0.8596828600783757\n",
      "Loss normal: 0.3187034250218041 Loss Control: 0.4087010941218809 Loss Patient: 0.29129981087170503 Loss balanced:  0.35000045249679296 Loss1+loss2: 0.35000045249679296\n",
      "Write summary at step 6670  Loss:  0.4483584463596344\n",
      "Write summary at step 6680  Loss:  0.28260698914527893\n",
      "Write summary at step 6690  Loss:  0.3517976701259613\n",
      "Write summary at step 6700  Loss:  0.5018746852874756\n",
      "Write summary at step 6710  Loss:  0.357376366853714\n",
      "Write summary at step 6720  Loss:  0.4898267388343811\n",
      "Write summary at step 6730  Loss:  0.29125258326530457\n",
      "Write summary at step 6740  Loss:  0.47578808665275574\n",
      "Write summary at step 6750  Loss:  0.3033010959625244\n",
      "Write summary at step 6760  Loss:  0.45281755924224854\n",
      "=================================================\n",
      "Epoch 68 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8915816326530612 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.9467554076539102 Acurracy Balanced 0.8285689606575561\n",
      "Loss normal: 0.28487117546705565 Loss Control: 0.6227131554337798 Loss Patient: 0.1820008217197488 Loss balanced:  0.4023569885767643 Loss1+loss2: 0.4023569885767643\n",
      "Write summary at step 6770  Loss:  0.4093934893608093\n",
      "Write summary at step 6780  Loss:  0.37533363699913025\n",
      "Write summary at step 6790  Loss:  0.4879004955291748\n",
      "Write summary at step 6800  Loss:  0.282157301902771\n",
      "Write summary at step 6810  Loss:  0.5996227264404297\n",
      "Write summary at step 6820  Loss:  0.6064804792404175\n",
      "Write summary at step 6830  Loss:  0.4118751883506775\n",
      "Write summary at step 6840  Loss:  0.5338954925537109\n",
      "Write summary at step 6850  Loss:  0.4721853733062744\n",
      "Write summary at step 6860  Loss:  0.42492353916168213\n",
      "=================================================\n",
      "Epoch 69 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.9367720465890182 Acurracy Balanced 0.850899684496695\n",
      "Loss normal: 0.2813761924982679 Loss Control: 0.5436477706731995 Loss Patient: 0.2015164572243484 Loss balanced:  0.37258211394877394 Loss1+loss2: 0.37258211394877394\n",
      "Write summary at step 6870  Loss:  0.4805133640766144\n",
      "Write summary at step 6880  Loss:  0.33964765071868896\n",
      "Write summary at step 6890  Loss:  0.41373366117477417\n",
      "Write summary at step 6900  Loss:  0.5679154396057129\n",
      "Write summary at step 6910  Loss:  0.4289790391921997\n",
      "Write summary at step 6920  Loss:  0.6801225543022156\n",
      "Write summary at step 6930  Loss:  0.8365634083747864\n",
      "Write summary at step 6940  Loss:  0.42612385749816895\n",
      "Write summary at step 6950  Loss:  0.35719889402389526\n",
      "=================================================\n",
      "Epoch 70 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9030612244897959 Acurracy Control:  0.7650273224043715 Acurracy Patient:  0.9450915141430949 Acurracy Balanced 0.8550594182737332\n",
      "Loss normal: 0.2917948316554634 Loss Control: 0.5344073655175381 Loss Patient: 0.2179211330989038 Loss balanced:  0.37616424930822095 Loss1+loss2: 0.37616424930822095\n",
      "Write summary at step 6960  Loss:  0.3781473636627197\n",
      "Write summary at step 6970  Loss:  0.45454686880111694\n",
      "Write summary at step 6980  Loss:  0.6038244962692261\n",
      "Write summary at step 6990  Loss:  0.42886513471603394\n",
      "Write summary at step 7000  Loss:  0.5723628997802734\n",
      "Saved checkpoint to: result/42/panns/checkpoint_7000.pt\n",
      "Validation:\n",
      "Acurracy:  0.8864795918367347 Acurracy Control:  0.6612021857923497 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.8081385305001683\n",
      "Loss normal: 0.28758213064652316 Loss Control: 0.6846826206790945 Loss Patient: 0.16666800398596512 Loss balanced:  0.4256753123325298 Loss1+loss2: 0.4256753123325298\n",
      "Write summary at step 7010  Loss:  0.5679294466972351\n",
      "Write summary at step 7020  Loss:  0.42870205640792847\n",
      "Write summary at step 7030  Loss:  0.524993896484375\n",
      "Write summary at step 7040  Loss:  0.2908743917942047\n",
      "Write summary at step 7050  Loss:  0.5695949792861938\n",
      "=================================================\n",
      "Epoch 71 End !\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.9094387755102041 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.8763217951865289\n",
      "Loss normal: 0.29265134249414715 Loss Control: 0.452493195325299 Loss Patient: 0.24398069433285274 Loss balanced:  0.34823694482907586 Loss1+loss2: 0.34823694482907586\n",
      "Write summary at step 7060  Loss:  0.3080498278141022\n",
      "Write summary at step 7070  Loss:  0.4310724139213562\n",
      "Write summary at step 7080  Loss:  0.19762912392616272\n",
      "Write summary at step 7090  Loss:  0.3239974081516266\n",
      "Write summary at step 7100  Loss:  0.48871272802352905\n",
      "Write summary at step 7110  Loss:  0.5938870906829834\n",
      "Write summary at step 7120  Loss:  0.4525792896747589\n",
      "Write summary at step 7130  Loss:  0.5387576818466187\n",
      "Write summary at step 7140  Loss:  0.4146750867366791\n",
      "Write summary at step 7150  Loss:  0.44193577766418457\n",
      "=================================================\n",
      "Epoch 72 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9017857142857143 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.8694298209723321\n",
      "Loss normal: 0.2849312271086537 Loss Control: 0.4248837685324455 Loss Patient: 0.24231672629143752 Loss balanced:  0.3336002474119415 Loss1+loss2: 0.3336002474119415\n",
      "Write summary at step 7160  Loss:  0.5174453854560852\n",
      "Write summary at step 7170  Loss:  0.3196737766265869\n",
      "Write summary at step 7180  Loss:  0.4591972529888153\n",
      "Write summary at step 7190  Loss:  0.3376742899417877\n",
      "Write summary at step 7200  Loss:  0.45039045810699463\n",
      "Write summary at step 7210  Loss:  0.36367473006248474\n",
      "Write summary at step 7220  Loss:  0.3819584846496582\n",
      "Write summary at step 7230  Loss:  0.47392988204956055\n",
      "Write summary at step 7240  Loss:  0.560157060623169\n",
      "Write summary at step 7250  Loss:  0.47743067145347595\n",
      "=================================================\n",
      "Epoch 73 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8801020408163265 Acurracy Control:  0.6284153005464481 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.7925770346326251\n",
      "Loss normal: 0.2969951967955852 Loss Control: 0.7030560774881331 Loss Patient: 0.17335270303061323 Loss balanced:  0.4382043902593732 Loss1+loss2: 0.4382043902593732\n",
      "Write summary at step 7260  Loss:  0.4325439929962158\n",
      "Write summary at step 7270  Loss:  0.44131457805633545\n",
      "Write summary at step 7280  Loss:  0.47675278782844543\n",
      "Write summary at step 7290  Loss:  0.15988057851791382\n",
      "Write summary at step 7300  Loss:  0.47443345189094543\n",
      "Write summary at step 7310  Loss:  0.5950206518173218\n",
      "Write summary at step 7320  Loss:  0.4951741695404053\n",
      "Write summary at step 7330  Loss:  0.5380281209945679\n",
      "Write summary at step 7340  Loss:  0.3399295210838318\n",
      "Write summary at step 7350  Loss:  0.3183591067790985\n",
      "=================================================\n",
      "Epoch 74 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8877551020408163 Acurracy Control:  0.8579234972677595 Acurracy Patient:  0.8968386023294509 Acurracy Balanced 0.8773810497986052\n",
      "Loss normal: 0.3092966310071702 Loss Control: 0.3556377327507311 Loss Patient: 0.2951861110681702 Loss balanced:  0.3254119219094507 Loss1+loss2: 0.3254119219094507\n",
      "Write summary at step 7360  Loss:  0.5177067518234253\n",
      "Write summary at step 7370  Loss:  0.3544062077999115\n",
      "Write summary at step 7380  Loss:  0.2640876770019531\n",
      "Write summary at step 7390  Loss:  0.25640931725502014\n",
      "Write summary at step 7400  Loss:  0.3927382826805115\n",
      "Write summary at step 7410  Loss:  0.2058037519454956\n",
      "Write summary at step 7420  Loss:  0.48443254828453064\n",
      "Write summary at step 7430  Loss:  0.4800843596458435\n",
      "Write summary at step 7440  Loss:  0.4614378809928894\n",
      "=================================================\n",
      "Epoch 75 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8928571428571429 Acurracy Control:  0.8142076502732241 Acurracy Patient:  0.9168053244592346 Acurracy Balanced 0.8655064873662293\n",
      "Loss normal: 0.2869580039108286 Loss Control: 0.4138944096903983 Loss Patient: 0.24830681740146707 Loss balanced:  0.3311006135459327 Loss1+loss2: 0.3311006135459327\n",
      "Write summary at step 7450  Loss:  0.5860823392868042\n",
      "Write summary at step 7460  Loss:  0.5810818672180176\n",
      "Write summary at step 7470  Loss:  0.5757525563240051\n",
      "Write summary at step 7480  Loss:  0.41668617725372314\n",
      "Write summary at step 7490  Loss:  0.4507107436656952\n",
      "Write summary at step 7500  Loss:  0.3508639633655548\n",
      "Saved checkpoint to: result/42/panns/checkpoint_7500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8737244897959183 Acurracy Control:  0.6065573770491803 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.7808161261285835\n",
      "Loss normal: 0.29836710736307565 Loss Control: 0.7871203585400608 Loss Patient: 0.14954540046697448 Loss balanced:  0.46833287950351765 Loss1+loss2: 0.46833287950351765\n",
      "Write summary at step 7510  Loss:  0.5901374816894531\n",
      "Write summary at step 7520  Loss:  0.2725318968296051\n",
      "Write summary at step 7530  Loss:  0.3125145435333252\n",
      "Write summary at step 7540  Loss:  0.28080958127975464\n",
      "=================================================\n",
      "Epoch 76 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8954081632653061 Acurracy Control:  0.819672131147541 Acurracy Patient:  0.9184692179700499 Acurracy Balanced 0.8690706745587955\n",
      "Loss normal: 0.2856894532332615 Loss Control: 0.4549386103947957 Loss Patient: 0.23415434650593311 Loss balanced:  0.3445464784503644 Loss1+loss2: 0.3445464784503644\n",
      "Write summary at step 7550  Loss:  0.3022075295448303\n",
      "Write summary at step 7560  Loss:  0.44954627752304077\n",
      "Write summary at step 7570  Loss:  0.3698332905769348\n",
      "Write summary at step 7580  Loss:  0.721717894077301\n",
      "Write summary at step 7590  Loss:  0.48683962225914\n",
      "Write summary at step 7600  Loss:  0.2764948010444641\n",
      "Write summary at step 7610  Loss:  0.5966081619262695\n",
      "Write summary at step 7620  Loss:  0.27589845657348633\n",
      "Write summary at step 7630  Loss:  0.40466299653053284\n",
      "Write summary at step 7640  Loss:  0.5913037061691284\n",
      "=================================================\n",
      "Epoch 77 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8813775510204082 Acurracy Control:  0.6338797814207651 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.7953092750697836\n",
      "Loss normal: 0.29600057028690163 Loss Control: 0.7057610105295651 Loss Patient: 0.1712315814219378 Loss balanced:  0.43849629597575146 Loss1+loss2: 0.43849629597575146\n",
      "Write summary at step 7650  Loss:  0.50547194480896\n",
      "Write summary at step 7660  Loss:  0.38601362705230713\n",
      "Write summary at step 7670  Loss:  0.46281200647354126\n",
      "Write summary at step 7680  Loss:  0.3792664408683777\n",
      "Write summary at step 7690  Loss:  0.4059886932373047\n",
      "Write summary at step 7700  Loss:  0.37821871042251587\n",
      "Write summary at step 7710  Loss:  0.33038949966430664\n",
      "Write summary at step 7720  Loss:  0.38431090116500854\n",
      "Write summary at step 7730  Loss:  0.35759735107421875\n",
      "Write summary at step 7740  Loss:  0.273487389087677\n",
      "=================================================\n",
      "Epoch 78 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8762755102040817 Acurracy Control:  0.907103825136612 Acurracy Patient:  0.8668885191347754 Acurracy Balanced 0.8869961721356937\n",
      "Loss normal: 0.33564471673904633 Loss Control: 0.29034863941656436 Loss Patient: 0.349437034963173 Loss balanced:  0.3198928371898687 Loss1+loss2: 0.3198928371898687\n",
      "Write summary at step 7750  Loss:  0.373409628868103\n",
      "Write summary at step 7760  Loss:  0.5496679544448853\n",
      "Write summary at step 7770  Loss:  0.34026288986206055\n",
      "Write summary at step 7780  Loss:  0.5381909012794495\n",
      "Write summary at step 7790  Loss:  0.419918030500412\n",
      "Write summary at step 7800  Loss:  0.45669373869895935\n",
      "Write summary at step 7810  Loss:  0.35822686553001404\n",
      "Write summary at step 7820  Loss:  0.43131452798843384\n",
      "Write summary at step 7830  Loss:  0.8657174110412598\n",
      "Write summary at step 7840  Loss:  0.2762998342514038\n",
      "=================================================\n",
      "Epoch 79 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8367346938775511 Acurracy Control:  0.3989071038251366 Acurracy Patient:  0.9700499168053245 Acurracy Balanced 0.6844785103152305\n",
      "Loss normal: 0.34535191573050555 Loss Control: 1.0788441147309182 Loss Patient: 0.12200902944148678 Loss balanced:  0.6004265720862025 Loss1+loss2: 0.6004265720862025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 7850  Loss:  0.5983586311340332\n",
      "Write summary at step 7860  Loss:  0.3913979232311249\n",
      "Write summary at step 7870  Loss:  0.480529248714447\n",
      "Write summary at step 7880  Loss:  0.47096994519233704\n",
      "Write summary at step 7890  Loss:  0.4901435971260071\n",
      "Write summary at step 7900  Loss:  0.3623330891132355\n",
      "Write summary at step 7910  Loss:  0.403878778219223\n",
      "Write summary at step 7920  Loss:  0.4778367877006531\n",
      "Write summary at step 7930  Loss:  0.5950177907943726\n",
      "=================================================\n",
      "Epoch 80 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8647959183673469 Acurracy Control:  0.5409836065573771 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.7521889746597201\n",
      "Loss normal: 0.2969521060205844 Loss Control: 0.8576672409401566 Loss Patient: 0.12621855174195945 Loss balanced:  0.49194289634105803 Loss1+loss2: 0.49194289634105803\n",
      "Write summary at step 7940  Loss:  0.4283124804496765\n",
      "Write summary at step 7950  Loss:  0.34335365891456604\n",
      "Write summary at step 7960  Loss:  0.4376283884048462\n",
      "Write summary at step 7970  Loss:  0.32286202907562256\n",
      "Write summary at step 7980  Loss:  0.4205949008464813\n",
      "Write summary at step 7990  Loss:  0.3792087435722351\n",
      "Write summary at step 8000  Loss:  0.54239422082901\n",
      "Saved checkpoint to: result/42/panns/checkpoint_8000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.7923497267759563 Acurracy Patient:  0.9384359400998337 Acurracy Balanced 0.865392833437895\n",
      "Loss normal: 0.28301007452667976 Loss Control: 0.4927240219272551 Loss Patient: 0.2191537488220932 Loss balanced:  0.35593888537467416 Loss1+loss2: 0.35593888537467416\n",
      "Write summary at step 8010  Loss:  0.47361254692077637\n",
      "Write summary at step 8020  Loss:  0.3393998146057129\n",
      "Write summary at step 8030  Loss:  0.7262872457504272\n",
      "=================================================\n",
      "Epoch 81 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8992346938775511 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.9550748752079867 Acurracy Balanced 0.835460934871753\n",
      "Loss normal: 0.27981261468055296 Loss Control: 0.6128494498508225 Loss Patient: 0.178405395165061 Loss balanced:  0.3956274225079417 Loss1+loss2: 0.3956274225079417\n",
      "Write summary at step 8040  Loss:  0.36229532957077026\n",
      "Write summary at step 8050  Loss:  0.41911375522613525\n",
      "Write summary at step 8060  Loss:  0.20198994874954224\n",
      "Write summary at step 8070  Loss:  0.23580288887023926\n",
      "Write summary at step 8080  Loss:  0.5429098010063171\n",
      "Write summary at step 8090  Loss:  0.27083930373191833\n",
      "Write summary at step 8100  Loss:  0.46318092942237854\n",
      "Write summary at step 8110  Loss:  0.4622786045074463\n",
      "Write summary at step 8120  Loss:  0.3561476767063141\n",
      "Write summary at step 8130  Loss:  0.305503785610199\n",
      "=================================================\n",
      "Epoch 82 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8775510204081632 Acurracy Control:  0.6174863387978142 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.7871125537583081\n",
      "Loss normal: 0.30555592005958365 Loss Control: 0.8093800336285367 Loss Patient: 0.15214525029286372 Loss balanced:  0.48076264196070023 Loss1+loss2: 0.48076264196070023\n",
      "Write summary at step 8140  Loss:  0.4852428436279297\n",
      "Write summary at step 8150  Loss:  0.54544597864151\n",
      "Write summary at step 8160  Loss:  0.4229156970977783\n",
      "Write summary at step 8170  Loss:  0.4114730954170227\n",
      "Write summary at step 8180  Loss:  0.42193594574928284\n",
      "Write summary at step 8190  Loss:  0.2524692416191101\n",
      "Write summary at step 8200  Loss:  0.4613816738128662\n",
      "Write summary at step 8210  Loss:  0.28634560108184814\n",
      "Write summary at step 8220  Loss:  0.5986639857292175\n",
      "Write summary at step 8230  Loss:  0.37227684259414673\n",
      "=================================================\n",
      "Epoch 83 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8737244897959183 Acurracy Control:  0.6010928961748634 Acurracy Patient:  0.956738768718802 Acurracy Balanced 0.7789158324468327\n",
      "Loss normal: 0.30872355405317276 Loss Control: 0.8480350801853535 Loss Patient: 0.14450723488819778 Loss balanced:  0.49627115753677564 Loss1+loss2: 0.49627115753677564\n",
      "Write summary at step 8240  Loss:  0.2875528931617737\n",
      "Write summary at step 8250  Loss:  0.31304067373275757\n",
      "Write summary at step 8260  Loss:  0.35218000411987305\n",
      "Write summary at step 8270  Loss:  0.12887337803840637\n",
      "Write summary at step 8280  Loss:  0.323137491941452\n",
      "Write summary at step 8290  Loss:  0.5606023073196411\n",
      "Write summary at step 8300  Loss:  0.25916948914527893\n",
      "Write summary at step 8310  Loss:  0.4063950777053833\n",
      "Write summary at step 8320  Loss:  0.4928562045097351\n",
      "Write summary at step 8330  Loss:  0.5179131627082825\n",
      "=================================================\n",
      "Epoch 84 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8698979591836735 Acurracy Control:  0.5628415300546448 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.763117936408354\n",
      "Loss normal: 0.3125332489761771 Loss Control: 0.8227993699370838 Loss Patient: 0.15716103381305288 Loss balanced:  0.48998020187506836 Loss1+loss2: 0.48998020187506836\n",
      "Write summary at step 8340  Loss:  0.5742309093475342\n",
      "Write summary at step 8350  Loss:  0.5613986253738403\n",
      "Write summary at step 8360  Loss:  0.21677689254283905\n",
      "Write summary at step 8370  Loss:  0.3705992102622986\n",
      "Write summary at step 8380  Loss:  0.40117767453193665\n",
      "Write summary at step 8390  Loss:  0.472064346075058\n",
      "Write summary at step 8400  Loss:  0.32171985507011414\n",
      "Write summary at step 8410  Loss:  0.4387422800064087\n",
      "Write summary at step 8420  Loss:  0.2618924081325531\n",
      "=================================================\n",
      "Epoch 85 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9005102040816326 Acurracy Control:  0.8032786885245902 Acurracy Patient:  0.930116472545757 Acurracy Balanced 0.8666975805351735\n",
      "Loss normal: 0.28504122428748074 Loss Control: 0.4223642933889816 Loss Patient: 0.24322738435224764 Loss balanced:  0.33279583887061465 Loss1+loss2: 0.33279583887061465\n",
      "Write summary at step 8430  Loss:  0.4548889100551605\n",
      "Write summary at step 8440  Loss:  0.37258464097976685\n",
      "Write summary at step 8450  Loss:  0.427074134349823\n",
      "Write summary at step 8460  Loss:  0.42400074005126953\n",
      "Write summary at step 8470  Loss:  0.5990991592407227\n",
      "Write summary at step 8480  Loss:  0.4144193232059479\n",
      "Write summary at step 8490  Loss:  0.3178785443305969\n",
      "Write summary at step 8500  Loss:  0.21307919919490814\n",
      "Saved checkpoint to: result/42/panns/checkpoint_8500.pt\n",
      "Validation:\n",
      "Acurracy:  0.8966836734693877 Acurracy Control:  0.7158469945355191 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8337970413609377\n",
      "Loss normal: 0.29633754362561265 Loss Control: 0.5284519860001861 Loss Patient: 0.22566043792568308 Loss balanced:  0.3770562119629346 Loss1+loss2: 0.3770562119629346\n",
      "Write summary at step 8510  Loss:  0.6307772397994995\n",
      "Write summary at step 8520  Loss:  0.21579644083976746\n",
      "=================================================\n",
      "Epoch 86 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8533163265306123 Acurracy Control:  0.4972677595628415 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.7294991044070447\n",
      "Loss normal: 0.3299618783045788 Loss Control: 0.9615318149816795 Loss Patient: 0.13765356544646962 Loss balanced:  0.5495926902140745 Loss1+loss2: 0.5495926902140745\n",
      "Write summary at step 8530  Loss:  0.5507364869117737\n",
      "Write summary at step 8540  Loss:  0.4896202087402344\n",
      "Write summary at step 8550  Loss:  0.256075382232666\n",
      "Write summary at step 8560  Loss:  0.31052517890930176\n",
      "Write summary at step 8570  Loss:  0.4428384304046631\n",
      "Write summary at step 8580  Loss:  0.5395625829696655\n",
      "Write summary at step 8590  Loss:  0.3993847966194153\n",
      "Write summary at step 8600  Loss:  0.6373040676116943\n",
      "Write summary at step 8610  Loss:  0.36607375741004944\n",
      "Write summary at step 8620  Loss:  0.4566628634929657\n",
      "=================================================\n",
      "Epoch 87 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8494897959183674 Acurracy Control:  0.45901639344262296 Acurracy Patient:  0.9683860232945092 Acurracy Balanced 0.7137012083685661\n",
      "Loss normal: 0.35637829589600467 Loss Control: 1.213179661276562 Loss Patient: 0.09548869818610181 Loss balanced:  0.6543341797313319 Loss1+loss2: 0.6543341797313319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write summary at step 8630  Loss:  0.37219732999801636\n",
      "Write summary at step 8640  Loss:  0.4697669446468353\n",
      "Write summary at step 8650  Loss:  0.2154027670621872\n",
      "Write summary at step 8660  Loss:  0.3005833029747009\n",
      "Write summary at step 8670  Loss:  0.3183627128601074\n",
      "Write summary at step 8680  Loss:  0.69375079870224\n",
      "Write summary at step 8690  Loss:  0.547927975654602\n",
      "Write summary at step 8700  Loss:  0.41575244069099426\n",
      "Write summary at step 8710  Loss:  0.39279869198799133\n",
      "Write summary at step 8720  Loss:  0.4916148781776428\n",
      "=================================================\n",
      "Epoch 88 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8775510204081632 Acurracy Control:  0.6284153005464481 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.7909131411218098\n",
      "Loss normal: 0.2992448608714099 Loss Control: 0.7985848429424515 Loss Patient: 0.14719957941383768 Loss balanced:  0.47289221117814456 Loss1+loss2: 0.47289221117814456\n",
      "Write summary at step 8730  Loss:  0.46368664503097534\n",
      "Write summary at step 8740  Loss:  0.3047294318675995\n",
      "Write summary at step 8750  Loss:  0.3953115940093994\n",
      "Write summary at step 8760  Loss:  0.6070859432220459\n",
      "Write summary at step 8770  Loss:  0.41440433263778687\n",
      "Write summary at step 8780  Loss:  0.4115595817565918\n",
      "Write summary at step 8790  Loss:  0.7267211675643921\n",
      "Write summary at step 8800  Loss:  0.5143105983734131\n",
      "Write summary at step 8810  Loss:  0.491243839263916\n",
      "Write summary at step 8820  Loss:  0.5064879059791565\n",
      "=================================================\n",
      "Epoch 89 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8864795918367347 Acurracy Control:  0.644808743169399 Acurracy Patient:  0.9600665557404326 Acurracy Balanced 0.8024376494549158\n",
      "Loss normal: 0.2813419004788204 Loss Control: 0.6975921086274861 Loss Patient: 0.15459682801103036 Loss balanced:  0.42609446831925823 Loss1+loss2: 0.42609446831925823\n",
      "Write summary at step 8830  Loss:  0.19694843888282776\n",
      "Write summary at step 8840  Loss:  0.2897297441959381\n",
      "Write summary at step 8850  Loss:  0.3176339268684387\n",
      "Write summary at step 8860  Loss:  0.5097957849502563\n",
      "Write summary at step 8870  Loss:  0.26175040006637573\n",
      "Write summary at step 8880  Loss:  0.4628295302391052\n",
      "Write summary at step 8890  Loss:  0.31632518768310547\n",
      "Write summary at step 8900  Loss:  0.32871338725090027\n",
      "Write summary at step 8910  Loss:  0.606024980545044\n",
      "=================================================\n",
      "Epoch 90 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8852040816326531 Acurracy Control:  0.6666666666666666 Acurracy Patient:  0.9517470881863561 Acurracy Balanced 0.8092068774265113\n",
      "Loss normal: 0.2957278078764069 Loss Control: 0.7334751724545422 Loss Patient: 0.16243700885187567 Loss balanced:  0.44795609065320896 Loss1+loss2: 0.44795609065320896\n",
      "Write summary at step 8920  Loss:  0.4426841735839844\n",
      "Write summary at step 8930  Loss:  0.43084320425987244\n",
      "Write summary at step 8940  Loss:  0.3320963382720947\n",
      "Write summary at step 8950  Loss:  0.7324632406234741\n",
      "Write summary at step 8960  Loss:  0.44753625988960266\n",
      "Write summary at step 8970  Loss:  0.2933102548122406\n",
      "Write summary at step 8980  Loss:  0.33918747305870056\n",
      "Write summary at step 8990  Loss:  0.6609888076782227\n",
      "Write summary at step 9000  Loss:  0.3917894959449768\n",
      "Saved checkpoint to: result/42/panns/checkpoint_9000.pt\n",
      "Validation:\n",
      "Acurracy:  0.9056122448979592 Acurracy Control:  0.7486338797814208 Acurracy Patient:  0.9534109816971714 Acurracy Balanced 0.8510224307392962\n",
      "Loss normal: 0.2589700883064343 Loss Control: 0.5791009664535522 Loss Patient: 0.16149263046743867 Loss balanced:  0.37029679846049546 Loss1+loss2: 0.37029679846049546\n",
      "Write summary at step 9010  Loss:  0.7306089401245117\n",
      "=================================================\n",
      "Epoch 91 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.7759562841530054 Acurracy Patient:  0.9434276206322796 Acurracy Balanced 0.8596919523926425\n",
      "Loss normal: 0.2667658545494992 Loss Control: 0.5642339297331096 Loss Patient: 0.17618905340078073 Loss balanced:  0.37021149156694516 Loss1+loss2: 0.37021149156694516\n",
      "Write summary at step 9020  Loss:  0.4810452461242676\n",
      "Write summary at step 9030  Loss:  0.37693142890930176\n",
      "Write summary at step 9040  Loss:  0.2824864983558655\n",
      "Write summary at step 9050  Loss:  0.362361878156662\n",
      "Write summary at step 9060  Loss:  0.3019503355026245\n",
      "Write summary at step 9070  Loss:  0.4786771833896637\n",
      "Write summary at step 9080  Loss:  0.3666081130504608\n",
      "Write summary at step 9090  Loss:  0.29120582342147827\n",
      "Write summary at step 9100  Loss:  0.3243620991706848\n",
      "Write summary at step 9110  Loss:  0.17579348385334015\n",
      "=================================================\n",
      "Epoch 92 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8686224489795918 Acurracy Control:  0.5737704918032787 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.766086577016448\n",
      "Loss normal: 0.32167540980997134 Loss Control: 0.9632417165516504 Loss Patient: 0.12632327466062618 Loss balanced:  0.5447824956061382 Loss1+loss2: 0.5447824956061382\n",
      "Write summary at step 9120  Loss:  0.35289064049720764\n",
      "Write summary at step 9130  Loss:  0.5435274243354797\n",
      "Write summary at step 9140  Loss:  0.6329930424690247\n",
      "Write summary at step 9150  Loss:  0.5443980693817139\n",
      "Write summary at step 9160  Loss:  0.6274548172950745\n",
      "Write summary at step 9170  Loss:  0.5285474061965942\n",
      "Write summary at step 9180  Loss:  0.539854109287262\n",
      "Write summary at step 9190  Loss:  0.6075855493545532\n",
      "Write summary at step 9200  Loss:  0.2853791415691376\n",
      "Write summary at step 9210  Loss:  0.4211631119251251\n",
      "=================================================\n",
      "Epoch 93 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8915816326530612 Acurracy Control:  0.8688524590163934 Acurracy Patient:  0.8985024958402662 Acurracy Balanced 0.8836774774283298\n",
      "Loss normal: 0.30378545121270784 Loss Control: 0.3269062126920523 Loss Patient: 0.2967453511701447 Loss balanced:  0.3118257819310985 Loss1+loss2: 0.3118257819310985\n",
      "Write summary at step 9220  Loss:  0.27816224098205566\n",
      "Write summary at step 9230  Loss:  0.5337005853652954\n",
      "Write summary at step 9240  Loss:  0.5602818727493286\n",
      "Write summary at step 9250  Loss:  0.24047201871871948\n",
      "Write summary at step 9260  Loss:  0.3044459819793701\n",
      "Write summary at step 9270  Loss:  0.43243134021759033\n",
      "Write summary at step 9280  Loss:  0.3334949016571045\n",
      "Write summary at step 9290  Loss:  0.420870304107666\n",
      "Write summary at step 9300  Loss:  0.25010180473327637\n",
      "Write summary at step 9310  Loss:  0.571057915687561\n",
      "=================================================\n",
      "Epoch 94 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8635204081632653 Acurracy Control:  0.5355191256830601 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.7494567342225618\n",
      "Loss normal: 0.3315927106887102 Loss Control: 0.9721613685941436 Loss Patient: 0.1365443493135757 Loss balanced:  0.5543528589538597 Loss1+loss2: 0.5543528589538597\n",
      "Write summary at step 9320  Loss:  0.5296614170074463\n",
      "Write summary at step 9330  Loss:  0.36789655685424805\n",
      "Write summary at step 9340  Loss:  0.5519264936447144\n",
      "Write summary at step 9350  Loss:  0.3944565951824188\n",
      "Write summary at step 9360  Loss:  0.42151105403900146\n",
      "Write summary at step 9370  Loss:  0.48879343271255493\n",
      "Write summary at step 9380  Loss:  0.5406470894813538\n",
      "Write summary at step 9390  Loss:  0.5698290467262268\n",
      "Write summary at step 9400  Loss:  0.2918916940689087\n",
      "=================================================\n",
      "Epoch 95 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8724489795918368 Acurracy Control:  0.5901639344262295 Acurracy Patient:  0.9584026622296173 Acurracy Balanced 0.7742832983279234\n",
      "Loss normal: 0.30504272133111954 Loss Control: 0.8233264378511189 Loss Patient: 0.1472292039884307 Loss balanced:  0.4852778209197748 Loss1+loss2: 0.4852778209197748\n",
      "Write summary at step 9410  Loss:  0.40416979789733887\n",
      "Write summary at step 9420  Loss:  0.49873635172843933\n",
      "Write summary at step 9430  Loss:  0.4094198942184448\n",
      "Write summary at step 9440  Loss:  0.23745466768741608\n",
      "Write summary at step 9450  Loss:  0.30039525032043457\n",
      "Write summary at step 9460  Loss:  0.4074011743068695\n",
      "Write summary at step 9470  Loss:  0.6511731743812561\n",
      "Write summary at step 9480  Loss:  0.44301143288612366\n",
      "Write summary at step 9490  Loss:  0.45892468094825745\n",
      "Write summary at step 9500  Loss:  0.26782849431037903\n",
      "Saved checkpoint to: result/42/panns/checkpoint_9500.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Acurracy:  0.8533163265306123 Acurracy Control:  0.4918032786885246 Acurracy Patient:  0.9633943427620633 Acurracy Balanced 0.727598810725294\n",
      "Loss normal: 0.35118849537506397 Loss Control: 1.0991261109628312 Loss Patient: 0.12344709838959024 Loss balanced:  0.6112866046762108 Loss1+loss2: 0.6112866046762108\n",
      "=================================================\n",
      "Epoch 96 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8584183673469388 Acurracy Control:  0.5191256830601093 Acurracy Patient:  0.961730449251248 Acurracy Balanced 0.7404280661556786\n",
      "Loss normal: 0.3425034925493659 Loss Control: 1.0342425010243401 Loss Patient: 0.13187413863503 Loss balanced:  0.583058319829685 Loss1+loss2: 0.583058319829685\n",
      "Write summary at step 9510  Loss:  0.506218671798706\n",
      "Write summary at step 9520  Loss:  0.4307716488838196\n",
      "Write summary at step 9530  Loss:  0.2698858678340912\n",
      "Write summary at step 9540  Loss:  0.4862688481807709\n",
      "Write summary at step 9550  Loss:  0.40269747376441956\n",
      "Write summary at step 9560  Loss:  0.3172602653503418\n",
      "Write summary at step 9570  Loss:  0.6056263446807861\n",
      "Write summary at step 9580  Loss:  0.3153522312641144\n",
      "Write summary at step 9590  Loss:  0.6769854426383972\n",
      "Write summary at step 9600  Loss:  0.43309563398361206\n",
      "=================================================\n",
      "Epoch 97 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.9043367346938775 Acurracy Control:  0.8087431693989071 Acurracy Patient:  0.9334442595673876 Acurracy Balanced 0.8710937144831474\n",
      "Loss normal: 0.2701191866428268 Loss Control: 0.4727046922907803 Loss Patient: 0.20843341463119933 Loss balanced:  0.3405690534609898 Loss1+loss2: 0.3405690534609898\n",
      "Write summary at step 9610  Loss:  0.7246288657188416\n",
      "Write summary at step 9620  Loss:  0.4541139304637909\n",
      "Write summary at step 9630  Loss:  0.42203742265701294\n",
      "Write summary at step 9640  Loss:  0.5304316878318787\n",
      "Write summary at step 9650  Loss:  0.33751553297042847\n",
      "Write summary at step 9660  Loss:  0.40348711609840393\n",
      "Write summary at step 9670  Loss:  0.4250093102455139\n",
      "Write summary at step 9680  Loss:  0.660590648651123\n",
      "Write summary at step 9690  Loss:  0.5312743186950684\n",
      "Write summary at step 9700  Loss:  0.23192526400089264\n",
      "=================================================\n",
      "Epoch 98 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8826530612244898 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.9351081530782029 Acurracy Balanced 0.8227453333697026\n",
      "Loss normal: 0.2896568080296322 Loss Control: 0.5667671115020585 Loss Patient: 0.20527879271451724 Loss balanced:  0.38602295210828785 Loss1+loss2: 0.38602295210828785\n",
      "Write summary at step 9710  Loss:  0.37244099378585815\n",
      "Write summary at step 9720  Loss:  0.5993486642837524\n",
      "Write summary at step 9730  Loss:  0.3166920840740204\n",
      "Write summary at step 9740  Loss:  0.5992891192436218\n",
      "Write summary at step 9750  Loss:  0.44076022505760193\n",
      "Write summary at step 9760  Loss:  0.39045536518096924\n",
      "Write summary at step 9770  Loss:  0.6226438283920288\n",
      "Write summary at step 9780  Loss:  0.4752250909805298\n",
      "Write summary at step 9790  Loss:  0.6456863880157471\n",
      "Write summary at step 9800  Loss:  0.5115989446640015\n",
      "=================================================\n",
      "Epoch 99 End !\n",
      "=================================================\n",
      "Validation:\n",
      "Acurracy:  0.8864795918367347 Acurracy Control:  0.7103825136612022 Acurracy Patient:  0.940099833610649 Acurracy Balanced 0.8252411736359255\n",
      "Loss normal: 0.29387155829035505 Loss Control: 0.6211331939436698 Loss Patient: 0.19422284006675747 Loss balanced:  0.40767801700521367 Loss1+loss2: 0.40767801700521367\n",
      "------------------------------\n",
      "SEED: 42 Best Loss: 0.2866105914986268\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "config = 'script/config.json'\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    command = f\"python script/train.py -c {config} -s {seed}\"\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08e513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
